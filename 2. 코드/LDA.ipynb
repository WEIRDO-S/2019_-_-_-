{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import glob\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer # 표제어\n",
    "from nltk.corpus import stopwords # 불용어\n",
    "from gensim.models import CoherenceModel # 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['energy', 'sugars', 'bars', 'grams', 'syrup',...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Are energy bars healthy?</td>\n",
       "      <td>https://www.cnn.com/2017/08/25/health/energy-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['facebook', 'whats', 'world', 'unfolds', 'tam...</td>\n",
       "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>Tamagotchi is back</td>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/10/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['jedi', 'shots', 'rey', 'force', 'wars', 'sta...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
       "      <td>http://money.cnn.com/2017/10/09/media/star-war...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           KEYWORDS  \\\n",
       "0           0  ['energy', 'sugars', 'bars', 'grams', 'syrup',...   \n",
       "1           1  ['facebook', 'whats', 'world', 'unfolds', 'tam...   \n",
       "2           2  ['jedi', 'shots', 'rey', 'force', 'wars', 'sta...   \n",
       "\n",
       "                                             SUMMARY  \\\n",
       "0  Story highlights Don't be fooled by the word \"...   \n",
       "1  Chat with us in Facebook Messenger.\\nFind out ...   \n",
       "2  ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "\n",
       "                                                TEXT  \\\n",
       "0  Story highlights Don't be fooled by the word \"...   \n",
       "1  Chat with us in Facebook Messenger. Find out w...   \n",
       "2  ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "\n",
       "                                               TITLE  \\\n",
       "0                           Are energy bars healthy?   \n",
       "1                                 Tamagotchi is back   \n",
       "2  'Star Wars: The Last Jedi' trailer debuts on '...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.cnn.com/2017/08/25/health/energy-b...  \n",
       "1  http://www.cnn.com/videos/cnnmoney/2017/10/10/...  \n",
       "2  http://money.cnn.com/2017/10/09/media/star-war...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/MyGithub/2019_Miraeassetdaewoo_Bigdata_Festival/CNN_20171006.csv\", encoding='utf-8')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 환경 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer() # 어근 추출\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "STOPWORDS = set(stopwords.words('english')) # 불용어 제거\n",
    "STOPWORDS.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>ALL_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['energy', 'sugars', 'bars', 'grams', 'syrup',...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Are energy bars healthy?</td>\n",
       "      <td>https://www.cnn.com/2017/08/25/health/energy-b...</td>\n",
       "      <td>Are energy bars healthy? Story highlights Don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['facebook', 'whats', 'world', 'unfolds', 'tam...</td>\n",
       "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>Tamagotchi is back</td>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/10/...</td>\n",
       "      <td>Tamagotchi is back Chat with us in Facebook Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['jedi', 'shots', 'rey', 'force', 'wars', 'sta...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
       "      <td>http://money.cnn.com/2017/10/09/media/star-war...</td>\n",
       "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['clients', 'art', 'science', 'scent', 'collid...</td>\n",
       "      <td>Lyn Harris' independent space, Perfumer H , in...</td>\n",
       "      <td>This feature is part of ' Details ,' a new ser...</td>\n",
       "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
       "      <td>https://www.cnn.com/style/article/details-perf...</td>\n",
       "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['akufoaddo', 'tanker', 'incidents', 'dozens',...</td>\n",
       "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
       "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
       "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
       "      <td>https://www.cnn.com/2017/10/08/africa/ghana-ta...</td>\n",
       "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['spanish', 'independence', 'regions', 'meets'...</td>\n",
       "      <td>Carles Puigdemont, the President of Catalonia,...</td>\n",
       "      <td>(CNN) Pro-independence Catalans gathered on th...</td>\n",
       "      <td>Catalans' future on line as parliament meets</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/europe/cataloni...</td>\n",
       "      <td>Catalans' future on line as parliament meets (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['press', 'excuse', 'secretary', 'trump', 'hou...</td>\n",
       "      <td>\"I think it's fake news, but if he did that, I...</td>\n",
       "      <td>(CNN) In a Forbes magazine interview published...</td>\n",
       "      <td>The Trump White House's 'joke' excuse</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/politics/trump-j...</td>\n",
       "      <td>The Trump White House's 'joke' excuse (CNN) In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['pollution', 'repeal', 'kellogg', 'asthma', '...</td>\n",
       "      <td>President Barak Obama shakes Camryn Kellogg's ...</td>\n",
       "      <td>(CNN) The days when all three of her children ...</td>\n",
       "      <td>Health impact of Trump environmental repeal</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/health/health-e...</td>\n",
       "      <td>Health impact of Trump environmental repeal (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['look', 'response', 'force', 'trump', 'tour',...</td>\n",
       "      <td>(CNN) Finally lumbering into a devastated Puer...</td>\n",
       "      <td>Michael D'Antonio is the author of the book \" ...</td>\n",
       "      <td>Trump in Puerto Rico: A narcissist's tour de f...</td>\n",
       "      <td>https://www.cnn.com/2017/10/03/opinions/trump-...</td>\n",
       "      <td>Trump in Puerto Rico: A narcissist's tour de f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['okunoin', 'tohoku', 'japan', 'risshakuji', '...</td>\n",
       "      <td>(CNN) — Upon hearing I would have to climb 1,0...</td>\n",
       "      <td>\\n\\n\\n\\nThis article was first published in Ju...</td>\n",
       "      <td>Yamadera Risshakuji in Tohoku: 1,015 steps to ...</td>\n",
       "      <td>https://www.cnn.com/travel/article/yamadera-te...</td>\n",
       "      <td>Yamadera Risshakuji in Tohoku: 1,015 steps to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>['land', 'life', 'purchased', 'doug', 'wonder'...</td>\n",
       "      <td>Doug Tompkins and Kristine McDivitt should hav...</td>\n",
       "      <td>Catch \"The Wonder List\" on CNN Saturdays at 9 ...</td>\n",
       "      <td>They purchased paradise ... then gave it all away</td>\n",
       "      <td>http://www.cnn.com/travel/article/wonder-list-...</td>\n",
       "      <td>They purchased paradise ... then gave it all a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>['kids', 'parental', 'really', 'husband', 'ste...</td>\n",
       "      <td>I'm not sure I needed a study to tell me paren...</td>\n",
       "      <td>Kelly Wallace is CNN's digital correspondent a...</td>\n",
       "      <td>Parental burnout: It's really a thing</td>\n",
       "      <td>https://www.cnn.com/2017/05/09/health/parentin...</td>\n",
       "      <td>Parental burnout: It's really a thing Kelly Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>['kids', 'television', 'impacts', 'drink', 'ad...</td>\n",
       "      <td>What they found is those underage drinkers who...</td>\n",
       "      <td>Kelly Wallace is CNN's digital correspondent a...</td>\n",
       "      <td>How alcohol advertising impacts underage drinking</td>\n",
       "      <td>https://www.cnn.com/2016/09/07/health/kids-alc...</td>\n",
       "      <td>How alcohol advertising impacts underage drink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>['kids', 'ferrara', 'way', 'thats', 'ah', 'say...</td>\n",
       "      <td>\"I always say to parents ... you've got to sto...</td>\n",
       "      <td>(CNN) Most parents have experienced it: that m...</td>\n",
       "      <td>Ah! My kid is having a tantrum, and I want to ...</td>\n",
       "      <td>https://www.cnn.com/2017/10/04/health/tantrums...</td>\n",
       "      <td>Ah! My kid is having a tantrum, and I want to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>['congress', 'issue', 'trump', 'women', 'calls...</td>\n",
       "      <td>Story highlights Ivanka Trump attends Fortune'...</td>\n",
       "      <td>Story highlights Ivanka Trump attends Fortune'...</td>\n",
       "      <td>Ivanka Trump calls on Congress to act on immig...</td>\n",
       "      <td>https://www.cnn.com/2017/10/09/politics/ivanka...</td>\n",
       "      <td>Ivanka Trump calls on Congress to act on immig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>['partner', 'men', 'low', 'interest', 'women',...</td>\n",
       "      <td>Story highlights Low desire in one partner is ...</td>\n",
       "      <td>Story highlights Low desire in one partner is ...</td>\n",
       "      <td>When you and your partner have mismatched libidos</td>\n",
       "      <td>https://www.cnn.com/2017/09/21/health/mismatch...</td>\n",
       "      <td>When you and your partner have mismatched libi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>['hes', 'music', 'seattle', 'working', 'world'...</td>\n",
       "      <td>(CNN) When Jay Park became one of the first an...</td>\n",
       "      <td>(CNN) When Jay Park became one of the first an...</td>\n",
       "      <td>Jay Park: from K-pop to Jay-Z</td>\n",
       "      <td>https://www.cnn.com/2017/10/08/asia/jay-park-j...</td>\n",
       "      <td>Jay Park: from K-pop to Jay-Z (CNN) When Jay P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>['plywoods', 'veneer', 'role', 'wood', 'shapin...</td>\n",
       "      <td>This exhibition, \"Plywood: Material of the Mod...</td>\n",
       "      <td>Written by Tom Morris, CNN London\\n\\nChristoph...</td>\n",
       "      <td>Plywood's surprising role in shaping our moder...</td>\n",
       "      <td>https://www.cnn.com/style/article/plywood-mate...</td>\n",
       "      <td>Plywood's surprising role in shaping our moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>['men', 'results', 'users', 'way', 'test', 'ki...</td>\n",
       "      <td>Story highlights The app Grindr is an effectiv...</td>\n",
       "      <td>Story highlights The app Grindr is an effectiv...</td>\n",
       "      <td>How Grindr got men to self-test for HIV</td>\n",
       "      <td>https://www.cnn.com/2016/07/25/health/grindr-h...</td>\n",
       "      <td>How Grindr got men to self-test for HIV Story ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>['according', 'boundaries', 'generations', 'ac...</td>\n",
       "      <td>\"The only generation we do define is Baby Boom...</td>\n",
       "      <td>We can all agree that Millennials are the wors...</td>\n",
       "      <td>Here Is When Each Generation Begins and Ends, ...</td>\n",
       "      <td>http://www.theatlantic.com/national/archive/20...</td>\n",
       "      <td>Here Is When Each Generation Begins and Ends, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>['hollywood', 'women', 'comments', 'player', '...</td>\n",
       "      <td>Designer Donna Karan has apologized for the re...</td>\n",
       "      <td>Designer Donna Karan has apologized for the re...</td>\n",
       "      <td>Donna Karan apologizes for Weinstein comments</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Donna Karan apologizes for Weinstein comments ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>['reckoned', 'history', 'past', 'nazi', 'confe...</td>\n",
       "      <td>(CNN) When it comes to Confederate monuments a...</td>\n",
       "      <td>(CNN) When it comes to Confederate monuments a...</td>\n",
       "      <td>Fareed Zakaria: US could learn from how German...</td>\n",
       "      <td>https://www.cnn.com/2017/08/20/us/fareed-zakar...</td>\n",
       "      <td>Fareed Zakaria: US could learn from how German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>['online', 'responsible', 'really', 'technolog...</td>\n",
       "      <td>James and Alexa Hirschfeld's successful online...</td>\n",
       "      <td>James and Alexa Hirschfeld's successful online...</td>\n",
       "      <td>Paperless Post founder's technology helps get ...</td>\n",
       "      <td>http://money.cnn.com/2017/10/04/technology/bus...</td>\n",
       "      <td>Paperless Post founder's technology helps get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>['important', 'cheeses', 'healthy', 'nutrients...</td>\n",
       "      <td>Story highlights Cheese contains important nut...</td>\n",
       "      <td>Story highlights Cheese contains important nut...</td>\n",
       "      <td>Is cheese healthy?</td>\n",
       "      <td>https://www.cnn.com/2017/09/25/health/cheese-h...</td>\n",
       "      <td>Is cheese healthy? Story highlights Cheese con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>['planet', 'book', 'degrees', 'science', 'must...</td>\n",
       "      <td>(CNN) \"Climate change is the canvas on which t...</td>\n",
       "      <td>CNN columnist John D. Sutter is spending the r...</td>\n",
       "      <td>Books: 12 must-reads on climate change (2 degr...</td>\n",
       "      <td>https://www.cnn.com/2015/05/19/opinions/sutter...</td>\n",
       "      <td>Books: 12 must-reads on climate change (2 degr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>['james', 'release', 'thought', 'think', 'w', ...</td>\n",
       "      <td>If you thought you were getting your hands on ...</td>\n",
       "      <td>If you thought you were getting your hands on ...</td>\n",
       "      <td>Whataburger sells out of James Avery charm hou...</td>\n",
       "      <td>http://cw33.com/2017/10/10/whataburger-and-jam...</td>\n",
       "      <td>Whataburger sells out of James Avery charm hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>['planned', 'fetus', 'videos', 'center', 'abor...</td>\n",
       "      <td>Abortion photo actually stillborn childThe pho...</td>\n",
       "      <td>Costa Mesa, California (CNN) David Daleiden wa...</td>\n",
       "      <td>The real story behind those Planned Parenthood...</td>\n",
       "      <td>https://www.cnn.com/2015/10/19/politics/planne...</td>\n",
       "      <td>The real story behind those Planned Parenthood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>['rovers', 'hide', 'image', 'opinion', 'camera...</td>\n",
       "      <td>Photos: Mars rover Curiosity Five years ago an...</td>\n",
       "      <td>Photos: Mars rover Curiosity Five years ago an...</td>\n",
       "      <td>Is it ethical to colonize Mars? (Opinion)</td>\n",
       "      <td>https://www.cnn.com/2015/10/15/opinions/green-...</td>\n",
       "      <td>Is it ethical to colonize Mars? (Opinion) Phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>['house', 'mary', 'danish', 'prince', 'giant',...</td>\n",
       "      <td>(CNN) — Get ready to embrace your inner child ...</td>\n",
       "      <td>(CNN) — Get ready to embrace your inner child ...</td>\n",
       "      <td>Inside Denmark's giant LEGO house</td>\n",
       "      <td>https://www.cnn.com/travel/article/lego-house-...</td>\n",
       "      <td>Inside Denmark's giant LEGO house (CNN) — Get ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>['im', 'stinks', 'economic', 'whites', 'white'...</td>\n",
       "      <td>Those are some of the reasons why working clas...</td>\n",
       "      <td>Social Security is running out of money. Ameri...</td>\n",
       "      <td>The economy stinks, but I'm doing OK, say work...</td>\n",
       "      <td>http://money.cnn.com/2016/09/23/news/economy/w...</td>\n",
       "      <td>The economy stinks, but I'm doing OK, say work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>['queen', 'wrong', 'denchs', 'motives', 'goes'...</td>\n",
       "      <td>(CNN) Even taking acknowledged liberties with ...</td>\n",
       "      <td>(CNN) Even taking acknowledged liberties with ...</td>\n",
       "      <td>'Victoria &amp; Abdul' goes skin-deep on great story</td>\n",
       "      <td>https://www.cnn.com/2017/09/22/entertainment/v...</td>\n",
       "      <td>'Victoria &amp; Abdul' goes skin-deep on great sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>['page', 'updated', 'specific', 'transcripts',...</td>\n",
       "      <td>Return to Transcripts main pageCNN Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\nReturn to Transcripts main page\\n\\nCNN...</td>\n",
       "      <td>Transcripts</td>\n",
       "      <td>https://www.cnn.com/TRANSCRIPTS/2017.10.04.html</td>\n",
       "      <td>Transcripts \\n\\n\\n\\nReturn to Transcripts main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>['aunts', 'hefner', 'jennifer', 'men', 'role',...</td>\n",
       "      <td>Story highlights Rebecca Jackson-Artis: My aun...</td>\n",
       "      <td>Story highlights Rebecca Jackson-Artis: My aun...</td>\n",
       "      <td>Playboy's role in creating strong black women</td>\n",
       "      <td>https://www.cnn.com/2017/10/07/opinions/race-s...</td>\n",
       "      <td>Playboy's role in creating strong black women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>['online', 'farm', 'crowd', 'buying', 'investo...</td>\n",
       "      <td>(CNN) For $1,000 you can be the proud owner of...</td>\n",
       "      <td>Story highlights Livestock Wealth \"crowd farms...</td>\n",
       "      <td>Cash cows: Why investors are buying pregnant c...</td>\n",
       "      <td>https://www.cnn.com/2017/05/01/africa/livestoc...</td>\n",
       "      <td>Cash cows: Why investors are buying pregnant c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>['kids', 'crooks', 'steal', 'van', 'school', '...</td>\n",
       "      <td>Recently, crooks went after one the vans' tank...</td>\n",
       "      <td>Omaha,Neb(FOX42KPTM)-Kids Can Community Center...</td>\n",
       "      <td>Crooks steal something valuable from a daycare...</td>\n",
       "      <td>http://fox42kptm.com/news/local/crooks-steal-s...</td>\n",
       "      <td>Crooks steal something valuable from a daycare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>['island', 'past', 'residents', 'farming', 'sa...</td>\n",
       "      <td>When this opportunity came up, he joined Jerom...</td>\n",
       "      <td>(CNN) Off the coast of Georgia lies a quiet is...</td>\n",
       "      <td>An island's future tied to farming crops from ...</td>\n",
       "      <td>https://www.cnn.com/2016/09/14/health/sapelo-i...</td>\n",
       "      <td>An island's future tied to farming crops from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>919</td>\n",
       "      <td>['defects', 'cause', 'birth', 'fever', 'early'...</td>\n",
       "      <td>\"We need to increase public awareness regardin...</td>\n",
       "      <td>(CNN) Running a high fever during early pregna...</td>\n",
       "      <td>How fever in early pregnancy can cause birth d...</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/health/pregnancy...</td>\n",
       "      <td>How fever in early pregnancy can cause birth d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>['james', 'commission', 'cancer', 'charities',...</td>\n",
       "      <td>JUST WATCHED Federal Trade Commission: Four ca...</td>\n",
       "      <td>Story highlights Government says donors gave $...</td>\n",
       "      <td>Government says four cancer charities are shams</td>\n",
       "      <td>https://www.cnn.com/2015/05/19/us/scam-charity...</td>\n",
       "      <td>Government says four cancer charities are sham...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>['mr', 'harvey', 'told', 'accused', 'women', '...</td>\n",
       "      <td>Harvey Weinstein stands accused of rape by mul...</td>\n",
       "      <td>Harvey Weinstein stands accused of rape by mul...</td>\n",
       "      <td>Harvey Weinstein accused of rape in New Yorker...</td>\n",
       "      <td>http://money.cnn.com/2017/10/10/media/harvey-w...</td>\n",
       "      <td>Harvey Weinstein accused of rape in New Yorker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>922</td>\n",
       "      <td>['los', 'angeles', 'months', 'veterans', 'care...</td>\n",
       "      <td>Los Angeles (CNN) Thousands of veterans who ar...</td>\n",
       "      <td>Los Angeles (CNN) Thousands of veterans who ar...</td>\n",
       "      <td>It's not over: Veterans waiting months for app...</td>\n",
       "      <td>https://www.cnn.com/2015/03/13/us/va-investiga...</td>\n",
       "      <td>It's not over: Veterans waiting months for app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>['cookies', 'continuing', 'information', 'term...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>2017 world's best travel photos</td>\n",
       "      <td>https://www.cnn.com/travel/gallery/best-travel...</td>\n",
       "      <td>2017 world's best travel photos By continuing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>['asked', 'told', 'day', 'nursing', 'raped', '...</td>\n",
       "      <td>Bobbi Young holds a photo of her mother, Maril...</td>\n",
       "      <td>Bobbi Young holds a photo of her mother, Maril...</td>\n",
       "      <td>My mother was raped in a nursing home at 88</td>\n",
       "      <td>https://www.cnn.com/2017/02/22/opinions/nursin...</td>\n",
       "      <td>My mother was raped in a nursing home at 88 Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>['met', 'survivor', 'trafficking', 'end', 'vic...</td>\n",
       "      <td>Humboldt County, California (CNN) Elle Snow la...</td>\n",
       "      <td>Humboldt County, California (CNN) Elle Snow la...</td>\n",
       "      <td>Sex trafficking survivor who wants to end 'The...</td>\n",
       "      <td>https://www.cnn.com/2017/06/28/world/elle-snow...</td>\n",
       "      <td>Sex trafficking survivor who wants to end 'The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>['told', 'secretary', 'added', 'trump', 'iq', ...</td>\n",
       "      <td>Washington (CNN) President Donald Trump, scorn...</td>\n",
       "      <td>Washington (CNN) President Donald Trump, scorn...</td>\n",
       "      <td>Trump boasts of a higher IQ than Tillerson</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/politics/donald-...</td>\n",
       "      <td>Trump boasts of a higher IQ than Tillerson Was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>['spanish', 'independence', 'regions', 'meets'...</td>\n",
       "      <td>Carles Puigdemont, the President of Catalonia,...</td>\n",
       "      <td>(CNN) Pro-independence Catalans gathered on th...</td>\n",
       "      <td>Catalans' future on line as parliament meets</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/europe/catalonia...</td>\n",
       "      <td>Catalans' future on line as parliament meets (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>['wrote', 'tiffany', 'disneys', 'thought', 'li...</td>\n",
       "      <td>Tiffany Thornton, who starred on \"Sonny with a...</td>\n",
       "      <td>(CNN) A former Disney Channel star has struck ...</td>\n",
       "      <td>Disney's Tiffany Thornton defends remarrying t...</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/entertainment/t...</td>\n",
       "      <td>Disney's Tiffany Thornton defends remarrying t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>['seattle', 'arrested', 'suspicion', 'rapper',...</td>\n",
       "      <td>Rapper Nelly was arrested on suspicion of rape...</td>\n",
       "      <td>Rapper Nelly was arrested on suspicion of rape...</td>\n",
       "      <td>Nelly arrested on suspicion of rape</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Nelly arrested on suspicion of rape Rapper Nel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>['vallabh', 'know', 'months', 'curse', 'diseas...</td>\n",
       "      <td>The family, who prefer not to use their surnam...</td>\n",
       "      <td>(CNN) \"Look, I'm so sorry to do this to you on...</td>\n",
       "      <td>A 'family curse': First insomnia, then death</td>\n",
       "      <td>https://www.cnn.com/2017/09/19/health/fatal-in...</td>\n",
       "      <td>A 'family curse': First insomnia, then death (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>['fairs', 'appeal', 'geary', 'state', 'recipe'...</td>\n",
       "      <td>County fairs, state fairs, street fairs -- you...</td>\n",
       "      <td>(CNN) — If there's one culinary truism about A...</td>\n",
       "      <td>Behind the appeal of America's craziest fair f...</td>\n",
       "      <td>https://www.cnn.com/travel/article/fair-food-a...</td>\n",
       "      <td>Behind the appeal of America's craziest fair f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>['asking', 'youre', 'harvey', 'women', 'harass...</td>\n",
       "      <td>(CNN) Designer Donna Karan has apologized for ...</td>\n",
       "      <td>(CNN) Designer Donna Karan has apologized for ...</td>\n",
       "      <td>Donna Karan slammed for Harvey Weinstein comments</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/entertainment/do...</td>\n",
       "      <td>Donna Karan slammed for Harvey Weinstein comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>['20', 'takes', 'america', 'clinton', 'state',...</td>\n",
       "      <td>Of course, Republicans have known for a long t...</td>\n",
       "      <td>(CNN) Amid the twists and turns of a tumultuou...</td>\n",
       "      <td>20 top takes on 2016</td>\n",
       "      <td>https://www.cnn.com/2016/12/21/opinions/best-o...</td>\n",
       "      <td>20 top takes on 2016 (CNN) Amid the twists and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>['views', 'hotel', 'lodge', 'escapes', 'inn', ...</td>\n",
       "      <td>If you'd like to enjoy a luxurious vacation th...</td>\n",
       "      <td>(CNN) — Upon arrival at the Old Edwards Inn in...</td>\n",
       "      <td>9 luxurious fall escapes</td>\n",
       "      <td>https://www.cnn.com/travel/article/luxury-fall...</td>\n",
       "      <td>9 luxurious fall escapes (CNN) — Upon arrival ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>['schools', 'deaths', 'trouble', 'hazing', 'st...</td>\n",
       "      <td>The Burch, Hipps and Braham families share a c...</td>\n",
       "      <td>(CNN) Nolan Burch 's parents didn't know what ...</td>\n",
       "      <td>Schools knew of trouble before student deaths</td>\n",
       "      <td>https://www.cnn.com/2015/11/02/us/fraternity-h...</td>\n",
       "      <td>Schools knew of trouble before student deaths ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>['incendiary', 'recovered', 'sources', 'rounds...</td>\n",
       "      <td>Story highlights Investigators found \"survival...</td>\n",
       "      <td>Story highlights Investigators found \"survival...</td>\n",
       "      <td>Las Vegas shooter fired 'incendiary' rounds at...</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/us/las-vegas-sho...</td>\n",
       "      <td>Las Vegas shooter fired 'incendiary' rounds at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>937</td>\n",
       "      <td>['20', 'consumer', 'contemporary', 'designed',...</td>\n",
       "      <td>Indeed, Karl Marx knew that the epic activitie...</td>\n",
       "      <td>What influences the appearance and character o...</td>\n",
       "      <td>20 designs that defined the modern world</td>\n",
       "      <td>http://edition.cnn.com/interactive/style/20-de...</td>\n",
       "      <td>20 designs that defined the modern world What ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>['facebook', 'actor', 'whats', 'movie', 'world...</td>\n",
       "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>Police take shot at actor on movie set</td>\n",
       "      <td>https://www.cnn.com/videos/us/2017/10/04/polic...</td>\n",
       "      <td>Police take shot at actor on movie set Chat wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>['races', 'danelle', 'mph', 'blind', 'life', '...</td>\n",
       "      <td>Photos: Blind skier puts her life in her husba...</td>\n",
       "      <td>(CNN) Danelle Umstead can't see when she skis ...</td>\n",
       "      <td>Blind skier races up to 70 mph</td>\n",
       "      <td>https://www.cnn.com/2016/12/16/health/turning-...</td>\n",
       "      <td>Blind skier races up to 70 mph (CNN) Danelle U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>['knew', 'harvey', 'harassed', 'hollywood', 'a...</td>\n",
       "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
       "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
       "      <td>Reporter accuses Weinstein of sexual advances</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Reporter accuses Weinstein of sexual advances ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>['cookies', 'continuing', 'information', 'term...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>Photos of the Times Square even locals love</td>\n",
       "      <td>http://www.cnn.com/travel/gallery/photos-times...</td>\n",
       "      <td>Photos of the Times Square even locals love By...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>['merkel', 'cap', 'party', 'limit', 'parties',...</td>\n",
       "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
       "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
       "      <td>Merkel changes tune on German refugee cap</td>\n",
       "      <td>https://www.cnn.com/2017/10/09/europe/germany-...</td>\n",
       "      <td>Merkel changes tune on German refugee cap (CNN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           KEYWORDS  \\\n",
       "0             0  ['energy', 'sugars', 'bars', 'grams', 'syrup',...   \n",
       "1             1  ['facebook', 'whats', 'world', 'unfolds', 'tam...   \n",
       "2             2  ['jedi', 'shots', 'rey', 'force', 'wars', 'sta...   \n",
       "3             3  ['clients', 'art', 'science', 'scent', 'collid...   \n",
       "4             4  ['akufoaddo', 'tanker', 'incidents', 'dozens',...   \n",
       "5             5  ['spanish', 'independence', 'regions', 'meets'...   \n",
       "6             6  ['press', 'excuse', 'secretary', 'trump', 'hou...   \n",
       "7             7  ['pollution', 'repeal', 'kellogg', 'asthma', '...   \n",
       "8             8  ['look', 'response', 'force', 'trump', 'tour',...   \n",
       "9             9  ['okunoin', 'tohoku', 'japan', 'risshakuji', '...   \n",
       "10           10  ['land', 'life', 'purchased', 'doug', 'wonder'...   \n",
       "11           11  ['kids', 'parental', 'really', 'husband', 'ste...   \n",
       "12           12  ['kids', 'television', 'impacts', 'drink', 'ad...   \n",
       "13           13  ['kids', 'ferrara', 'way', 'thats', 'ah', 'say...   \n",
       "14           14  ['congress', 'issue', 'trump', 'women', 'calls...   \n",
       "15           15  ['partner', 'men', 'low', 'interest', 'women',...   \n",
       "16           16  ['hes', 'music', 'seattle', 'working', 'world'...   \n",
       "17           17  ['plywoods', 'veneer', 'role', 'wood', 'shapin...   \n",
       "18           18  ['men', 'results', 'users', 'way', 'test', 'ki...   \n",
       "19           19  ['according', 'boundaries', 'generations', 'ac...   \n",
       "20           20  ['hollywood', 'women', 'comments', 'player', '...   \n",
       "21           21  ['reckoned', 'history', 'past', 'nazi', 'confe...   \n",
       "22           22  ['online', 'responsible', 'really', 'technolog...   \n",
       "23           23  ['important', 'cheeses', 'healthy', 'nutrients...   \n",
       "24           24  ['planet', 'book', 'degrees', 'science', 'must...   \n",
       "25           25  ['james', 'release', 'thought', 'think', 'w', ...   \n",
       "26           26  ['planned', 'fetus', 'videos', 'center', 'abor...   \n",
       "27           27  ['rovers', 'hide', 'image', 'opinion', 'camera...   \n",
       "28           28  ['house', 'mary', 'danish', 'prince', 'giant',...   \n",
       "29           29  ['im', 'stinks', 'economic', 'whites', 'white'...   \n",
       "..          ...                                                ...   \n",
       "913         913  ['queen', 'wrong', 'denchs', 'motives', 'goes'...   \n",
       "914         914  ['page', 'updated', 'specific', 'transcripts',...   \n",
       "915         915  ['aunts', 'hefner', 'jennifer', 'men', 'role',...   \n",
       "916         916  ['online', 'farm', 'crowd', 'buying', 'investo...   \n",
       "917         917  ['kids', 'crooks', 'steal', 'van', 'school', '...   \n",
       "918         918  ['island', 'past', 'residents', 'farming', 'sa...   \n",
       "919         919  ['defects', 'cause', 'birth', 'fever', 'early'...   \n",
       "920         920  ['james', 'commission', 'cancer', 'charities',...   \n",
       "921         921  ['mr', 'harvey', 'told', 'accused', 'women', '...   \n",
       "922         922  ['los', 'angeles', 'months', 'veterans', 'care...   \n",
       "923         923  ['cookies', 'continuing', 'information', 'term...   \n",
       "924         924  ['asked', 'told', 'day', 'nursing', 'raped', '...   \n",
       "925         925  ['met', 'survivor', 'trafficking', 'end', 'vic...   \n",
       "926         926  ['told', 'secretary', 'added', 'trump', 'iq', ...   \n",
       "927         927  ['spanish', 'independence', 'regions', 'meets'...   \n",
       "928         928  ['wrote', 'tiffany', 'disneys', 'thought', 'li...   \n",
       "929         929  ['seattle', 'arrested', 'suspicion', 'rapper',...   \n",
       "930         930  ['vallabh', 'know', 'months', 'curse', 'diseas...   \n",
       "931         931  ['fairs', 'appeal', 'geary', 'state', 'recipe'...   \n",
       "932         932  ['asking', 'youre', 'harvey', 'women', 'harass...   \n",
       "933         933  ['20', 'takes', 'america', 'clinton', 'state',...   \n",
       "934         934  ['views', 'hotel', 'lodge', 'escapes', 'inn', ...   \n",
       "935         935  ['schools', 'deaths', 'trouble', 'hazing', 'st...   \n",
       "936         936  ['incendiary', 'recovered', 'sources', 'rounds...   \n",
       "937         937  ['20', 'consumer', 'contemporary', 'designed',...   \n",
       "938         938  ['facebook', 'actor', 'whats', 'movie', 'world...   \n",
       "939         939  ['races', 'danelle', 'mph', 'blind', 'life', '...   \n",
       "940         940  ['knew', 'harvey', 'harassed', 'hollywood', 'a...   \n",
       "941         941  ['cookies', 'continuing', 'information', 'term...   \n",
       "942         942  ['merkel', 'cap', 'party', 'limit', 'parties',...   \n",
       "\n",
       "                                               SUMMARY  \\\n",
       "0    Story highlights Don't be fooled by the word \"...   \n",
       "1    Chat with us in Facebook Messenger.\\nFind out ...   \n",
       "2    ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "3    Lyn Harris' independent space, Perfumer H , in...   \n",
       "4    (CNN) A tanker exploded near a gas station in ...   \n",
       "5    Carles Puigdemont, the President of Catalonia,...   \n",
       "6    \"I think it's fake news, but if he did that, I...   \n",
       "7    President Barak Obama shakes Camryn Kellogg's ...   \n",
       "8    (CNN) Finally lumbering into a devastated Puer...   \n",
       "9    (CNN) — Upon hearing I would have to climb 1,0...   \n",
       "10   Doug Tompkins and Kristine McDivitt should hav...   \n",
       "11   I'm not sure I needed a study to tell me paren...   \n",
       "12   What they found is those underage drinkers who...   \n",
       "13   \"I always say to parents ... you've got to sto...   \n",
       "14   Story highlights Ivanka Trump attends Fortune'...   \n",
       "15   Story highlights Low desire in one partner is ...   \n",
       "16   (CNN) When Jay Park became one of the first an...   \n",
       "17   This exhibition, \"Plywood: Material of the Mod...   \n",
       "18   Story highlights The app Grindr is an effectiv...   \n",
       "19   \"The only generation we do define is Baby Boom...   \n",
       "20   Designer Donna Karan has apologized for the re...   \n",
       "21   (CNN) When it comes to Confederate monuments a...   \n",
       "22   James and Alexa Hirschfeld's successful online...   \n",
       "23   Story highlights Cheese contains important nut...   \n",
       "24   (CNN) \"Climate change is the canvas on which t...   \n",
       "25   If you thought you were getting your hands on ...   \n",
       "26   Abortion photo actually stillborn childThe pho...   \n",
       "27   Photos: Mars rover Curiosity Five years ago an...   \n",
       "28   (CNN) — Get ready to embrace your inner child ...   \n",
       "29   Those are some of the reasons why working clas...   \n",
       "..                                                 ...   \n",
       "913  (CNN) Even taking acknowledged liberties with ...   \n",
       "914  Return to Transcripts main pageCNN Transcripts...   \n",
       "915  Story highlights Rebecca Jackson-Artis: My aun...   \n",
       "916  (CNN) For $1,000 you can be the proud owner of...   \n",
       "917  Recently, crooks went after one the vans' tank...   \n",
       "918  When this opportunity came up, he joined Jerom...   \n",
       "919  \"We need to increase public awareness regardin...   \n",
       "920  JUST WATCHED Federal Trade Commission: Four ca...   \n",
       "921  Harvey Weinstein stands accused of rape by mul...   \n",
       "922  Los Angeles (CNN) Thousands of veterans who ar...   \n",
       "923  By continuing to browse our site you agree to ...   \n",
       "924  Bobbi Young holds a photo of her mother, Maril...   \n",
       "925  Humboldt County, California (CNN) Elle Snow la...   \n",
       "926  Washington (CNN) President Donald Trump, scorn...   \n",
       "927  Carles Puigdemont, the President of Catalonia,...   \n",
       "928  Tiffany Thornton, who starred on \"Sonny with a...   \n",
       "929  Rapper Nelly was arrested on suspicion of rape...   \n",
       "930  The family, who prefer not to use their surnam...   \n",
       "931  County fairs, state fairs, street fairs -- you...   \n",
       "932  (CNN) Designer Donna Karan has apologized for ...   \n",
       "933  Of course, Republicans have known for a long t...   \n",
       "934  If you'd like to enjoy a luxurious vacation th...   \n",
       "935  The Burch, Hipps and Braham families share a c...   \n",
       "936  Story highlights Investigators found \"survival...   \n",
       "937  Indeed, Karl Marx knew that the epic activitie...   \n",
       "938  Chat with us in Facebook Messenger.\\nFind out ...   \n",
       "939  Photos: Blind skier puts her life in her husba...   \n",
       "940  Journalist Lauren Sivan says Hollywood mogul H...   \n",
       "941  By continuing to browse our site you agree to ...   \n",
       "942  (CNN) German Chancellor Angela Merkel has agre...   \n",
       "\n",
       "                                                  TEXT  \\\n",
       "0    Story highlights Don't be fooled by the word \"...   \n",
       "1    Chat with us in Facebook Messenger. Find out w...   \n",
       "2    ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "3    This feature is part of ' Details ,' a new ser...   \n",
       "4    (CNN) A tanker exploded near a gas station in ...   \n",
       "5    (CNN) Pro-independence Catalans gathered on th...   \n",
       "6    (CNN) In a Forbes magazine interview published...   \n",
       "7    (CNN) The days when all three of her children ...   \n",
       "8    Michael D'Antonio is the author of the book \" ...   \n",
       "9    \\n\\n\\n\\nThis article was first published in Ju...   \n",
       "10   Catch \"The Wonder List\" on CNN Saturdays at 9 ...   \n",
       "11   Kelly Wallace is CNN's digital correspondent a...   \n",
       "12   Kelly Wallace is CNN's digital correspondent a...   \n",
       "13   (CNN) Most parents have experienced it: that m...   \n",
       "14   Story highlights Ivanka Trump attends Fortune'...   \n",
       "15   Story highlights Low desire in one partner is ...   \n",
       "16   (CNN) When Jay Park became one of the first an...   \n",
       "17   Written by Tom Morris, CNN London\\n\\nChristoph...   \n",
       "18   Story highlights The app Grindr is an effectiv...   \n",
       "19   We can all agree that Millennials are the wors...   \n",
       "20   Designer Donna Karan has apologized for the re...   \n",
       "21   (CNN) When it comes to Confederate monuments a...   \n",
       "22   James and Alexa Hirschfeld's successful online...   \n",
       "23   Story highlights Cheese contains important nut...   \n",
       "24   CNN columnist John D. Sutter is spending the r...   \n",
       "25   If you thought you were getting your hands on ...   \n",
       "26   Costa Mesa, California (CNN) David Daleiden wa...   \n",
       "27   Photos: Mars rover Curiosity Five years ago an...   \n",
       "28   (CNN) — Get ready to embrace your inner child ...   \n",
       "29   Social Security is running out of money. Ameri...   \n",
       "..                                                 ...   \n",
       "913  (CNN) Even taking acknowledged liberties with ...   \n",
       "914  \\n\\n\\n\\nReturn to Transcripts main page\\n\\nCNN...   \n",
       "915  Story highlights Rebecca Jackson-Artis: My aun...   \n",
       "916  Story highlights Livestock Wealth \"crowd farms...   \n",
       "917  Omaha,Neb(FOX42KPTM)-Kids Can Community Center...   \n",
       "918  (CNN) Off the coast of Georgia lies a quiet is...   \n",
       "919  (CNN) Running a high fever during early pregna...   \n",
       "920  Story highlights Government says donors gave $...   \n",
       "921  Harvey Weinstein stands accused of rape by mul...   \n",
       "922  Los Angeles (CNN) Thousands of veterans who ar...   \n",
       "923  By continuing to browse our site you agree to ...   \n",
       "924  Bobbi Young holds a photo of her mother, Maril...   \n",
       "925  Humboldt County, California (CNN) Elle Snow la...   \n",
       "926  Washington (CNN) President Donald Trump, scorn...   \n",
       "927  (CNN) Pro-independence Catalans gathered on th...   \n",
       "928  (CNN) A former Disney Channel star has struck ...   \n",
       "929  Rapper Nelly was arrested on suspicion of rape...   \n",
       "930  (CNN) \"Look, I'm so sorry to do this to you on...   \n",
       "931  (CNN) — If there's one culinary truism about A...   \n",
       "932  (CNN) Designer Donna Karan has apologized for ...   \n",
       "933  (CNN) Amid the twists and turns of a tumultuou...   \n",
       "934  (CNN) — Upon arrival at the Old Edwards Inn in...   \n",
       "935  (CNN) Nolan Burch 's parents didn't know what ...   \n",
       "936  Story highlights Investigators found \"survival...   \n",
       "937  What influences the appearance and character o...   \n",
       "938  Chat with us in Facebook Messenger. Find out w...   \n",
       "939  (CNN) Danelle Umstead can't see when she skis ...   \n",
       "940  Journalist Lauren Sivan says Hollywood mogul H...   \n",
       "941  By continuing to browse our site you agree to ...   \n",
       "942  (CNN) German Chancellor Angela Merkel has agre...   \n",
       "\n",
       "                                                 TITLE  \\\n",
       "0                             Are energy bars healthy?   \n",
       "1                                   Tamagotchi is back   \n",
       "2    'Star Wars: The Last Jedi' trailer debuts on '...   \n",
       "3    Art and science collide in this one-of-a-kind ...   \n",
       "4    Seven killed, dozens injured in Ghana tanker e...   \n",
       "5         Catalans' future on line as parliament meets   \n",
       "6                The Trump White House's 'joke' excuse   \n",
       "7          Health impact of Trump environmental repeal   \n",
       "8    Trump in Puerto Rico: A narcissist's tour de f...   \n",
       "9    Yamadera Risshakuji in Tohoku: 1,015 steps to ...   \n",
       "10   They purchased paradise ... then gave it all away   \n",
       "11               Parental burnout: It's really a thing   \n",
       "12   How alcohol advertising impacts underage drinking   \n",
       "13   Ah! My kid is having a tantrum, and I want to ...   \n",
       "14   Ivanka Trump calls on Congress to act on immig...   \n",
       "15   When you and your partner have mismatched libidos   \n",
       "16                       Jay Park: from K-pop to Jay-Z   \n",
       "17   Plywood's surprising role in shaping our moder...   \n",
       "18             How Grindr got men to self-test for HIV   \n",
       "19   Here Is When Each Generation Begins and Ends, ...   \n",
       "20       Donna Karan apologizes for Weinstein comments   \n",
       "21   Fareed Zakaria: US could learn from how German...   \n",
       "22   Paperless Post founder's technology helps get ...   \n",
       "23                                  Is cheese healthy?   \n",
       "24   Books: 12 must-reads on climate change (2 degr...   \n",
       "25   Whataburger sells out of James Avery charm hou...   \n",
       "26   The real story behind those Planned Parenthood...   \n",
       "27           Is it ethical to colonize Mars? (Opinion)   \n",
       "28                   Inside Denmark's giant LEGO house   \n",
       "29   The economy stinks, but I'm doing OK, say work...   \n",
       "..                                                 ...   \n",
       "913   'Victoria & Abdul' goes skin-deep on great story   \n",
       "914                                        Transcripts   \n",
       "915      Playboy's role in creating strong black women   \n",
       "916  Cash cows: Why investors are buying pregnant c...   \n",
       "917  Crooks steal something valuable from a daycare...   \n",
       "918  An island's future tied to farming crops from ...   \n",
       "919  How fever in early pregnancy can cause birth d...   \n",
       "920    Government says four cancer charities are shams   \n",
       "921  Harvey Weinstein accused of rape in New Yorker...   \n",
       "922  It's not over: Veterans waiting months for app...   \n",
       "923                    2017 world's best travel photos   \n",
       "924        My mother was raped in a nursing home at 88   \n",
       "925  Sex trafficking survivor who wants to end 'The...   \n",
       "926         Trump boasts of a higher IQ than Tillerson   \n",
       "927       Catalans' future on line as parliament meets   \n",
       "928  Disney's Tiffany Thornton defends remarrying t...   \n",
       "929                Nelly arrested on suspicion of rape   \n",
       "930       A 'family curse': First insomnia, then death   \n",
       "931  Behind the appeal of America's craziest fair f...   \n",
       "932  Donna Karan slammed for Harvey Weinstein comments   \n",
       "933                               20 top takes on 2016   \n",
       "934                           9 luxurious fall escapes   \n",
       "935      Schools knew of trouble before student deaths   \n",
       "936  Las Vegas shooter fired 'incendiary' rounds at...   \n",
       "937           20 designs that defined the modern world   \n",
       "938             Police take shot at actor on movie set   \n",
       "939                     Blind skier races up to 70 mph   \n",
       "940      Reporter accuses Weinstein of sexual advances   \n",
       "941        Photos of the Times Square even locals love   \n",
       "942          Merkel changes tune on German refugee cap   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://www.cnn.com/2017/08/25/health/energy-b...   \n",
       "1    http://www.cnn.com/videos/cnnmoney/2017/10/10/...   \n",
       "2    http://money.cnn.com/2017/10/09/media/star-war...   \n",
       "3    https://www.cnn.com/style/article/details-perf...   \n",
       "4    https://www.cnn.com/2017/10/08/africa/ghana-ta...   \n",
       "5    https://www.cnn.com/2017/10/10/europe/cataloni...   \n",
       "6    http://www.cnn.com/2017/10/10/politics/trump-j...   \n",
       "7    https://www.cnn.com/2017/10/10/health/health-e...   \n",
       "8    https://www.cnn.com/2017/10/03/opinions/trump-...   \n",
       "9    https://www.cnn.com/travel/article/yamadera-te...   \n",
       "10   http://www.cnn.com/travel/article/wonder-list-...   \n",
       "11   https://www.cnn.com/2017/05/09/health/parentin...   \n",
       "12   https://www.cnn.com/2016/09/07/health/kids-alc...   \n",
       "13   https://www.cnn.com/2017/10/04/health/tantrums...   \n",
       "14   https://www.cnn.com/2017/10/09/politics/ivanka...   \n",
       "15   https://www.cnn.com/2017/09/21/health/mismatch...   \n",
       "16   https://www.cnn.com/2017/10/08/asia/jay-park-j...   \n",
       "17   https://www.cnn.com/style/article/plywood-mate...   \n",
       "18   https://www.cnn.com/2016/07/25/health/grindr-h...   \n",
       "19   http://www.theatlantic.com/national/archive/20...   \n",
       "20   https://www.cnn.com/videos/entertainment/2017/...   \n",
       "21   https://www.cnn.com/2017/08/20/us/fareed-zakar...   \n",
       "22   http://money.cnn.com/2017/10/04/technology/bus...   \n",
       "23   https://www.cnn.com/2017/09/25/health/cheese-h...   \n",
       "24   https://www.cnn.com/2015/05/19/opinions/sutter...   \n",
       "25   http://cw33.com/2017/10/10/whataburger-and-jam...   \n",
       "26   https://www.cnn.com/2015/10/19/politics/planne...   \n",
       "27   https://www.cnn.com/2015/10/15/opinions/green-...   \n",
       "28   https://www.cnn.com/travel/article/lego-house-...   \n",
       "29   http://money.cnn.com/2016/09/23/news/economy/w...   \n",
       "..                                                 ...   \n",
       "913  https://www.cnn.com/2017/09/22/entertainment/v...   \n",
       "914    https://www.cnn.com/TRANSCRIPTS/2017.10.04.html   \n",
       "915  https://www.cnn.com/2017/10/07/opinions/race-s...   \n",
       "916  https://www.cnn.com/2017/05/01/africa/livestoc...   \n",
       "917  http://fox42kptm.com/news/local/crooks-steal-s...   \n",
       "918  https://www.cnn.com/2016/09/14/health/sapelo-i...   \n",
       "919  http://www.cnn.com/2017/10/10/health/pregnancy...   \n",
       "920  https://www.cnn.com/2015/05/19/us/scam-charity...   \n",
       "921  http://money.cnn.com/2017/10/10/media/harvey-w...   \n",
       "922  https://www.cnn.com/2015/03/13/us/va-investiga...   \n",
       "923  https://www.cnn.com/travel/gallery/best-travel...   \n",
       "924  https://www.cnn.com/2017/02/22/opinions/nursin...   \n",
       "925  https://www.cnn.com/2017/06/28/world/elle-snow...   \n",
       "926  http://www.cnn.com/2017/10/10/politics/donald-...   \n",
       "927  http://www.cnn.com/2017/10/10/europe/catalonia...   \n",
       "928  https://www.cnn.com/2017/10/10/entertainment/t...   \n",
       "929  https://www.cnn.com/videos/entertainment/2017/...   \n",
       "930  https://www.cnn.com/2017/09/19/health/fatal-in...   \n",
       "931  https://www.cnn.com/travel/article/fair-food-a...   \n",
       "932  http://www.cnn.com/2017/10/10/entertainment/do...   \n",
       "933  https://www.cnn.com/2016/12/21/opinions/best-o...   \n",
       "934  https://www.cnn.com/travel/article/luxury-fall...   \n",
       "935  https://www.cnn.com/2015/11/02/us/fraternity-h...   \n",
       "936  http://www.cnn.com/2017/10/10/us/las-vegas-sho...   \n",
       "937  http://edition.cnn.com/interactive/style/20-de...   \n",
       "938  https://www.cnn.com/videos/us/2017/10/04/polic...   \n",
       "939  https://www.cnn.com/2016/12/16/health/turning-...   \n",
       "940  https://www.cnn.com/videos/entertainment/2017/...   \n",
       "941  http://www.cnn.com/travel/gallery/photos-times...   \n",
       "942  https://www.cnn.com/2017/10/09/europe/germany-...   \n",
       "\n",
       "                                              ALL_TEXT  \n",
       "0    Are energy bars healthy? Story highlights Don'...  \n",
       "1    Tamagotchi is back Chat with us in Facebook Me...  \n",
       "2    'Star Wars: The Last Jedi' trailer debuts on '...  \n",
       "3    Art and science collide in this one-of-a-kind ...  \n",
       "4    Seven killed, dozens injured in Ghana tanker e...  \n",
       "5    Catalans' future on line as parliament meets (...  \n",
       "6    The Trump White House's 'joke' excuse (CNN) In...  \n",
       "7    Health impact of Trump environmental repeal (C...  \n",
       "8    Trump in Puerto Rico: A narcissist's tour de f...  \n",
       "9    Yamadera Risshakuji in Tohoku: 1,015 steps to ...  \n",
       "10   They purchased paradise ... then gave it all a...  \n",
       "11   Parental burnout: It's really a thing Kelly Wa...  \n",
       "12   How alcohol advertising impacts underage drink...  \n",
       "13   Ah! My kid is having a tantrum, and I want to ...  \n",
       "14   Ivanka Trump calls on Congress to act on immig...  \n",
       "15   When you and your partner have mismatched libi...  \n",
       "16   Jay Park: from K-pop to Jay-Z (CNN) When Jay P...  \n",
       "17   Plywood's surprising role in shaping our moder...  \n",
       "18   How Grindr got men to self-test for HIV Story ...  \n",
       "19   Here Is When Each Generation Begins and Ends, ...  \n",
       "20   Donna Karan apologizes for Weinstein comments ...  \n",
       "21   Fareed Zakaria: US could learn from how German...  \n",
       "22   Paperless Post founder's technology helps get ...  \n",
       "23   Is cheese healthy? Story highlights Cheese con...  \n",
       "24   Books: 12 must-reads on climate change (2 degr...  \n",
       "25   Whataburger sells out of James Avery charm hou...  \n",
       "26   The real story behind those Planned Parenthood...  \n",
       "27   Is it ethical to colonize Mars? (Opinion) Phot...  \n",
       "28   Inside Denmark's giant LEGO house (CNN) — Get ...  \n",
       "29   The economy stinks, but I'm doing OK, say work...  \n",
       "..                                                 ...  \n",
       "913  'Victoria & Abdul' goes skin-deep on great sto...  \n",
       "914  Transcripts \\n\\n\\n\\nReturn to Transcripts main...  \n",
       "915  Playboy's role in creating strong black women ...  \n",
       "916  Cash cows: Why investors are buying pregnant c...  \n",
       "917  Crooks steal something valuable from a daycare...  \n",
       "918  An island's future tied to farming crops from ...  \n",
       "919  How fever in early pregnancy can cause birth d...  \n",
       "920  Government says four cancer charities are sham...  \n",
       "921  Harvey Weinstein accused of rape in New Yorker...  \n",
       "922  It's not over: Veterans waiting months for app...  \n",
       "923  2017 world's best travel photos By continuing ...  \n",
       "924  My mother was raped in a nursing home at 88 Bo...  \n",
       "925  Sex trafficking survivor who wants to end 'The...  \n",
       "926  Trump boasts of a higher IQ than Tillerson Was...  \n",
       "927  Catalans' future on line as parliament meets (...  \n",
       "928  Disney's Tiffany Thornton defends remarrying t...  \n",
       "929  Nelly arrested on suspicion of rape Rapper Nel...  \n",
       "930  A 'family curse': First insomnia, then death (...  \n",
       "931  Behind the appeal of America's craziest fair f...  \n",
       "932  Donna Karan slammed for Harvey Weinstein comme...  \n",
       "933  20 top takes on 2016 (CNN) Amid the twists and...  \n",
       "934  9 luxurious fall escapes (CNN) — Upon arrival ...  \n",
       "935  Schools knew of trouble before student deaths ...  \n",
       "936  Las Vegas shooter fired 'incendiary' rounds at...  \n",
       "937  20 designs that defined the modern world What ...  \n",
       "938  Police take shot at actor on movie set Chat wi...  \n",
       "939  Blind skier races up to 70 mph (CNN) Danelle U...  \n",
       "940  Reporter accuses Weinstein of sexual advances ...  \n",
       "941  Photos of the Times Square even locals love By...  \n",
       "942  Merkel changes tune on German refugee cap (CNN...  \n",
       "\n",
       "[943 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ALL_TEXT'] = data['TITLE'] + ' ' + data['TEXT'] # 제목과 Text 모두 이용\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', '10', '20', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', '150', '200', 'calorie', 'general', 'try', 'aim', 'bar', 'le', '3', 'gram', 'saturated', 'fat', 'least', '4', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', '10', '20', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', '150', '200', 'calorie', 'general', 'try', 'aim', 'bar', 'le', '3', 'gram', 'saturated', 'fat', 'least', '4', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', '10', '20', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', '150', '200', 'calorie', 'general', 'try', 'aim', 'bar', 'le', '3', 'gram', 'saturated', 'fat', 'least', '4', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', '10', '20', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', '150', '200', 'calorie', 'general', 'try', 'aim', 'bar', 'le', '3', 'gram', 'saturated', 'fat', 'least', '4', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', '10', '20', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', '150', '200', 'calorie', 'general', 'try', 'aim', 'bar', 'le', '3', 'gram', 'saturated', 'fat', 'least', '4', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read']]\n"
     ]
    }
   ],
   "source": [
    "def data_token(x):\n",
    "    alltext = data.loc[x:x, 'ALL_TEXT'].tolist() * 5 # 리스트로 만들기\n",
    "    # alltext를 5배, 10배.. 변경시켜도 output에 변화가 있다.\n",
    "    # alltext가 키워드 추출하기에 너무 적은 단어 수로 구성되어 있을 경우, 5배를 해 주는게 효과적이다.\n",
    "    alltext = [[wordnet_lemmatizer.lemmatize(z) for z in tokenizer.tokenize(str(t).lower()) if z not in STOPWORDS] for t in alltext] # 불용어 제거\n",
    "    return alltext\n",
    "\n",
    "alltext = data_token(0)\n",
    "print(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', 'calorie', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', 'calorie', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', 'calorie', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', 'calorie', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read'], ['energy', 'bar', 'healthy', 'story', 'highlight', 'fooled', 'word', 'energy', 'energy', 'bar', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'cnn', 'energy', 'bar', 'convenient', 'source', 'nutrition', 'come', 'wide', 'variety', 'flavor', 'satisfy', 'different', 'palate', 'often', 'fortified', 'vitamin', 'mineral', 'help', 'fill', 'nutritional', 'gap', 'like', 'many', 'food', 'specific', 'category', 'energy', 'bar', 'created', 'equal', 'low', 'saturated', 'fat', 'sugar', 'decent', 'amount', 'protein', 'fiber', 'provide', 'nutritious', 'satisfying', 'pick', 'others', 'closely', 'mimic', 'candy', 'bar', 'example', 'bar', 'covered', 'chocolate', 'contain', 'much', 'saturated', 'fat', 'snicker', 'bar', 'others', 'contain', 'almost', 'much', 'sugar', 'granola', 'bar', 'convenient', 'source', 'nutrition', 'vary', 'significantly', 'term', 'nutrition', 'energy', 'bar', 'containing', 'mostly', 'fruit', 'nut', 'serve', 'satisfying', 'snack', 'looking', 'meal', 'replacement', 'aim', 'bar', 'higher', 'amount', 'protein', 'gram', 'athlete', 'also', 'benefit', 'choosing', 'bar', 'protein', 'carbohydrate', 'need', 'higher', 'afford', 'calorie', 'bar', 'consumed', 'place', 'meal', 'snack', 'bar', 'intended', 'tide', 'dinner', 'limit', 'calorie', 'general', 'try', 'aim', 'bar', 'le', 'gram', 'saturated', 'fat', 'least', 'gram', 'fiber', 'palm', 'kernel', 'oil', 'yogurt', 'chocolate', 'coating', 'boost', 'saturated', 'fat', 'also', 'watch', 'bar', 'ingredient', 'brown', 'rice', 'syrup', 'cane', 'invert', 'syrup', 'listed', 'first', 'generally', 'higher', 'sugar', 'others', 'better', 'suited', 'athlete', 'weight', 'watcher', 'read']]\n"
     ]
    }
   ],
   "source": [
    "# 한 번만 등장하는 단어 제거\n",
    "def remove_once(alltext) :\n",
    "    frequency = defaultdict(int)\n",
    "    for text in alltext:\n",
    "        for token in text:\n",
    "            if not token.isdigit():\n",
    "                frequency[token] += 1\n",
    "    alltext = [[token for token in text if frequency[token] > 1] for text in alltext]\n",
    "    return alltext\n",
    "\n",
    "alltext = remove_once(alltext)\n",
    "print(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:13,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:13,792 : INFO : built Dictionary(111 unique tokens: ['replacement', 'energy', 'watch', 'come', 'satisfying']...) from 5 documents (total 845 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(111 unique tokens: ['replacement', 'energy', 'watch', 'come', 'satisfying']...)\n"
     ]
    }
   ],
   "source": [
    "def gensim_dict(alltext):\n",
    "    dictionary = gensim.corpora.Dictionary(alltext)\n",
    "    return dictionary\n",
    "\n",
    "dictionary = gensim_dict(alltext)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_text(dictionary, alltext):\n",
    "    corpus = [dictionary.doc2bow(text) for text in alltext]\n",
    "    return corpus\n",
    "\n",
    "corpus = corpus_text(dictionary, alltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. LDA 최선의 하이퍼 파라미터 찾기 - Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:14,122 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:14,125 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:14,127 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:14,131 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:14,133 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:14,229 : INFO : -6.803 per-word bound, 111.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:14,232 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:14,299 : INFO : topic #5 (0.100): 0.012*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"much\" + 0.009*\"nutrition\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:14,301 : INFO : topic #3 (0.100): 0.101*\"bar\" + 0.031*\"energy\" + 0.030*\"saturated\" + 0.029*\"fat\" + 0.021*\"gram\" + 0.019*\"much\" + 0.018*\"others\" + 0.017*\"protein\" + 0.016*\"nutrition\" + 0.015*\"contain\"\n",
      "2019-10-29 00:37:14,302 : INFO : topic #8 (0.100): 0.012*\"bar\" + 0.010*\"fat\" + 0.010*\"higher\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:14,311 : INFO : topic #9 (0.100): 0.051*\"bar\" + 0.026*\"fat\" + 0.023*\"energy\" + 0.022*\"saturated\" + 0.017*\"protein\" + 0.014*\"sugar\" + 0.014*\"nutrition\" + 0.014*\"much\" + 0.013*\"others\" + 0.012*\"athlete\"\n",
      "2019-10-29 00:37:14,315 : INFO : topic #2 (0.100): 0.086*\"bar\" + 0.033*\"energy\" + 0.033*\"fat\" + 0.028*\"saturated\" + 0.021*\"higher\" + 0.020*\"contain\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.016*\"protein\" + 0.015*\"gram\"\n",
      "2019-10-29 00:37:14,321 : INFO : topic diff=2.416796, rho=1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Coherence 1.0000889005818406e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:14,624 : INFO : -5.678 per-word bound, 51.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity -5.67769354504241 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:14,841 : INFO : -5.676 per-word bound, 51.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:14,850 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:14,854 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:14,857 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:14,867 : INFO : running online (multi-pass) LDA training, 10 topics, 5 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:14,869 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:14,964 : INFO : -6.801 per-word bound, 111.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:14,966 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:14,999 : INFO : topic #9 (0.100): 0.077*\"bar\" + 0.026*\"fat\" + 0.021*\"energy\" + 0.021*\"higher\" + 0.020*\"saturated\" + 0.019*\"contain\" + 0.018*\"others\" + 0.016*\"nutrition\" + 0.016*\"protein\" + 0.016*\"sugar\"\n",
      "2019-10-29 00:37:15,001 : INFO : topic #8 (0.100): 0.057*\"bar\" + 0.037*\"energy\" + 0.029*\"saturated\" + 0.024*\"fat\" + 0.020*\"higher\" + 0.018*\"gram\" + 0.018*\"nutrition\" + 0.017*\"protein\" + 0.015*\"others\" + 0.014*\"sugar\"\n",
      "2019-10-29 00:37:15,003 : INFO : topic #6 (0.100): 0.046*\"bar\" + 0.026*\"energy\" + 0.025*\"saturated\" + 0.017*\"fat\" + 0.017*\"higher\" + 0.015*\"protein\" + 0.015*\"sugar\" + 0.015*\"contain\" + 0.014*\"others\" + 0.013*\"much\"\n",
      "2019-10-29 00:37:15,005 : INFO : topic #7 (0.100): 0.022*\"bar\" + 0.015*\"saturated\" + 0.014*\"energy\" + 0.014*\"fat\" + 0.012*\"nutrition\" + 0.011*\"higher\" + 0.011*\"sugar\" + 0.011*\"gram\" + 0.011*\"contain\" + 0.011*\"much\"\n",
      "2019-10-29 00:37:15,009 : INFO : topic #0 (0.100): 0.043*\"bar\" + 0.025*\"energy\" + 0.021*\"saturated\" + 0.019*\"fat\" + 0.017*\"sugar\" + 0.015*\"contain\" + 0.015*\"gram\" + 0.014*\"others\" + 0.014*\"higher\" + 0.013*\"snack\"\n",
      "2019-10-29 00:37:15,012 : INFO : topic diff=2.325080, rho=1.000000\n",
      "2019-10-29 00:37:15,069 : INFO : -5.416 per-word bound, 42.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,071 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:15,097 : INFO : topic #8 (0.100): 0.046*\"bar\" + 0.031*\"energy\" + 0.024*\"saturated\" + 0.020*\"fat\" + 0.017*\"higher\" + 0.016*\"gram\" + 0.016*\"nutrition\" + 0.015*\"protein\" + 0.014*\"others\" + 0.013*\"sugar\"\n",
      "2019-10-29 00:37:15,099 : INFO : topic #1 (0.100): 0.059*\"bar\" + 0.028*\"energy\" + 0.027*\"saturated\" + 0.026*\"fat\" + 0.018*\"higher\" + 0.016*\"nutrition\" + 0.016*\"sugar\" + 0.016*\"snack\" + 0.016*\"protein\" + 0.014*\"much\"\n",
      "2019-10-29 00:37:15,102 : INFO : topic #6 (0.100): 0.032*\"bar\" + 0.020*\"energy\" + 0.019*\"saturated\" + 0.014*\"fat\" + 0.014*\"higher\" + 0.013*\"protein\" + 0.013*\"sugar\" + 0.013*\"contain\" + 0.012*\"others\" + 0.012*\"much\"\n",
      "2019-10-29 00:37:15,105 : INFO : topic #7 (0.100): 0.015*\"bar\" + 0.012*\"saturated\" + 0.012*\"energy\" + 0.011*\"fat\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"sugar\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:15,108 : INFO : topic #3 (0.100): 0.021*\"bar\" + 0.013*\"saturated\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.011*\"others\" + 0.011*\"higher\" + 0.011*\"nutrition\" + 0.011*\"sugar\" + 0.010*\"protein\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:15,110 : INFO : topic diff=1.128217, rho=0.577350\n",
      "2019-10-29 00:37:15,149 : INFO : -5.121 per-word bound, 34.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,151 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:15,164 : INFO : topic #8 (0.100): 0.036*\"bar\" + 0.025*\"energy\" + 0.020*\"saturated\" + 0.017*\"fat\" + 0.015*\"higher\" + 0.014*\"gram\" + 0.014*\"nutrition\" + 0.014*\"protein\" + 0.012*\"others\" + 0.012*\"sugar\"\n",
      "2019-10-29 00:37:15,165 : INFO : topic #7 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"sugar\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:15,167 : INFO : topic #9 (0.100): 0.047*\"bar\" + 0.018*\"fat\" + 0.016*\"energy\" + 0.016*\"higher\" + 0.015*\"saturated\" + 0.014*\"contain\" + 0.014*\"others\" + 0.013*\"nutrition\" + 0.013*\"protein\" + 0.013*\"sugar\"\n",
      "2019-10-29 00:37:15,168 : INFO : topic #4 (0.100): 0.066*\"bar\" + 0.037*\"energy\" + 0.026*\"saturated\" + 0.025*\"fat\" + 0.020*\"higher\" + 0.019*\"gram\" + 0.017*\"contain\" + 0.016*\"sugar\" + 0.015*\"others\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:15,170 : INFO : topic #6 (0.100): 0.023*\"bar\" + 0.015*\"energy\" + 0.015*\"saturated\" + 0.012*\"fat\" + 0.012*\"higher\" + 0.011*\"protein\" + 0.011*\"sugar\" + 0.011*\"contain\" + 0.011*\"others\" + 0.011*\"much\"\n",
      "2019-10-29 00:37:15,173 : INFO : topic diff=0.917387, rho=0.500000\n",
      "2019-10-29 00:37:15,239 : INFO : -4.977 per-word bound, 31.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,241 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:15,258 : INFO : topic #8 (0.100): 0.027*\"bar\" + 0.020*\"energy\" + 0.017*\"saturated\" + 0.015*\"fat\" + 0.013*\"higher\" + 0.013*\"gram\" + 0.013*\"nutrition\" + 0.012*\"protein\" + 0.011*\"others\" + 0.011*\"sugar\"\n",
      "2019-10-29 00:37:15,262 : INFO : topic #5 (0.100): 0.033*\"bar\" + 0.019*\"energy\" + 0.018*\"saturated\" + 0.015*\"fat\" + 0.013*\"contain\" + 0.013*\"higher\" + 0.013*\"others\" + 0.012*\"nutrition\" + 0.012*\"sugar\" + 0.012*\"gram\"\n",
      "2019-10-29 00:37:15,265 : INFO : topic #1 (0.100): 0.038*\"bar\" + 0.020*\"energy\" + 0.019*\"saturated\" + 0.019*\"fat\" + 0.014*\"higher\" + 0.013*\"nutrition\" + 0.013*\"sugar\" + 0.013*\"snack\" + 0.013*\"protein\" + 0.012*\"much\"\n",
      "2019-10-29 00:37:15,267 : INFO : topic #9 (0.100): 0.035*\"bar\" + 0.016*\"fat\" + 0.014*\"energy\" + 0.014*\"higher\" + 0.013*\"saturated\" + 0.013*\"contain\" + 0.012*\"others\" + 0.012*\"nutrition\" + 0.012*\"protein\" + 0.012*\"sugar\"\n",
      "2019-10-29 00:37:15,269 : INFO : topic #2 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:15,270 : INFO : topic diff=0.708868, rho=0.447214\n",
      "2019-10-29 00:37:15,330 : INFO : -4.902 per-word bound, 29.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,332 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:15,346 : INFO : topic #3 (0.100): 0.011*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:15,348 : INFO : topic #9 (0.100): 0.026*\"bar\" + 0.013*\"fat\" + 0.012*\"energy\" + 0.012*\"higher\" + 0.012*\"saturated\" + 0.012*\"contain\" + 0.011*\"others\" + 0.011*\"nutrition\" + 0.011*\"protein\" + 0.011*\"sugar\"\n",
      "2019-10-29 00:37:15,350 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.010*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:15,355 : INFO : topic #0 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"gram\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"snack\"\n",
      "2019-10-29 00:37:15,360 : INFO : topic #6 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"higher\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"others\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:15,363 : INFO : topic diff=0.527736, rho=0.408248\n",
      "2019-10-29 00:37:15,454 : INFO : -4.863 per-word bound, 29.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,507 : INFO : -4.863 per-word bound, 29.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,509 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:15,512 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:15,513 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:15,516 : INFO : running online (multi-pass) LDA training, 10 topics, 10 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.862789062141667 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:15,617 : INFO : -6.790 per-word bound, 110.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,620 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:15,658 : INFO : topic #4 (0.100): 0.098*\"bar\" + 0.030*\"fat\" + 0.021*\"others\" + 0.020*\"nutrition\" + 0.020*\"saturated\" + 0.019*\"energy\" + 0.018*\"chocolate\" + 0.017*\"higher\" + 0.017*\"protein\" + 0.017*\"gram\"\n",
      "2019-10-29 00:37:15,660 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:15,662 : INFO : topic #7 (0.100): 0.044*\"bar\" + 0.025*\"energy\" + 0.025*\"fat\" + 0.021*\"saturated\" + 0.017*\"higher\" + 0.016*\"gram\" + 0.016*\"protein\" + 0.016*\"contain\" + 0.015*\"nutrition\" + 0.015*\"others\"\n",
      "2019-10-29 00:37:15,664 : INFO : topic #6 (0.100): 0.063*\"bar\" + 0.027*\"saturated\" + 0.023*\"fat\" + 0.022*\"energy\" + 0.022*\"contain\" + 0.017*\"protein\" + 0.017*\"higher\" + 0.015*\"gram\" + 0.015*\"chocolate\" + 0.014*\"sugar\"\n",
      "2019-10-29 00:37:15,665 : INFO : topic #9 (0.100): 0.093*\"bar\" + 0.040*\"energy\" + 0.028*\"saturated\" + 0.027*\"fat\" + 0.019*\"much\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.017*\"protein\"\n",
      "2019-10-29 00:37:15,667 : INFO : topic diff=2.871124, rho=1.000000\n",
      "2019-10-29 00:37:15,728 : INFO : -5.394 per-word bound, 42.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,729 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:15,745 : INFO : topic #7 (0.100): 0.032*\"bar\" + 0.020*\"energy\" + 0.019*\"fat\" + 0.017*\"saturated\" + 0.014*\"higher\" + 0.014*\"gram\" + 0.013*\"protein\" + 0.013*\"contain\" + 0.013*\"nutrition\" + 0.013*\"others\"\n",
      "2019-10-29 00:37:15,747 : INFO : topic #2 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"higher\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:15,749 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:15,751 : INFO : topic #9 (0.100): 0.093*\"bar\" + 0.036*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"much\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.018*\"protein\"\n",
      "2019-10-29 00:37:15,754 : INFO : topic #6 (0.100): 0.049*\"bar\" + 0.022*\"saturated\" + 0.020*\"fat\" + 0.019*\"energy\" + 0.019*\"contain\" + 0.015*\"protein\" + 0.015*\"higher\" + 0.014*\"gram\" + 0.014*\"chocolate\" + 0.013*\"sugar\"\n",
      "2019-10-29 00:37:15,756 : INFO : topic diff=0.913528, rho=0.577350\n",
      "2019-10-29 00:37:15,797 : INFO : -5.124 per-word bound, 34.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,799 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:15,813 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:15,815 : INFO : topic #8 (0.100): 0.020*\"bar\" + 0.013*\"fat\" + 0.012*\"saturated\" + 0.011*\"protein\" + 0.011*\"sugar\" + 0.011*\"energy\" + 0.011*\"others\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:15,817 : INFO : topic #4 (0.100): 0.075*\"bar\" + 0.025*\"fat\" + 0.018*\"others\" + 0.017*\"nutrition\" + 0.017*\"saturated\" + 0.017*\"energy\" + 0.016*\"chocolate\" + 0.015*\"higher\" + 0.015*\"protein\" + 0.015*\"gram\"\n",
      "2019-10-29 00:37:15,819 : INFO : topic #0 (0.100): 0.066*\"bar\" + 0.031*\"saturated\" + 0.030*\"fat\" + 0.028*\"energy\" + 0.020*\"higher\" + 0.017*\"much\" + 0.017*\"nutrition\" + 0.016*\"protein\" + 0.016*\"sugar\" + 0.014*\"contain\"\n",
      "2019-10-29 00:37:15,820 : INFO : topic #1 (0.100): 0.025*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.011*\"others\" + 0.011*\"higher\" + 0.011*\"much\" + 0.011*\"gram\" + 0.010*\"protein\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:15,822 : INFO : topic diff=0.760623, rho=0.500000\n",
      "2019-10-29 00:37:15,905 : INFO : -4.984 per-word bound, 31.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:15,908 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:15,923 : INFO : topic #3 (0.100): 0.056*\"bar\" + 0.023*\"energy\" + 0.019*\"saturated\" + 0.017*\"gram\" + 0.017*\"fat\" + 0.014*\"others\" + 0.014*\"sugar\" + 0.014*\"contain\" + 0.013*\"protein\" + 0.012*\"snack\"\n",
      "2019-10-29 00:37:15,933 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:15,937 : INFO : topic #4 (0.100): 0.061*\"bar\" + 0.022*\"fat\" + 0.016*\"others\" + 0.015*\"nutrition\" + 0.015*\"saturated\" + 0.015*\"energy\" + 0.014*\"chocolate\" + 0.014*\"higher\" + 0.014*\"protein\" + 0.014*\"gram\"\n",
      "2019-10-29 00:37:15,940 : INFO : topic #7 (0.100): 0.018*\"bar\" + 0.013*\"energy\" + 0.013*\"fat\" + 0.012*\"saturated\" + 0.011*\"higher\" + 0.011*\"gram\" + 0.011*\"protein\" + 0.011*\"contain\" + 0.011*\"nutrition\" + 0.011*\"others\"\n",
      "2019-10-29 00:37:15,944 : INFO : topic #6 (0.100): 0.027*\"bar\" + 0.015*\"saturated\" + 0.014*\"fat\" + 0.014*\"energy\" + 0.014*\"contain\" + 0.012*\"protein\" + 0.012*\"higher\" + 0.011*\"gram\" + 0.011*\"chocolate\" + 0.011*\"sugar\"\n",
      "2019-10-29 00:37:15,947 : INFO : topic diff=0.616287, rho=0.447214\n",
      "2019-10-29 00:37:16,035 : INFO : -4.907 per-word bound, 30.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,037 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:16,046 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:16,048 : INFO : topic #6 (0.100): 0.021*\"bar\" + 0.013*\"saturated\" + 0.012*\"fat\" + 0.012*\"energy\" + 0.012*\"contain\" + 0.011*\"protein\" + 0.011*\"higher\" + 0.010*\"gram\" + 0.010*\"chocolate\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:16,051 : INFO : topic #1 (0.100): 0.015*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"much\" + 0.010*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:16,053 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:16,055 : INFO : topic #0 (0.100): 0.046*\"bar\" + 0.023*\"saturated\" + 0.023*\"fat\" + 0.021*\"energy\" + 0.016*\"higher\" + 0.014*\"much\" + 0.014*\"nutrition\" + 0.014*\"protein\" + 0.014*\"sugar\" + 0.012*\"contain\"\n",
      "2019-10-29 00:37:16,057 : INFO : topic diff=0.480999, rho=0.408248\n",
      "2019-10-29 00:37:16,118 : INFO : -4.865 per-word bound, 29.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,121 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:16,131 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"much\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.018*\"protein\"\n",
      "2019-10-29 00:37:16,133 : INFO : topic #4 (0.100): 0.038*\"bar\" + 0.016*\"fat\" + 0.013*\"others\" + 0.012*\"nutrition\" + 0.012*\"saturated\" + 0.012*\"energy\" + 0.012*\"chocolate\" + 0.012*\"higher\" + 0.012*\"protein\" + 0.012*\"gram\"\n",
      "2019-10-29 00:37:16,137 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:16,140 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:16,143 : INFO : topic #7 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"saturated\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:16,146 : INFO : topic diff=0.362184, rho=0.377964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:16,324 : INFO : -4.843 per-word bound, 28.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,353 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:16,368 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"snack\"\n",
      "2019-10-29 00:37:16,380 : INFO : topic #3 (0.100): 0.027*\"bar\" + 0.014*\"energy\" + 0.013*\"saturated\" + 0.012*\"gram\" + 0.012*\"fat\" + 0.011*\"others\" + 0.011*\"sugar\" + 0.011*\"contain\" + 0.010*\"protein\" + 0.010*\"snack\"\n",
      "2019-10-29 00:37:16,383 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"much\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.018*\"protein\"\n",
      "2019-10-29 00:37:16,392 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:16,399 : INFO : topic #7 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:16,402 : INFO : topic diff=0.265579, rho=0.353553\n",
      "2019-10-29 00:37:16,468 : INFO : -4.831 per-word bound, 28.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,471 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:16,480 : INFO : topic #1 (0.100): 0.011*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:16,483 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"chocolate\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:16,486 : INFO : topic #3 (0.100): 0.022*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.011*\"gram\" + 0.011*\"fat\" + 0.010*\"others\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"snack\"\n",
      "2019-10-29 00:37:16,488 : INFO : topic #4 (0.100): 0.024*\"bar\" + 0.013*\"fat\" + 0.011*\"others\" + 0.011*\"nutrition\" + 0.011*\"saturated\" + 0.011*\"energy\" + 0.011*\"chocolate\" + 0.010*\"higher\" + 0.010*\"protein\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:16,491 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"much\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.018*\"protein\"\n",
      "2019-10-29 00:37:16,493 : INFO : topic diff=0.191664, rho=0.333333\n",
      "2019-10-29 00:37:16,567 : INFO : -4.825 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,569 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:16,581 : INFO : topic #3 (0.100): 0.018*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"gram\" + 0.011*\"fat\" + 0.010*\"others\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"snack\"\n",
      "2019-10-29 00:37:16,584 : INFO : topic #0 (0.100): 0.020*\"bar\" + 0.013*\"saturated\" + 0.013*\"fat\" + 0.013*\"energy\" + 0.011*\"higher\" + 0.011*\"much\" + 0.011*\"nutrition\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.010*\"contain\"\n",
      "2019-10-29 00:37:16,588 : INFO : topic #4 (0.100): 0.020*\"bar\" + 0.012*\"fat\" + 0.010*\"others\" + 0.010*\"nutrition\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"chocolate\" + 0.010*\"higher\" + 0.010*\"protein\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:16,591 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:16,595 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:16,598 : INFO : topic diff=0.137319, rho=0.316228\n",
      "2019-10-29 00:37:16,691 : INFO : -4.822 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,693 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:16,711 : INFO : topic #3 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"fat\" + 0.010*\"others\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"snack\"\n",
      "2019-10-29 00:37:16,716 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"significantly\" + 0.009*\"snack\" + 0.009*\"decent\"\n",
      "2019-10-29 00:37:16,719 : INFO : topic #0 (0.100): 0.017*\"bar\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.012*\"energy\" + 0.011*\"higher\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.010*\"contain\"\n",
      "2019-10-29 00:37:16,721 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:16,723 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:16,726 : INFO : topic diff=0.098269, rho=0.301511\n",
      "2019-10-29 00:37:16,869 : INFO : -4.820 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.819665212744087 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:16,947 : INFO : -4.820 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:16,950 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:16,954 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:16,958 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:16,962 : INFO : running online (multi-pass) LDA training, 10 topics, 15 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:17,054 : INFO : -6.796 per-word bound, 111.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,057 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:17,105 : INFO : topic #9 (0.100): 0.096*\"bar\" + 0.031*\"energy\" + 0.022*\"fat\" + 0.021*\"sugar\" + 0.021*\"saturated\" + 0.020*\"gram\" + 0.019*\"contain\" + 0.019*\"protein\" + 0.018*\"much\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:17,108 : INFO : topic #3 (0.100): 0.083*\"bar\" + 0.037*\"energy\" + 0.033*\"fat\" + 0.032*\"saturated\" + 0.020*\"higher\" + 0.020*\"protein\" + 0.020*\"others\" + 0.019*\"nutrition\" + 0.017*\"gram\" + 0.017*\"contain\"\n",
      "2019-10-29 00:37:17,110 : INFO : topic #8 (0.100): 0.093*\"bar\" + 0.036*\"energy\" + 0.030*\"saturated\" + 0.029*\"fat\" + 0.020*\"much\" + 0.018*\"nutrition\" + 0.018*\"sugar\" + 0.018*\"contain\" + 0.017*\"higher\" + 0.016*\"syrup\"\n",
      "2019-10-29 00:37:17,113 : INFO : topic #0 (0.100): 0.030*\"bar\" + 0.024*\"energy\" + 0.020*\"saturated\" + 0.015*\"protein\" + 0.015*\"fat\" + 0.015*\"contain\" + 0.014*\"gram\" + 0.013*\"higher\" + 0.012*\"much\" + 0.012*\"aim\"\n",
      "2019-10-29 00:37:17,117 : INFO : topic #4 (0.100): 0.104*\"bar\" + 0.029*\"saturated\" + 0.026*\"energy\" + 0.026*\"fat\" + 0.017*\"contain\" + 0.017*\"others\" + 0.017*\"much\" + 0.016*\"nutrition\" + 0.015*\"protein\" + 0.014*\"higher\"\n",
      "2019-10-29 00:37:17,120 : INFO : topic diff=2.656097, rho=1.000000\n",
      "2019-10-29 00:37:17,199 : INFO : -5.533 per-word bound, 46.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,201 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:17,232 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:17,237 : INFO : topic #9 (0.100): 0.088*\"bar\" + 0.029*\"energy\" + 0.021*\"fat\" + 0.020*\"sugar\" + 0.020*\"saturated\" + 0.019*\"gram\" + 0.018*\"contain\" + 0.018*\"protein\" + 0.017*\"much\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:17,240 : INFO : topic #8 (0.100): 0.087*\"bar\" + 0.034*\"energy\" + 0.028*\"saturated\" + 0.027*\"fat\" + 0.019*\"much\" + 0.018*\"nutrition\" + 0.018*\"sugar\" + 0.017*\"contain\" + 0.016*\"higher\" + 0.015*\"syrup\"\n",
      "2019-10-29 00:37:17,244 : INFO : topic #3 (0.100): 0.091*\"bar\" + 0.036*\"energy\" + 0.030*\"fat\" + 0.030*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:17,251 : INFO : topic #7 (0.100): 0.051*\"bar\" + 0.024*\"energy\" + 0.021*\"saturated\" + 0.019*\"much\" + 0.017*\"fat\" + 0.015*\"gram\" + 0.014*\"sugar\" + 0.013*\"protein\" + 0.013*\"others\" + 0.013*\"meal\"\n",
      "2019-10-29 00:37:17,253 : INFO : topic diff=0.821934, rho=0.577350\n",
      "2019-10-29 00:37:17,336 : INFO : -5.196 per-word bound, 36.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,338 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:17,354 : INFO : topic #4 (0.100): 0.079*\"bar\" + 0.024*\"saturated\" + 0.022*\"energy\" + 0.022*\"fat\" + 0.015*\"contain\" + 0.015*\"others\" + 0.015*\"much\" + 0.014*\"nutrition\" + 0.013*\"protein\" + 0.013*\"higher\"\n",
      "2019-10-29 00:37:17,357 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:17,360 : INFO : topic #2 (0.100): 0.051*\"bar\" + 0.022*\"energy\" + 0.020*\"fat\" + 0.017*\"saturated\" + 0.015*\"gram\" + 0.015*\"sugar\" + 0.015*\"much\" + 0.014*\"protein\" + 0.014*\"meal\" + 0.014*\"higher\"\n",
      "2019-10-29 00:37:17,363 : INFO : topic #7 (0.100): 0.037*\"bar\" + 0.019*\"energy\" + 0.017*\"saturated\" + 0.016*\"much\" + 0.015*\"fat\" + 0.013*\"gram\" + 0.012*\"sugar\" + 0.012*\"protein\" + 0.012*\"others\" + 0.012*\"meal\"\n",
      "2019-10-29 00:37:17,366 : INFO : topic #6 (0.100): 0.032*\"bar\" + 0.017*\"energy\" + 0.015*\"gram\" + 0.014*\"saturated\" + 0.013*\"others\" + 0.013*\"fat\" + 0.012*\"protein\" + 0.012*\"much\" + 0.011*\"contain\" + 0.011*\"higher\"\n",
      "2019-10-29 00:37:17,369 : INFO : topic diff=0.760735, rho=0.500000\n",
      "2019-10-29 00:37:17,434 : INFO : -5.028 per-word bound, 32.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,436 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:17,448 : INFO : topic #7 (0.100): 0.028*\"bar\" + 0.016*\"energy\" + 0.015*\"saturated\" + 0.014*\"much\" + 0.013*\"fat\" + 0.012*\"gram\" + 0.011*\"sugar\" + 0.011*\"protein\" + 0.011*\"others\" + 0.011*\"meal\"\n",
      "2019-10-29 00:37:17,451 : INFO : topic #6 (0.100): 0.024*\"bar\" + 0.014*\"energy\" + 0.013*\"gram\" + 0.012*\"saturated\" + 0.012*\"others\" + 0.012*\"fat\" + 0.011*\"protein\" + 0.011*\"much\" + 0.010*\"contain\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:17,453 : INFO : topic #8 (0.100): 0.067*\"bar\" + 0.028*\"energy\" + 0.023*\"saturated\" + 0.023*\"fat\" + 0.016*\"much\" + 0.015*\"nutrition\" + 0.015*\"sugar\" + 0.015*\"contain\" + 0.014*\"higher\" + 0.014*\"syrup\"\n",
      "2019-10-29 00:37:17,455 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:17,458 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:17,460 : INFO : topic diff=0.658711, rho=0.447214\n",
      "2019-10-29 00:37:17,526 : INFO : -4.933 per-word bound, 30.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,529 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:17,541 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:17,543 : INFO : topic #4 (0.100): 0.051*\"bar\" + 0.018*\"saturated\" + 0.017*\"energy\" + 0.017*\"fat\" + 0.013*\"contain\" + 0.012*\"others\" + 0.012*\"much\" + 0.012*\"nutrition\" + 0.012*\"protein\" + 0.011*\"higher\"\n",
      "2019-10-29 00:37:17,545 : INFO : topic #8 (0.100): 0.055*\"bar\" + 0.024*\"energy\" + 0.021*\"saturated\" + 0.020*\"fat\" + 0.015*\"much\" + 0.014*\"nutrition\" + 0.014*\"sugar\" + 0.014*\"contain\" + 0.013*\"higher\" + 0.013*\"syrup\"\n",
      "2019-10-29 00:37:17,549 : INFO : topic #6 (0.100): 0.019*\"bar\" + 0.012*\"energy\" + 0.011*\"gram\" + 0.011*\"saturated\" + 0.011*\"others\" + 0.011*\"fat\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:17,552 : INFO : topic #7 (0.100): 0.021*\"bar\" + 0.013*\"energy\" + 0.013*\"saturated\" + 0.012*\"much\" + 0.011*\"fat\" + 0.011*\"gram\" + 0.010*\"sugar\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"meal\"\n",
      "2019-10-29 00:37:17,554 : INFO : topic diff=0.536052, rho=0.408248\n",
      "2019-10-29 00:37:17,628 : INFO : -4.880 per-word bound, 29.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,632 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:17,652 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:17,667 : INFO : topic #9 (0.100): 0.042*\"bar\" + 0.017*\"energy\" + 0.014*\"fat\" + 0.014*\"sugar\" + 0.013*\"saturated\" + 0.013*\"gram\" + 0.013*\"contain\" + 0.013*\"protein\" + 0.012*\"much\" + 0.012*\"others\"\n",
      "2019-10-29 00:37:17,676 : INFO : topic #4 (0.100): 0.040*\"bar\" + 0.016*\"saturated\" + 0.015*\"energy\" + 0.015*\"fat\" + 0.012*\"contain\" + 0.012*\"others\" + 0.011*\"much\" + 0.011*\"nutrition\" + 0.011*\"protein\" + 0.011*\"higher\"\n",
      "2019-10-29 00:37:17,684 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:17,696 : INFO : topic #3 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:17,704 : INFO : topic diff=0.415558, rho=0.377964\n",
      "2019-10-29 00:37:17,773 : INFO : -4.852 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,777 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:17,786 : INFO : topic #8 (0.100): 0.036*\"bar\" + 0.018*\"energy\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.012*\"much\" + 0.012*\"nutrition\" + 0.012*\"sugar\" + 0.012*\"contain\" + 0.012*\"higher\" + 0.011*\"syrup\"\n",
      "2019-10-29 00:37:17,789 : INFO : topic #7 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"much\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"meal\"\n",
      "2019-10-29 00:37:17,792 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:17,795 : INFO : topic #6 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"gram\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"fat\" + 0.010*\"protein\" + 0.010*\"much\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:17,798 : INFO : topic #3 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:17,800 : INFO : topic diff=0.311318, rho=0.353553\n",
      "2019-10-29 00:37:17,863 : INFO : -4.836 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,864 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:17,873 : INFO : topic #9 (0.100): 0.027*\"bar\" + 0.013*\"energy\" + 0.012*\"fat\" + 0.011*\"sugar\" + 0.011*\"saturated\" + 0.011*\"gram\" + 0.011*\"contain\" + 0.011*\"protein\" + 0.011*\"much\" + 0.011*\"others\"\n",
      "2019-10-29 00:37:17,875 : INFO : topic #0 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:17,877 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:17,879 : INFO : topic #6 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"gram\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"fat\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:17,881 : INFO : topic #2 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"protein\" + 0.010*\"meal\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:17,882 : INFO : topic diff=0.228291, rho=0.333333\n",
      "2019-10-29 00:37:17,925 : INFO : -4.828 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:17,928 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:17,936 : INFO : topic #9 (0.100): 0.022*\"bar\" + 0.012*\"energy\" + 0.011*\"fat\" + 0.011*\"sugar\" + 0.011*\"saturated\" + 0.011*\"gram\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:17,938 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:17,940 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:17,943 : INFO : topic #4 (0.100): 0.020*\"bar\" + 0.011*\"saturated\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"contain\" + 0.010*\"others\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"protein\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:17,944 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:17,945 : INFO : topic diff=0.165512, rho=0.316228\n",
      "2019-10-29 00:37:18,002 : INFO : -4.823 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,005 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:18,010 : INFO : topic #8 (0.100): 0.020*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"higher\" + 0.010*\"syrup\"\n",
      "2019-10-29 00:37:18,012 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:18,013 : INFO : topic #2 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"meal\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,015 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,016 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,017 : INFO : topic diff=0.119489, rho=0.301511\n",
      "2019-10-29 00:37:18,057 : INFO : -4.821 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,059 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:18,066 : INFO : topic #9 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:18,068 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"energy\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,069 : INFO : topic #8 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"higher\" + 0.010*\"syrup\"\n",
      "2019-10-29 00:37:18,071 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:18,072 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,073 : INFO : topic diff=0.086310, rho=0.288675\n",
      "2019-10-29 00:37:18,125 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,127 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:18,136 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,140 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,144 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:18,149 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:18,151 : INFO : topic #9 (0.100): 0.014*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"much\" + 0.009*\"others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:18,153 : INFO : topic diff=0.062565, rho=0.277350\n",
      "2019-10-29 00:37:18,209 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,211 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:18,218 : INFO : topic #9 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:18,220 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:18,223 : INFO : topic #4 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,225 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:18,228 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:18,231 : INFO : topic diff=0.045593, rho=0.267261\n",
      "2019-10-29 00:37:18,290 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,293 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:18,300 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:18,302 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:18,303 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:18,305 : INFO : topic #8 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"syrup\"\n",
      "2019-10-29 00:37:18,307 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"meal\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,308 : INFO : topic diff=0.033431, rho=0.258199\n",
      "2019-10-29 00:37:18,362 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,364 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:18,371 : INFO : topic #9 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:18,374 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:18,379 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:18,388 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"meal\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,391 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:18,394 : INFO : topic diff=0.024678, rho=0.250000\n",
      "2019-10-29 00:37:18,477 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,542 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,544 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:18,546 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:18,550 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:18,553 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817499524037514 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:18,637 : INFO : -6.794 per-word bound, 111.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,638 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:18,679 : INFO : topic #8 (0.100): 0.055*\"bar\" + 0.028*\"energy\" + 0.022*\"saturated\" + 0.019*\"fat\" + 0.019*\"protein\" + 0.017*\"higher\" + 0.014*\"much\" + 0.014*\"others\" + 0.014*\"contain\" + 0.013*\"gram\"\n",
      "2019-10-29 00:37:18,681 : INFO : topic #1 (0.100): 0.062*\"bar\" + 0.024*\"energy\" + 0.021*\"saturated\" + 0.020*\"fat\" + 0.018*\"others\" + 0.018*\"much\" + 0.016*\"higher\" + 0.015*\"snicker\" + 0.014*\"contain\" + 0.014*\"sugar\"\n",
      "2019-10-29 00:37:18,683 : INFO : topic #4 (0.100): 0.031*\"bar\" + 0.019*\"energy\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.014*\"sugar\" + 0.012*\"contain\" + 0.012*\"others\" + 0.012*\"much\" + 0.012*\"protein\" + 0.011*\"calorie\"\n",
      "2019-10-29 00:37:18,685 : INFO : topic #2 (0.100): 0.088*\"bar\" + 0.037*\"energy\" + 0.035*\"saturated\" + 0.025*\"fat\" + 0.021*\"higher\" + 0.019*\"gram\" + 0.019*\"much\" + 0.019*\"nutrition\" + 0.018*\"others\" + 0.017*\"protein\"\n",
      "2019-10-29 00:37:18,693 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"convenient\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:18,696 : INFO : topic diff=2.296248, rho=1.000000\n",
      "2019-10-29 00:37:18,765 : INFO : -5.595 per-word bound, 48.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,767 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:18,796 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.038*\"energy\" + 0.030*\"fat\" + 0.027*\"saturated\" + 0.019*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.017*\"much\" + 0.017*\"contain\" + 0.017*\"nutrition\"\n",
      "2019-10-29 00:37:18,799 : INFO : topic #7 (0.100): 0.091*\"bar\" + 0.033*\"saturated\" + 0.031*\"fat\" + 0.022*\"energy\" + 0.021*\"sugar\" + 0.020*\"others\" + 0.019*\"contain\" + 0.018*\"nutrition\" + 0.018*\"snack\" + 0.017*\"protein\"\n",
      "2019-10-29 00:37:18,802 : INFO : topic #8 (0.100): 0.040*\"bar\" + 0.022*\"energy\" + 0.017*\"saturated\" + 0.016*\"fat\" + 0.016*\"protein\" + 0.014*\"higher\" + 0.012*\"much\" + 0.012*\"others\" + 0.012*\"contain\" + 0.012*\"gram\"\n",
      "2019-10-29 00:37:18,804 : INFO : topic #0 (0.100): 0.051*\"bar\" + 0.026*\"energy\" + 0.026*\"saturated\" + 0.020*\"fat\" + 0.015*\"contain\" + 0.015*\"protein\" + 0.014*\"others\" + 0.014*\"meal\" + 0.014*\"much\" + 0.013*\"also\"\n",
      "2019-10-29 00:37:18,807 : INFO : topic #4 (0.100): 0.021*\"bar\" + 0.014*\"energy\" + 0.013*\"saturated\" + 0.012*\"fat\" + 0.011*\"sugar\" + 0.011*\"contain\" + 0.011*\"others\" + 0.011*\"much\" + 0.010*\"protein\" + 0.010*\"calorie\"\n",
      "2019-10-29 00:37:18,810 : INFO : topic diff=0.951919, rho=0.577350\n",
      "2019-10-29 00:37:18,868 : INFO : -5.248 per-word bound, 38.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,870 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:18,895 : INFO : topic #4 (0.100): 0.015*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"others\" + 0.010*\"much\" + 0.010*\"protein\" + 0.010*\"calorie\"\n",
      "2019-10-29 00:37:18,897 : INFO : topic #2 (0.100): 0.074*\"bar\" + 0.032*\"energy\" + 0.031*\"saturated\" + 0.022*\"fat\" + 0.019*\"higher\" + 0.018*\"gram\" + 0.018*\"much\" + 0.017*\"nutrition\" + 0.016*\"others\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:18,900 : INFO : topic #3 (0.100): 0.054*\"bar\" + 0.025*\"energy\" + 0.017*\"saturated\" + 0.017*\"fat\" + 0.015*\"nutrition\" + 0.015*\"much\" + 0.015*\"contain\" + 0.015*\"syrup\" + 0.014*\"sugar\" + 0.014*\"meal\"\n",
      "2019-10-29 00:37:18,903 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.036*\"energy\" + 0.029*\"fat\" + 0.028*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.017*\"contain\" + 0.017*\"nutrition\"\n",
      "2019-10-29 00:37:18,907 : INFO : topic #0 (0.100): 0.040*\"bar\" + 0.022*\"energy\" + 0.021*\"saturated\" + 0.017*\"fat\" + 0.014*\"contain\" + 0.013*\"protein\" + 0.013*\"others\" + 0.013*\"meal\" + 0.012*\"much\" + 0.012*\"also\"\n",
      "2019-10-29 00:37:18,910 : INFO : topic diff=0.829108, rho=0.500000\n",
      "2019-10-29 00:37:18,992 : INFO : -5.071 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:18,995 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:19,013 : INFO : topic #4 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,016 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.036*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,019 : INFO : topic #2 (0.100): 0.064*\"bar\" + 0.029*\"energy\" + 0.027*\"saturated\" + 0.020*\"fat\" + 0.018*\"higher\" + 0.016*\"gram\" + 0.016*\"much\" + 0.016*\"nutrition\" + 0.015*\"others\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:19,021 : INFO : topic #7 (0.100): 0.079*\"bar\" + 0.029*\"saturated\" + 0.028*\"fat\" + 0.020*\"energy\" + 0.019*\"sugar\" + 0.018*\"others\" + 0.017*\"contain\" + 0.017*\"nutrition\" + 0.017*\"snack\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:19,024 : INFO : topic #1 (0.100): 0.024*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.012*\"others\" + 0.011*\"much\" + 0.011*\"higher\" + 0.011*\"snicker\" + 0.010*\"contain\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:19,027 : INFO : topic diff=0.674221, rho=0.447214\n",
      "2019-10-29 00:37:19,076 : INFO : -4.968 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,078 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:19,099 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"snack\"\n",
      "2019-10-29 00:37:19,106 : INFO : topic #2 (0.100): 0.054*\"bar\" + 0.025*\"energy\" + 0.024*\"saturated\" + 0.018*\"fat\" + 0.016*\"higher\" + 0.015*\"gram\" + 0.015*\"much\" + 0.015*\"nutrition\" + 0.014*\"others\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:19,109 : INFO : topic #8 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.011*\"protein\" + 0.010*\"higher\" + 0.010*\"much\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:19,112 : INFO : topic #7 (0.100): 0.070*\"bar\" + 0.027*\"saturated\" + 0.025*\"fat\" + 0.018*\"energy\" + 0.018*\"sugar\" + 0.017*\"others\" + 0.016*\"contain\" + 0.016*\"nutrition\" + 0.016*\"snack\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:19,116 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,119 : INFO : topic diff=0.534535, rho=0.408248\n",
      "2019-10-29 00:37:19,180 : INFO : -4.907 per-word bound, 30.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,182 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:19,192 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"convenient\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:19,194 : INFO : topic #8 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"protein\" + 0.010*\"higher\" + 0.010*\"much\" + 0.010*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,196 : INFO : topic #1 (0.100): 0.015*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"others\" + 0.010*\"much\" + 0.010*\"higher\" + 0.010*\"snicker\" + 0.010*\"contain\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:19,199 : INFO : topic #2 (0.100): 0.044*\"bar\" + 0.021*\"energy\" + 0.021*\"saturated\" + 0.016*\"fat\" + 0.015*\"higher\" + 0.014*\"gram\" + 0.014*\"much\" + 0.013*\"nutrition\" + 0.013*\"others\" + 0.012*\"protein\"\n",
      "2019-10-29 00:37:19,201 : INFO : topic #7 (0.100): 0.061*\"bar\" + 0.024*\"saturated\" + 0.023*\"fat\" + 0.017*\"energy\" + 0.017*\"sugar\" + 0.016*\"others\" + 0.015*\"contain\" + 0.015*\"nutrition\" + 0.015*\"snack\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:19,202 : INFO : topic diff=0.417526, rho=0.377964\n",
      "2019-10-29 00:37:19,251 : INFO : -4.871 per-word bound, 29.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:19,253 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:19,262 : INFO : topic #7 (0.100): 0.051*\"bar\" + 0.021*\"saturated\" + 0.020*\"fat\" + 0.016*\"energy\" + 0.015*\"sugar\" + 0.015*\"others\" + 0.014*\"contain\" + 0.014*\"nutrition\" + 0.014*\"snack\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:19,264 : INFO : topic #5 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"contain\" + 0.010*\"much\" + 0.010*\"others\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:19,267 : INFO : topic #3 (0.100): 0.020*\"bar\" + 0.013*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.011*\"nutrition\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"syrup\" + 0.010*\"sugar\" + 0.010*\"meal\"\n",
      "2019-10-29 00:37:19,268 : INFO : topic #0 (0.100): 0.015*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"meal\" + 0.010*\"much\" + 0.010*\"also\"\n",
      "2019-10-29 00:37:19,270 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,272 : INFO : topic diff=0.321963, rho=0.353553\n",
      "2019-10-29 00:37:19,315 : INFO : -4.849 per-word bound, 28.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,317 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:19,331 : INFO : topic #8 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,337 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,341 : INFO : topic #7 (0.100): 0.043*\"bar\" + 0.019*\"saturated\" + 0.018*\"fat\" + 0.014*\"energy\" + 0.014*\"sugar\" + 0.013*\"others\" + 0.013*\"contain\" + 0.013*\"nutrition\" + 0.013*\"snack\" + 0.012*\"protein\"\n",
      "2019-10-29 00:37:19,345 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:19,348 : INFO : topic #0 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"meal\" + 0.010*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:19,354 : INFO : topic diff=0.245291, rho=0.333333\n",
      "2019-10-29 00:37:19,408 : INFO : -4.836 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,411 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:19,420 : INFO : topic #7 (0.100): 0.035*\"bar\" + 0.017*\"saturated\" + 0.016*\"fat\" + 0.013*\"energy\" + 0.013*\"sugar\" + 0.012*\"others\" + 0.012*\"contain\" + 0.012*\"nutrition\" + 0.012*\"snack\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:19,422 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,426 : INFO : topic #0 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:19,429 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,435 : INFO : topic #2 (0.100): 0.024*\"bar\" + 0.014*\"energy\" + 0.014*\"saturated\" + 0.012*\"fat\" + 0.011*\"higher\" + 0.011*\"gram\" + 0.011*\"much\" + 0.011*\"nutrition\" + 0.011*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:19,443 : INFO : topic diff=0.184989, rho=0.316228\n",
      "2019-10-29 00:37:19,495 : INFO : -4.828 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,497 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:19,506 : INFO : topic #3 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"nutrition\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:19,509 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,511 : INFO : topic #2 (0.100): 0.020*\"bar\" + 0.013*\"energy\" + 0.013*\"saturated\" + 0.011*\"fat\" + 0.011*\"higher\" + 0.010*\"gram\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:19,513 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:19,515 : INFO : topic #7 (0.100): 0.029*\"bar\" + 0.015*\"saturated\" + 0.014*\"fat\" + 0.012*\"energy\" + 0.012*\"sugar\" + 0.012*\"others\" + 0.011*\"contain\" + 0.011*\"nutrition\" + 0.011*\"snack\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:19,518 : INFO : topic diff=0.138492, rho=0.301511\n",
      "2019-10-29 00:37:19,566 : INFO : -4.824 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,567 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:19,576 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,579 : INFO : topic #2 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:19,581 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,584 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"snack\" + 0.009*\"sugar\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"convenient\" + 0.009*\"protein\" + 0.009*\"saturated\"\n",
      "2019-10-29 00:37:19,586 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:19,589 : INFO : topic diff=0.103236, rho=0.288675\n",
      "2019-10-29 00:37:19,633 : INFO : -4.821 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,635 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:19,646 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,648 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,650 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,655 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,657 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:19,659 : INFO : topic diff=0.076833, rho=0.277350\n",
      "2019-10-29 00:37:19,710 : INFO : -4.820 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,712 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:19,719 : INFO : topic #7 (0.100): 0.018*\"bar\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"sugar\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"snack\" + 0.010*\"protein\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:19,722 : INFO : topic #2 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:19,724 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:19,726 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,728 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"gap\" + 0.009*\"snack\" + 0.009*\"generally\" + 0.009*\"satisfying\" + 0.009*\"fill\"\n",
      "2019-10-29 00:37:19,730 : INFO : topic diff=0.057220, rho=0.267261\n",
      "2019-10-29 00:37:19,783 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,788 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:19,797 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:19,800 : INFO : topic #0 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:19,804 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,807 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:19,811 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:19,814 : INFO : topic diff=0.042712, rho=0.258199\n",
      "2019-10-29 00:37:19,877 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,879 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:19,889 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"convenient\" + 0.009*\"sugar\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"snack\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"saturated\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,892 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:19,894 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:19,896 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:19,898 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:19,903 : INFO : topic diff=0.031994, rho=0.250000\n",
      "2019-10-29 00:37:19,971 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:19,973 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:19,983 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"convenient\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:19,996 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:20,001 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:20,004 : INFO : topic #2 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:20,007 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:20,010 : INFO : topic diff=0.024070, rho=0.242536\n",
      "2019-10-29 00:37:20,102 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,107 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:20,127 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:20,150 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:20,162 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:20,166 : INFO : topic #7 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"snack\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:20,172 : INFO : topic #6 (0.100): 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"pick\" + 0.009*\"oil\" + 0.009*\"nutritious\"\n",
      "2019-10-29 00:37:20,177 : INFO : topic diff=0.018195, rho=0.235702\n",
      "2019-10-29 00:37:20,255 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,258 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:20,265 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:20,267 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:20,270 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:20,276 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\"\n",
      "2019-10-29 00:37:20,278 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:20,280 : INFO : topic diff=0.013824, rho=0.229416\n",
      "2019-10-29 00:37:20,332 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,349 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:20,364 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:20,407 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:20,419 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:20,426 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"meal\"\n",
      "2019-10-29 00:37:20,430 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:20,433 : INFO : topic diff=0.010558, rho=0.223607\n",
      "2019-10-29 00:37:20,476 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,479 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:20,485 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:20,487 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\"\n",
      "2019-10-29 00:37:20,490 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"meal\" + 0.009*\"much\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:20,493 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"snack\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:20,496 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:20,498 : INFO : topic diff=0.008107, rho=0.218218\n",
      "2019-10-29 00:37:20,583 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,623 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,625 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:20,626 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:20,627 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:20,630 : INFO : running online (multi-pass) LDA training, 10 topics, 25 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817324998675013 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:20,702 : INFO : -6.823 per-word bound, 113.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,703 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:20,744 : INFO : topic #7 (0.100): 0.080*\"bar\" + 0.031*\"energy\" + 0.028*\"saturated\" + 0.025*\"fat\" + 0.022*\"protein\" + 0.020*\"higher\" + 0.017*\"gram\" + 0.017*\"contain\" + 0.017*\"much\" + 0.015*\"convenient\"\n",
      "2019-10-29 00:37:20,746 : INFO : topic #3 (0.100): 0.096*\"bar\" + 0.041*\"energy\" + 0.030*\"fat\" + 0.027*\"saturated\" + 0.019*\"much\" + 0.019*\"protein\" + 0.017*\"nutrition\" + 0.017*\"others\" + 0.017*\"sugar\" + 0.015*\"higher\"\n",
      "2019-10-29 00:37:20,748 : INFO : topic #9 (0.100): 0.080*\"bar\" + 0.035*\"saturated\" + 0.030*\"fat\" + 0.024*\"energy\" + 0.019*\"others\" + 0.018*\"contain\" + 0.017*\"sugar\" + 0.017*\"much\" + 0.016*\"gram\" + 0.015*\"aim\"\n",
      "2019-10-29 00:37:20,750 : INFO : topic #5 (0.100): 0.080*\"bar\" + 0.031*\"saturated\" + 0.028*\"energy\" + 0.023*\"fat\" + 0.021*\"contain\" + 0.018*\"gram\" + 0.018*\"higher\" + 0.018*\"others\" + 0.015*\"nutrition\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:20,752 : INFO : topic #4 (0.100): 0.102*\"bar\" + 0.032*\"energy\" + 0.028*\"fat\" + 0.023*\"saturated\" + 0.022*\"gram\" + 0.020*\"sugar\" + 0.018*\"contain\" + 0.018*\"nutrition\" + 0.017*\"higher\" + 0.016*\"protein\"\n",
      "2019-10-29 00:37:20,759 : INFO : topic diff=1.713416, rho=1.000000\n",
      "2019-10-29 00:37:20,825 : INFO : -5.723 per-word bound, 52.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,827 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:20,849 : INFO : topic #5 (0.100): 0.071*\"bar\" + 0.028*\"saturated\" + 0.026*\"energy\" + 0.021*\"fat\" + 0.020*\"contain\" + 0.017*\"gram\" + 0.017*\"higher\" + 0.016*\"others\" + 0.015*\"nutrition\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:20,851 : INFO : topic #2 (0.100): 0.049*\"bar\" + 0.026*\"saturated\" + 0.025*\"energy\" + 0.023*\"fat\" + 0.017*\"others\" + 0.016*\"higher\" + 0.016*\"nutrition\" + 0.015*\"sugar\" + 0.013*\"protein\" + 0.013*\"athlete\"\n",
      "2019-10-29 00:37:20,853 : INFO : topic #9 (0.100): 0.070*\"bar\" + 0.031*\"saturated\" + 0.027*\"fat\" + 0.022*\"energy\" + 0.018*\"others\" + 0.017*\"contain\" + 0.016*\"sugar\" + 0.016*\"much\" + 0.015*\"gram\" + 0.014*\"aim\"\n",
      "2019-10-29 00:37:20,855 : INFO : topic #6 (0.100): 0.038*\"bar\" + 0.022*\"energy\" + 0.019*\"fat\" + 0.019*\"saturated\" + 0.015*\"contain\" + 0.014*\"nutrition\" + 0.013*\"protein\" + 0.013*\"much\" + 0.013*\"sugar\" + 0.012*\"higher\"\n",
      "2019-10-29 00:37:20,858 : INFO : topic #1 (0.100): 0.066*\"bar\" + 0.028*\"energy\" + 0.022*\"fat\" + 0.022*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"higher\" + 0.016*\"others\" + 0.016*\"gram\" + 0.016*\"sugar\" + 0.015*\"much\"\n",
      "2019-10-29 00:37:20,859 : INFO : topic diff=0.925092, rho=0.577350\n",
      "2019-10-29 00:37:20,927 : INFO : -5.273 per-word bound, 38.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:20,929 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:20,942 : INFO : topic #0 (0.100): 0.054*\"bar\" + 0.021*\"energy\" + 0.020*\"fat\" + 0.019*\"saturated\" + 0.017*\"contain\" + 0.016*\"much\" + 0.014*\"convenient\" + 0.014*\"nutrition\" + 0.014*\"gram\" + 0.014*\"others\"\n",
      "2019-10-29 00:37:20,944 : INFO : topic #6 (0.100): 0.028*\"bar\" + 0.017*\"energy\" + 0.016*\"fat\" + 0.015*\"saturated\" + 0.013*\"contain\" + 0.012*\"nutrition\" + 0.012*\"protein\" + 0.011*\"much\" + 0.011*\"sugar\" + 0.011*\"higher\"\n",
      "2019-10-29 00:37:20,946 : INFO : topic #2 (0.100): 0.037*\"bar\" + 0.021*\"saturated\" + 0.021*\"energy\" + 0.019*\"fat\" + 0.015*\"others\" + 0.014*\"higher\" + 0.014*\"nutrition\" + 0.013*\"sugar\" + 0.012*\"protein\" + 0.012*\"athlete\"\n",
      "2019-10-29 00:37:20,951 : INFO : topic #7 (0.100): 0.060*\"bar\" + 0.025*\"energy\" + 0.022*\"saturated\" + 0.021*\"fat\" + 0.018*\"protein\" + 0.017*\"higher\" + 0.015*\"gram\" + 0.015*\"contain\" + 0.014*\"much\" + 0.013*\"convenient\"\n",
      "2019-10-29 00:37:20,954 : INFO : topic #1 (0.100): 0.053*\"bar\" + 0.023*\"energy\" + 0.019*\"fat\" + 0.019*\"saturated\" + 0.016*\"nutrition\" + 0.016*\"higher\" + 0.015*\"others\" + 0.015*\"gram\" + 0.014*\"sugar\" + 0.014*\"much\"\n",
      "2019-10-29 00:37:20,957 : INFO : topic diff=0.958061, rho=0.500000\n",
      "2019-10-29 00:37:21,010 : INFO : -5.059 per-word bound, 33.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,011 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:21,023 : INFO : topic #0 (0.100): 0.042*\"bar\" + 0.018*\"energy\" + 0.017*\"fat\" + 0.016*\"saturated\" + 0.015*\"contain\" + 0.014*\"much\" + 0.013*\"convenient\" + 0.013*\"nutrition\" + 0.013*\"gram\" + 0.012*\"others\"\n",
      "2019-10-29 00:37:21,026 : INFO : topic #1 (0.100): 0.041*\"bar\" + 0.019*\"energy\" + 0.017*\"fat\" + 0.017*\"saturated\" + 0.014*\"nutrition\" + 0.014*\"higher\" + 0.013*\"others\" + 0.013*\"gram\" + 0.013*\"sugar\" + 0.013*\"much\"\n",
      "2019-10-29 00:37:21,027 : INFO : topic #9 (0.100): 0.046*\"bar\" + 0.023*\"saturated\" + 0.020*\"fat\" + 0.017*\"energy\" + 0.014*\"others\" + 0.014*\"contain\" + 0.013*\"sugar\" + 0.013*\"much\" + 0.013*\"gram\" + 0.012*\"aim\"\n",
      "2019-10-29 00:37:21,030 : INFO : topic #4 (0.100): 0.068*\"bar\" + 0.023*\"energy\" + 0.021*\"fat\" + 0.018*\"saturated\" + 0.017*\"gram\" + 0.016*\"sugar\" + 0.015*\"contain\" + 0.014*\"nutrition\" + 0.014*\"higher\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:21,032 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:21,034 : INFO : topic diff=0.859785, rho=0.447214\n",
      "2019-10-29 00:37:21,101 : INFO : -4.944 per-word bound, 30.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,104 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:21,115 : INFO : topic #1 (0.100): 0.031*\"bar\" + 0.016*\"energy\" + 0.014*\"fat\" + 0.014*\"saturated\" + 0.013*\"nutrition\" + 0.012*\"higher\" + 0.012*\"others\" + 0.012*\"gram\" + 0.012*\"sugar\" + 0.012*\"much\"\n",
      "2019-10-29 00:37:21,118 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:21,122 : INFO : topic #6 (0.100): 0.016*\"bar\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.012*\"saturated\" + 0.011*\"contain\" + 0.010*\"nutrition\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"sugar\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:21,125 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,129 : INFO : topic #9 (0.100): 0.036*\"bar\" + 0.019*\"saturated\" + 0.017*\"fat\" + 0.015*\"energy\" + 0.013*\"others\" + 0.012*\"contain\" + 0.012*\"sugar\" + 0.012*\"much\" + 0.012*\"gram\" + 0.011*\"aim\"\n",
      "2019-10-29 00:37:21,132 : INFO : topic diff=0.696270, rho=0.408248\n",
      "2019-10-29 00:37:21,180 : INFO : -4.883 per-word bound, 29.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,182 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:21,193 : INFO : topic #6 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.011*\"saturated\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"sugar\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:21,196 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:21,198 : INFO : topic #7 (0.100): 0.030*\"bar\" + 0.016*\"energy\" + 0.014*\"saturated\" + 0.014*\"fat\" + 0.013*\"protein\" + 0.012*\"higher\" + 0.011*\"gram\" + 0.011*\"contain\" + 0.011*\"much\" + 0.011*\"convenient\"\n",
      "2019-10-29 00:37:21,200 : INFO : topic #5 (0.100): 0.030*\"bar\" + 0.016*\"saturated\" + 0.015*\"energy\" + 0.013*\"fat\" + 0.013*\"contain\" + 0.012*\"gram\" + 0.012*\"higher\" + 0.012*\"others\" + 0.011*\"nutrition\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:21,202 : INFO : topic #9 (0.100): 0.029*\"bar\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.013*\"energy\" + 0.012*\"others\" + 0.011*\"contain\" + 0.011*\"sugar\" + 0.011*\"much\" + 0.011*\"gram\" + 0.011*\"aim\"\n",
      "2019-10-29 00:37:21,204 : INFO : topic diff=0.528946, rho=0.377964\n",
      "2019-10-29 00:37:21,254 : INFO : -4.852 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:21,257 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:21,266 : INFO : topic #0 (0.100): 0.020*\"bar\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.012*\"saturated\" + 0.011*\"contain\" + 0.011*\"much\" + 0.010*\"convenient\" + 0.010*\"nutrition\" + 0.010*\"gram\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:21,268 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,270 : INFO : topic #1 (0.100): 0.020*\"bar\" + 0.013*\"energy\" + 0.012*\"fat\" + 0.012*\"saturated\" + 0.011*\"nutrition\" + 0.011*\"higher\" + 0.010*\"others\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:21,274 : INFO : topic #2 (0.100): 0.015*\"bar\" + 0.011*\"saturated\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"nutrition\" + 0.010*\"sugar\" + 0.010*\"protein\" + 0.010*\"athlete\"\n",
      "2019-10-29 00:37:21,276 : INFO : topic #4 (0.100): 0.035*\"bar\" + 0.015*\"energy\" + 0.014*\"fat\" + 0.013*\"saturated\" + 0.012*\"gram\" + 0.012*\"sugar\" + 0.012*\"contain\" + 0.011*\"nutrition\" + 0.011*\"higher\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:21,278 : INFO : topic diff=0.387214, rho=0.353553\n",
      "2019-10-29 00:37:21,331 : INFO : -4.836 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,332 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:21,341 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"snicker\"\n",
      "2019-10-29 00:37:21,343 : INFO : topic #7 (0.100): 0.020*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.011*\"protein\" + 0.011*\"higher\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"much\" + 0.010*\"convenient\"\n",
      "2019-10-29 00:37:21,345 : INFO : topic #5 (0.100): 0.020*\"bar\" + 0.012*\"saturated\" + 0.012*\"energy\" + 0.011*\"fat\" + 0.011*\"contain\" + 0.010*\"gram\" + 0.010*\"higher\" + 0.010*\"others\" + 0.010*\"nutrition\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:21,347 : INFO : topic #1 (0.100): 0.017*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.011*\"saturated\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"others\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:21,349 : INFO : topic #2 (0.100): 0.013*\"bar\" + 0.011*\"saturated\" + 0.011*\"energy\" + 0.010*\"fat\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"nutrition\" + 0.010*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:21,351 : INFO : topic diff=0.278009, rho=0.333333\n",
      "2019-10-29 00:37:21,410 : INFO : -4.827 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,412 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:21,421 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:21,424 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,427 : INFO : topic #0 (0.100): 0.015*\"bar\" + 0.011*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"contain\" + 0.010*\"much\" + 0.010*\"convenient\" + 0.010*\"nutrition\" + 0.010*\"gram\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:21,430 : INFO : topic #7 (0.100): 0.017*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"protein\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"much\" + 0.010*\"convenient\"\n",
      "2019-10-29 00:37:21,433 : INFO : topic #9 (0.100): 0.016*\"bar\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"gram\" + 0.010*\"aim\"\n",
      "2019-10-29 00:37:21,435 : INFO : topic diff=0.197984, rho=0.316228\n",
      "2019-10-29 00:37:21,487 : INFO : -4.823 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,490 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:21,499 : INFO : topic #0 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"contain\" + 0.010*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:21,501 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"calorie\" + 0.009*\"snicker\"\n",
      "2019-10-29 00:37:21,508 : INFO : topic #4 (0.100): 0.019*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.011*\"saturated\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:21,511 : INFO : topic #1 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:21,514 : INFO : topic #9 (0.100): 0.014*\"bar\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:21,517 : INFO : topic diff=0.140835, rho=0.301511\n",
      "2019-10-29 00:37:21,582 : INFO : -4.820 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,592 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:21,604 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,621 : INFO : topic #0 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:21,624 : INFO : topic #4 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:21,628 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:21,639 : INFO : topic #5 (0.100): 0.013*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"contain\" + 0.010*\"gram\" + 0.010*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:21,643 : INFO : topic diff=0.100493, rho=0.288675\n",
      "2019-10-29 00:37:21,697 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,699 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:21,709 : INFO : topic #9 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:21,711 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:21,714 : INFO : topic #5 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:21,716 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"energy\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"sugar\" + 0.009*\"healthy\"\n",
      "2019-10-29 00:37:21,719 : INFO : topic #7 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:21,721 : INFO : topic diff=0.072105, rho=0.277350\n",
      "2019-10-29 00:37:21,771 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,773 : INFO : PROGRESS: pass 12, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:21,780 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:21,783 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:21,787 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"chocolate\" + 0.009*\"syrup\" + 0.009*\"higher\" + 0.009*\"sugar\" + 0.009*\"others\" + 0.009*\"satisfying\"\n",
      "2019-10-29 00:37:21,790 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:21,793 : INFO : topic #7 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:21,795 : INFO : topic diff=0.052093, rho=0.267261\n",
      "2019-10-29 00:37:21,839 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,841 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:21,848 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:21,851 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"snicker\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:21,852 : INFO : topic #7 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:21,853 : INFO : topic #4 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:21,857 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:21,860 : INFO : topic diff=0.037922, rho=0.258199\n",
      "2019-10-29 00:37:21,910 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,912 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:21,920 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:21,923 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:21,927 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,930 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutritious\" + 0.009*\"nutrition\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:21,933 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:21,936 : INFO : topic diff=0.027823, rho=0.250000\n",
      "2019-10-29 00:37:21,980 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:21,983 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:21,994 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:21,997 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:21,999 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"snack\" + 0.009*\"fiber\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"source\" + 0.009*\"healthy\" + 0.009*\"energy\"\n",
      "2019-10-29 00:37:22,000 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,003 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,008 : INFO : topic diff=0.020576, rho=0.242536\n",
      "2019-10-29 00:37:22,060 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,063 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:22,075 : INFO : topic #0 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:22,078 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,082 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:22,086 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,094 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:22,106 : INFO : topic diff=0.015336, rho=0.235702\n",
      "2019-10-29 00:37:22,201 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,204 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:22,214 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:22,217 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:22,219 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:22,222 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,225 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"snicker\" + 0.009*\"snack\" + 0.009*\"gram\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:22,228 : INFO : topic diff=0.011517, rho=0.229416\n",
      "2019-10-29 00:37:22,299 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,302 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:22,310 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:22,313 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,316 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"fat\"\n",
      "2019-10-29 00:37:22,319 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,323 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:22,326 : INFO : topic diff=0.008714, rho=0.223607\n",
      "2019-10-29 00:37:22,392 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,394 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:22,409 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,419 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:22,422 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:22,427 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:22,430 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,432 : INFO : topic diff=0.006640, rho=0.218218\n",
      "2019-10-29 00:37:22,500 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,503 : INFO : PROGRESS: pass 20, at document #5/5\n",
      "2019-10-29 00:37:22,513 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:22,515 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:22,519 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:22,522 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:22,527 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:22,530 : INFO : topic diff=0.005094, rho=0.213201\n",
      "2019-10-29 00:37:22,595 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,597 : INFO : PROGRESS: pass 21, at document #5/5\n",
      "2019-10-29 00:37:22,605 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:22,611 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:22,615 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:22,621 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,624 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:22,628 : INFO : topic diff=0.003933, rho=0.208514\n",
      "2019-10-29 00:37:22,698 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,701 : INFO : PROGRESS: pass 22, at document #5/5\n",
      "2019-10-29 00:37:22,710 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:22,713 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:22,715 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:22,717 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,719 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:22,721 : INFO : topic diff=0.003056, rho=0.204124\n",
      "2019-10-29 00:37:22,787 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,790 : INFO : PROGRESS: pass 23, at document #5/5\n",
      "2019-10-29 00:37:22,799 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:22,802 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:37:22,805 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n",
      "2019-10-29 00:37:22,808 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\"\n",
      "2019-10-29 00:37:22,810 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,813 : INFO : topic diff=0.002387, rho=0.200000\n",
      "2019-10-29 00:37:22,880 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:22,882 : INFO : PROGRESS: pass 24, at document #5/5\n",
      "2019-10-29 00:37:22,891 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:22,894 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"aim\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:22,897 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:22,900 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"convenient\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:22,903 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:22,904 : INFO : topic diff=0.001876, rho=0.196116\n",
      "2019-10-29 00:37:23,030 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817281461749556 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:23,125 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,128 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:23,130 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:23,133 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:23,136 : INFO : running online (multi-pass) LDA training, 10 topics, 30 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:23,264 : INFO : -6.786 per-word bound, 110.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,267 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:23,317 : INFO : topic #4 (0.100): 0.094*\"bar\" + 0.036*\"energy\" + 0.029*\"saturated\" + 0.026*\"fat\" + 0.020*\"nutrition\" + 0.019*\"much\" + 0.019*\"protein\" + 0.017*\"sugar\" + 0.017*\"higher\" + 0.017*\"fiber\"\n",
      "2019-10-29 00:37:23,333 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:23,336 : INFO : topic #1 (0.100): 0.085*\"bar\" + 0.030*\"energy\" + 0.026*\"fat\" + 0.025*\"saturated\" + 0.020*\"others\" + 0.019*\"gram\" + 0.019*\"higher\" + 0.018*\"nutrition\" + 0.018*\"contain\" + 0.016*\"protein\"\n",
      "2019-10-29 00:37:23,339 : INFO : topic #8 (0.100): 0.087*\"bar\" + 0.033*\"saturated\" + 0.029*\"fat\" + 0.026*\"energy\" + 0.019*\"higher\" + 0.019*\"gram\" + 0.018*\"protein\" + 0.018*\"contain\" + 0.017*\"satisfying\" + 0.017*\"sugar\"\n",
      "2019-10-29 00:37:23,342 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"chocolate\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:23,346 : INFO : topic diff=3.048394, rho=1.000000\n",
      "2019-10-29 00:37:23,472 : INFO : -5.537 per-word bound, 46.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,475 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:23,517 : INFO : topic #6 (0.100): 0.043*\"bar\" + 0.020*\"fat\" + 0.020*\"energy\" + 0.016*\"nutrition\" + 0.015*\"saturated\" + 0.014*\"others\" + 0.013*\"contain\" + 0.013*\"protein\" + 0.013*\"much\" + 0.012*\"higher\"\n",
      "2019-10-29 00:37:23,520 : INFO : topic #1 (0.100): 0.076*\"bar\" + 0.028*\"energy\" + 0.024*\"fat\" + 0.023*\"saturated\" + 0.019*\"others\" + 0.018*\"gram\" + 0.018*\"higher\" + 0.017*\"nutrition\" + 0.017*\"contain\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:23,523 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:23,525 : INFO : topic #8 (0.100): 0.080*\"bar\" + 0.031*\"saturated\" + 0.027*\"fat\" + 0.025*\"energy\" + 0.018*\"higher\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.017*\"contain\" + 0.016*\"satisfying\" + 0.016*\"sugar\"\n",
      "2019-10-29 00:37:23,527 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:23,528 : INFO : topic diff=0.656443, rho=0.577350\n",
      "2019-10-29 00:37:23,599 : INFO : -5.205 per-word bound, 36.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,601 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:23,617 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"chocolate\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:23,623 : INFO : topic #9 (0.100): 0.028*\"bar\" + 0.017*\"energy\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.014*\"nutrition\" + 0.012*\"contain\" + 0.012*\"calorie\" + 0.012*\"others\" + 0.011*\"gram\" + 0.011*\"sugar\"\n",
      "2019-10-29 00:37:23,629 : INFO : topic #1 (0.100): 0.066*\"bar\" + 0.025*\"energy\" + 0.022*\"fat\" + 0.021*\"saturated\" + 0.018*\"others\" + 0.017*\"gram\" + 0.017*\"higher\" + 0.015*\"nutrition\" + 0.015*\"contain\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:23,633 : INFO : topic #8 (0.100): 0.071*\"bar\" + 0.028*\"saturated\" + 0.024*\"fat\" + 0.023*\"energy\" + 0.017*\"higher\" + 0.017*\"gram\" + 0.016*\"protein\" + 0.016*\"contain\" + 0.015*\"satisfying\" + 0.015*\"sugar\"\n",
      "2019-10-29 00:37:23,636 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"snicker\"\n",
      "2019-10-29 00:37:23,640 : INFO : topic diff=0.647124, rho=0.500000\n",
      "2019-10-29 00:37:23,693 : INFO : -5.038 per-word bound, 32.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,695 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:23,706 : INFO : topic #4 (0.100): 0.068*\"bar\" + 0.028*\"energy\" + 0.023*\"saturated\" + 0.021*\"fat\" + 0.017*\"nutrition\" + 0.016*\"much\" + 0.016*\"protein\" + 0.015*\"sugar\" + 0.014*\"higher\" + 0.014*\"fiber\"\n",
      "2019-10-29 00:37:23,708 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:23,712 : INFO : topic #5 (0.100): 0.041*\"bar\" + 0.022*\"energy\" + 0.018*\"saturated\" + 0.018*\"fat\" + 0.015*\"gram\" + 0.015*\"protein\" + 0.014*\"higher\" + 0.013*\"others\" + 0.013*\"sugar\" + 0.012*\"nutrition\"\n",
      "2019-10-29 00:37:23,714 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:23,717 : INFO : topic #1 (0.100): 0.054*\"bar\" + 0.021*\"energy\" + 0.019*\"fat\" + 0.018*\"saturated\" + 0.016*\"others\" + 0.015*\"gram\" + 0.015*\"higher\" + 0.014*\"nutrition\" + 0.014*\"contain\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:23,718 : INFO : topic diff=0.591695, rho=0.447214\n",
      "2019-10-29 00:37:23,776 : INFO : -4.940 per-word bound, 30.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,779 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:23,789 : INFO : topic #6 (0.100): 0.018*\"bar\" + 0.012*\"fat\" + 0.012*\"energy\" + 0.011*\"nutrition\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:23,791 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"snicker\"\n",
      "2019-10-29 00:37:23,796 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:23,800 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:23,802 : INFO : topic #9 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.011*\"nutrition\" + 0.010*\"contain\" + 0.010*\"calorie\" + 0.010*\"others\" + 0.010*\"gram\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:23,805 : INFO : topic diff=0.501799, rho=0.408248\n",
      "2019-10-29 00:37:23,861 : INFO : -4.885 per-word bound, 29.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,865 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:23,876 : INFO : topic #1 (0.100): 0.034*\"bar\" + 0.016*\"energy\" + 0.015*\"fat\" + 0.014*\"saturated\" + 0.013*\"others\" + 0.012*\"gram\" + 0.012*\"higher\" + 0.012*\"nutrition\" + 0.012*\"contain\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:23,881 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:23,883 : INFO : topic #5 (0.100): 0.026*\"bar\" + 0.016*\"energy\" + 0.014*\"saturated\" + 0.014*\"fat\" + 0.012*\"gram\" + 0.012*\"protein\" + 0.012*\"higher\" + 0.011*\"others\" + 0.011*\"sugar\" + 0.011*\"nutrition\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:23,886 : INFO : topic #4 (0.100): 0.046*\"bar\" + 0.021*\"energy\" + 0.018*\"saturated\" + 0.016*\"fat\" + 0.014*\"nutrition\" + 0.013*\"much\" + 0.013*\"protein\" + 0.013*\"sugar\" + 0.012*\"higher\" + 0.012*\"fiber\"\n",
      "2019-10-29 00:37:23,889 : INFO : topic #9 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"nutrition\" + 0.010*\"contain\" + 0.010*\"calorie\" + 0.010*\"others\" + 0.010*\"gram\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:23,891 : INFO : topic diff=0.400681, rho=0.377964\n",
      "2019-10-29 00:37:23,943 : INFO : -4.854 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:23,949 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:23,957 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:23,963 : INFO : topic #4 (0.100): 0.037*\"bar\" + 0.018*\"energy\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.013*\"nutrition\" + 0.012*\"much\" + 0.012*\"protein\" + 0.012*\"sugar\" + 0.012*\"higher\" + 0.012*\"fiber\"\n",
      "2019-10-29 00:37:23,966 : INFO : topic #6 (0.100): 0.013*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"nutrition\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:23,967 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"chocolate\" + 0.009*\"gram\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:23,969 : INFO : topic #1 (0.100): 0.027*\"bar\" + 0.014*\"energy\" + 0.013*\"fat\" + 0.013*\"saturated\" + 0.012*\"others\" + 0.011*\"gram\" + 0.011*\"higher\" + 0.011*\"nutrition\" + 0.011*\"contain\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:23,970 : INFO : topic diff=0.306548, rho=0.353553\n",
      "2019-10-29 00:37:24,035 : INFO : -4.838 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,038 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:24,060 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,068 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,071 : INFO : topic #8 (0.100): 0.025*\"bar\" + 0.014*\"saturated\" + 0.013*\"fat\" + 0.013*\"energy\" + 0.011*\"higher\" + 0.011*\"gram\" + 0.011*\"protein\" + 0.011*\"contain\" + 0.011*\"satisfying\" + 0.011*\"sugar\"\n",
      "2019-10-29 00:37:24,077 : INFO : topic #9 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,081 : INFO : topic #6 (0.100): 0.012*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,084 : INFO : topic diff=0.228211, rho=0.333333\n",
      "2019-10-29 00:37:24,129 : INFO : -4.829 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,132 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:24,141 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,144 : INFO : topic #8 (0.100): 0.021*\"bar\" + 0.013*\"saturated\" + 0.012*\"fat\" + 0.012*\"energy\" + 0.011*\"higher\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"contain\" + 0.010*\"satisfying\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:24,146 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,148 : INFO : topic #5 (0.100): 0.015*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"higher\" + 0.010*\"others\" + 0.010*\"sugar\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:24,150 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"snack\" + 0.009*\"snicker\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:24,153 : INFO : topic diff=0.167269, rho=0.316228\n",
      "2019-10-29 00:37:24,194 : INFO : -4.824 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,196 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:24,204 : INFO : topic #4 (0.100): 0.020*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.010*\"nutrition\" + 0.010*\"much\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.010*\"higher\" + 0.010*\"fiber\"\n",
      "2019-10-29 00:37:24,206 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,208 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"source\" + 0.009*\"snicker\" + 0.009*\"gram\" + 0.009*\"fiber\" + 0.009*\"snack\"\n",
      "2019-10-29 00:37:24,210 : INFO : topic #5 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"higher\" + 0.010*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,213 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,214 : INFO : topic diff=0.121712, rho=0.301511\n",
      "2019-10-29 00:37:24,258 : INFO : -4.821 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,260 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:24,268 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,271 : INFO : topic #8 (0.100): 0.015*\"bar\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"contain\" + 0.010*\"satisfying\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:24,273 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:24,276 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,279 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"source\" + 0.009*\"nutrition\" + 0.009*\"snicker\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:24,281 : INFO : topic diff=0.088410, rho=0.288675\n",
      "2019-10-29 00:37:24,334 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,336 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:24,342 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"chocolate\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:24,346 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,350 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"nutritious\"\n",
      "2019-10-29 00:37:24,353 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:24,355 : INFO : topic #1 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"gram\" + 0.010*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,357 : INFO : topic diff=0.064339, rho=0.277350\n",
      "2019-10-29 00:37:24,400 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,401 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:24,408 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,410 : INFO : topic #4 (0.100): 0.014*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"nutrition\" + 0.010*\"much\" + 0.010*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:24,414 : INFO : topic #8 (0.100): 0.013*\"bar\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,416 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,421 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,423 : INFO : topic diff=0.047010, rho=0.267261\n",
      "2019-10-29 00:37:24,471 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,473 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:24,483 : INFO : topic #0 (0.100): 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"bar\" + 0.009*\"snicker\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"convenient\" + 0.009*\"source\" + 0.009*\"higher\" + 0.009*\"snack\"\n",
      "2019-10-29 00:37:24,485 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,488 : INFO : topic #1 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,490 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:24,493 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,498 : INFO : topic diff=0.034533, rho=0.258199\n",
      "2019-10-29 00:37:24,543 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,546 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:24,556 : INFO : topic #4 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:24,559 : INFO : topic #1 (0.100): 0.011*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,562 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"snack\" + 0.009*\"sugar\" + 0.009*\"source\" + 0.009*\"snicker\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:24,565 : INFO : topic #8 (0.100): 0.011*\"bar\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,568 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"others\" + 0.009*\"syrup\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"energy\" + 0.009*\"satisfying\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:24,570 : INFO : topic diff=0.025521, rho=0.250000\n",
      "2019-10-29 00:37:24,624 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,626 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:24,632 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:24,635 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,637 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"chocolate\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,640 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,642 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:24,645 : INFO : topic diff=0.018983, rho=0.242536\n",
      "2019-10-29 00:37:24,685 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,689 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:24,700 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,702 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,707 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,712 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"protein\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nutritional\" + 0.009*\"palate\"\n",
      "2019-10-29 00:37:24,715 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:24,718 : INFO : topic diff=0.014214, rho=0.235702\n",
      "2019-10-29 00:37:24,785 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,789 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:24,802 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,805 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,809 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:24,812 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"palate\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutritional\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:24,816 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:24,819 : INFO : topic diff=0.010714, rho=0.229416\n",
      "2019-10-29 00:37:24,894 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:24,899 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:24,910 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:24,914 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:24,917 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:24,920 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:24,922 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\"\n",
      "2019-10-29 00:37:24,925 : INFO : topic diff=0.008130, rho=0.223607\n",
      "2019-10-29 00:37:25,001 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,005 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:25,015 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,018 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:25,020 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,023 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,025 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,028 : INFO : topic diff=0.006209, rho=0.218218\n",
      "2019-10-29 00:37:25,070 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,073 : INFO : PROGRESS: pass 20, at document #5/5\n",
      "2019-10-29 00:37:25,080 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,082 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,085 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,098 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,101 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,103 : INFO : topic diff=0.004772, rho=0.213201\n",
      "2019-10-29 00:37:25,154 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,156 : INFO : PROGRESS: pass 21, at document #5/5\n",
      "2019-10-29 00:37:25,164 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,166 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,169 : INFO : topic #0 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,171 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:25,174 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,176 : INFO : topic diff=0.003690, rho=0.208514\n",
      "2019-10-29 00:37:25,218 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,220 : INFO : PROGRESS: pass 22, at document #5/5\n",
      "2019-10-29 00:37:25,226 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,228 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:25,232 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:25,234 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,237 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,239 : INFO : topic diff=0.002870, rho=0.204124\n",
      "2019-10-29 00:37:25,292 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,294 : INFO : PROGRESS: pass 23, at document #5/5\n",
      "2019-10-29 00:37:25,303 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,305 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,309 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,312 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:25,316 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:25,319 : INFO : topic diff=0.002244, rho=0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:25,375 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,382 : INFO : PROGRESS: pass 24, at document #5/5\n",
      "2019-10-29 00:37:25,391 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,393 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,396 : INFO : topic #0 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,401 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,404 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,407 : INFO : topic diff=0.001765, rho=0.196116\n",
      "2019-10-29 00:37:25,473 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,475 : INFO : PROGRESS: pass 25, at document #5/5\n",
      "2019-10-29 00:37:25,492 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,494 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"chocolate\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:25,499 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,503 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,506 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:25,509 : INFO : topic diff=0.001395, rho=0.192450\n",
      "2019-10-29 00:37:25,564 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,567 : INFO : PROGRESS: pass 26, at document #5/5\n",
      "2019-10-29 00:37:25,587 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,594 : INFO : topic #0 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,603 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,608 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,611 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,615 : INFO : topic diff=0.001108, rho=0.188982\n",
      "2019-10-29 00:37:25,672 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,681 : INFO : PROGRESS: pass 27, at document #5/5\n",
      "2019-10-29 00:37:25,691 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,694 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,698 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:25,701 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,704 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,707 : INFO : topic diff=0.000884, rho=0.185695\n",
      "2019-10-29 00:37:25,750 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,752 : INFO : PROGRESS: pass 28, at document #5/5\n",
      "2019-10-29 00:37:25,762 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,765 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"others\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:25,768 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,770 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,772 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:25,774 : INFO : topic diff=0.000708, rho=0.182574\n",
      "2019-10-29 00:37:25,820 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:25,823 : INFO : PROGRESS: pass 29, at document #5/5\n",
      "2019-10-29 00:37:25,832 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:25,834 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"others\" + 0.009*\"gram\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:25,837 : INFO : topic #0 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,840 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:25,842 : INFO : topic #3 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"much\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:25,844 : INFO : topic diff=0.000570, rho=0.179605\n",
      "2019-10-29 00:37:25,946 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817278531810941 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:26,030 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,034 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:26,036 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:26,038 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:26,041 : INFO : running online (multi-pass) LDA training, 10 topics, 35 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:26,185 : INFO : -6.802 per-word bound, 111.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,187 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:26,223 : INFO : topic #9 (0.100): 0.074*\"bar\" + 0.039*\"energy\" + 0.032*\"fat\" + 0.024*\"saturated\" + 0.023*\"gram\" + 0.020*\"contain\" + 0.020*\"protein\" + 0.018*\"nutrition\" + 0.017*\"higher\" + 0.017*\"sugar\"\n",
      "2019-10-29 00:37:26,227 : INFO : topic #3 (0.100): 0.092*\"bar\" + 0.033*\"energy\" + 0.032*\"saturated\" + 0.028*\"fat\" + 0.022*\"sugar\" + 0.022*\"protein\" + 0.019*\"nutrition\" + 0.018*\"much\" + 0.016*\"higher\" + 0.015*\"gram\"\n",
      "2019-10-29 00:37:26,234 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:26,237 : INFO : topic #4 (0.100): 0.036*\"bar\" + 0.018*\"energy\" + 0.017*\"saturated\" + 0.017*\"fat\" + 0.013*\"gram\" + 0.013*\"much\" + 0.013*\"contain\" + 0.013*\"protein\" + 0.012*\"others\" + 0.012*\"nutrition\"\n",
      "2019-10-29 00:37:26,241 : INFO : topic #0 (0.100): 0.070*\"bar\" + 0.029*\"energy\" + 0.025*\"saturated\" + 0.023*\"fat\" + 0.020*\"gram\" + 0.018*\"others\" + 0.018*\"protein\" + 0.018*\"much\" + 0.017*\"higher\" + 0.015*\"nutrition\"\n",
      "2019-10-29 00:37:26,246 : INFO : topic diff=2.393688, rho=1.000000\n",
      "2019-10-29 00:37:26,335 : INFO : -5.689 per-word bound, 51.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,337 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:26,377 : INFO : topic #0 (0.100): 0.059*\"bar\" + 0.026*\"energy\" + 0.022*\"saturated\" + 0.020*\"fat\" + 0.018*\"gram\" + 0.017*\"others\" + 0.017*\"protein\" + 0.016*\"much\" + 0.015*\"higher\" + 0.014*\"nutrition\"\n",
      "2019-10-29 00:37:26,381 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:26,383 : INFO : topic #6 (0.100): 0.092*\"bar\" + 0.036*\"energy\" + 0.030*\"saturated\" + 0.027*\"fat\" + 0.020*\"contain\" + 0.019*\"others\" + 0.019*\"higher\" + 0.018*\"nutrition\" + 0.017*\"much\" + 0.016*\"gram\"\n",
      "2019-10-29 00:37:26,385 : INFO : topic #1 (0.100): 0.097*\"bar\" + 0.032*\"energy\" + 0.029*\"fat\" + 0.024*\"saturated\" + 0.018*\"much\" + 0.018*\"contain\" + 0.018*\"others\" + 0.017*\"higher\" + 0.017*\"gram\" + 0.013*\"chocolate\"\n",
      "2019-10-29 00:37:26,387 : INFO : topic #8 (0.100): 0.019*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.011*\"gram\" + 0.011*\"much\" + 0.011*\"contain\" + 0.011*\"fat\" + 0.011*\"sugar\" + 0.010*\"nutrition\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:26,389 : INFO : topic diff=0.821022, rho=0.577350\n",
      "2019-10-29 00:37:26,468 : INFO : -5.372 per-word bound, 41.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,470 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:26,519 : INFO : topic #3 (0.100): 0.090*\"bar\" + 0.032*\"energy\" + 0.031*\"fat\" + 0.029*\"saturated\" + 0.022*\"protein\" + 0.022*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.017*\"gram\" + 0.015*\"higher\"\n",
      "2019-10-29 00:37:26,522 : INFO : topic #1 (0.100): 0.087*\"bar\" + 0.030*\"energy\" + 0.026*\"fat\" + 0.022*\"saturated\" + 0.017*\"much\" + 0.017*\"contain\" + 0.017*\"others\" + 0.016*\"higher\" + 0.016*\"gram\" + 0.013*\"chocolate\"\n",
      "2019-10-29 00:37:26,524 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:26,529 : INFO : topic #0 (0.100): 0.047*\"bar\" + 0.022*\"energy\" + 0.019*\"saturated\" + 0.018*\"fat\" + 0.016*\"gram\" + 0.015*\"others\" + 0.015*\"protein\" + 0.015*\"much\" + 0.014*\"higher\" + 0.013*\"nutrition\"\n",
      "2019-10-29 00:37:26,534 : INFO : topic #4 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"gram\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:26,536 : INFO : topic diff=0.726620, rho=0.500000\n",
      "2019-10-29 00:37:26,619 : INFO : -5.151 per-word bound, 35.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,621 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:26,647 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:26,656 : INFO : topic #6 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.017*\"gram\"\n",
      "2019-10-29 00:37:26,659 : INFO : topic #9 (0.100): 0.048*\"bar\" + 0.027*\"energy\" + 0.023*\"fat\" + 0.018*\"saturated\" + 0.017*\"gram\" + 0.016*\"contain\" + 0.015*\"protein\" + 0.015*\"nutrition\" + 0.014*\"higher\" + 0.014*\"sugar\"\n",
      "2019-10-29 00:37:26,662 : INFO : topic #7 (0.100): 0.022*\"bar\" + 0.014*\"fat\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.011*\"much\" + 0.011*\"gram\" + 0.011*\"others\" + 0.011*\"contain\" + 0.010*\"sugar\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:26,669 : INFO : topic #4 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:26,671 : INFO : topic diff=0.626325, rho=0.447214\n",
      "2019-10-29 00:37:26,725 : INFO : -5.029 per-word bound, 32.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,727 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:26,744 : INFO : topic #6 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.017*\"gram\"\n",
      "2019-10-29 00:37:26,746 : INFO : topic #7 (0.100): 0.017*\"bar\" + 0.012*\"fat\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.010*\"much\" + 0.010*\"gram\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:26,751 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:26,754 : INFO : topic #9 (0.100): 0.039*\"bar\" + 0.023*\"energy\" + 0.020*\"fat\" + 0.016*\"saturated\" + 0.015*\"gram\" + 0.014*\"contain\" + 0.014*\"protein\" + 0.013*\"nutrition\" + 0.013*\"higher\" + 0.012*\"sugar\"\n",
      "2019-10-29 00:37:26,756 : INFO : topic #3 (0.100): 0.080*\"bar\" + 0.029*\"energy\" + 0.028*\"fat\" + 0.026*\"saturated\" + 0.020*\"protein\" + 0.020*\"sugar\" + 0.017*\"nutrition\" + 0.017*\"much\" + 0.016*\"gram\" + 0.014*\"higher\"\n",
      "2019-10-29 00:37:26,758 : INFO : topic diff=0.522191, rho=0.408248\n",
      "2019-10-29 00:37:26,807 : INFO : -4.952 per-word bound, 31.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,809 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:26,825 : INFO : topic #7 (0.100): 0.014*\"bar\" + 0.011*\"fat\" + 0.011*\"energy\" + 0.010*\"saturated\" + 0.010*\"much\" + 0.010*\"gram\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:26,827 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:26,830 : INFO : topic #0 (0.100): 0.022*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.011*\"gram\" + 0.011*\"others\" + 0.011*\"protein\" + 0.011*\"much\" + 0.011*\"higher\" + 0.010*\"nutrition\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:26,836 : INFO : topic #6 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:26,839 : INFO : topic #3 (0.100): 0.073*\"bar\" + 0.027*\"energy\" + 0.026*\"fat\" + 0.025*\"saturated\" + 0.019*\"protein\" + 0.019*\"sugar\" + 0.016*\"nutrition\" + 0.016*\"much\" + 0.016*\"gram\" + 0.014*\"higher\"\n",
      "2019-10-29 00:37:26,841 : INFO : topic diff=0.425022, rho=0.377964\n",
      "2019-10-29 00:37:26,911 : INFO : -4.903 per-word bound, 29.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:26,914 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:26,931 : INFO : topic #3 (0.100): 0.065*\"bar\" + 0.025*\"energy\" + 0.024*\"fat\" + 0.023*\"saturated\" + 0.018*\"protein\" + 0.018*\"sugar\" + 0.015*\"nutrition\" + 0.015*\"much\" + 0.015*\"gram\" + 0.013*\"higher\"\n",
      "2019-10-29 00:37:26,946 : INFO : topic #6 (0.100): 0.093*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:26,951 : INFO : topic #0 (0.100): 0.018*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.011*\"gram\" + 0.010*\"others\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"higher\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:26,954 : INFO : topic #7 (0.100): 0.013*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"much\" + 0.010*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:26,957 : INFO : topic #1 (0.100): 0.039*\"bar\" + 0.017*\"energy\" + 0.016*\"fat\" + 0.014*\"saturated\" + 0.012*\"much\" + 0.012*\"contain\" + 0.012*\"others\" + 0.012*\"higher\" + 0.012*\"gram\" + 0.010*\"chocolate\"\n",
      "2019-10-29 00:37:26,959 : INFO : topic diff=0.340738, rho=0.353553\n",
      "2019-10-29 00:37:27,010 : INFO : -4.872 per-word bound, 29.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,012 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:27,024 : INFO : topic #7 (0.100): 0.011*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,026 : INFO : topic #5 (0.100): 0.017*\"bar\" + 0.011*\"fat\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"others\" + 0.010*\"nutrition\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"higher\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:27,028 : INFO : topic #9 (0.100): 0.020*\"bar\" + 0.014*\"energy\" + 0.013*\"fat\" + 0.012*\"saturated\" + 0.011*\"gram\" + 0.011*\"contain\" + 0.011*\"protein\" + 0.011*\"nutrition\" + 0.010*\"higher\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:27,031 : INFO : topic #1 (0.100): 0.032*\"bar\" + 0.015*\"energy\" + 0.014*\"fat\" + 0.013*\"saturated\" + 0.011*\"much\" + 0.011*\"contain\" + 0.011*\"others\" + 0.011*\"higher\" + 0.011*\"gram\" + 0.010*\"chocolate\"\n",
      "2019-10-29 00:37:27,034 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:27,036 : INFO : topic diff=0.270411, rho=0.333333\n",
      "2019-10-29 00:37:27,097 : INFO : -4.852 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,108 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:27,121 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:27,124 : INFO : topic #3 (0.100): 0.049*\"bar\" + 0.020*\"energy\" + 0.019*\"fat\" + 0.019*\"saturated\" + 0.015*\"protein\" + 0.015*\"sugar\" + 0.013*\"nutrition\" + 0.013*\"much\" + 0.013*\"gram\" + 0.012*\"higher\"\n",
      "2019-10-29 00:37:27,125 : INFO : topic #5 (0.100): 0.015*\"bar\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"nutrition\" + 0.010*\"gram\" + 0.010*\"sugar\" + 0.010*\"higher\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:27,130 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,134 : INFO : topic #1 (0.100): 0.026*\"bar\" + 0.013*\"energy\" + 0.013*\"fat\" + 0.012*\"saturated\" + 0.011*\"much\" + 0.011*\"contain\" + 0.011*\"others\" + 0.011*\"higher\" + 0.010*\"gram\" + 0.010*\"chocolate\"\n",
      "2019-10-29 00:37:27,138 : INFO : topic diff=0.212761, rho=0.316228\n",
      "2019-10-29 00:37:27,196 : INFO : -4.839 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,199 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:27,211 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:27,214 : INFO : topic #0 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,217 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"snicker\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"convenient\" + 0.009*\"source\"\n",
      "2019-10-29 00:37:27,219 : INFO : topic #1 (0.100): 0.021*\"bar\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.011*\"saturated\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.010*\"chocolate\"\n",
      "2019-10-29 00:37:27,221 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,223 : INFO : topic diff=0.166052, rho=0.301511\n",
      "2019-10-29 00:37:27,276 : INFO : -4.831 per-word bound, 28.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,278 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:27,286 : INFO : topic #9 (0.100): 0.013*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"contain\" + 0.010*\"protein\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"sugar\"\n",
      "2019-10-29 00:37:27,289 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:27,291 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:27,292 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,295 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"chocolate\" + 0.009*\"snack\" + 0.009*\"nutrition\" + 0.009*\"syrup\" + 0.009*\"gram\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:27,296 : INFO : topic diff=0.128669, rho=0.288675\n",
      "2019-10-29 00:37:27,359 : INFO : -4.826 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,363 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:27,375 : INFO : topic #1 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"much\" + 0.010*\"contain\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:27,387 : INFO : topic #3 (0.100): 0.029*\"bar\" + 0.015*\"energy\" + 0.014*\"fat\" + 0.014*\"saturated\" + 0.012*\"protein\" + 0.012*\"sugar\" + 0.011*\"nutrition\" + 0.011*\"much\" + 0.011*\"gram\" + 0.011*\"higher\"\n",
      "2019-10-29 00:37:27,390 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,394 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:27,398 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:27,405 : INFO : topic diff=0.099137, rho=0.277350\n",
      "2019-10-29 00:37:27,474 : INFO : -4.822 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,477 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:27,491 : INFO : topic #3 (0.100): 0.025*\"bar\" + 0.013*\"energy\" + 0.013*\"fat\" + 0.013*\"saturated\" + 0.011*\"protein\" + 0.011*\"sugar\" + 0.011*\"nutrition\" + 0.011*\"much\" + 0.011*\"gram\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:27,494 : INFO : topic #9 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:27,497 : INFO : topic #1 (0.100): 0.014*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"much\" + 0.010*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:27,500 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,503 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:27,506 : INFO : topic diff=0.076089, rho=0.267261\n",
      "2019-10-29 00:37:27,559 : INFO : -4.821 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,561 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:27,571 : INFO : topic #3 (0.100): 0.021*\"bar\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.012*\"saturated\" + 0.011*\"protein\" + 0.011*\"sugar\" + 0.010*\"nutrition\" + 0.010*\"much\" + 0.010*\"gram\" + 0.010*\"higher\"\n",
      "2019-10-29 00:37:27,575 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:27,578 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:27,581 : INFO : topic #1 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:27,584 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,587 : INFO : topic diff=0.058280, rho=0.258199\n",
      "2019-10-29 00:37:27,664 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,667 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:27,678 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:27,681 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,684 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,687 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:27,690 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:27,696 : INFO : topic diff=0.044621, rho=0.250000\n",
      "2019-10-29 00:37:27,766 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,767 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:27,777 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,780 : INFO : topic #1 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:27,783 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,786 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:27,789 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:27,792 : INFO : topic diff=0.034195, rho=0.242536\n",
      "2019-10-29 00:37:27,855 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,858 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:27,868 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"pick\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nutritional\"\n",
      "2019-10-29 00:37:27,870 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:27,872 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,874 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:27,876 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:27,878 : INFO : topic diff=0.026255, rho=0.235702\n",
      "2019-10-29 00:37:27,946 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:27,948 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:27,959 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"palate\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutritional\" + 0.009*\"palm\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:27,962 : INFO : topic #3 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.010*\"protein\" + 0.010*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:27,967 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:27,970 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:27,973 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:27,975 : INFO : topic diff=0.020214, rho=0.229416\n",
      "2019-10-29 00:37:28,041 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,049 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:28,064 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,067 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,071 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\"\n",
      "2019-10-29 00:37:28,074 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:28,078 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,081 : INFO : topic diff=0.015612, rho=0.223607\n",
      "2019-10-29 00:37:28,157 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,163 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:28,175 : INFO : topic #3 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:28,177 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:28,181 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,185 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,191 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,194 : INFO : topic diff=0.012101, rho=0.218218\n",
      "2019-10-29 00:37:28,289 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,292 : INFO : PROGRESS: pass 20, at document #5/5\n",
      "2019-10-29 00:37:28,301 : INFO : topic #3 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:28,304 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,307 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:28,310 : INFO : topic #1 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,313 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,315 : INFO : topic diff=0.009416, rho=0.213201\n",
      "2019-10-29 00:37:28,371 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,373 : INFO : PROGRESS: pass 21, at document #5/5\n",
      "2019-10-29 00:37:28,385 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,388 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:28,391 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,393 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,396 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,399 : INFO : topic diff=0.007355, rho=0.208514\n",
      "2019-10-29 00:37:28,468 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,470 : INFO : PROGRESS: pass 22, at document #5/5\n",
      "2019-10-29 00:37:28,479 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:28,482 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,484 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,488 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:28,499 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,504 : INFO : topic diff=0.005769, rho=0.204124\n",
      "2019-10-29 00:37:28,573 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,577 : INFO : PROGRESS: pass 23, at document #5/5\n",
      "2019-10-29 00:37:28,587 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,591 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:28,594 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:28,597 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,599 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,608 : INFO : topic diff=0.004543, rho=0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:28,679 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,680 : INFO : PROGRESS: pass 24, at document #5/5\n",
      "2019-10-29 00:37:28,690 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:28,696 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,699 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,702 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,706 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:28,711 : INFO : topic diff=0.003593, rho=0.196116\n",
      "2019-10-29 00:37:28,772 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,774 : INFO : PROGRESS: pass 25, at document #5/5\n",
      "2019-10-29 00:37:28,794 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:28,799 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,802 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,811 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,815 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,820 : INFO : topic diff=0.002853, rho=0.192450\n",
      "2019-10-29 00:37:28,882 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,884 : INFO : PROGRESS: pass 26, at document #5/5\n",
      "2019-10-29 00:37:28,893 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,896 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,899 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,901 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,904 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:28,907 : INFO : topic diff=0.002274, rho=0.188982\n",
      "2019-10-29 00:37:28,964 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:28,966 : INFO : PROGRESS: pass 27, at document #5/5\n",
      "2019-10-29 00:37:28,973 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:28,975 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:28,976 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:28,977 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:28,979 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:28,981 : INFO : topic diff=0.001820, rho=0.185695\n",
      "2019-10-29 00:37:29,042 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,045 : INFO : PROGRESS: pass 28, at document #5/5\n",
      "2019-10-29 00:37:29,050 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,053 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:29,058 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,061 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:29,063 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,065 : INFO : topic diff=0.001462, rho=0.182574\n",
      "2019-10-29 00:37:29,148 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,150 : INFO : PROGRESS: pass 29, at document #5/5\n",
      "2019-10-29 00:37:29,157 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:29,160 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,163 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:29,167 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:29,173 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,176 : INFO : topic diff=0.001179, rho=0.179605\n",
      "2019-10-29 00:37:29,219 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:29,223 : INFO : PROGRESS: pass 30, at document #5/5\n",
      "2019-10-29 00:37:29,230 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:29,233 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,234 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:29,240 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,243 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,244 : INFO : topic diff=0.000954, rho=0.176777\n",
      "2019-10-29 00:37:29,313 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,316 : INFO : PROGRESS: pass 31, at document #5/5\n",
      "2019-10-29 00:37:29,322 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,326 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,328 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:29,329 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:29,330 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,332 : INFO : topic diff=0.000775, rho=0.174078\n",
      "2019-10-29 00:37:29,386 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,388 : INFO : PROGRESS: pass 32, at document #5/5\n",
      "2019-10-29 00:37:29,396 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,399 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,402 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:29,404 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,407 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:29,409 : INFO : topic diff=0.000632, rho=0.171499\n",
      "2019-10-29 00:37:29,452 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,455 : INFO : PROGRESS: pass 33, at document #5/5\n",
      "2019-10-29 00:37:29,464 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,472 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"chocolate\"\n",
      "2019-10-29 00:37:29,475 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"saturated\" + 0.029*\"fat\" + 0.018*\"contain\" + 0.018*\"others\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"gram\"\n",
      "2019-10-29 00:37:29,477 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,479 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:29,480 : INFO : topic diff=0.000516, rho=0.169031\n",
      "2019-10-29 00:37:29,550 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,552 : INFO : PROGRESS: pass 34, at document #5/5\n",
      "2019-10-29 00:37:29,559 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:29,562 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:29,566 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:29,570 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:29,572 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:29,573 : INFO : topic diff=0.000424, rho=0.166667\n",
      "2019-10-29 00:37:29,667 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,740 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,743 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:29,744 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:29,747 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:29,749 : INFO : running online (multi-pass) LDA training, 10 topics, 40 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817278763810559 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:29,869 : INFO : -6.767 per-word bound, 108.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:29,873 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:29,934 : INFO : topic #8 (0.100): 0.060*\"bar\" + 0.031*\"energy\" + 0.022*\"fat\" + 0.021*\"saturated\" + 0.019*\"sugar\" + 0.018*\"much\" + 0.016*\"higher\" + 0.016*\"contain\" + 0.014*\"calorie\" + 0.014*\"protein\"\n",
      "2019-10-29 00:37:29,938 : INFO : topic #3 (0.100): 0.078*\"bar\" + 0.031*\"energy\" + 0.029*\"fat\" + 0.023*\"saturated\" + 0.018*\"contain\" + 0.017*\"sugar\" + 0.017*\"much\" + 0.017*\"higher\" + 0.016*\"others\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:29,940 : INFO : topic #1 (0.100): 0.102*\"bar\" + 0.034*\"energy\" + 0.029*\"fat\" + 0.027*\"saturated\" + 0.019*\"nutrition\" + 0.019*\"protein\" + 0.019*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:29,942 : INFO : topic #5 (0.100): 0.031*\"bar\" + 0.019*\"energy\" + 0.017*\"saturated\" + 0.017*\"fat\" + 0.014*\"higher\" + 0.013*\"much\" + 0.012*\"contain\" + 0.012*\"meal\" + 0.012*\"syrup\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:29,944 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"amount\"\n",
      "2019-10-29 00:37:29,945 : INFO : topic diff=3.098528, rho=1.000000\n",
      "2019-10-29 00:37:30,009 : INFO : -5.311 per-word bound, 39.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,010 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:30,024 : INFO : topic #8 (0.100): 0.047*\"bar\" + 0.025*\"energy\" + 0.018*\"fat\" + 0.018*\"saturated\" + 0.016*\"sugar\" + 0.016*\"much\" + 0.014*\"higher\" + 0.014*\"contain\" + 0.013*\"calorie\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:30,026 : INFO : topic #5 (0.100): 0.021*\"bar\" + 0.014*\"energy\" + 0.013*\"saturated\" + 0.013*\"fat\" + 0.011*\"higher\" + 0.011*\"much\" + 0.011*\"contain\" + 0.010*\"meal\" + 0.010*\"syrup\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:30,028 : INFO : topic #4 (0.100): 0.062*\"bar\" + 0.032*\"energy\" + 0.032*\"saturated\" + 0.024*\"fat\" + 0.022*\"sugar\" + 0.019*\"higher\" + 0.017*\"others\" + 0.016*\"much\" + 0.016*\"gram\" + 0.015*\"contain\"\n",
      "2019-10-29 00:37:30,030 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"satisfying\" + 0.009*\"others\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:30,033 : INFO : topic #1 (0.100): 0.096*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,035 : INFO : topic diff=0.891460, rho=0.577350\n",
      "2019-10-29 00:37:30,092 : INFO : -5.069 per-word bound, 33.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,095 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:30,107 : INFO : topic #6 (0.100): 0.034*\"bar\" + 0.017*\"saturated\" + 0.017*\"energy\" + 0.015*\"fat\" + 0.013*\"much\" + 0.012*\"higher\" + 0.012*\"contain\" + 0.012*\"protein\" + 0.012*\"gram\" + 0.012*\"others\"\n",
      "2019-10-29 00:37:30,110 : INFO : topic #4 (0.100): 0.053*\"bar\" + 0.029*\"energy\" + 0.028*\"saturated\" + 0.022*\"fat\" + 0.020*\"sugar\" + 0.017*\"higher\" + 0.015*\"others\" + 0.015*\"much\" + 0.015*\"gram\" + 0.014*\"contain\"\n",
      "2019-10-29 00:37:30,113 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"satisfying\" + 0.009*\"contain\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,117 : INFO : topic #3 (0.100): 0.053*\"bar\" + 0.023*\"energy\" + 0.022*\"fat\" + 0.018*\"saturated\" + 0.014*\"contain\" + 0.014*\"sugar\" + 0.014*\"much\" + 0.014*\"higher\" + 0.014*\"others\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:30,121 : INFO : topic #9 (0.100): 0.052*\"bar\" + 0.028*\"energy\" + 0.026*\"saturated\" + 0.023*\"fat\" + 0.015*\"nutrition\" + 0.015*\"others\" + 0.014*\"higher\" + 0.014*\"syrup\" + 0.013*\"protein\" + 0.013*\"gram\"\n",
      "2019-10-29 00:37:30,125 : INFO : topic diff=0.757701, rho=0.500000\n",
      "2019-10-29 00:37:30,181 : INFO : -4.947 per-word bound, 30.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,183 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:30,191 : INFO : topic #6 (0.100): 0.025*\"bar\" + 0.014*\"saturated\" + 0.014*\"energy\" + 0.013*\"fat\" + 0.011*\"much\" + 0.011*\"higher\" + 0.011*\"contain\" + 0.011*\"protein\" + 0.011*\"gram\" + 0.011*\"others\"\n",
      "2019-10-29 00:37:30,193 : INFO : topic #3 (0.100): 0.041*\"bar\" + 0.019*\"energy\" + 0.018*\"fat\" + 0.015*\"saturated\" + 0.013*\"contain\" + 0.013*\"sugar\" + 0.013*\"much\" + 0.012*\"higher\" + 0.012*\"others\" + 0.012*\"protein\"\n",
      "2019-10-29 00:37:30,195 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"satisfying\" + 0.009*\"contain\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,196 : INFO : topic #4 (0.100): 0.044*\"bar\" + 0.025*\"energy\" + 0.024*\"saturated\" + 0.019*\"fat\" + 0.018*\"sugar\" + 0.016*\"higher\" + 0.014*\"others\" + 0.014*\"much\" + 0.013*\"gram\" + 0.013*\"contain\"\n",
      "2019-10-29 00:37:30,197 : INFO : topic #9 (0.100): 0.042*\"bar\" + 0.024*\"energy\" + 0.022*\"saturated\" + 0.020*\"fat\" + 0.014*\"nutrition\" + 0.013*\"others\" + 0.013*\"higher\" + 0.013*\"syrup\" + 0.012*\"protein\" + 0.012*\"gram\"\n",
      "2019-10-29 00:37:30,199 : INFO : topic diff=0.602462, rho=0.447214\n",
      "2019-10-29 00:37:30,249 : INFO : -4.883 per-word bound, 29.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,251 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:30,260 : INFO : topic #9 (0.100): 0.033*\"bar\" + 0.020*\"energy\" + 0.019*\"saturated\" + 0.017*\"fat\" + 0.013*\"nutrition\" + 0.012*\"others\" + 0.012*\"higher\" + 0.012*\"syrup\" + 0.011*\"protein\" + 0.011*\"gram\"\n",
      "2019-10-29 00:37:30,262 : INFO : topic #3 (0.100): 0.031*\"bar\" + 0.016*\"energy\" + 0.015*\"fat\" + 0.013*\"saturated\" + 0.012*\"contain\" + 0.012*\"sugar\" + 0.011*\"much\" + 0.011*\"higher\" + 0.011*\"others\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:30,263 : INFO : topic #4 (0.100): 0.036*\"bar\" + 0.021*\"energy\" + 0.021*\"saturated\" + 0.017*\"fat\" + 0.016*\"sugar\" + 0.014*\"higher\" + 0.013*\"others\" + 0.012*\"much\" + 0.012*\"gram\" + 0.012*\"contain\"\n",
      "2019-10-29 00:37:30,265 : INFO : topic #8 (0.100): 0.020*\"bar\" + 0.014*\"energy\" + 0.012*\"fat\" + 0.012*\"saturated\" + 0.011*\"sugar\" + 0.011*\"much\" + 0.011*\"higher\" + 0.010*\"contain\" + 0.010*\"calorie\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:30,266 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"satisfying\" + 0.009*\"amount\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,267 : INFO : topic diff=0.453533, rho=0.408248\n",
      "2019-10-29 00:37:30,321 : INFO : -4.851 per-word bound, 28.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,323 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:30,334 : INFO : topic #4 (0.100): 0.029*\"bar\" + 0.018*\"energy\" + 0.018*\"saturated\" + 0.015*\"fat\" + 0.014*\"sugar\" + 0.013*\"higher\" + 0.012*\"others\" + 0.012*\"much\" + 0.012*\"gram\" + 0.011*\"contain\"\n",
      "2019-10-29 00:37:30,336 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"satisfying\" + 0.009*\"contain\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,339 : INFO : topic #8 (0.100): 0.017*\"bar\" + 0.012*\"energy\" + 0.011*\"fat\" + 0.011*\"saturated\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"higher\" + 0.010*\"contain\" + 0.010*\"calorie\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:30,346 : INFO : topic #3 (0.100): 0.024*\"bar\" + 0.014*\"energy\" + 0.013*\"fat\" + 0.012*\"saturated\" + 0.011*\"contain\" + 0.011*\"sugar\" + 0.011*\"much\" + 0.011*\"higher\" + 0.011*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:30,349 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,350 : INFO : topic diff=0.329009, rho=0.377964\n",
      "2019-10-29 00:37:30,402 : INFO : -4.835 per-word bound, 28.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:30,404 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:30,415 : INFO : topic #9 (0.100): 0.021*\"bar\" + 0.014*\"energy\" + 0.014*\"saturated\" + 0.013*\"fat\" + 0.011*\"nutrition\" + 0.011*\"others\" + 0.011*\"higher\" + 0.010*\"syrup\" + 0.010*\"protein\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:30,417 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"much\" + 0.009*\"amount\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:30,419 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,421 : INFO : topic #3 (0.100): 0.020*\"bar\" + 0.012*\"energy\" + 0.012*\"fat\" + 0.011*\"saturated\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"higher\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:30,425 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,430 : INFO : topic diff=0.233671, rho=0.353553\n",
      "2019-10-29 00:37:30,484 : INFO : -4.826 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,486 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:30,498 : INFO : topic #9 (0.100): 0.018*\"bar\" + 0.013*\"energy\" + 0.012*\"saturated\" + 0.012*\"fat\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"syrup\" + 0.010*\"protein\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:30,502 : INFO : topic #0 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:30,505 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"satisfying\" + 0.009*\"amount\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,508 : INFO : topic #6 (0.100): 0.012*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,511 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,513 : INFO : topic diff=0.164379, rho=0.333333\n",
      "2019-10-29 00:37:30,560 : INFO : -4.822 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,562 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:30,569 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"satisfying\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"fiber\"\n",
      "2019-10-29 00:37:30,571 : INFO : topic #3 (0.100): 0.014*\"bar\" + 0.011*\"energy\" + 0.011*\"fat\" + 0.010*\"saturated\" + 0.010*\"contain\" + 0.010*\"sugar\" + 0.010*\"much\" + 0.010*\"higher\" + 0.010*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,574 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"satisfying\"\n",
      "2019-10-29 00:37:30,576 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"saturated\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,579 : INFO : topic #9 (0.100): 0.015*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.011*\"fat\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"syrup\" + 0.010*\"protein\" + 0.010*\"gram\"\n",
      "2019-10-29 00:37:30,580 : INFO : topic diff=0.115412, rho=0.316228\n",
      "2019-10-29 00:37:30,631 : INFO : -4.820 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,633 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:30,645 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:30,648 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,651 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fiber\" + 0.009*\"source\" + 0.009*\"snicker\" + 0.009*\"afford\" + 0.009*\"satisfying\"\n",
      "2019-10-29 00:37:30,653 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,656 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,660 : INFO : topic diff=0.081256, rho=0.301511\n",
      "2019-10-29 00:37:30,710 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,712 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:30,720 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,723 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,727 : INFO : topic #3 (0.100): 0.012*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.010*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,730 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,733 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,735 : INFO : topic diff=0.057525, rho=0.288675\n",
      "2019-10-29 00:37:30,792 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,795 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:30,807 : INFO : topic #9 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:30,811 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,813 : INFO : topic #3 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,815 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"energy\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"amount\"\n",
      "2019-10-29 00:37:30,817 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:30,818 : INFO : topic diff=0.041016, rho=0.277350\n",
      "2019-10-29 00:37:30,875 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,878 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:30,883 : INFO : topic #9 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:30,886 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,887 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:30,889 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,891 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,894 : INFO : topic diff=0.029480, rho=0.267261\n",
      "2019-10-29 00:37:30,944 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:30,947 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:30,958 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:30,961 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:30,963 : INFO : topic #2 (0.100): 0.009*\"energy\" + 0.009*\"bar\" + 0.009*\"snicker\" + 0.009*\"sugar\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"convenient\" + 0.009*\"source\" + 0.009*\"higher\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:30,965 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"source\" + 0.009*\"afford\" + 0.009*\"energy\" + 0.009*\"satisfying\" + 0.009*\"fiber\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:30,967 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:30,969 : INFO : topic diff=0.021367, rho=0.258199\n",
      "2019-10-29 00:37:31,036 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,039 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:31,050 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"protein\" + 0.009*\"fat\"\n",
      "2019-10-29 00:37:31,053 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,059 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,064 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:31,066 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,069 : INFO : topic diff=0.015621, rho=0.250000\n",
      "2019-10-29 00:37:31,137 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,139 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:31,150 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,152 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,154 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:31,156 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,158 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"satisfying\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"fat\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:31,161 : INFO : topic diff=0.011518, rho=0.242536\n",
      "2019-10-29 00:37:31,229 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,230 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:31,240 : INFO : topic #9 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:31,242 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,245 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,247 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,249 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,251 : INFO : topic diff=0.008564, rho=0.235702\n",
      "2019-10-29 00:37:31,312 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,314 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:31,322 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nutrition\" + 0.009*\"palate\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,326 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:31,329 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,331 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:31,333 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,336 : INFO : topic diff=0.006420, rho=0.229416\n",
      "2019-10-29 00:37:31,375 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,377 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:31,382 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,385 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:31,387 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,390 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,393 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:31,397 : INFO : topic diff=0.004849, rho=0.223607\n",
      "2019-10-29 00:37:31,456 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,461 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:31,470 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,472 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,476 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,479 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:31,482 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:31,483 : INFO : topic diff=0.003691, rho=0.218218\n",
      "2019-10-29 00:37:31,532 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,534 : INFO : PROGRESS: pass 20, at document #5/5\n",
      "2019-10-29 00:37:31,542 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,545 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,547 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:31,549 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:31,552 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,555 : INFO : topic diff=0.002828, rho=0.213201\n",
      "2019-10-29 00:37:31,613 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,614 : INFO : PROGRESS: pass 21, at document #5/5\n",
      "2019-10-29 00:37:31,623 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:31,626 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,630 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:31,633 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,636 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,638 : INFO : topic diff=0.002182, rho=0.208514\n",
      "2019-10-29 00:37:31,704 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,705 : INFO : PROGRESS: pass 22, at document #5/5\n",
      "2019-10-29 00:37:31,715 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,719 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,727 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:31,731 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,733 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,735 : INFO : topic diff=0.001694, rho=0.204124\n",
      "2019-10-29 00:37:31,806 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,808 : INFO : PROGRESS: pass 23, at document #5/5\n",
      "2019-10-29 00:37:31,820 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,822 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:31,825 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,829 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:31,834 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:31,837 : INFO : topic diff=0.001323, rho=0.200000\n",
      "2019-10-29 00:37:31,894 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:31,896 : INFO : PROGRESS: pass 24, at document #5/5\n",
      "2019-10-29 00:37:31,903 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:31,906 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,912 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:31,916 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:31,921 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:31,926 : INFO : topic diff=0.001039, rho=0.196116\n",
      "2019-10-29 00:37:32,012 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,025 : INFO : PROGRESS: pass 25, at document #5/5\n",
      "2019-10-29 00:37:32,036 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,038 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,042 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,045 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,048 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,057 : INFO : topic diff=0.000821, rho=0.192450\n",
      "2019-10-29 00:37:32,130 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,132 : INFO : PROGRESS: pass 26, at document #5/5\n",
      "2019-10-29 00:37:32,142 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,149 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,156 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,158 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:32,163 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,167 : INFO : topic diff=0.000651, rho=0.188982\n",
      "2019-10-29 00:37:32,220 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,223 : INFO : PROGRESS: pass 27, at document #5/5\n",
      "2019-10-29 00:37:32,231 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,234 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,236 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,239 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,241 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:32,242 : INFO : topic diff=0.000519, rho=0.185695\n",
      "2019-10-29 00:37:32,292 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,294 : INFO : PROGRESS: pass 28, at document #5/5\n",
      "2019-10-29 00:37:32,302 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,304 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:32,306 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,309 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,312 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,314 : INFO : topic diff=0.000416, rho=0.182574\n",
      "2019-10-29 00:37:32,358 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,360 : INFO : PROGRESS: pass 29, at document #5/5\n",
      "2019-10-29 00:37:32,370 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,372 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,375 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,377 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,380 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,383 : INFO : topic diff=0.000335, rho=0.179605\n",
      "2019-10-29 00:37:32,425 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,428 : INFO : PROGRESS: pass 30, at document #5/5\n",
      "2019-10-29 00:37:32,437 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,439 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,442 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,446 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:32,448 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,449 : INFO : topic diff=0.000270, rho=0.176777\n",
      "2019-10-29 00:37:32,497 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,498 : INFO : PROGRESS: pass 31, at document #5/5\n",
      "2019-10-29 00:37:32,506 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,508 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:32,511 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"protein\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,514 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,517 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:32,520 : INFO : topic diff=0.000219, rho=0.174078\n",
      "2019-10-29 00:37:32,560 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,562 : INFO : PROGRESS: pass 32, at document #5/5\n",
      "2019-10-29 00:37:32,570 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,573 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,575 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,578 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,579 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,582 : INFO : topic diff=0.000178, rho=0.171499\n",
      "2019-10-29 00:37:32,625 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,627 : INFO : PROGRESS: pass 33, at document #5/5\n",
      "2019-10-29 00:37:32,636 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,638 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,640 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:32,642 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,644 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,646 : INFO : topic diff=0.000146, rho=0.169031\n",
      "2019-10-29 00:37:32,693 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,695 : INFO : PROGRESS: pass 34, at document #5/5\n",
      "2019-10-29 00:37:32,704 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,706 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:32,709 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:32,712 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,714 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"meal\" + 0.009*\"syrup\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,716 : INFO : topic diff=0.000119, rho=0.166667\n",
      "2019-10-29 00:37:32,761 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,764 : INFO : PROGRESS: pass 35, at document #5/5\n",
      "2019-10-29 00:37:32,773 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,776 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:32,779 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"syrup\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:32,782 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,785 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,787 : INFO : topic diff=0.000098, rho=0.164399\n",
      "2019-10-29 00:37:32,841 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,844 : INFO : PROGRESS: pass 36, at document #5/5\n",
      "2019-10-29 00:37:32,852 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"syrup\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:32,853 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:32,855 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,856 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,859 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:32,861 : INFO : topic diff=0.000081, rho=0.162221\n",
      "2019-10-29 00:37:32,913 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:32,915 : INFO : PROGRESS: pass 37, at document #5/5\n",
      "2019-10-29 00:37:32,924 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,926 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:32,931 : INFO : topic #7 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:32,934 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:32,936 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:32,939 : INFO : topic diff=0.000067, rho=0.160128\n",
      "2019-10-29 00:37:33,000 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,003 : INFO : PROGRESS: pass 38, at document #5/5\n",
      "2019-10-29 00:37:33,011 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:33,014 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:33,017 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"syrup\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:33,020 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:33,023 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"calorie\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:33,026 : INFO : topic diff=0.000056, rho=0.158114\n",
      "2019-10-29 00:37:33,102 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,108 : INFO : PROGRESS: pass 39, at document #5/5\n",
      "2019-10-29 00:37:33,116 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"syrup\" + 0.009*\"protein\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:33,119 : INFO : topic #2 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:33,122 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:33,124 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"nutrition\" + 0.009*\"much\" + 0.009*\"syrup\" + 0.009*\"sugar\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:33,128 : INFO : topic #1 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"nutrition\" + 0.018*\"gram\" + 0.018*\"contain\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:33,131 : INFO : topic diff=0.000046, rho=0.156174\n",
      "2019-10-29 00:37:33,261 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.817277975195259 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:33,321 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,324 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:33,325 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:33,328 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:33,331 : INFO : running online (multi-pass) LDA training, 10 topics, 45 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:33,417 : INFO : -6.798 per-word bound, 111.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,419 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:33,458 : INFO : topic #6 (0.100): 0.076*\"bar\" + 0.030*\"energy\" + 0.028*\"saturated\" + 0.021*\"gram\" + 0.019*\"fat\" + 0.016*\"contain\" + 0.015*\"nutrition\" + 0.015*\"others\" + 0.015*\"higher\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:33,460 : INFO : topic #4 (0.100): 0.042*\"bar\" + 0.029*\"energy\" + 0.024*\"saturated\" + 0.019*\"contain\" + 0.018*\"fat\" + 0.016*\"much\" + 0.015*\"protein\" + 0.015*\"gram\" + 0.015*\"higher\" + 0.013*\"others\"\n",
      "2019-10-29 00:37:33,464 : INFO : topic #2 (0.100): 0.084*\"bar\" + 0.027*\"energy\" + 0.024*\"saturated\" + 0.024*\"fat\" + 0.022*\"much\" + 0.018*\"contain\" + 0.018*\"higher\" + 0.017*\"gram\" + 0.016*\"nutrition\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:33,467 : INFO : topic #3 (0.100): 0.061*\"bar\" + 0.026*\"energy\" + 0.025*\"saturated\" + 0.018*\"fat\" + 0.018*\"gram\" + 0.017*\"higher\" + 0.015*\"much\" + 0.015*\"nutrition\" + 0.015*\"others\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:33,470 : INFO : topic #8 (0.100): 0.015*\"bar\" + 0.012*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"protein\" + 0.010*\"gram\" + 0.010*\"others\" + 0.010*\"sugar\" + 0.010*\"higher\" + 0.010*\"contain\"\n",
      "2019-10-29 00:37:33,473 : INFO : topic diff=2.958542, rho=1.000000\n",
      "2019-10-29 00:37:33,549 : INFO : -5.377 per-word bound, 41.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,551 : INFO : PROGRESS: pass 1, at document #5/5\n",
      "2019-10-29 00:37:33,569 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:33,572 : INFO : topic #3 (0.100): 0.046*\"bar\" + 0.021*\"energy\" + 0.020*\"saturated\" + 0.015*\"fat\" + 0.015*\"gram\" + 0.015*\"higher\" + 0.013*\"much\" + 0.013*\"nutrition\" + 0.013*\"others\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:33,573 : INFO : topic #6 (0.100): 0.062*\"bar\" + 0.025*\"energy\" + 0.024*\"saturated\" + 0.019*\"gram\" + 0.017*\"fat\" + 0.015*\"contain\" + 0.014*\"nutrition\" + 0.014*\"others\" + 0.014*\"higher\" + 0.013*\"protein\"\n",
      "2019-10-29 00:37:33,575 : INFO : topic #2 (0.100): 0.076*\"bar\" + 0.025*\"energy\" + 0.023*\"saturated\" + 0.022*\"fat\" + 0.020*\"much\" + 0.017*\"contain\" + 0.017*\"higher\" + 0.016*\"gram\" + 0.015*\"nutrition\" + 0.015*\"others\"\n",
      "2019-10-29 00:37:33,577 : INFO : topic #7 (0.100): 0.070*\"bar\" + 0.033*\"energy\" + 0.025*\"fat\" + 0.018*\"contain\" + 0.018*\"saturated\" + 0.016*\"nutrition\" + 0.016*\"higher\" + 0.016*\"protein\" + 0.015*\"others\" + 0.014*\"much\"\n",
      "2019-10-29 00:37:33,579 : INFO : topic diff=0.850969, rho=0.577350\n",
      "2019-10-29 00:37:33,645 : INFO : -5.108 per-word bound, 34.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,648 : INFO : PROGRESS: pass 2, at document #5/5\n",
      "2019-10-29 00:37:33,662 : INFO : topic #2 (0.100): 0.065*\"bar\" + 0.022*\"energy\" + 0.020*\"saturated\" + 0.020*\"fat\" + 0.018*\"much\" + 0.016*\"contain\" + 0.016*\"higher\" + 0.015*\"gram\" + 0.014*\"nutrition\" + 0.014*\"others\"\n",
      "2019-10-29 00:37:33,664 : INFO : topic #6 (0.100): 0.048*\"bar\" + 0.021*\"energy\" + 0.020*\"saturated\" + 0.016*\"gram\" + 0.015*\"fat\" + 0.013*\"contain\" + 0.013*\"nutrition\" + 0.013*\"others\" + 0.013*\"higher\" + 0.012*\"protein\"\n",
      "2019-10-29 00:37:33,667 : INFO : topic #5 (0.100): 0.058*\"bar\" + 0.022*\"fat\" + 0.022*\"energy\" + 0.022*\"saturated\" + 0.020*\"others\" + 0.018*\"contain\" + 0.017*\"gram\" + 0.016*\"protein\" + 0.016*\"much\" + 0.015*\"nutrition\"\n",
      "2019-10-29 00:37:33,670 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.030*\"fat\" + 0.030*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.017*\"much\" + 0.017*\"others\"\n",
      "2019-10-29 00:37:33,673 : INFO : topic #0 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"contain\" + 0.010*\"higher\" + 0.010*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:33,675 : INFO : topic diff=0.760091, rho=0.500000\n",
      "2019-10-29 00:37:33,744 : INFO : -4.969 per-word bound, 31.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,748 : INFO : PROGRESS: pass 3, at document #5/5\n",
      "2019-10-29 00:37:33,760 : INFO : topic #8 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:33,763 : INFO : topic #7 (0.100): 0.045*\"bar\" + 0.023*\"energy\" + 0.019*\"fat\" + 0.015*\"contain\" + 0.014*\"saturated\" + 0.013*\"nutrition\" + 0.013*\"higher\" + 0.013*\"protein\" + 0.013*\"others\" + 0.012*\"much\"\n",
      "2019-10-29 00:37:33,767 : INFO : topic #3 (0.100): 0.025*\"bar\" + 0.014*\"energy\" + 0.014*\"saturated\" + 0.012*\"fat\" + 0.012*\"gram\" + 0.012*\"higher\" + 0.011*\"much\" + 0.011*\"nutrition\" + 0.011*\"others\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:33,769 : INFO : topic #6 (0.100): 0.037*\"bar\" + 0.018*\"energy\" + 0.017*\"saturated\" + 0.014*\"gram\" + 0.013*\"fat\" + 0.012*\"contain\" + 0.012*\"nutrition\" + 0.012*\"others\" + 0.012*\"higher\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:33,772 : INFO : topic #5 (0.100): 0.048*\"bar\" + 0.020*\"fat\" + 0.019*\"energy\" + 0.019*\"saturated\" + 0.018*\"others\" + 0.016*\"contain\" + 0.015*\"gram\" + 0.014*\"protein\" + 0.014*\"much\" + 0.013*\"nutrition\"\n",
      "2019-10-29 00:37:33,775 : INFO : topic diff=0.630437, rho=0.447214\n",
      "2019-10-29 00:37:33,831 : INFO : -4.896 per-word bound, 29.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,834 : INFO : PROGRESS: pass 4, at document #5/5\n",
      "2019-10-29 00:37:33,845 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:33,848 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:33,851 : INFO : topic #2 (0.100): 0.042*\"bar\" + 0.017*\"energy\" + 0.016*\"saturated\" + 0.016*\"fat\" + 0.014*\"much\" + 0.013*\"contain\" + 0.013*\"higher\" + 0.013*\"gram\" + 0.012*\"nutrition\" + 0.012*\"others\"\n",
      "2019-10-29 00:37:33,853 : INFO : topic #3 (0.100): 0.019*\"bar\" + 0.012*\"energy\" + 0.012*\"saturated\" + 0.011*\"fat\" + 0.011*\"gram\" + 0.011*\"higher\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:33,855 : INFO : topic #6 (0.100): 0.028*\"bar\" + 0.015*\"energy\" + 0.014*\"saturated\" + 0.012*\"gram\" + 0.012*\"fat\" + 0.011*\"contain\" + 0.011*\"nutrition\" + 0.011*\"others\" + 0.011*\"higher\" + 0.011*\"protein\"\n",
      "2019-10-29 00:37:33,858 : INFO : topic diff=0.488944, rho=0.408248\n",
      "2019-10-29 00:37:33,901 : INFO : -4.858 per-word bound, 29.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,903 : INFO : PROGRESS: pass 5, at document #5/5\n",
      "2019-10-29 00:37:33,912 : INFO : topic #5 (0.100): 0.030*\"bar\" + 0.015*\"fat\" + 0.015*\"energy\" + 0.015*\"saturated\" + 0.014*\"others\" + 0.013*\"contain\" + 0.012*\"gram\" + 0.012*\"protein\" + 0.012*\"much\" + 0.011*\"nutrition\"\n",
      "2019-10-29 00:37:33,915 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:33,917 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:33,918 : INFO : topic #6 (0.100): 0.022*\"bar\" + 0.013*\"energy\" + 0.013*\"saturated\" + 0.011*\"gram\" + 0.011*\"fat\" + 0.010*\"contain\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"higher\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:33,920 : INFO : topic #3 (0.100): 0.016*\"bar\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"higher\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:33,921 : INFO : topic diff=0.361996, rho=0.377964\n",
      "2019-10-29 00:37:33,969 : INFO : -4.838 per-word bound, 28.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:33,970 : INFO : PROGRESS: pass 6, at document #5/5\n",
      "2019-10-29 00:37:33,979 : INFO : topic #2 (0.100): 0.026*\"bar\" + 0.013*\"energy\" + 0.013*\"saturated\" + 0.012*\"fat\" + 0.012*\"much\" + 0.011*\"contain\" + 0.011*\"higher\" + 0.011*\"gram\" + 0.011*\"nutrition\" + 0.010*\"others\"\n",
      "2019-10-29 00:37:33,982 : INFO : topic #7 (0.100): 0.022*\"bar\" + 0.014*\"energy\" + 0.012*\"fat\" + 0.011*\"contain\" + 0.011*\"saturated\" + 0.011*\"nutrition\" + 0.011*\"higher\" + 0.011*\"protein\" + 0.010*\"others\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:33,985 : INFO : topic #3 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"fat\" + 0.010*\"gram\" + 0.010*\"higher\" + 0.010*\"much\" + 0.010*\"nutrition\" + 0.010*\"others\" + 0.010*\"protein\"\n",
      "2019-10-29 00:37:33,988 : INFO : topic #5 (0.100): 0.024*\"bar\" + 0.013*\"fat\" + 0.013*\"energy\" + 0.013*\"saturated\" + 0.012*\"others\" + 0.012*\"contain\" + 0.011*\"gram\" + 0.011*\"protein\" + 0.011*\"much\" + 0.011*\"nutrition\"\n",
      "2019-10-29 00:37:33,993 : INFO : topic #4 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"contain\" + 0.010*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:33,995 : INFO : topic diff=0.260654, rho=0.353553\n",
      "2019-10-29 00:37:34,042 : INFO : -4.828 per-word bound, 28.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,044 : INFO : PROGRESS: pass 7, at document #5/5\n",
      "2019-10-29 00:37:34,054 : INFO : topic #7 (0.100): 0.018*\"bar\" + 0.013*\"energy\" + 0.011*\"fat\" + 0.010*\"contain\" + 0.010*\"saturated\" + 0.010*\"nutrition\" + 0.010*\"higher\" + 0.010*\"protein\" + 0.010*\"others\" + 0.010*\"much\"\n",
      "2019-10-29 00:37:34,056 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,059 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,062 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,065 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:34,068 : INFO : topic diff=0.185046, rho=0.333333\n",
      "2019-10-29 00:37:34,119 : INFO : -4.823 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,121 : INFO : PROGRESS: pass 8, at document #5/5\n",
      "2019-10-29 00:37:34,127 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,130 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,132 : INFO : topic #6 (0.100): 0.013*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"gram\" + 0.010*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,135 : INFO : topic #5 (0.100): 0.017*\"bar\" + 0.011*\"fat\" + 0.011*\"energy\" + 0.011*\"saturated\" + 0.011*\"others\" + 0.010*\"contain\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:34,137 : INFO : topic #3 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,140 : INFO : topic diff=0.130720, rho=0.316228\n",
      "2019-10-29 00:37:34,192 : INFO : -4.820 per-word bound, 28.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,194 : INFO : PROGRESS: pass 9, at document #5/5\n",
      "2019-10-29 00:37:34,202 : INFO : topic #5 (0.100): 0.015*\"bar\" + 0.011*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"contain\" + 0.010*\"gram\" + 0.010*\"protein\" + 0.010*\"much\" + 0.010*\"nutrition\"\n",
      "2019-10-29 00:37:34,204 : INFO : topic #4 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,205 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,207 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,208 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:34,209 : INFO : topic diff=0.092426, rho=0.301511\n",
      "2019-10-29 00:37:34,261 : INFO : -4.819 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,263 : INFO : PROGRESS: pass 10, at document #5/5\n",
      "2019-10-29 00:37:34,273 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:34,275 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,278 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:34,279 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,282 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,285 : INFO : topic diff=0.065640, rho=0.288675\n",
      "2019-10-29 00:37:34,333 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,335 : INFO : PROGRESS: pass 11, at document #5/5\n",
      "2019-10-29 00:37:34,342 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,345 : INFO : topic #5 (0.100): 0.012*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.010*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,347 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,351 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:34,353 : INFO : topic #6 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,355 : INFO : topic diff=0.046918, rho=0.277350\n",
      "2019-10-29 00:37:34,408 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,410 : INFO : PROGRESS: pass 12, at document #5/5\n",
      "2019-10-29 00:37:34,418 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,421 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,424 : INFO : topic #7 (0.100): 0.011*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:34,426 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.010*\"fat\" + 0.010*\"energy\" + 0.010*\"saturated\" + 0.010*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,428 : INFO : topic #3 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,429 : INFO : topic diff=0.033791, rho=0.267261\n",
      "2019-10-29 00:37:34,482 : INFO : -4.818 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,484 : INFO : PROGRESS: pass 13, at document #5/5\n",
      "2019-10-29 00:37:34,494 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,496 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.010*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:34,500 : INFO : topic #2 (0.100): 0.011*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,503 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,505 : INFO : topic #5 (0.100): 0.011*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,508 : INFO : topic diff=0.024534, rho=0.258199\n",
      "2019-10-29 00:37:34,555 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,557 : INFO : PROGRESS: pass 14, at document #5/5\n",
      "2019-10-29 00:37:34,564 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:34,567 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,570 : INFO : topic #7 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:34,573 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,576 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,578 : INFO : topic diff=0.017962, rho=0.250000\n",
      "2019-10-29 00:37:34,621 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,623 : INFO : PROGRESS: pass 15, at document #5/5\n",
      "2019-10-29 00:37:34,631 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,633 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,636 : INFO : topic #6 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,638 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,640 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,641 : INFO : topic diff=0.013259, rho=0.242536\n",
      "2019-10-29 00:37:34,692 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,694 : INFO : PROGRESS: pass 16, at document #5/5\n",
      "2019-10-29 00:37:34,702 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,704 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:34,707 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,709 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:34,711 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,713 : INFO : topic diff=0.009868, rho=0.235702\n",
      "2019-10-29 00:37:34,757 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,759 : INFO : PROGRESS: pass 17, at document #5/5\n",
      "2019-10-29 00:37:34,768 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:34,770 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:34,772 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:34,774 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,777 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:34,780 : INFO : topic diff=0.007402, rho=0.229416\n",
      "2019-10-29 00:37:34,837 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,840 : INFO : PROGRESS: pass 18, at document #5/5\n",
      "2019-10-29 00:37:34,846 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,849 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,852 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:34,854 : INFO : topic #2 (0.100): 0.010*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,857 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,860 : INFO : topic diff=0.005595, rho=0.223607\n",
      "2019-10-29 00:37:34,904 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,905 : INFO : PROGRESS: pass 19, at document #5/5\n",
      "2019-10-29 00:37:34,914 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:34,915 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,917 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,918 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,920 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,922 : INFO : topic diff=0.004260, rho=0.218218\n",
      "2019-10-29 00:37:34,971 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:34,973 : INFO : PROGRESS: pass 20, at document #5/5\n",
      "2019-10-29 00:37:34,980 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:34,982 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,984 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:34,986 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:34,987 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:34,989 : INFO : topic diff=0.003266, rho=0.213201\n",
      "2019-10-29 00:37:35,038 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,040 : INFO : PROGRESS: pass 21, at document #5/5\n",
      "2019-10-29 00:37:35,049 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,053 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"much\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"syrup\"\n",
      "2019-10-29 00:37:35,057 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,060 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,063 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:35,068 : INFO : topic diff=0.002521, rho=0.208514\n",
      "2019-10-29 00:37:35,145 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,147 : INFO : PROGRESS: pass 22, at document #5/5\n",
      "2019-10-29 00:37:35,160 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,162 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,164 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,167 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,170 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,172 : INFO : topic diff=0.001957, rho=0.204124\n",
      "2019-10-29 00:37:35,213 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,215 : INFO : PROGRESS: pass 23, at document #5/5\n",
      "2019-10-29 00:37:35,224 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,228 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,233 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"syrup\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,237 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,240 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,242 : INFO : topic diff=0.001529, rho=0.200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:35,294 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,296 : INFO : PROGRESS: pass 24, at document #5/5\n",
      "2019-10-29 00:37:35,304 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,306 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,309 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,312 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,316 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,320 : INFO : topic diff=0.001201, rho=0.196116\n",
      "2019-10-29 00:37:35,365 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,366 : INFO : PROGRESS: pass 25, at document #5/5\n",
      "2019-10-29 00:37:35,374 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"source\" + 0.009*\"afford\" + 0.009*\"sugar\" + 0.009*\"convenient\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,376 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,378 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,381 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,384 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,386 : INFO : topic diff=0.000948, rho=0.192450\n",
      "2019-10-29 00:37:35,434 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,436 : INFO : PROGRESS: pass 26, at document #5/5\n",
      "2019-10-29 00:37:35,443 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"source\" + 0.009*\"nutrition\" + 0.009*\"snack\" + 0.009*\"protein\" + 0.009*\"saturated\"\n",
      "2019-10-29 00:37:35,446 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,448 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,451 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,454 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,456 : INFO : topic diff=0.000753, rho=0.188982\n",
      "2019-10-29 00:37:35,500 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,502 : INFO : PROGRESS: pass 27, at document #5/5\n",
      "2019-10-29 00:37:35,509 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"snack\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,511 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,514 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,516 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,518 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,520 : INFO : topic diff=0.000600, rho=0.185695\n",
      "2019-10-29 00:37:35,562 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,563 : INFO : PROGRESS: pass 28, at document #5/5\n",
      "2019-10-29 00:37:35,571 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,574 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,575 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,577 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:35,579 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,582 : INFO : topic diff=0.000481, rho=0.182574\n",
      "2019-10-29 00:37:35,631 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,634 : INFO : PROGRESS: pass 29, at document #5/5\n",
      "2019-10-29 00:37:35,643 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,646 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,648 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,651 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,654 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,657 : INFO : topic diff=0.000387, rho=0.179605\n",
      "2019-10-29 00:37:35,709 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:35,711 : INFO : PROGRESS: pass 30, at document #5/5\n",
      "2019-10-29 00:37:35,724 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,733 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,737 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:35,740 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,743 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"afford\" + 0.009*\"dinner\" + 0.009*\"fiber\" + 0.009*\"convenient\" + 0.009*\"source\" + 0.009*\"satisfying\" + 0.009*\"snicker\"\n",
      "2019-10-29 00:37:35,747 : INFO : topic diff=0.000312, rho=0.176777\n",
      "2019-10-29 00:37:35,821 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,824 : INFO : PROGRESS: pass 31, at document #5/5\n",
      "2019-10-29 00:37:35,833 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,836 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,839 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:35,843 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,845 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:35,848 : INFO : topic diff=0.000253, rho=0.174078\n",
      "2019-10-29 00:37:35,919 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:35,922 : INFO : PROGRESS: pass 32, at document #5/5\n",
      "2019-10-29 00:37:35,931 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:35,933 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,935 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:35,937 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"contain\" + 0.009*\"satisfying\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"source\" + 0.009*\"higher\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"syrup\"\n",
      "2019-10-29 00:37:35,938 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:35,940 : INFO : topic diff=0.000206, rho=0.171499\n",
      "2019-10-29 00:37:36,006 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,009 : INFO : PROGRESS: pass 33, at document #5/5\n",
      "2019-10-29 00:37:36,018 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,021 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,024 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,026 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,029 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,031 : INFO : topic diff=0.000168, rho=0.169031\n",
      "2019-10-29 00:37:36,096 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,098 : INFO : PROGRESS: pass 34, at document #5/5\n",
      "2019-10-29 00:37:36,108 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,111 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,115 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:36,119 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,122 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,125 : INFO : topic diff=0.000138, rho=0.166667\n",
      "2019-10-29 00:37:36,183 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,186 : INFO : PROGRESS: pass 35, at document #5/5\n",
      "2019-10-29 00:37:36,194 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,197 : INFO : topic #1 (0.100): 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"often\" + 0.009*\"oil\"\n",
      "2019-10-29 00:37:36,200 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,203 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,205 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,208 : INFO : topic diff=0.000113, rho=0.164399\n",
      "2019-10-29 00:37:36,277 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,279 : INFO : PROGRESS: pass 36, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:36,289 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,293 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,295 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,297 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,299 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,301 : INFO : topic diff=0.000094, rho=0.162221\n",
      "2019-10-29 00:37:36,385 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,388 : INFO : PROGRESS: pass 37, at document #5/5\n",
      "2019-10-29 00:37:36,400 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,407 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,410 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,414 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,418 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,422 : INFO : topic diff=0.000077, rho=0.160128\n",
      "2019-10-29 00:37:36,485 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,487 : INFO : PROGRESS: pass 38, at document #5/5\n",
      "2019-10-29 00:37:36,496 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,499 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,503 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,506 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,509 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,512 : INFO : topic diff=0.000064, rho=0.158114\n",
      "2019-10-29 00:37:36,565 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,568 : INFO : PROGRESS: pass 39, at document #5/5\n",
      "2019-10-29 00:37:36,576 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:36,579 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,581 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,583 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,587 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:36,591 : INFO : topic diff=0.000053, rho=0.156174\n",
      "2019-10-29 00:37:36,645 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,647 : INFO : PROGRESS: pass 40, at document #5/5\n",
      "2019-10-29 00:37:36,655 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"nutrition\" + 0.009*\"saturated\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,657 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,660 : INFO : topic #1 (0.100): 0.009*\"bar\" + 0.009*\"palate\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:36,662 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:36,665 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,667 : INFO : topic diff=0.000045, rho=0.154303\n",
      "2019-10-29 00:37:36,712 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,714 : INFO : PROGRESS: pass 41, at document #5/5\n",
      "2019-10-29 00:37:36,722 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,725 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,727 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,729 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,732 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"higher\" + 0.018*\"protein\" + 0.018*\"much\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:36,735 : INFO : topic diff=0.000037, rho=0.152499\n",
      "2019-10-29 00:37:36,779 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,781 : INFO : PROGRESS: pass 42, at document #5/5\n",
      "2019-10-29 00:37:36,792 : INFO : topic #9 (0.100): 0.094*\"bar\" + 0.035*\"energy\" + 0.029*\"fat\" + 0.029*\"saturated\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"much\" + 0.018*\"others\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:36,793 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,795 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,797 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,798 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,799 : INFO : topic diff=0.000031, rho=0.150756\n",
      "2019-10-29 00:37:36,850 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,852 : INFO : PROGRESS: pass 43, at document #5/5\n",
      "2019-10-29 00:37:36,859 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,862 : INFO : topic #7 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:36,864 : INFO : topic #6 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"gram\" + 0.009*\"fat\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"higher\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,867 : INFO : topic #1 (0.100): 0.009*\"others\" + 0.009*\"palate\" + 0.009*\"nutritional\" + 0.009*\"nutritious\" + 0.009*\"often\" + 0.009*\"oil\" + 0.009*\"nut\" + 0.009*\"protein\" + 0.009*\"pick\" + 0.009*\"need\"\n",
      "2019-10-29 00:37:36,870 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"others\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:36,872 : INFO : topic diff=0.000026, rho=0.149071\n",
      "2019-10-29 00:37:36,915 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:36,917 : INFO : PROGRESS: pass 44, at document #5/5\n",
      "2019-10-29 00:37:36,927 : INFO : topic #5 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:36,930 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,931 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"much\" + 0.009*\"nutrition\" + 0.009*\"protein\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,933 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"fat\" + 0.009*\"much\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"higher\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:36,936 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"contain\"\n",
      "2019-10-29 00:37:36,938 : INFO : topic diff=0.000022, rho=0.147442\n",
      "2019-10-29 00:37:37,033 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:37,082 : INFO : -4.817 per-word bound, 28.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -4.81727692869288 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 실험값 담을 곳\n",
    "find_coherence=[]\n",
    "find_perplexity=[]\n",
    "find_pass=[]\n",
    "\n",
    "for i in range(10): # 10회 실험\n",
    "    t_Num_topic = 10 # 토픽 갯수\n",
    "    \n",
    "    # 실험에서 pass는 5씩 커지게 설정\n",
    "    if i==0:\n",
    "        p=1\n",
    "    else:\n",
    "        p=i*5\n",
    "            \n",
    "    # 실험\n",
    "    find_lda = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=t_Num_topic, passes=p) # p 값에 따라 실험하기\n",
    "    \n",
    "    # 실험값 담기 - Pass\n",
    "    print('Epoch', p)\n",
    "    find_pass.append(p)\n",
    "    \n",
    "    # 실험값 담기 - Coherence\n",
    "    t_cm = CoherenceModel(model=find_lda, corpus=corpus, coherence='u_mass')\n",
    "    t_coherence = t_cm.get_coherence()\n",
    "    print('Coherence', t_coherence)\n",
    "    find_coherence.append(t_coherence)\n",
    "    \n",
    "    # 실험값 담기 - perplexity\n",
    "    print('Perplexity', find_lda.log_perplexity(corpus),'\\n')\n",
    "    find_perplexity.append(find_lda.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb74c70f98>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFbhJREFUeJzt3X2MHPV9x/HPd/eefH723Rn8RO4MiSFpEtNcEhLaBBPSECcNQUqrVA1KpSYkUqlIlBSR9I/SSm1VBIFWSpGA0EZq2jQiUUsRTQSJ3dC0pRzggMExobeHH7F3zjb2zdk+3+63f+zaPs67d3u3eze383u/pJV3Hm7mez+4/czO/OY35u4CAIQnk3QBAIBkEAAAECgCAAACRQAAQKAIAAAIFAEAAIEiAAAgUAQAAASKAACAQLUkXcBUuru7vbe3N+kyAKBpPPPMM5G799Sy7oIOgN7eXg0MDCRdBgA0DTN7tdZ1OQUEAIFqWACY2VfNzM2su8ryO83sRTPbZWZ/Y2bWqH0DAGauIQFgZhskfVjSnirL3y/paknvkPQrkt4t6YON2DcAYHYa9Q3gHkm3Sao2trRL6pDUJqldUqukQw3aNwBgFuoOADP7hKT97v7zauu4+39L2ibpYPn1I3ffVWV7N5vZgJkN5PP5essDAFRRUy8gM3tC0sUVFv2xpK9L+o1pfv4ySVdIWl+e9biZfcDdfzp5XXe/X9L9ktTf38/TagBgjtQUAO5+XaX5ZvZ2SX2Sfl6+prte0rNm9h53f23CqjdK+h93Hyn/3L9LukrSBQEAAJgfdd0H4O4vSFp9dtrMhiT1u3s0adU9kj5vZn8pyVS6AHxvPfvG9IpF13jRVSi6xotFFYvSeLGoQtFVcNd4wc+9LxQnTxdL02eXFX3S9iZOF1UoqvQz5eWFor/hgtDEJ4/6pEtF1Z5KOvlxpW/cxuR1Z779mWjIV1Eev4oadba36IsfvHTO9zNnN4KZWb+kL7r75yQ9LOlaSS+o9Lf0Q3f/t7nad0jGxot6euiItu8+rO2789pzZPTcBzQWHjo/oxbdS9qbLwDcvXfC+wFJnyu/L0j6QiP3FbIDx05q++68tu0+rP96JVI8VlBr1vTevi5tuXy1WjKmlowpm8kom5GymUx5+vyrJWPKnFvP1DJp3Tcue+N0dsL2L1hmpmy29G9m0qfdVB9+E5eZrOL80rKJP2NTLJu8fT55gckW9FAQKDlTKGpg6Oi5o/zdh05IktatWKRPXrlO12xarfdf2qXF7fznBFA7PjEWqNdeP6Xtuw9r2+7D+tkrwxo5Pa7WrOndvav09Xddri2bVuuy1Us4sgUwawTAAnGmUNSzrx7Vtt15bd99WL94rXSUv2Z5h37znWt0zabVuvqybi3hKB9Ag/BpkqBDx0/pP3bntf3lw3ry5UgnTo+rJWPq712p2z96ua7Z1KNNFy3lKB/AnCAA5tF4oajn9h7Ttl+UzuW/dPC4JOmiZe3a+vY12nJ5j66+rFtLO1oTrhRACAiAOXb4xNmj/LyefDmv46fGlc2Y3vWmlbrt+k265i2rdcUajvIBzD8CoMEKRdeOvUfPddPcub90lN+ztF0fedvF2nJ56Vz+8kUc5QNIFgHQANHIaf305by27c7ryV/mdWz0jDImvetNK/VHH9mkD76lR29bu4yjfAALCgFQpxf2va5P/u3PVCi6upe060OXX6Qtl/fo1y/r0fJOjvIBLFwEQJ127D2qQtH1j59/r67q61Imw1E+gOZAANRpMIrV2ZbV+zZ2cYoHQFPhofB1ykWxersW8+EPoOkQAHXKRbH6ehYnXQYAzBgBUIex8aL2HhnVxm4CAEDzIQDqsOfIqIou9REAAJoQAVCHoSiWRAAAaE4EQB1yBACAJkYA1GEwirWys1UrOtuSLgUAZowAqEMuGuHoH0DTIgDqkIti9XUvSboMAJgVAmCW4tPjOnT8tDZyDwCAJkUAzNLQMBeAATQ3AmCW6AEEoNkRALOUy5cCoLeLAADQnAiAWcpFsdYs79CitmzSpQDArBAAszQYxZz+AdDUCIBZyhEAAJocATALR+MxvX7yDAEAoKkRALMwWO4BxD0AAJoZATAL57uAchcwgOZFAMxCLhpRNmNav3JR0qUAwKwRALOQi2JdsqpTrVmaD0Dz4hNsFgbz9AAC0PwIgBkqFl2vDo8SAACaHgEwQ4dOnNLJMwUCAEDTIwBm6OwYQBsJAABNjgCYobP3APQSAACaXF0BYGZ3mNl+M9tRfm2tst71ZrbbzF4xs9vr2WfSclGsjtaMLl7WkXQpAFCXlgZs4x53v6vaQjPLSvqmpA9L2ifpaTN7xN1fasC+510uitXbtViZjCVdCgDUZT5OAb1H0ivuPujuY5K+K+mGedjvnMhFMUNAAEiFRgTALWb2vJk9ZGYrKyxfJ2nvhOl95XkVmdnNZjZgZgP5fL4B5TXOmUJRe4/QBRRAOkwbAGb2hJntrPC6QdJ9ki6VtFnSQUl3V9pEhXlebX/ufr+797t7f09PT42/xvzYd/SkxovOGEAAUmHaawDufl0tGzKzByQ9WmHRPkkbJkyvl3SgpuoWmFw0Iknq6+5MuBIAqF+9vYDWTJi8UdLOCqs9LenNZtZnZm2SPi3pkXr2m5TBPKOAAkiPensB3Wlmm1U6pTMk6QuSZGZrJT3o7lvdfdzMbpH0I0lZSQ+5+4t17jcRuSjW8kWtWtnZmnQpAFC3ugLA3W+qMv+ApK0Tph+T9Fg9+1oIzj4G0owuoACaH3cCz8BQFDMEBIDUIABqdHKsoAOvn6ILKIDUIABqNDTMGEAA0oUAqNH55wATAADSgQCoEQEAIG0IgBoN5mNdtKxdi9sbMX4eACSPAKjR0DDPAQaQLgRAjUr3AHAHMID0IABqcGx0TEfiMcYAApAqBEANzl8A5hsAgPQgAGpADyAAaUQA1CAXxcqYdMkqTgEBSA8CoAa5KNaGVZ1qa6G5AKQHn2g1ODsKKACkCQEwDXdXLorV20UAAEgXAmAah0+c1uhYQRt7CAAA6UIATOP8YyAJAADpQgBMgy6gANKKAJjG0HCstpaM1i5flHQpANBQBMA0BvOx+roWK5PhOcAA0oUAmEYuGlEvYwABSCECYArjhaL2HBllDCAAqUQATGH/sZM6U3Bt5AIwgBQiAKYweLYHEPcAAEghAmAKQ3QBBZBiBMAUclGspR0t6lrclnQpANBwBMAUclGsjd2LZUYXUADpQwBMYTAfq5fTPwBSigCo4tSZgg68fpLz/wBSiwCo4tXhUblzARhAehEAVZwdBG4jN4EBSCkCoIqzAcAwEADSigCoIheNqGdpu5Z2tCZdCgDMCQKgilxUGgUUANKKAKiCB8EDSDsCoILjp84oGhljDCAAqUYAVMAYQABCUFcAmNkdZrbfzHaUX1srrLPBzLaZ2S4ze9HMbq1nn/PhfBdQAgBAerU0YBv3uPtdUywfl/QVd3/WzJZKesbMHnf3lxqw7zkxmI9lJl3SRRdQAOk156eA3P2guz9bfn9C0i5J6+Z6v/XIRbHWrVik9pZs0qUAwJxpRADcYmbPm9lDZrZyqhXNrFfSlZKemmKdm81swMwG8vl8A8qbOXoAAQjBtAFgZk+Y2c4Krxsk3SfpUkmbJR2UdPcU21ki6fuSvuTux6ut5+73u3u/u/f39PTM+Beql7ufGwYaANJs2msA7n5dLRsyswckPVplWatKH/7fcfcfzKjCeRaNjGnk9DjfAACkXr29gNZMmLxR0s4K65ikb0na5e7fqGd/8yF37jnADAIHIN3qvQZwp5m9YGbPS9oi6cuSZGZrzeyx8jpXS7pJ0rVTdRddKHLRiCS6gAJIv7q6gbr7TVXmH5C0tfz+PyU1zTMVB6NYbdmM1q5YlHQpADCnuBN4klw+1iVdncpmmiazAGBWCIBJ6AIKIBQEwASFouvV4VHO/wMIAgEwwYFjJzVWKPINAEAQCIAJcowCCiAgBMAEBACAkBAAE+SiWIvbsupZ2p50KQAw5wiACQajWH09i1W6eRkA0o0AmCAXjaivmyEgAISBACg7PV7Q/qMnOf8PIBgEQNneI6MqOmMAAQgHAVA2mC/1AOolAAAEggAoO9cFtIsAABAGAqAsF8XqWtym5Z2tSZcCAPOCACgbZBA4AIEhAMqGCAAAgSEAJI2cHtfhE6fV10MAAAgHAaDS0b/EBWAAYSEAVDr/L4lvAACCQgCo9BhISerlGwCAgBAAKo0BtG7FInW0ZpMuBQDmDQEgKTc8Sg8gAMEJPgDcXbn8CAEAIDjBB8CReEzHT40zBhCA4AQfAGfHAGIUUAChCT4ABnkOMIBABR8AuShWS8a0fuWipEsBgHkVfAAMRbEu6epUSzb4pgAQmOA/9XJRzPl/AEEKOgCKRVcuirkDGECQgg6Ag8dP6fR4kTGAAAQp6AA4OwYQPYAAhCjsAIhGJEkbu5ckXAkAzL/AA2BUi1qzumhZe9KlAMC8CzwASmMAmVnSpQDAvAs8AGIuAAMIVrABMDZe1N6jJ3kMJIBg1RUAZnaHme03sx3l19Yp1s2a2XNm9mg9+2yUvUdHVSg6PYAABKulAdu4x93vqmG9WyXtkrSsAfus27kuoJwCAhCoeTkFZGbrJX1M0oPzsb9aDA0zDDSAsDUiAG4xs+fN7CEzW1llnXsl3SapON3GzOxmMxsws4F8Pt+A8iobjGKt7GzVis62OdsHACxk0waAmT1hZjsrvG6QdJ+kSyVtlnRQ0t0Vfv7jkg67+zO1FOTu97t7v7v39/T0zOy3mYFcPub8P4CgTXsNwN2vq2VDZvaApEoXeK+W9InyBeIOScvM7B/c/TMzqrTBclGs91/WlWQJAJCoensBrZkweaOknZPXcfevuft6d++V9GlJP0n6wz8+Pa7Xjp/i/D+AoNV7DeBOM3vBzJ6XtEXSlyXJzNaa2WN1VzdHzl4A7mMMIAABq6sbqLvfVGX+AUkX3BPg7tslba9nn40wFI1KYhRQAGEL8k7gs6OA9nZ3JlwJACQnyAAYjGKtWd6hzrZG3AcHAM0pyADgMZAAEHAAMAQEgNAFFwBH4zEdGz1DF1AAwQsuAHLDPAcYAKQQA4AHwQOApBADIIqVzZg2rKILKICwBRkAG1YuUms2uF8dAN4guE/BwYhRQAFACiwAikXXUBQzBhAAKLAAOHTilE6eKXAPAAAosADIRTwGEgDOCjIAuAYAAKEFQD5We0tGFy/rSLoUAEhcWAFQ7gGUyVjSpQBA4oIMAABAQAEwXihqz5FRAgAAyoIJgH1HT2q86AQAAJQFEwDnuoByDwAASAooAAbLAcCTwACgJJgAyEUjWtbRolWL25IuBQAWhIACIFZfzxKZ0QUUAKSQAiAfMwQEAEwQRACcOlPQgddP0QMIACYIIgCGeA4wAFwgiADgOcAAcKEgAuBcF1ACAADOCSIAclGs1UvbtaS9JelSAGDBCCYAOP0DAG8URAAMRTFDQADAJKkPgNdHz2g4HuMbAABMkvoAyA0zBhAAVJL+AIhGJDEKKABMlv4AyMfKmLRhVWfSpQDAgpL6ABiMYq1f2an2lmzSpQDAgpL6ABgapgsoAFRSVwCY2R1mtt/MdpRfW6ust8LMHjazX5jZLjN7Xz37rZW7K5cnAACgkkbcGnuPu981zTp/LemH7v4pM2uTNC8n5PMnTiseKxAAAFDBnI+NYGbLJH1A0u9JkruPSRqb6/1K58cAIgAA4EKNuAZwi5k9b2YPmdnKCss3SspL+jsze87MHjSzqp/IZnazmQ2Y2UA+n6+rsBwBAABVTRsAZvaEme2s8LpB0n2SLpW0WdJBSXdX2ESLpF+VdJ+7XykplnR7tf25+/3u3u/u/T09PbP5nc7JRbHaWjJau2JRXdsBgDSa9hSQu19Xy4bM7AFJj1ZYtE/SPnd/qjz9sKYIgEbKRbF6uzqVzfAcYACYrN5eQGsmTN4oaefkddz9NUl7zWxTedaHJL1Uz35rxSigAFBdvdcA7jSzF8zseUlbJH1ZksxsrZk9NmG9P5T0nfJ6myX9RZ37nVah6Hp1OFZf95K53hUANKW6egG5+01V5h+QtHXC9A5J/fXsa6b2Hz2pMwVXXzdDQABAJam9E3iwPAgc3wAAoLLUBgBdQAFgaqkNgKEo1tL2FnUvaUu6FABYkFIbAINRrL6exTKjCygAVJLaAKALKABMLZUBcOpMQfuPneQxkAAwhVQGwJ4jo3LnMZAAMJVUBsBgnh5AADCdVAbA0HApAHoJAACoKpUBkMvH6l7SrmUdrUmXAgALVjoDIIq1kaN/AJhSKgNgMIrVyxhAADCl1AXAeKGoD7ylW++7tCvpUgBgQZvzZwLPt5ZsRt/47c1JlwEAC17qvgEAAGpDAABAoAgAAAgUAQAAgSIAACBQBAAABIoAAIBAEQAAEChz96RrqMrM8pJenWKVbknRPJXTLGiTC9EmF6JNKktDu7zJ3XtqWXFBB8B0zGzA3fuTrmMhoU0uRJtciDapLLR24RQQAASKAACAQDV7ANyfdAELEG1yIdrkQrRJZUG1S1NfAwAAzF6zfwMAAMxSUwaAmV1vZrvN7BUzuz3pepJiZg+Z2WEz2zlh3ioze9zMfln+d2WSNc43M9tgZtvMbJeZvWhmt5bnB9suZtZhZv9rZj8vt8mfluf3mdlT5Tb5ZzNrS7rW+WZmWTN7zsweLU8H1SZNFwBmlpX0TUkflfRWSb9jZm9NtqrE/L2k6yfNu13Sj939zZJ+XJ4Oybikr7j7FZKukvQH5f8/Qm6X05Kudfd3Stos6Xozu0rSX0m6p9wmRyX9foI1JuVWSbsmTAfVJk0XAJLeI+kVdx909zFJ35V0Q8I1JcLdfyrpyKTZN0j6dvn9tyV9cl6LSpi7H3T3Z8vvT6j0x71OAbeLl4yUJ1vLL5d0raSHy/ODahNJMrP1kj4m6cHytCmwNmnGAFgnae+E6X3leSi5yN0PSqUPQ0mrE64nMWbWK+lKSU8p8HYpn+rYIemwpMcl/Z+kY+4+Xl4lxL+jeyXdJqlYnu5SYG3SjAFgFebRlQlvYGZLJH1f0pfc/XjS9STN3QvuvlnSepW+RV9RabX5rSo5ZvZxSYfd/ZmJsyusmuo2acaHwu+TtGHC9HpJBxKqZSE6ZGZr3P2gma1R6YgvKGbWqtKH/3fc/Qfl2cG3iyS5+zEz267S9ZEVZtZSPuIN7e/oakmfMLOtkjokLVPpG0FQbdKM3wCelvTm8tX6NkmflvRIwjUtJI9I+mz5/Wcl/WuCtcy78nncb0na5e7fmLAo2HYxsx4zW1F+v0jSdSpdG9km6VPl1YJqE3f/mruvd/delT5DfuLuv6vA2qQpbwQrp/a9krKSHnL3P0+4pESY2T9JukalEQwPSfoTSf8i6XuSLpG0R9JvufvkC8WpZWa/JulJSS/o/Lndr6t0HSDIdjGzd6h0QTOr0kHf99z9z8xso0qdKFZJek7SZ9z9dHKVJsPMrpH0VXf/eGht0pQBAACoXzOeAgIANAABAACBIgAAIFAEAAAEigAAgEARAAAQKAIAAAJFAABAoP4feEDyjdohFeAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = find_pass\n",
    "y = find_perplexity\n",
    "plt.plot(x, y)\n",
    "\n",
    "# 결론 : perplexity는 낮을 수록 좋으므로, pass를 1로 설정하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. LDA 최선의 하이퍼 파라미터 찾기 - Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:37,518 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:37,523 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:37,525 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:37,528 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:37,530 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:37,587 : INFO : -6.847 per-word bound, 115.1 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:37,589 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:37,596 : INFO : topic #1 (0.100): 0.093*\"bar\" + 0.033*\"energy\" + 0.030*\"saturated\" + 0.021*\"fat\" + 0.019*\"sugar\" + 0.018*\"contain\" + 0.017*\"others\" + 0.017*\"much\" + 0.017*\"gram\" + 0.016*\"protein\"\n",
      "2019-10-29 00:37:37,600 : INFO : topic #6 (0.100): 0.094*\"bar\" + 0.027*\"saturated\" + 0.027*\"energy\" + 0.026*\"fat\" + 0.023*\"contain\" + 0.020*\"gram\" + 0.019*\"much\" + 0.019*\"nutrition\" + 0.018*\"protein\" + 0.017*\"sugar\"\n",
      "2019-10-29 00:37:37,605 : INFO : topic #5 (0.100): 0.072*\"bar\" + 0.033*\"energy\" + 0.032*\"fat\" + 0.020*\"saturated\" + 0.020*\"nutrition\" + 0.019*\"gram\" + 0.018*\"higher\" + 0.017*\"much\" + 0.017*\"protein\" + 0.016*\"contain\"\n",
      "2019-10-29 00:37:37,608 : INFO : topic #7 (0.100): 0.095*\"bar\" + 0.036*\"energy\" + 0.023*\"saturated\" + 0.022*\"fat\" + 0.019*\"much\" + 0.019*\"gram\" + 0.018*\"others\" + 0.017*\"sugar\" + 0.017*\"satisfying\" + 0.017*\"higher\"\n",
      "2019-10-29 00:37:37,611 : INFO : topic #9 (0.100): 0.079*\"bar\" + 0.034*\"fat\" + 0.034*\"saturated\" + 0.029*\"energy\" + 0.019*\"higher\" + 0.018*\"nutrition\" + 0.017*\"much\" + 0.017*\"contain\" + 0.016*\"sugar\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:37,615 : INFO : topic diff=0.836249, rho=1.000000\n",
      "2019-10-29 00:37:37,732 : INFO : -6.438 per-word bound, 86.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -6.438348466828025 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:37,805 : INFO : -6.440 per-word bound, 86.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:37,807 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:37,817 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:37,824 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:37,840 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 10x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:37,848 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:37,919 : INFO : -6.853 per-word bound, 115.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:37,923 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:37,956 : INFO : topic #0 (0.100): 0.095*\"bar\" + 0.030*\"energy\" + 0.030*\"saturated\" + 0.024*\"fat\" + 0.021*\"higher\" + 0.020*\"others\" + 0.017*\"nutrition\" + 0.017*\"sugar\" + 0.017*\"protein\" + 0.017*\"much\"\n",
      "2019-10-29 00:37:37,959 : INFO : topic #6 (0.100): 0.077*\"bar\" + 0.030*\"energy\" + 0.024*\"saturated\" + 0.024*\"fat\" + 0.022*\"gram\" + 0.020*\"protein\" + 0.019*\"nutrition\" + 0.018*\"much\" + 0.018*\"higher\" + 0.018*\"contain\"\n",
      "2019-10-29 00:37:37,963 : INFO : topic #2 (0.100): 0.085*\"bar\" + 0.033*\"energy\" + 0.028*\"saturated\" + 0.027*\"fat\" + 0.023*\"gram\" + 0.020*\"sugar\" + 0.018*\"higher\" + 0.017*\"protein\" + 0.017*\"much\" + 0.016*\"contain\"\n",
      "2019-10-29 00:37:37,967 : INFO : topic #4 (0.100): 0.078*\"bar\" + 0.033*\"energy\" + 0.031*\"saturated\" + 0.023*\"fat\" + 0.020*\"nutrition\" + 0.020*\"sugar\" + 0.019*\"protein\" + 0.018*\"contain\" + 0.016*\"higher\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:37,971 : INFO : topic #8 (0.100): 0.070*\"bar\" + 0.031*\"fat\" + 0.029*\"energy\" + 0.028*\"saturated\" + 0.021*\"nutrition\" + 0.020*\"gram\" + 0.018*\"protein\" + 0.018*\"others\" + 0.018*\"sugar\" + 0.017*\"athlete\"\n",
      "2019-10-29 00:37:37,979 : INFO : topic diff=0.846996, rho=1.000000\n",
      "2019-10-29 00:37:38,108 : INFO : -6.325 per-word bound, 80.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -6.325154849058072 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:38,209 : INFO : -6.334 per-word bound, 80.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:38,212 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:38,215 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:38,218 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:38,220 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 20x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:38,223 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:38,363 : INFO : -6.843 per-word bound, 114.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:38,366 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:38,393 : INFO : topic #2 (0.100): 0.090*\"bar\" + 0.029*\"saturated\" + 0.026*\"energy\" + 0.020*\"fat\" + 0.020*\"contain\" + 0.020*\"higher\" + 0.018*\"nutrition\" + 0.018*\"sugar\" + 0.017*\"others\" + 0.017*\"gram\"\n",
      "2019-10-29 00:37:38,404 : INFO : topic #0 (0.100): 0.075*\"bar\" + 0.028*\"fat\" + 0.028*\"energy\" + 0.026*\"saturated\" + 0.020*\"higher\" + 0.019*\"protein\" + 0.018*\"others\" + 0.017*\"much\" + 0.016*\"gram\" + 0.015*\"sugar\"\n",
      "2019-10-29 00:37:38,408 : INFO : topic #6 (0.100): 0.082*\"bar\" + 0.034*\"fat\" + 0.027*\"energy\" + 0.021*\"saturated\" + 0.021*\"much\" + 0.018*\"contain\" + 0.018*\"nutrition\" + 0.018*\"others\" + 0.017*\"protein\" + 0.016*\"higher\"\n",
      "2019-10-29 00:37:38,412 : INFO : topic #8 (0.100): 0.071*\"bar\" + 0.034*\"energy\" + 0.029*\"fat\" + 0.028*\"saturated\" + 0.021*\"much\" + 0.020*\"protein\" + 0.019*\"nutrition\" + 0.019*\"sugar\" + 0.018*\"others\" + 0.018*\"higher\"\n",
      "2019-10-29 00:37:38,416 : INFO : topic #7 (0.100): 0.090*\"bar\" + 0.035*\"energy\" + 0.023*\"saturated\" + 0.020*\"higher\" + 0.019*\"sugar\" + 0.019*\"fat\" + 0.017*\"protein\" + 0.017*\"nutrition\" + 0.014*\"convenient\" + 0.014*\"calorie\"\n",
      "2019-10-29 00:37:38,419 : INFO : topic diff=0.878177, rho=1.000000\n",
      "2019-10-29 00:37:38,601 : INFO : -6.173 per-word bound, 72.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:38,686 : INFO : -6.175 per-word bound, 72.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:38,688 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:38,692 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:38,693 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:38,696 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 30x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:38,697 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:38,802 : INFO : -6.821 per-word bound, 113.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:38,830 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:38,865 : INFO : topic #3 (0.100): 0.099*\"bar\" + 0.029*\"energy\" + 0.025*\"fat\" + 0.024*\"saturated\" + 0.020*\"gram\" + 0.019*\"sugar\" + 0.019*\"contain\" + 0.017*\"nutrition\" + 0.017*\"others\" + 0.017*\"higher\"\n",
      "2019-10-29 00:37:38,869 : INFO : topic #9 (0.100): 0.082*\"bar\" + 0.026*\"energy\" + 0.025*\"saturated\" + 0.024*\"fat\" + 0.020*\"contain\" + 0.019*\"protein\" + 0.019*\"sugar\" + 0.018*\"much\" + 0.015*\"higher\" + 0.015*\"gram\"\n",
      "2019-10-29 00:37:38,874 : INFO : topic #2 (0.100): 0.060*\"bar\" + 0.032*\"saturated\" + 0.031*\"energy\" + 0.023*\"fat\" + 0.018*\"much\" + 0.018*\"nutrition\" + 0.016*\"contain\" + 0.016*\"meal\" + 0.016*\"sugar\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:38,877 : INFO : topic #0 (0.100): 0.066*\"bar\" + 0.032*\"fat\" + 0.030*\"saturated\" + 0.029*\"energy\" + 0.019*\"gram\" + 0.019*\"sugar\" + 0.018*\"higher\" + 0.018*\"much\" + 0.017*\"others\" + 0.016*\"protein\"\n",
      "2019-10-29 00:37:38,883 : INFO : topic #6 (0.100): 0.081*\"bar\" + 0.041*\"energy\" + 0.035*\"saturated\" + 0.020*\"higher\" + 0.019*\"fat\" + 0.018*\"protein\" + 0.017*\"sugar\" + 0.017*\"others\" + 0.017*\"much\" + 0.016*\"contain\"\n",
      "2019-10-29 00:37:38,886 : INFO : topic diff=1.437245, rho=1.000000\n",
      "2019-10-29 00:37:39,079 : INFO : -5.706 per-word bound, 52.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -6.173160414159651 \n",
      "\n",
      "Iteration 30\n",
      "Coherence 1.0000889005818406e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-10-29 00:37:39,221 : INFO : -5.706 per-word bound, 52.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:39,237 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:39,241 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:39,246 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:39,250 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 40x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:39,254 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity -5.705853722645686 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:39,378 : INFO : -6.824 per-word bound, 113.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:39,381 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:39,423 : INFO : topic #8 (0.100): 0.043*\"bar\" + 0.018*\"saturated\" + 0.018*\"energy\" + 0.017*\"fat\" + 0.016*\"higher\" + 0.016*\"others\" + 0.014*\"nutrition\" + 0.013*\"contain\" + 0.013*\"protein\" + 0.013*\"syrup\"\n",
      "2019-10-29 00:37:39,427 : INFO : topic #7 (0.100): 0.084*\"bar\" + 0.033*\"energy\" + 0.027*\"saturated\" + 0.025*\"gram\" + 0.024*\"fat\" + 0.019*\"others\" + 0.019*\"much\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.017*\"contain\"\n",
      "2019-10-29 00:37:39,450 : INFO : topic #1 (0.100): 0.102*\"bar\" + 0.040*\"energy\" + 0.034*\"fat\" + 0.025*\"saturated\" + 0.020*\"sugar\" + 0.019*\"higher\" + 0.018*\"protein\" + 0.018*\"nutrition\" + 0.017*\"contain\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:39,463 : INFO : topic #0 (0.100): 0.076*\"bar\" + 0.027*\"saturated\" + 0.026*\"energy\" + 0.022*\"fat\" + 0.021*\"nutrition\" + 0.020*\"gram\" + 0.017*\"protein\" + 0.017*\"contain\" + 0.016*\"others\" + 0.015*\"higher\"\n",
      "2019-10-29 00:37:39,467 : INFO : topic #5 (0.100): 0.067*\"bar\" + 0.027*\"fat\" + 0.025*\"energy\" + 0.024*\"saturated\" + 0.019*\"nutrition\" + 0.016*\"gram\" + 0.016*\"others\" + 0.015*\"much\" + 0.015*\"contain\" + 0.015*\"sugar\"\n",
      "2019-10-29 00:37:39,470 : INFO : topic diff=1.550929, rho=1.000000\n",
      "2019-10-29 00:37:39,615 : INFO : -5.716 per-word bound, 52.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -5.716131630733874 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:39,745 : INFO : -5.716 per-word bound, 52.5 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:39,748 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:39,750 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:39,753 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:39,756 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:39,767 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:39,877 : INFO : -6.786 per-word bound, 110.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:39,879 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:39,928 : INFO : topic #3 (0.100): 0.083*\"bar\" + 0.029*\"saturated\" + 0.029*\"energy\" + 0.019*\"protein\" + 0.019*\"fat\" + 0.018*\"much\" + 0.017*\"sugar\" + 0.016*\"gram\" + 0.016*\"contain\" + 0.016*\"nutrition\"\n",
      "2019-10-29 00:37:39,931 : INFO : topic #7 (0.100): 0.087*\"bar\" + 0.038*\"energy\" + 0.027*\"fat\" + 0.023*\"saturated\" + 0.021*\"nutrition\" + 0.021*\"protein\" + 0.020*\"contain\" + 0.018*\"higher\" + 0.016*\"much\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:39,934 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"saturated\" + 0.009*\"contain\" + 0.009*\"nutrition\" + 0.009*\"gram\" + 0.009*\"sugar\" + 0.009*\"calorie\"\n",
      "2019-10-29 00:37:39,937 : INFO : topic #5 (0.100): 0.069*\"bar\" + 0.022*\"fat\" + 0.020*\"energy\" + 0.020*\"saturated\" + 0.019*\"sugar\" + 0.019*\"contain\" + 0.019*\"higher\" + 0.016*\"gram\" + 0.016*\"much\" + 0.015*\"also\"\n",
      "2019-10-29 00:37:39,940 : INFO : topic #6 (0.100): 0.095*\"bar\" + 0.034*\"energy\" + 0.031*\"saturated\" + 0.023*\"fat\" + 0.021*\"gram\" + 0.019*\"much\" + 0.018*\"nutrition\" + 0.018*\"protein\" + 0.018*\"higher\" + 0.018*\"others\"\n",
      "2019-10-29 00:37:39,943 : INFO : topic diff=3.423177, rho=1.000000\n",
      "2019-10-29 00:37:40,047 : INFO : -5.431 per-word bound, 43.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,117 : INFO : -5.431 per-word bound, 43.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,118 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -5.431444958681186 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:40,120 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:40,122 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:40,124 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 60x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:40,129 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:40,210 : INFO : -6.758 per-word bound, 108.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,212 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:40,251 : INFO : topic #5 (0.100): 0.010*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"protein\" + 0.009*\"much\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:40,254 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"higher\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:40,260 : INFO : topic #2 (0.100): 0.009*\"bar\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"higher\" + 0.009*\"contain\" + 0.009*\"sugar\" + 0.009*\"much\" + 0.009*\"fiber\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:40,263 : INFO : topic #1 (0.100): 0.048*\"bar\" + 0.020*\"energy\" + 0.018*\"fat\" + 0.017*\"saturated\" + 0.013*\"higher\" + 0.013*\"sugar\" + 0.013*\"fiber\" + 0.013*\"contain\" + 0.013*\"gram\" + 0.013*\"much\"\n",
      "2019-10-29 00:37:40,265 : INFO : topic #0 (0.100): 0.050*\"bar\" + 0.020*\"energy\" + 0.020*\"contain\" + 0.020*\"fat\" + 0.019*\"saturated\" + 0.017*\"sugar\" + 0.016*\"others\" + 0.016*\"higher\" + 0.015*\"much\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:40,270 : INFO : topic diff=3.901061, rho=1.000000\n",
      "2019-10-29 00:37:40,365 : INFO : -5.279 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,425 : INFO : -5.279 per-word bound, 38.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,427 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:40,430 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:40,432 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:40,434 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 70x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:40,437 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -5.278545400870622 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:40,529 : INFO : -6.768 per-word bound, 109.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,532 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:40,586 : INFO : topic #9 (0.100): 0.022*\"bar\" + 0.014*\"saturated\" + 0.013*\"energy\" + 0.013*\"fat\" + 0.012*\"higher\" + 0.012*\"contain\" + 0.012*\"protein\" + 0.011*\"nutrition\" + 0.011*\"sugar\" + 0.011*\"athlete\"\n",
      "2019-10-29 00:37:40,588 : INFO : topic #4 (0.100): 0.076*\"bar\" + 0.038*\"energy\" + 0.029*\"saturated\" + 0.028*\"fat\" + 0.028*\"higher\" + 0.020*\"nutrition\" + 0.017*\"others\" + 0.016*\"gram\" + 0.016*\"protein\" + 0.015*\"contain\"\n",
      "2019-10-29 00:37:40,591 : INFO : topic #8 (0.100): 0.043*\"bar\" + 0.022*\"energy\" + 0.019*\"saturated\" + 0.016*\"protein\" + 0.016*\"higher\" + 0.015*\"fat\" + 0.014*\"amount\" + 0.013*\"contain\" + 0.013*\"others\" + 0.013*\"sugar\"\n",
      "2019-10-29 00:37:40,592 : INFO : topic #1 (0.100): 0.065*\"bar\" + 0.033*\"saturated\" + 0.031*\"energy\" + 0.022*\"fat\" + 0.020*\"contain\" + 0.020*\"protein\" + 0.018*\"higher\" + 0.018*\"nutrition\" + 0.016*\"syrup\" + 0.016*\"sugar\"\n",
      "2019-10-29 00:37:40,594 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"saturated\" + 0.009*\"higher\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"gram\" + 0.009*\"others\"\n",
      "2019-10-29 00:37:40,595 : INFO : topic diff=4.259239, rho=1.000000\n",
      "2019-10-29 00:37:40,680 : INFO : -5.158 per-word bound, 35.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,733 : INFO : -5.158 per-word bound, 35.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,735 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:40,737 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:40,739 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:40,741 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 80x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:40,743 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -5.157826068485982 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:40,835 : INFO : -6.754 per-word bound, 108.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:40,837 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:40,902 : INFO : topic #0 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"energy\" + 0.009*\"much\" + 0.009*\"sugar\" + 0.009*\"gram\" + 0.009*\"nutrition\" + 0.009*\"contain\" + 0.009*\"protein\"\n",
      "2019-10-29 00:37:40,904 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"others\" + 0.009*\"much\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"contain\" + 0.009*\"sugar\"\n",
      "2019-10-29 00:37:40,906 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"nutrition\" + 0.009*\"sugar\" + 0.009*\"syrup\" + 0.009*\"much\"\n",
      "2019-10-29 00:37:40,907 : INFO : topic #1 (0.100): 0.057*\"bar\" + 0.021*\"energy\" + 0.020*\"saturated\" + 0.020*\"fat\" + 0.019*\"others\" + 0.017*\"higher\" + 0.017*\"much\" + 0.016*\"protein\" + 0.015*\"sugar\" + 0.014*\"meal\"\n",
      "2019-10-29 00:37:40,909 : INFO : topic #8 (0.100): 0.099*\"bar\" + 0.033*\"energy\" + 0.031*\"saturated\" + 0.028*\"fat\" + 0.022*\"much\" + 0.018*\"higher\" + 0.017*\"others\" + 0.017*\"gram\" + 0.016*\"nutrition\" + 0.016*\"protein\"\n",
      "2019-10-29 00:37:40,911 : INFO : topic diff=4.894935, rho=1.000000\n",
      "2019-10-29 00:37:41,041 : INFO : -5.296 per-word bound, 39.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80\n",
      "Coherence 1.0000889005818406e-12\n",
      "Perplexity -5.296427826627472 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:41,134 : INFO : -5.296 per-word bound, 39.3 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:41,136 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:41,140 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:41,144 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:41,147 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 90x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:41,149 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:41,270 : INFO : -6.784 per-word bound, 110.2 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:41,273 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:41,352 : INFO : topic #9 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"saturated\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"gram\" + 0.009*\"contain\" + 0.009*\"also\"\n",
      "2019-10-29 00:37:41,353 : INFO : topic #2 (0.100): 0.088*\"bar\" + 0.033*\"fat\" + 0.030*\"energy\" + 0.020*\"much\" + 0.019*\"gram\" + 0.019*\"protein\" + 0.018*\"nutrition\" + 0.017*\"saturated\" + 0.015*\"contain\" + 0.014*\"amount\"\n",
      "2019-10-29 00:37:41,355 : INFO : topic #8 (0.100): 0.009*\"bar\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"nutrition\" + 0.009*\"energy\" + 0.009*\"also\" + 0.009*\"protein\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"higher\"\n",
      "2019-10-29 00:37:41,360 : INFO : topic #3 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"nutrition\" + 0.009*\"fat\" + 0.009*\"protein\" + 0.009*\"others\" + 0.009*\"sugar\" + 0.009*\"contain\" + 0.009*\"gram\"\n",
      "2019-10-29 00:37:41,371 : INFO : topic #4 (0.100): 0.009*\"bar\" + 0.009*\"energy\" + 0.009*\"saturated\" + 0.009*\"fat\" + 0.009*\"sugar\" + 0.009*\"higher\" + 0.009*\"protein\" + 0.009*\"gram\" + 0.009*\"others\" + 0.009*\"nutrition\"\n",
      "2019-10-29 00:37:41,383 : INFO : topic diff=3.449589, rho=1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90\n",
      "Coherence 1.0000889005818406e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:41,579 : INFO : -5.663 per-word bound, 50.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:41,693 : INFO : -5.662 per-word bound, 50.6 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity -5.662517524470944 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 실험값 담을 곳\n",
    "find_coherence=[]\n",
    "find_perplexity=[]\n",
    "find_Iteration=[]\n",
    "\n",
    "for i in range(10): # 10회 실험\n",
    "    t_Num_topic = 10 # 토픽 갯수\n",
    "    \n",
    "    # 실험에서 iteration은 10씩 커지게 설정\n",
    "    if i==0:\n",
    "        t_Iteration = 1\n",
    "    else:\n",
    "        t_Iteration=i*10\n",
    "            \n",
    "    # 실험\n",
    "    find_lda = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=t_Num_topic, passes=1, iterations = t_Iteration) # t_Iteration 값에 따라 실험하기\n",
    "    \n",
    "    # 실험값 담기 - Iteration\n",
    "    print('Iteration', t_Iteration)\n",
    "    find_Iteration.append(t_Iteration)\n",
    "    \n",
    "    # 실험값 담기 - Coherence\n",
    "    t_cm = CoherenceModel(model=find_lda, corpus=corpus, coherence='u_mass')\n",
    "    t_coherence = t_cm.get_coherence()\n",
    "    print('Coherence', t_coherence)\n",
    "    find_coherence.append(t_coherence)\n",
    "    \n",
    "    # 실험값 담기 - Perplexity\n",
    "    print('Perplexity', find_lda.log_perplexity(corpus),'\\n')\n",
    "    find_perplexity.append(find_lda.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bb74cd8ef0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = find_Iteration\n",
    "y = find_perplexity\n",
    "plt.plot(x, y)\n",
    "\n",
    "# 결론 : perplexity는 낮을 수록 좋으므로, Iteration을 1로 설정하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LDA 하이퍼 파라미터 튜닝 & LDA 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 하이퍼 파라미터 튜닝\n",
    "Num_topic = 10 # 가설 토픽 수\n",
    "Pass = 1 # Epochs\n",
    "Iteration = 1 # Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:42,250 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:42,256 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:42,271 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:42,276 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:42,279 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:42,350 : INFO : -6.842 per-word bound, 114.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:42,352 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:42,359 : INFO : topic #9 (0.100): 0.079*\"bar\" + 0.025*\"saturated\" + 0.024*\"fat\" + 0.023*\"energy\" + 0.023*\"much\" + 0.020*\"sugar\" + 0.018*\"contain\" + 0.018*\"higher\" + 0.018*\"others\" + 0.017*\"nutrition\"\n",
      "2019-10-29 00:37:42,361 : INFO : topic #5 (0.100): 0.101*\"bar\" + 0.030*\"saturated\" + 0.026*\"energy\" + 0.023*\"fat\" + 0.022*\"contain\" + 0.021*\"much\" + 0.018*\"higher\" + 0.015*\"others\" + 0.015*\"gram\" + 0.015*\"amount\"\n",
      "2019-10-29 00:37:42,367 : INFO : topic #6 (0.100): 0.083*\"bar\" + 0.032*\"energy\" + 0.027*\"saturated\" + 0.026*\"fat\" + 0.021*\"gram\" + 0.018*\"contain\" + 0.016*\"nutrition\" + 0.015*\"higher\" + 0.014*\"protein\" + 0.014*\"sugar\"\n",
      "2019-10-29 00:37:42,371 : INFO : topic #4 (0.100): 0.089*\"bar\" + 0.036*\"energy\" + 0.027*\"saturated\" + 0.026*\"fat\" + 0.021*\"protein\" + 0.020*\"higher\" + 0.020*\"sugar\" + 0.020*\"others\" + 0.019*\"contain\" + 0.017*\"much\"\n",
      "2019-10-29 00:37:42,374 : INFO : topic #0 (0.100): 0.081*\"bar\" + 0.029*\"energy\" + 0.026*\"saturated\" + 0.023*\"fat\" + 0.020*\"nutrition\" + 0.020*\"others\" + 0.019*\"higher\" + 0.018*\"protein\" + 0.016*\"sugar\" + 0.015*\"contain\"\n",
      "2019-10-29 00:37:42,378 : INFO : topic diff=0.836788, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "# LDA 생성\n",
    "def lda_model(corpus, dictionary):\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary,\n",
    "                                          num_topics=Num_topic, update_every=1, \n",
    "                                          chunksize=10000, passes=Pass,\n",
    "                                          iterations = Iteration\n",
    "                                         )\n",
    "    return lda\n",
    "\n",
    "lda = lda_model(corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LDA 토픽, 확률 추출\n",
    "def lda_topic_prob(lda):\n",
    "    return lda.show_topic(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 토픽 추출\n",
    "def lda_topic(lda):\n",
    "    return [word for word, prob in lda.show_topic(1, topn=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. LDA 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA 이용\n",
    "def LDA_modul(x):\n",
    "    alltext = data_token(x)\n",
    "    alltext = remove_once(alltext)\n",
    "    dictionary = gensim_dict(alltext)\n",
    "    corpus = corpus_text(dictionary, alltext)\n",
    "    lda = lda_model(corpus, dictionary)\n",
    "    result1 = lda_topic_prob(lda)\n",
    "    result2 = lda_topic(lda)\n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:42,961 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:42,967 : INFO : built Dictionary(69 unique tokens: ['ensure', 'fireball', 'relative', 'spread', 'come']...) from 5 documents (total 450 corpus positions)\n",
      "2019-10-29 00:37:42,971 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:42,974 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:42,976 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:42,981 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:42,983 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:43,023 : INFO : -6.723 per-word bound, 105.7 perplexity estimate based on a held-out corpus of 5 documents with 450 words\n",
      "2019-10-29 00:37:43,028 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:43,036 : INFO : topic #7 (0.100): 0.042*\"incident\" + 0.038*\"said\" + 0.031*\"ghana\" + 0.023*\"ensure\" + 0.023*\"dozen\" + 0.022*\"government\" + 0.022*\"gas\" + 0.022*\"akufo\" + 0.021*\"killed\" + 0.021*\"explosion\"\n",
      "2019-10-29 00:37:43,039 : INFO : topic #8 (0.100): 0.054*\"said\" + 0.046*\"incident\" + 0.029*\"ghana\" + 0.024*\"ensure\" + 0.024*\"seven\" + 0.024*\"addo\" + 0.024*\"dozen\" + 0.023*\"injured\" + 0.022*\"nana\" + 0.022*\"explosion\"\n",
      "2019-10-29 00:37:43,042 : INFO : topic #1 (0.100): 0.043*\"incident\" + 0.039*\"said\" + 0.032*\"ghana\" + 0.024*\"addo\" + 0.024*\"ensure\" + 0.023*\"akufo\" + 0.022*\"killed\" + 0.021*\"tanker\" + 0.021*\"government\" + 0.021*\"explosion\"\n",
      "2019-10-29 00:37:43,046 : INFO : topic #6 (0.100): 0.039*\"said\" + 0.034*\"incident\" + 0.032*\"ghana\" + 0.025*\"tanker\" + 0.023*\"akufo\" + 0.023*\"nana\" + 0.023*\"ensure\" + 0.022*\"injured\" + 0.022*\"gas\" + 0.022*\"station\"\n",
      "2019-10-29 00:37:43,058 : INFO : topic #4 (0.100): 0.050*\"incident\" + 0.038*\"said\" + 0.034*\"ghana\" + 0.025*\"dozen\" + 0.024*\"killed\" + 0.023*\"gas\" + 0.022*\"station\" + 0.022*\"akufo\" + 0.021*\"addo\" + 0.021*\"nana\"\n",
      "2019-10-29 00:37:43,061 : INFO : topic diff=0.712408, rho=1.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('incident', 0.043400817),\n",
       "  ('said', 0.038928043),\n",
       "  ('ghana', 0.03182353),\n",
       "  ('addo', 0.024351856),\n",
       "  ('ensure', 0.023543656),\n",
       "  ('akufo', 0.023127707),\n",
       "  ('killed', 0.021543942),\n",
       "  ('tanker', 0.021284917),\n",
       "  ('government', 0.021256097),\n",
       "  ('explosion', 0.020926414)],\n",
       " ['incident',\n",
       "  'said',\n",
       "  'ghana',\n",
       "  'addo',\n",
       "  'ensure',\n",
       "  'akufo',\n",
       "  'killed',\n",
       "  'tanker',\n",
       "  'government',\n",
       "  'explosion'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_modul(4) # data의 4번째 행 키워드 추출 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['akufoaddo', 'tanker', 'incidents', 'dozens', 'streetsgovernment', 'work', 'station', 'seven', 'explosion', 'gas', 'ghana', 'nana', 'injured', 'ensure', 'killed']\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['KEYWORDS'][4] # data의 4번째 행 키워드 정답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. LDA로 전체 데이터의 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PREDICT_KEYWORDS_PROB'] = 0\n",
    "data['PREDICT_KEYWORDS'] = 0\n",
    "data['HASHTAG'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:43,387 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:43,400 : INFO : built Dictionary(111 unique tokens: ['replacement', 'energy', 'watch', 'come', 'satisfying']...) from 5 documents (total 845 corpus positions)\n",
      "2019-10-29 00:37:43,403 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:43,405 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:43,406 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:43,409 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:43,413 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:43,547 : INFO : -6.856 per-word bound, 115.8 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:37:43,554 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:43,561 : INFO : topic #6 (0.100): 0.090*\"bar\" + 0.035*\"energy\" + 0.031*\"saturated\" + 0.028*\"fat\" + 0.019*\"much\" + 0.018*\"sugar\" + 0.018*\"nutrition\" + 0.017*\"protein\" + 0.017*\"higher\" + 0.017*\"gram\"\n",
      "2019-10-29 00:37:43,563 : INFO : topic #7 (0.100): 0.072*\"bar\" + 0.030*\"fat\" + 0.027*\"energy\" + 0.024*\"saturated\" + 0.020*\"gram\" + 0.019*\"contain\" + 0.017*\"higher\" + 0.017*\"sugar\" + 0.017*\"nutrition\" + 0.016*\"others\"\n",
      "2019-10-29 00:37:43,570 : INFO : topic #0 (0.100): 0.083*\"bar\" + 0.036*\"energy\" + 0.031*\"saturated\" + 0.025*\"fat\" + 0.022*\"much\" + 0.020*\"others\" + 0.018*\"nutrition\" + 0.016*\"higher\" + 0.016*\"gram\" + 0.015*\"protein\"\n",
      "2019-10-29 00:37:43,575 : INFO : topic #9 (0.100): 0.102*\"bar\" + 0.028*\"saturated\" + 0.025*\"energy\" + 0.023*\"fat\" + 0.020*\"much\" + 0.019*\"gram\" + 0.017*\"nutrition\" + 0.017*\"higher\" + 0.016*\"protein\" + 0.014*\"calorie\"\n",
      "2019-10-29 00:37:43,578 : INFO : topic #3 (0.100): 0.089*\"bar\" + 0.034*\"energy\" + 0.025*\"fat\" + 0.023*\"saturated\" + 0.019*\"protein\" + 0.018*\"higher\" + 0.018*\"sugar\" + 0.017*\"nutrition\" + 0.016*\"gram\" + 0.016*\"contain\"\n",
      "2019-10-29 00:37:43,611 : INFO : topic diff=0.833873, rho=1.000000\n",
      "2019-10-29 00:37:44,643 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:44,649 : INFO : built Dictionary(10 unique tokens: ['chat', 'world', 'unfolds', 'facebook', 'messenger']...) from 5 documents (total 50 corpus positions)\n",
      "2019-10-29 00:37:44,659 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:44,666 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:44,674 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:44,682 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:44,686 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:44,698 : INFO : -6.352 per-word bound, 81.7 perplexity estimate based on a held-out corpus of 5 documents with 50 words\n",
      "2019-10-29 00:37:44,699 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:44,709 : INFO : topic #8 (0.100): 0.112*\"back\" + 0.107*\"unfolds\" + 0.105*\"find\" + 0.103*\"tamagotchi\" + 0.100*\"world\" + 0.099*\"facebook\" + 0.097*\"messenger\" + 0.096*\"happening\" + 0.090*\"chat\" + 0.090*\"u\"\n",
      "2019-10-29 00:37:44,711 : INFO : topic #1 (0.100): 0.115*\"unfolds\" + 0.109*\"find\" + 0.105*\"tamagotchi\" + 0.102*\"happening\" + 0.101*\"messenger\" + 0.098*\"back\" + 0.098*\"u\" + 0.095*\"chat\" + 0.093*\"facebook\" + 0.084*\"world\"\n",
      "2019-10-29 00:37:44,716 : INFO : topic #4 (0.100): 0.127*\"chat\" + 0.110*\"world\" + 0.109*\"unfolds\" + 0.104*\"facebook\" + 0.098*\"find\" + 0.092*\"messenger\" + 0.092*\"back\" + 0.091*\"tamagotchi\" + 0.091*\"u\" + 0.086*\"happening\"\n",
      "2019-10-29 00:37:44,720 : INFO : topic #5 (0.100): 0.115*\"facebook\" + 0.112*\"find\" + 0.110*\"tamagotchi\" + 0.106*\"messenger\" + 0.104*\"back\" + 0.096*\"unfolds\" + 0.095*\"world\" + 0.093*\"happening\" + 0.090*\"u\" + 0.080*\"chat\"\n",
      "2019-10-29 00:37:44,724 : INFO : topic #7 (0.100): 0.119*\"back\" + 0.109*\"happening\" + 0.107*\"tamagotchi\" + 0.106*\"chat\" + 0.103*\"facebook\" + 0.100*\"u\" + 0.098*\"find\" + 0.091*\"messenger\" + 0.088*\"unfolds\" + 0.079*\"world\"\n",
      "2019-10-29 00:37:44,727 : INFO : topic diff=0.488778, rho=1.000000\n",
      "2019-10-29 00:37:45,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:45,239 : INFO : built Dictionary(159 unique tokens: ['minnesota', 'racked', 'story', 'scrambling', 'end']...) from 5 documents (total 1190 corpus positions)\n",
      "2019-10-29 00:37:45,241 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:45,242 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:45,243 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:45,247 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:45,248 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:45,317 : INFO : -7.190 per-word bound, 146.1 perplexity estimate based on a held-out corpus of 5 documents with 1190 words\n",
      "2019-10-29 00:37:45,319 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:45,328 : INFO : topic #0 (0.100): 0.035*\"war\" + 0.034*\"star\" + 0.029*\"trailer\" + 0.023*\"last\" + 0.021*\"rey\" + 0.020*\"monday\" + 0.018*\"jedi\" + 0.017*\"night\" + 0.015*\"film\" + 0.014*\"force\"\n",
      "2019-10-29 00:37:45,331 : INFO : topic #5 (0.100): 0.040*\"star\" + 0.030*\"last\" + 0.030*\"war\" + 0.027*\"trailer\" + 0.021*\"jedi\" + 0.020*\"new\" + 0.019*\"rey\" + 0.015*\"night\" + 0.012*\"film\" + 0.012*\"monday\"\n",
      "2019-10-29 00:37:45,333 : INFO : topic #7 (0.100): 0.037*\"trailer\" + 0.035*\"war\" + 0.035*\"star\" + 0.020*\"jedi\" + 0.020*\"last\" + 0.017*\"new\" + 0.015*\"monday\" + 0.015*\"film\" + 0.014*\"rey\" + 0.014*\"skywalker\"\n",
      "2019-10-29 00:37:45,337 : INFO : topic #9 (0.100): 0.033*\"star\" + 0.033*\"trailer\" + 0.030*\"last\" + 0.022*\"rey\" + 0.020*\"war\" + 0.019*\"jedi\" + 0.018*\"monday\" + 0.018*\"new\" + 0.016*\"night\" + 0.015*\"film\"\n",
      "2019-10-29 00:37:45,339 : INFO : topic #4 (0.100): 0.041*\"trailer\" + 0.031*\"last\" + 0.026*\"star\" + 0.023*\"war\" + 0.022*\"rey\" + 0.020*\"new\" + 0.018*\"jedi\" + 0.016*\"monday\" + 0.015*\"film\" + 0.013*\"billion\"\n",
      "2019-10-29 00:37:45,341 : INFO : topic diff=0.823748, rho=1.000000\n",
      "2019-10-29 00:37:45,851 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:45,854 : INFO : built Dictionary(82 unique tokens: ['perfume', 'paris', 'business', 'come', 'something']...) from 5 documents (total 510 corpus positions)\n",
      "2019-10-29 00:37:45,856 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:45,858 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:45,859 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:45,862 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:45,863 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:45,904 : INFO : -6.947 per-word bound, 123.3 perplexity estimate based on a held-out corpus of 5 documents with 510 words\n",
      "2019-10-29 00:37:45,907 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:45,913 : INFO : topic #1 (0.100): 0.049*\"harris\" + 0.048*\"scent\" + 0.033*\"perfumer\" + 0.026*\"art\" + 0.023*\"perfume\" + 0.021*\"one\" + 0.020*\"client\" + 0.019*\"founded\" + 0.018*\"made\" + 0.017*\"h\"\n",
      "2019-10-29 00:37:45,915 : INFO : topic #8 (0.100): 0.040*\"harris\" + 0.034*\"scent\" + 0.032*\"art\" + 0.024*\"h\" + 0.024*\"perfumer\" + 0.021*\"world\" + 0.019*\"perfume\" + 0.019*\"made\" + 0.018*\"quite\" + 0.017*\"one\"\n",
      "2019-10-29 00:37:45,917 : INFO : topic #0 (0.100): 0.059*\"harris\" + 0.036*\"scent\" + 0.027*\"art\" + 0.025*\"perfumer\" + 0.021*\"founded\" + 0.020*\"h\" + 0.019*\"quite\" + 0.019*\"perfume\" + 0.018*\"world\" + 0.017*\"client\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:45,919 : INFO : topic #6 (0.100): 0.039*\"harris\" + 0.035*\"scent\" + 0.034*\"perfumer\" + 0.029*\"art\" + 0.028*\"one\" + 0.021*\"client\" + 0.020*\"founded\" + 0.020*\"world\" + 0.017*\"made\" + 0.017*\"perfume\"\n",
      "2019-10-29 00:37:45,940 : INFO : topic #2 (0.100): 0.062*\"harris\" + 0.041*\"scent\" + 0.028*\"art\" + 0.024*\"perfumer\" + 0.020*\"made\" + 0.020*\"one\" + 0.019*\"quite\" + 0.018*\"client\" + 0.018*\"perfume\" + 0.017*\"founded\"\n",
      "2019-10-29 00:37:45,945 : INFO : topic diff=0.702210, rho=1.000000\n",
      "2019-10-29 00:37:46,578 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:46,580 : INFO : built Dictionary(69 unique tokens: ['ensure', 'fireball', 'relative', 'spread', 'come']...) from 5 documents (total 450 corpus positions)\n",
      "2019-10-29 00:37:46,582 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:46,583 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:46,585 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:46,587 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:46,589 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:46,635 : INFO : -6.719 per-word bound, 105.4 perplexity estimate based on a held-out corpus of 5 documents with 450 words\n",
      "2019-10-29 00:37:46,638 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:46,644 : INFO : topic #1 (0.100): 0.042*\"said\" + 0.037*\"incident\" + 0.028*\"ghana\" + 0.025*\"gas\" + 0.024*\"addo\" + 0.023*\"ensure\" + 0.023*\"seven\" + 0.022*\"government\" + 0.021*\"dozen\" + 0.021*\"killed\"\n",
      "2019-10-29 00:37:46,647 : INFO : topic #9 (0.100): 0.052*\"incident\" + 0.038*\"said\" + 0.026*\"ghana\" + 0.025*\"ensure\" + 0.023*\"akufo\" + 0.022*\"explosion\" + 0.022*\"station\" + 0.021*\"dozen\" + 0.021*\"gas\" + 0.021*\"nana\"\n",
      "2019-10-29 00:37:46,650 : INFO : topic #5 (0.100): 0.044*\"incident\" + 0.036*\"said\" + 0.035*\"ghana\" + 0.025*\"ensure\" + 0.025*\"station\" + 0.025*\"dozen\" + 0.025*\"killed\" + 0.024*\"explosion\" + 0.023*\"tanker\" + 0.022*\"nana\"\n",
      "2019-10-29 00:37:46,653 : INFO : topic #8 (0.100): 0.053*\"incident\" + 0.050*\"said\" + 0.032*\"ghana\" + 0.027*\"government\" + 0.025*\"seven\" + 0.024*\"station\" + 0.023*\"injured\" + 0.023*\"addo\" + 0.023*\"akufo\" + 0.022*\"killed\"\n",
      "2019-10-29 00:37:46,661 : INFO : topic #4 (0.100): 0.042*\"said\" + 0.034*\"incident\" + 0.034*\"ghana\" + 0.028*\"nana\" + 0.027*\"explosion\" + 0.027*\"seven\" + 0.026*\"akufo\" + 0.022*\"gas\" + 0.021*\"station\" + 0.020*\"tanker\"\n",
      "2019-10-29 00:37:46,664 : INFO : topic diff=0.704621, rho=1.000000\n",
      "2019-10-29 00:37:47,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:47,266 : INFO : built Dictionary(367 unique tokens: ['prime', 'party', 'mayor', 'spokesman', 'local']...) from 5 documents (total 3120 corpus positions)\n",
      "2019-10-29 00:37:47,271 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:47,273 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:47,274 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:47,278 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:47,280 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:47,414 : INFO : -7.784 per-word bound, 220.5 perplexity estimate based on a held-out corpus of 5 documents with 3120 words\n",
      "2019-10-29 00:37:47,416 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:47,425 : INFO : topic #6 (0.100): 0.024*\"catalonia\" + 0.023*\"independence\" + 0.022*\"said\" + 0.018*\"catalan\" + 0.016*\"would\" + 0.015*\"spain\" + 0.013*\"government\" + 0.010*\"spanish\" + 0.008*\"barcelona\" + 0.008*\"parliament\"\n",
      "2019-10-29 00:37:47,428 : INFO : topic #5 (0.100): 0.031*\"catalonia\" + 0.024*\"independence\" + 0.020*\"catalan\" + 0.018*\"said\" + 0.017*\"would\" + 0.015*\"spain\" + 0.010*\"minister\" + 0.010*\"european\" + 0.009*\"spanish\" + 0.008*\"want\"\n",
      "2019-10-29 00:37:47,431 : INFO : topic #2 (0.100): 0.027*\"catalonia\" + 0.019*\"independence\" + 0.016*\"said\" + 0.015*\"catalan\" + 0.015*\"would\" + 0.014*\"government\" + 0.012*\"spanish\" + 0.011*\"spain\" + 0.010*\"barcelona\" + 0.009*\"puigdemont\"\n",
      "2019-10-29 00:37:47,434 : INFO : topic #8 (0.100): 0.027*\"catalonia\" + 0.024*\"independence\" + 0.018*\"spain\" + 0.017*\"said\" + 0.015*\"catalan\" + 0.014*\"would\" + 0.011*\"government\" + 0.010*\"barcelona\" + 0.010*\"minister\" + 0.009*\"puigdemont\"\n",
      "2019-10-29 00:37:47,438 : INFO : topic #4 (0.100): 0.029*\"catalonia\" + 0.018*\"independence\" + 0.018*\"spain\" + 0.017*\"would\" + 0.016*\"said\" + 0.015*\"catalan\" + 0.013*\"government\" + 0.011*\"barcelona\" + 0.010*\"minister\" + 0.010*\"puigdemont\"\n",
      "2019-10-29 00:37:47,442 : INFO : topic diff=0.872868, rho=1.000000\n",
      "2019-10-29 00:37:47,921 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:47,928 : INFO : built Dictionary(147 unique tokens: ['previously', 'offered', 'campaign', 'quotient', 'come']...) from 5 documents (total 1110 corpus positions)\n",
      "2019-10-29 00:37:47,933 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:47,936 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:47,939 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:47,945 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:47,948 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:48,036 : INFO : -7.109 per-word bound, 138.1 perplexity estimate based on a held-out corpus of 5 documents with 1110 words\n",
      "2019-10-29 00:37:48,039 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:48,052 : INFO : topic #3 (0.100): 0.038*\"joke\" + 0.037*\"iq\" + 0.037*\"trump\" + 0.034*\"tillerson\" + 0.017*\"house\" + 0.017*\"white\" + 0.017*\"joking\" + 0.015*\"know\" + 0.015*\"secretary\" + 0.014*\"state\"\n",
      "2019-10-29 00:37:48,056 : INFO : topic #5 (0.100): 0.037*\"iq\" + 0.034*\"joke\" + 0.032*\"trump\" + 0.027*\"tillerson\" + 0.021*\"secretary\" + 0.017*\"state\" + 0.017*\"joking\" + 0.017*\"white\" + 0.017*\"know\" + 0.015*\"high\"\n",
      "2019-10-29 00:37:48,060 : INFO : topic #6 (0.100): 0.052*\"trump\" + 0.034*\"iq\" + 0.030*\"tillerson\" + 0.024*\"state\" + 0.022*\"joking\" + 0.021*\"joke\" + 0.020*\"white\" + 0.018*\"house\" + 0.016*\"know\" + 0.015*\"president\"\n",
      "2019-10-29 00:37:48,064 : INFO : topic #8 (0.100): 0.047*\"trump\" + 0.038*\"iq\" + 0.034*\"tillerson\" + 0.024*\"joke\" + 0.019*\"house\" + 0.019*\"president\" + 0.018*\"white\" + 0.018*\"secretary\" + 0.016*\"know\" + 0.015*\"joking\"\n",
      "2019-10-29 00:37:48,068 : INFO : topic #7 (0.100): 0.045*\"trump\" + 0.038*\"tillerson\" + 0.036*\"iq\" + 0.025*\"joke\" + 0.018*\"state\" + 0.017*\"know\" + 0.017*\"white\" + 0.016*\"president\" + 0.016*\"house\" + 0.014*\"test\"\n",
      "2019-10-29 00:37:48,070 : INFO : topic diff=0.851163, rho=1.000000\n",
      "2019-10-29 00:37:48,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:48,537 : INFO : built Dictionary(462 unique tokens: ['energy', 'deep', 'school', 'one', 'new']...) from 5 documents (total 3905 corpus positions)\n",
      "2019-10-29 00:37:48,543 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:48,544 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:48,545 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:48,549 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:48,550 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:48,710 : INFO : -8.017 per-word bound, 259.0 perplexity estimate based on a held-out corpus of 5 documents with 3905 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:48,712 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:48,724 : INFO : topic #2 (0.100): 0.023*\"kellogg\" + 0.018*\"power\" + 0.018*\"said\" + 0.017*\"child\" + 0.016*\"air\" + 0.013*\"clean\" + 0.010*\"asthma\" + 0.010*\"health\" + 0.009*\"plan\" + 0.009*\"pollution\"\n",
      "2019-10-29 00:37:48,727 : INFO : topic #6 (0.100): 0.020*\"child\" + 0.016*\"kellogg\" + 0.016*\"air\" + 0.011*\"power\" + 0.011*\"health\" + 0.011*\"asthma\" + 0.011*\"said\" + 0.010*\"clean\" + 0.009*\"plan\" + 0.009*\"pollution\"\n",
      "2019-10-29 00:37:48,731 : INFO : topic #4 (0.100): 0.017*\"kellogg\" + 0.016*\"child\" + 0.016*\"said\" + 0.015*\"asthma\" + 0.014*\"power\" + 0.014*\"air\" + 0.011*\"health\" + 0.011*\"year\" + 0.010*\"clean\" + 0.009*\"administration\"\n",
      "2019-10-29 00:37:48,734 : INFO : topic #5 (0.100): 0.020*\"kellogg\" + 0.020*\"child\" + 0.017*\"air\" + 0.014*\"power\" + 0.012*\"said\" + 0.012*\"health\" + 0.012*\"asthma\" + 0.010*\"lung\" + 0.010*\"clean\" + 0.009*\"obama\"\n",
      "2019-10-29 00:37:48,738 : INFO : topic #0 (0.100): 0.019*\"kellogg\" + 0.019*\"said\" + 0.019*\"child\" + 0.018*\"power\" + 0.018*\"air\" + 0.013*\"asthma\" + 0.013*\"health\" + 0.010*\"clean\" + 0.009*\"year\" + 0.009*\"pollution\"\n",
      "2019-10-29 00:37:48,742 : INFO : topic diff=0.900132, rho=1.000000\n",
      "2019-10-29 00:37:49,346 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:49,358 : INFO : built Dictionary(463 unique tokens: ['flattering', 'method', 'happy', 'allergic', 'mishandled']...) from 5 documents (total 3345 corpus positions)\n",
      "2019-10-29 00:37:49,367 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:49,368 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:49,372 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:49,376 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:49,379 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:49,685 : INFO : -8.250 per-word bound, 304.4 perplexity estimate based on a held-out corpus of 5 documents with 3345 words\n",
      "2019-10-29 00:37:49,687 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:49,702 : INFO : topic #7 (0.100): 0.031*\"trump\" + 0.020*\"president\" + 0.014*\"puerto\" + 0.014*\"said\" + 0.011*\"reality\" + 0.010*\"rico\" + 0.007*\"make\" + 0.007*\"even\" + 0.006*\"day\" + 0.006*\"another\"\n",
      "2019-10-29 00:37:49,705 : INFO : topic #0 (0.100): 0.034*\"trump\" + 0.020*\"president\" + 0.015*\"said\" + 0.012*\"reality\" + 0.010*\"rico\" + 0.009*\"made\" + 0.009*\"puerto\" + 0.007*\"make\" + 0.006*\"people\" + 0.006*\"look\"\n",
      "2019-10-29 00:37:49,708 : INFO : topic #4 (0.100): 0.018*\"president\" + 0.017*\"trump\" + 0.015*\"said\" + 0.013*\"rico\" + 0.013*\"reality\" + 0.009*\"puerto\" + 0.008*\"make\" + 0.007*\"even\" + 0.006*\"everyone\" + 0.006*\"day\"\n",
      "2019-10-29 00:37:49,719 : INFO : topic #5 (0.100): 0.031*\"trump\" + 0.014*\"president\" + 0.013*\"said\" + 0.013*\"rico\" + 0.012*\"puerto\" + 0.008*\"price\" + 0.008*\"another\" + 0.007*\"make\" + 0.007*\"reality\" + 0.006*\"thing\"\n",
      "2019-10-29 00:37:49,722 : INFO : topic #6 (0.100): 0.029*\"trump\" + 0.015*\"president\" + 0.014*\"reality\" + 0.011*\"puerto\" + 0.011*\"said\" + 0.008*\"made\" + 0.008*\"make\" + 0.007*\"another\" + 0.007*\"rico\" + 0.007*\"donald\"\n",
      "2019-10-29 00:37:49,726 : INFO : topic diff=0.791757, rho=1.000000\n",
      "2019-10-29 00:37:50,285 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:50,293 : INFO : built Dictionary(248 unique tokens: ['forward', 'located', 'school', 'hanging', 'journey']...) from 5 documents (total 1750 corpus positions)\n",
      "2019-10-29 00:37:50,303 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:50,310 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:50,317 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:50,322 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:50,326 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:50,471 : INFO : -7.696 per-word bound, 207.4 perplexity estimate based on a held-out corpus of 5 documents with 1750 words\n",
      "2019-10-29 00:37:50,473 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:50,483 : INFO : topic #3 (0.100): 0.025*\"yamadera\" + 0.024*\"temple\" + 0.014*\"hall\" + 0.013*\"risshakuji\" + 0.011*\"minute\" + 0.011*\"step\" + 0.011*\"japan\" + 0.010*\"reach\" + 0.009*\"yamagata\" + 0.009*\"tohoku\"\n",
      "2019-10-29 00:37:50,487 : INFO : topic #8 (0.100): 0.029*\"yamadera\" + 0.029*\"temple\" + 0.019*\"station\" + 0.017*\"japan\" + 0.013*\"hall\" + 0.013*\"risshakuji\" + 0.012*\"step\" + 0.010*\"yamagata\" + 0.009*\"okunoin\" + 0.009*\"complex\"\n",
      "2019-10-29 00:37:50,491 : INFO : topic #0 (0.100): 0.024*\"temple\" + 0.021*\"yamadera\" + 0.013*\"risshakuji\" + 0.012*\"japan\" + 0.011*\"hall\" + 0.011*\"station\" + 0.011*\"prefecture\" + 0.010*\"complex\" + 0.010*\"step\" + 0.009*\"yamagata\"\n",
      "2019-10-29 00:37:50,494 : INFO : topic #9 (0.100): 0.032*\"temple\" + 0.024*\"yamadera\" + 0.014*\"hall\" + 0.014*\"risshakuji\" + 0.014*\"station\" + 0.011*\"minute\" + 0.011*\"yamagata\" + 0.011*\"step\" + 0.010*\"japan\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:37:50,497 : INFO : topic #4 (0.100): 0.029*\"temple\" + 0.027*\"yamadera\" + 0.016*\"japan\" + 0.014*\"hall\" + 0.013*\"risshakuji\" + 0.010*\"station\" + 0.009*\"yamagata\" + 0.009*\"complex\" + 0.009*\"step\" + 0.009*\"buddhist\"\n",
      "2019-10-29 00:37:50,499 : INFO : topic diff=0.765125, rho=1.000000\n",
      "2019-10-29 00:37:51,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:51,095 : INFO : built Dictionary(355 unique tokens: ['let', 'paradise', 'wave', 'deep', 'rugged']...) from 5 documents (total 2670 corpus positions)\n",
      "2019-10-29 00:37:51,107 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:51,110 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:51,118 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:51,123 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:51,127 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:51,288 : INFO : -7.932 per-word bound, 244.1 perplexity estimate based on a held-out corpus of 5 documents with 2670 words\n",
      "2019-10-29 00:37:51,290 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:51,298 : INFO : topic #8 (0.100): 0.021*\"doug\" + 0.016*\"tompkins\" + 0.012*\"kris\" + 0.012*\"land\" + 0.010*\"south\" + 0.009*\"wild\" + 0.009*\"patagonia\" + 0.008*\"chile\" + 0.008*\"cnn\" + 0.008*\"national\"\n",
      "2019-10-29 00:37:51,301 : INFO : topic #7 (0.100): 0.030*\"tompkins\" + 0.022*\"doug\" + 0.014*\"kris\" + 0.012*\"land\" + 0.010*\"south\" + 0.010*\"chile\" + 0.008*\"patagonia\" + 0.008*\"wild\" + 0.008*\"much\" + 0.008*\"could\"\n",
      "2019-10-29 00:37:51,304 : INFO : topic #4 (0.100): 0.022*\"tompkins\" + 0.020*\"doug\" + 0.015*\"kris\" + 0.011*\"chile\" + 0.009*\"south\" + 0.008*\"cnn\" + 0.008*\"love\" + 0.008*\"land\" + 0.008*\"much\" + 0.008*\"life\"\n",
      "2019-10-29 00:37:51,307 : INFO : topic #6 (0.100): 0.020*\"doug\" + 0.018*\"tompkins\" + 0.013*\"kris\" + 0.009*\"land\" + 0.009*\"south\" + 0.009*\"love\" + 0.009*\"patagonia\" + 0.008*\"national\" + 0.008*\"park\" + 0.008*\"chile\"\n",
      "2019-10-29 00:37:51,309 : INFO : topic #2 (0.100): 0.027*\"tompkins\" + 0.025*\"doug\" + 0.009*\"kris\" + 0.008*\"south\" + 0.008*\"chile\" + 0.008*\"land\" + 0.008*\"cnn\" + 0.008*\"much\" + 0.008*\"national\" + 0.008*\"million\"\n",
      "2019-10-29 00:37:51,312 : INFO : topic diff=0.797142, rho=1.000000\n",
      "2019-10-29 00:37:51,968 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:51,979 : INFO : built Dictionary(662 unique tokens: ['let', 'acceptable', 'assignment', 'real', 'happy']...) from 5 documents (total 6160 corpus positions)\n",
      "2019-10-29 00:37:51,994 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:51,996 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:52,004 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:52,009 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:52,011 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:52,284 : INFO : -8.243 per-word bound, 302.9 perplexity estimate based on a held-out corpus of 5 documents with 6160 words\n",
      "2019-10-29 00:37:52,286 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:52,298 : INFO : topic #2 (0.100): 0.023*\"said\" + 0.021*\"parent\" + 0.018*\"burnout\" + 0.014*\"need\" + 0.012*\"time\" + 0.011*\"two\" + 0.010*\"mom\" + 0.009*\"kid\" + 0.009*\"mother\" + 0.008*\"everything\"\n",
      "2019-10-29 00:37:52,302 : INFO : topic #6 (0.100): 0.030*\"said\" + 0.024*\"parent\" + 0.013*\"mom\" + 0.012*\"kid\" + 0.011*\"burnout\" + 0.009*\"mother\" + 0.009*\"time\" + 0.009*\"need\" + 0.008*\"day\" + 0.007*\"two\"\n",
      "2019-10-29 00:37:52,306 : INFO : topic #8 (0.100): 0.026*\"said\" + 0.023*\"parent\" + 0.016*\"burnout\" + 0.014*\"mom\" + 0.014*\"need\" + 0.011*\"kid\" + 0.011*\"mother\" + 0.010*\"time\" + 0.009*\"two\" + 0.007*\"husband\"\n",
      "2019-10-29 00:37:52,309 : INFO : topic #5 (0.100): 0.026*\"said\" + 0.018*\"parent\" + 0.017*\"burnout\" + 0.013*\"mom\" + 0.011*\"need\" + 0.011*\"kid\" + 0.009*\"mother\" + 0.009*\"time\" + 0.008*\"husband\" + 0.007*\"day\"\n",
      "2019-10-29 00:37:52,312 : INFO : topic #4 (0.100): 0.025*\"parent\" + 0.022*\"said\" + 0.014*\"burnout\" + 0.013*\"mom\" + 0.012*\"need\" + 0.009*\"kid\" + 0.008*\"mother\" + 0.008*\"time\" + 0.007*\"husband\" + 0.007*\"go\"\n",
      "2019-10-29 00:37:52,315 : INFO : topic diff=0.927697, rho=1.000000\n",
      "2019-10-29 00:37:52,812 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:52,820 : INFO : built Dictionary(305 unique tokens: ['forward', 'roper', 'school', 'significant', 'campaign']...) from 5 documents (total 2825 corpus positions)\n",
      "2019-10-29 00:37:52,827 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:52,828 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:52,830 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:52,834 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:52,838 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:53,000 : INFO : -7.503 per-word bound, 181.5 perplexity estimate based on a held-out corpus of 5 documents with 2825 words\n",
      "2019-10-29 00:37:53,003 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:53,012 : INFO : topic #5 (0.100): 0.037*\"alcohol\" + 0.030*\"advertising\" + 0.026*\"said\" + 0.024*\"drink\" + 0.016*\"study\" + 0.015*\"kid\" + 0.014*\"much\" + 0.014*\"drinking\" + 0.013*\"parent\" + 0.011*\"brand\"\n",
      "2019-10-29 00:37:53,014 : INFO : topic #3 (0.100): 0.034*\"alcohol\" + 0.030*\"advertising\" + 0.021*\"said\" + 0.020*\"drink\" + 0.017*\"kid\" + 0.017*\"study\" + 0.015*\"drinking\" + 0.012*\"underage\" + 0.011*\"month\" + 0.011*\"decision\"\n",
      "2019-10-29 00:37:53,016 : INFO : topic #6 (0.100): 0.032*\"alcohol\" + 0.023*\"drink\" + 0.020*\"advertising\" + 0.019*\"said\" + 0.018*\"underage\" + 0.015*\"much\" + 0.015*\"study\" + 0.014*\"kid\" + 0.013*\"drinking\" + 0.013*\"brand\"\n",
      "2019-10-29 00:37:53,017 : INFO : topic #1 (0.100): 0.042*\"alcohol\" + 0.023*\"drink\" + 0.023*\"said\" + 0.019*\"study\" + 0.016*\"advertising\" + 0.015*\"underage\" + 0.014*\"kid\" + 0.013*\"parent\" + 0.013*\"brand\" + 0.012*\"much\"\n",
      "2019-10-29 00:37:53,019 : INFO : topic #0 (0.100): 0.038*\"alcohol\" + 0.027*\"said\" + 0.026*\"drink\" + 0.021*\"advertising\" + 0.016*\"study\" + 0.016*\"much\" + 0.015*\"ad\" + 0.014*\"drinking\" + 0.013*\"kid\" + 0.013*\"underage\"\n",
      "2019-10-29 00:37:53,021 : INFO : topic diff=0.931798, rho=1.000000\n",
      "2019-10-29 00:37:53,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:53,544 : INFO : built Dictionary(275 unique tokens: ['let', 'school', 'small', 'end', 'stop']...) from 5 documents (total 2340 corpus positions)\n",
      "2019-10-29 00:37:53,549 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:53,555 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:53,559 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:53,563 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:53,566 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:53,687 : INFO : -7.512 per-word bound, 182.6 perplexity estimate based on a held-out corpus of 5 documents with 2340 words\n",
      "2019-10-29 00:37:53,689 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:53,697 : INFO : topic #8 (0.100): 0.033*\"said\" + 0.022*\"tantrum\" + 0.017*\"child\" + 0.016*\"go\" + 0.016*\"ferrara\" + 0.016*\"parent\" + 0.015*\"kid\" + 0.013*\"going\" + 0.012*\"want\" + 0.010*\"way\"\n",
      "2019-10-29 00:37:53,699 : INFO : topic #0 (0.100): 0.025*\"said\" + 0.023*\"kid\" + 0.023*\"tantrum\" + 0.019*\"parent\" + 0.016*\"child\" + 0.016*\"go\" + 0.015*\"ferrara\" + 0.014*\"going\" + 0.012*\"want\" + 0.011*\"say\"\n",
      "2019-10-29 00:37:53,700 : INFO : topic #1 (0.100): 0.025*\"said\" + 0.021*\"kid\" + 0.020*\"parent\" + 0.019*\"child\" + 0.019*\"tantrum\" + 0.015*\"going\" + 0.014*\"go\" + 0.013*\"ferrara\" + 0.013*\"want\" + 0.011*\"may\"\n",
      "2019-10-29 00:37:53,701 : INFO : topic #6 (0.100): 0.036*\"said\" + 0.024*\"parent\" + 0.021*\"kid\" + 0.021*\"tantrum\" + 0.018*\"want\" + 0.016*\"go\" + 0.014*\"ferrara\" + 0.013*\"going\" + 0.011*\"child\" + 0.011*\"grader\"\n",
      "2019-10-29 00:37:53,703 : INFO : topic #4 (0.100): 0.029*\"said\" + 0.026*\"parent\" + 0.020*\"kid\" + 0.019*\"tantrum\" + 0.017*\"ferrara\" + 0.017*\"go\" + 0.014*\"going\" + 0.012*\"child\" + 0.012*\"want\" + 0.010*\"may\"\n",
      "2019-10-29 00:37:53,705 : INFO : topic diff=0.867218, rho=1.000000\n",
      "2019-10-29 00:37:54,181 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:54,183 : INFO : built Dictionary(100 unique tokens: ['end', 'fate', 'topic', 'summit', 'diane']...) from 5 documents (total 690 corpus positions)\n",
      "2019-10-29 00:37:54,185 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:54,187 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:54,188 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:54,190 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:54,191 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:54,238 : INFO : -6.922 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 5 documents with 690 words\n",
      "2019-10-29 00:37:54,239 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:54,246 : INFO : topic #9 (0.100): 0.044*\"trump\" + 0.030*\"ivanka\" + 0.024*\"immigration\" + 0.019*\"issue\" + 0.018*\"fortune\" + 0.017*\"program\" + 0.017*\"long\" + 0.017*\"woman\" + 0.015*\"young\" + 0.015*\"asked\"\n",
      "2019-10-29 00:37:54,248 : INFO : topic #7 (0.100): 0.042*\"trump\" + 0.025*\"ivanka\" + 0.023*\"issue\" + 0.017*\"childhood\" + 0.017*\"program\" + 0.017*\"long\" + 0.017*\"woman\" + 0.017*\"need\" + 0.016*\"fix\" + 0.016*\"immigration\"\n",
      "2019-10-29 00:37:54,249 : INFO : topic #2 (0.100): 0.049*\"trump\" + 0.024*\"woman\" + 0.023*\"ivanka\" + 0.023*\"issue\" + 0.020*\"immigration\" + 0.019*\"program\" + 0.017*\"young\" + 0.017*\"summit\" + 0.016*\"act\" + 0.016*\"powerful\"\n",
      "2019-10-29 00:37:54,250 : INFO : topic #3 (0.100): 0.038*\"trump\" + 0.031*\"immigration\" + 0.023*\"issue\" + 0.023*\"ivanka\" + 0.022*\"woman\" + 0.019*\"asked\" + 0.018*\"program\" + 0.017*\"powerful\" + 0.016*\"action\" + 0.016*\"monday\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:54,252 : INFO : topic #1 (0.100): 0.037*\"trump\" + 0.025*\"ivanka\" + 0.019*\"immigration\" + 0.019*\"issue\" + 0.018*\"program\" + 0.018*\"arrival\" + 0.017*\"complicated\" + 0.016*\"woman\" + 0.016*\"monday\" + 0.015*\"act\"\n",
      "2019-10-29 00:37:54,254 : INFO : topic diff=0.716242, rho=1.000000\n",
      "2019-10-29 00:37:54,705 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:54,708 : INFO : built Dictionary(124 unique tokens: ['fox', 'anxious', 'kerner', 'ian', 'focus']...) from 5 documents (total 895 corpus positions)\n",
      "2019-10-29 00:37:54,712 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:54,719 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:54,721 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:54,725 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:54,726 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:54,789 : INFO : -7.032 per-word bound, 130.9 perplexity estimate based on a held-out corpus of 5 documents with 895 words\n",
      "2019-10-29 00:37:54,792 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:54,798 : INFO : topic #1 (0.100): 0.039*\"sex\" + 0.027*\"partner\" + 0.025*\"desire\" + 0.023*\"men\" + 0.022*\"one\" + 0.017*\"interest\" + 0.017*\"due\" + 0.017*\"low\" + 0.016*\"sexual\" + 0.016*\"time\"\n",
      "2019-10-29 00:37:54,801 : INFO : topic #4 (0.100): 0.055*\"sex\" + 0.024*\"one\" + 0.022*\"desire\" + 0.021*\"men\" + 0.021*\"partner\" + 0.018*\"woman\" + 0.018*\"couple\" + 0.015*\"interest\" + 0.015*\"low\" + 0.015*\"libido\"\n",
      "2019-10-29 00:37:54,804 : INFO : topic #7 (0.100): 0.049*\"sex\" + 0.024*\"partner\" + 0.023*\"one\" + 0.020*\"sexual\" + 0.019*\"men\" + 0.019*\"time\" + 0.019*\"couple\" + 0.019*\"desire\" + 0.017*\"due\" + 0.016*\"low\"\n",
      "2019-10-29 00:37:54,807 : INFO : topic #0 (0.100): 0.039*\"sex\" + 0.026*\"partner\" + 0.023*\"desire\" + 0.021*\"men\" + 0.019*\"due\" + 0.019*\"one\" + 0.017*\"interest\" + 0.017*\"time\" + 0.016*\"libido\" + 0.015*\"low\"\n",
      "2019-10-29 00:37:54,811 : INFO : topic #3 (0.100): 0.043*\"sex\" + 0.027*\"desire\" + 0.025*\"partner\" + 0.021*\"men\" + 0.021*\"one\" + 0.020*\"time\" + 0.020*\"libido\" + 0.017*\"low\" + 0.017*\"issue\" + 0.017*\"interest\"\n",
      "2019-10-29 00:37:54,814 : INFO : topic diff=0.806220, rho=1.000000\n",
      "2019-10-29 00:37:55,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:55,256 : INFO : built Dictionary(322 unique tokens: ['school', 'aspiration', 'reach', 'rattled', 'industry']...) from 5 documents (total 2430 corpus positions)\n",
      "2019-10-29 00:37:55,260 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:55,262 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:55,263 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:55,268 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:55,269 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:55,380 : INFO : -7.837 per-word bound, 228.6 perplexity estimate based on a held-out corpus of 5 documents with 2430 words\n",
      "2019-10-29 00:37:55,382 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:55,392 : INFO : topic #3 (0.100): 0.058*\"park\" + 0.016*\"said\" + 0.014*\"b\" + 0.011*\"seattle\" + 0.010*\"k\" + 0.010*\"music\" + 0.010*\"jay\" + 0.009*\"pop\" + 0.009*\"one\" + 0.009*\"asia\"\n",
      "2019-10-29 00:37:55,395 : INFO : topic #5 (0.100): 0.054*\"park\" + 0.013*\"jay\" + 0.013*\"said\" + 0.013*\"k\" + 0.011*\"seattle\" + 0.010*\"asia\" + 0.009*\"b\" + 0.009*\"album\" + 0.009*\"pop\" + 0.009*\"label\"\n",
      "2019-10-29 00:37:55,398 : INFO : topic #7 (0.100): 0.037*\"park\" + 0.014*\"b\" + 0.013*\"jay\" + 0.013*\"said\" + 0.011*\"pop\" + 0.010*\"rapper\" + 0.009*\"mom\" + 0.009*\"asian\" + 0.009*\"asia\" + 0.009*\"label\"\n",
      "2019-10-29 00:37:55,400 : INFO : topic #4 (0.100): 0.052*\"park\" + 0.014*\"said\" + 0.013*\"jay\" + 0.011*\"pop\" + 0.011*\"b\" + 0.010*\"music\" + 0.010*\"seattle\" + 0.008*\"k\" + 0.008*\"asia\" + 0.008*\"album\"\n",
      "2019-10-29 00:37:55,403 : INFO : topic #6 (0.100): 0.031*\"park\" + 0.018*\"jay\" + 0.016*\"said\" + 0.011*\"seattle\" + 0.010*\"music\" + 0.010*\"k\" + 0.009*\"b\" + 0.009*\"asia\" + 0.009*\"mom\" + 0.008*\"like\"\n",
      "2019-10-29 00:37:55,405 : INFO : topic diff=0.823981, rho=1.000000\n",
      "2019-10-29 00:37:55,894 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:55,900 : INFO : built Dictionary(247 unique tokens: ['concern', 'de', 'aircraft', 'timber', 'one']...) from 5 documents (total 1680 corpus positions)\n",
      "2019-10-29 00:37:55,904 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:55,905 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:55,907 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:55,911 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:55,913 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:56,037 : INFO : -7.755 per-word bound, 216.0 perplexity estimate based on a held-out corpus of 5 documents with 1680 words\n",
      "2019-10-29 00:37:56,040 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:56,049 : INFO : topic #4 (0.100): 0.030*\"plywood\" + 0.024*\"material\" + 0.018*\"furniture\" + 0.015*\"veneer\" + 0.013*\"london\" + 0.012*\"say\" + 0.012*\"wilk\" + 0.012*\"albert\" + 0.011*\"modern\" + 0.011*\"used\"\n",
      "2019-10-29 00:37:56,053 : INFO : topic #1 (0.100): 0.035*\"plywood\" + 0.018*\"material\" + 0.016*\"wilk\" + 0.015*\"veneer\" + 0.014*\"world\" + 0.014*\"say\" + 0.013*\"furniture\" + 0.011*\"museum\" + 0.010*\"modern\" + 0.010*\"london\"\n",
      "2019-10-29 00:37:56,055 : INFO : topic #5 (0.100): 0.037*\"plywood\" + 0.018*\"material\" + 0.017*\"furniture\" + 0.015*\"say\" + 0.014*\"veneer\" + 0.014*\"wilk\" + 0.012*\"modern\" + 0.010*\"london\" + 0.009*\"became\" + 0.008*\"wood\"\n",
      "2019-10-29 00:37:56,059 : INFO : topic #7 (0.100): 0.039*\"plywood\" + 0.025*\"material\" + 0.014*\"furniture\" + 0.013*\"veneer\" + 0.012*\"wilk\" + 0.012*\"say\" + 0.010*\"albert\" + 0.010*\"london\" + 0.010*\"modern\" + 0.009*\"victoria\"\n",
      "2019-10-29 00:37:56,063 : INFO : topic #2 (0.100): 0.042*\"plywood\" + 0.021*\"furniture\" + 0.019*\"material\" + 0.014*\"wilk\" + 0.014*\"modern\" + 0.014*\"veneer\" + 0.013*\"say\" + 0.013*\"world\" + 0.010*\"victoria\" + 0.010*\"victorian\"\n",
      "2019-10-29 00:37:56,066 : INFO : topic diff=0.774856, rho=1.000000\n",
      "2019-10-29 00:37:56,553 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:56,556 : INFO : built Dictionary(123 unique tokens: ['dating', 'offered', 'help', 'home', 'making']...) from 5 documents (total 885 corpus positions)\n",
      "2019-10-29 00:37:56,559 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:56,564 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:56,566 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:56,569 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:56,571 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:56,623 : INFO : -7.031 per-word bound, 130.8 perplexity estimate based on a held-out corpus of 5 documents with 885 words\n",
      "2019-10-29 00:37:56,624 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:56,633 : INFO : topic #3 (0.100): 0.039*\"test\" + 0.039*\"hiv\" + 0.034*\"study\" + 0.028*\"grindr\" + 0.024*\"kit\" + 0.018*\"self\" + 0.018*\"men\" + 0.014*\"according\" + 0.013*\"access\" + 0.013*\"home\"\n",
      "2019-10-29 00:37:56,638 : INFO : topic #0 (0.100): 0.049*\"hiv\" + 0.045*\"test\" + 0.034*\"study\" + 0.032*\"kit\" + 0.025*\"grindr\" + 0.024*\"men\" + 0.019*\"self\" + 0.013*\"ad\" + 0.013*\"spread\" + 0.012*\"user\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:56,641 : INFO : topic #6 (0.100): 0.041*\"study\" + 0.039*\"kit\" + 0.037*\"test\" + 0.036*\"hiv\" + 0.027*\"grindr\" + 0.017*\"men\" + 0.014*\"self\" + 0.013*\"researcher\" + 0.013*\"getting\" + 0.013*\"app\"\n",
      "2019-10-29 00:37:56,648 : INFO : topic #4 (0.100): 0.041*\"hiv\" + 0.038*\"test\" + 0.031*\"grindr\" + 0.029*\"kit\" + 0.028*\"study\" + 0.020*\"men\" + 0.013*\"way\" + 0.013*\"self\" + 0.013*\"user\" + 0.013*\"risk\"\n",
      "2019-10-29 00:37:56,656 : INFO : topic #9 (0.100): 0.050*\"test\" + 0.046*\"study\" + 0.042*\"hiv\" + 0.026*\"kit\" + 0.022*\"grindr\" + 0.016*\"men\" + 0.015*\"self\" + 0.014*\"tested\" + 0.014*\"stigma\" + 0.013*\"gay\"\n",
      "2019-10-29 00:37:56,668 : INFO : topic diff=0.801690, rho=1.000000\n",
      "2019-10-29 00:37:57,164 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:57,166 : INFO : built Dictionary(178 unique tokens: ['sorry', 'end', 'extent', 'u', 'new']...) from 5 documents (total 1255 corpus positions)\n",
      "2019-10-29 00:37:57,169 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:57,170 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:57,172 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:57,175 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:57,176 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:57,246 : INFO : -7.395 per-word bound, 168.3 perplexity estimate based on a held-out corpus of 5 documents with 1255 words\n",
      "2019-10-29 00:37:57,247 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:57,253 : INFO : topic #1 (0.100): 0.035*\"generation\" + 0.019*\"time\" + 0.019*\"millennials\" + 0.016*\"year\" + 0.015*\"diprete\" + 0.014*\"people\" + 0.013*\"old\" + 0.013*\"article\" + 0.012*\"rise\" + 0.012*\"actually\"\n",
      "2019-10-29 00:37:57,255 : INFO : topic #7 (0.100): 0.029*\"generation\" + 0.023*\"millennials\" + 0.017*\"old\" + 0.017*\"diprete\" + 0.015*\"year\" + 0.014*\"time\" + 0.013*\"actually\" + 0.012*\"boundary\" + 0.012*\"slate\" + 0.012*\"friend\"\n",
      "2019-10-29 00:37:57,256 : INFO : topic #5 (0.100): 0.038*\"generation\" + 0.020*\"millennials\" + 0.017*\"old\" + 0.016*\"year\" + 0.015*\"diprete\" + 0.014*\"actually\" + 0.014*\"drawn\" + 0.013*\"friend\" + 0.012*\"time\" + 0.012*\"example\"\n",
      "2019-10-29 00:37:57,258 : INFO : topic #3 (0.100): 0.039*\"generation\" + 0.023*\"millennials\" + 0.016*\"time\" + 0.015*\"year\" + 0.014*\"diprete\" + 0.012*\"boundary\" + 0.012*\"people\" + 0.012*\"drawn\" + 0.011*\"millennial\" + 0.011*\"example\"\n",
      "2019-10-29 00:37:57,260 : INFO : topic #2 (0.100): 0.035*\"generation\" + 0.022*\"millennials\" + 0.015*\"time\" + 0.015*\"year\" + 0.014*\"slate\" + 0.014*\"old\" + 0.013*\"rise\" + 0.013*\"example\" + 0.013*\"article\" + 0.012*\"millennial\"\n",
      "2019-10-29 00:37:57,263 : INFO : topic diff=0.772857, rho=1.000000\n",
      "2019-10-29 00:37:57,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:57,721 : INFO : built Dictionary(19 unique tokens: ['weinstein', 'player', 'made', 'harvey', 'apologized']...) from 5 documents (total 110 corpus positions)\n",
      "2019-10-29 00:37:57,723 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:57,725 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:57,727 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:57,729 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:57,730 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:57,749 : INFO : -6.155 per-word bound, 71.3 perplexity estimate based on a held-out corpus of 5 documents with 110 words\n",
      "2019-10-29 00:37:57,752 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:57,756 : INFO : topic #3 (0.100): 0.096*\"karan\" + 0.082*\"weinstein\" + 0.081*\"donna\" + 0.060*\"made\" + 0.055*\"sexual\" + 0.054*\"hollywood\" + 0.049*\"designer\" + 0.048*\"wake\" + 0.047*\"scandal\" + 0.047*\"apologizes\"\n",
      "2019-10-29 00:37:57,760 : INFO : topic #6 (0.100): 0.095*\"weinstein\" + 0.093*\"donna\" + 0.083*\"karan\" + 0.057*\"power\" + 0.056*\"apologized\" + 0.052*\"hollywood\" + 0.048*\"woman\" + 0.048*\"remark\" + 0.047*\"scandal\" + 0.047*\"harvey\"\n",
      "2019-10-29 00:37:57,763 : INFO : topic #0 (0.100): 0.108*\"weinstein\" + 0.094*\"karan\" + 0.058*\"donna\" + 0.057*\"apologized\" + 0.052*\"hollywood\" + 0.051*\"wake\" + 0.050*\"scandal\" + 0.049*\"harvey\" + 0.048*\"made\" + 0.046*\"designer\"\n",
      "2019-10-29 00:37:57,767 : INFO : topic #9 (0.100): 0.112*\"weinstein\" + 0.082*\"karan\" + 0.074*\"donna\" + 0.061*\"made\" + 0.051*\"woman\" + 0.051*\"player\" + 0.049*\"harvey\" + 0.049*\"remark\" + 0.049*\"harassment\" + 0.048*\"comment\"\n",
      "2019-10-29 00:37:57,770 : INFO : topic #2 (0.100): 0.108*\"donna\" + 0.073*\"karan\" + 0.061*\"weinstein\" + 0.060*\"designer\" + 0.058*\"wake\" + 0.053*\"apologizes\" + 0.053*\"harvey\" + 0.052*\"sexual\" + 0.050*\"power\" + 0.049*\"harassment\"\n",
      "2019-10-29 00:37:57,773 : INFO : topic diff=0.627414, rho=1.000000\n",
      "2019-10-29 00:37:58,214 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:58,220 : INFO : built Dictionary(204 unique tokens: ['violence', 'book', 'marched', 'come', 'broke']...) from 5 documents (total 1445 corpus positions)\n",
      "2019-10-29 00:37:58,225 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:58,232 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:58,235 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:58,239 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:58,242 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:58,367 : INFO : -7.516 per-word bound, 183.1 perplexity estimate based on a held-out corpus of 5 documents with 1445 words\n",
      "2019-10-29 00:37:58,369 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:58,375 : INFO : topic #4 (0.100): 0.033*\"germany\" + 0.022*\"zakaria\" + 0.021*\"said\" + 0.019*\"memorial\" + 0.017*\"country\" + 0.016*\"america\" + 0.015*\"nazi\" + 0.013*\"confederate\" + 0.012*\"monument\" + 0.011*\"history\"\n",
      "2019-10-29 00:37:58,378 : INFO : topic #8 (0.100): 0.034*\"germany\" + 0.022*\"zakaria\" + 0.020*\"said\" + 0.014*\"america\" + 0.014*\"memorial\" + 0.011*\"monument\" + 0.011*\"country\" + 0.010*\"state\" + 0.010*\"confederate\" + 0.010*\"could\"\n",
      "2019-10-29 00:37:58,381 : INFO : topic #5 (0.100): 0.035*\"germany\" + 0.031*\"zakaria\" + 0.022*\"said\" + 0.019*\"country\" + 0.015*\"memorial\" + 0.014*\"nazi\" + 0.013*\"monument\" + 0.010*\"cnn\" + 0.010*\"america\" + 0.009*\"could\"\n",
      "2019-10-29 00:37:58,383 : INFO : topic #7 (0.100): 0.044*\"germany\" + 0.029*\"zakaria\" + 0.016*\"country\" + 0.015*\"said\" + 0.015*\"america\" + 0.013*\"memorial\" + 0.012*\"monument\" + 0.011*\"nazi\" + 0.010*\"united\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:37:58,386 : INFO : topic #9 (0.100): 0.033*\"germany\" + 0.028*\"said\" + 0.026*\"zakaria\" + 0.018*\"country\" + 0.017*\"memorial\" + 0.013*\"united\" + 0.012*\"america\" + 0.012*\"monument\" + 0.011*\"nazi\" + 0.010*\"confederate\"\n",
      "2019-10-29 00:37:58,388 : INFO : topic diff=0.786132, rho=1.000000\n",
      "2019-10-29 00:37:58,795 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:58,802 : INFO : built Dictionary(220 unique tokens: ['let', 'product', 'experiencing', 'size', 'attending']...) from 5 documents (total 1585 corpus positions)\n",
      "2019-10-29 00:37:58,808 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:58,811 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:58,815 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:58,819 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:37:58,822 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:58,938 : INFO : -7.552 per-word bound, 187.6 perplexity estimate based on a held-out corpus of 5 documents with 1585 words\n",
      "2019-10-29 00:37:58,940 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:58,948 : INFO : topic #3 (0.100): 0.029*\"said\" + 0.021*\"company\" + 0.017*\"worrying\" + 0.014*\"paperless\" + 0.014*\"post\" + 0.013*\"people\" + 0.013*\"online\" + 0.012*\"hirschfeld\" + 0.012*\"really\" + 0.011*\"life\"\n",
      "2019-10-29 00:37:58,950 : INFO : topic #0 (0.100): 0.025*\"said\" + 0.017*\"company\" + 0.015*\"people\" + 0.015*\"life\" + 0.015*\"worrying\" + 0.013*\"online\" + 0.013*\"face\" + 0.012*\"paperless\" + 0.012*\"founder\" + 0.012*\"post\"\n",
      "2019-10-29 00:37:58,951 : INFO : topic #2 (0.100): 0.025*\"said\" + 0.022*\"company\" + 0.018*\"people\" + 0.015*\"online\" + 0.014*\"paperless\" + 0.014*\"worrying\" + 0.013*\"post\" + 0.013*\"technology\" + 0.012*\"really\" + 0.011*\"life\"\n",
      "2019-10-29 00:37:58,954 : INFO : topic #1 (0.100): 0.026*\"said\" + 0.024*\"company\" + 0.017*\"people\" + 0.015*\"paperless\" + 0.014*\"post\" + 0.013*\"technology\" + 0.013*\"hirschfeld\" + 0.013*\"online\" + 0.013*\"worrying\" + 0.013*\"life\"\n",
      "2019-10-29 00:37:58,956 : INFO : topic #9 (0.100): 0.019*\"company\" + 0.018*\"said\" + 0.016*\"worrying\" + 0.015*\"online\" + 0.015*\"post\" + 0.014*\"technology\" + 0.014*\"paperless\" + 0.013*\"hirschfeld\" + 0.013*\"really\" + 0.013*\"people\"\n",
      "2019-10-29 00:37:58,957 : INFO : topic diff=0.793707, rho=1.000000\n",
      "2019-10-29 00:37:59,405 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:59,407 : INFO : built Dictionary(89 unique tokens: ['fewer', 'sodium', 'portion', 'suggest', 'milk']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:37:59,409 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:59,415 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:59,417 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:59,421 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:59,423 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:37:59,477 : INFO : -6.877 per-word bound, 117.5 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:37:59,479 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:37:59,487 : INFO : topic #6 (0.100): 0.061*\"cheese\" + 0.051*\"calorie\" + 0.044*\"ounce\" + 0.027*\"one\" + 0.022*\"nutrient\" + 0.020*\"important\" + 0.020*\"fat\" + 0.018*\"cholesterol\" + 0.017*\"saturated\" + 0.017*\"milk\"\n",
      "2019-10-29 00:37:59,489 : INFO : topic #9 (0.100): 0.067*\"calorie\" + 0.062*\"cheese\" + 0.037*\"ounce\" + 0.030*\"one\" + 0.024*\"nutrient\" + 0.021*\"cholesterol\" + 0.019*\"whole\" + 0.019*\"saturated\" + 0.017*\"important\" + 0.016*\"add\"\n",
      "2019-10-29 00:37:59,491 : INFO : topic #5 (0.100): 0.060*\"calorie\" + 0.057*\"cheese\" + 0.040*\"ounce\" + 0.033*\"nutrient\" + 0.024*\"one\" + 0.015*\"add\" + 0.015*\"saturated\" + 0.015*\"milk\" + 0.015*\"important\" + 0.014*\"fat\"\n",
      "2019-10-29 00:37:59,496 : INFO : topic #1 (0.100): 0.078*\"calorie\" + 0.057*\"cheese\" + 0.032*\"ounce\" + 0.022*\"nutrient\" + 0.021*\"one\" + 0.019*\"cholesterol\" + 0.018*\"whole\" + 0.017*\"milk\" + 0.017*\"saturated\" + 0.016*\"fat\"\n",
      "2019-10-29 00:37:59,505 : INFO : topic #0 (0.100): 0.064*\"calorie\" + 0.056*\"cheese\" + 0.035*\"ounce\" + 0.025*\"one\" + 0.018*\"milk\" + 0.018*\"nutrient\" + 0.016*\"saturated\" + 0.015*\"fat\" + 0.015*\"add\" + 0.014*\"whole\"\n",
      "2019-10-29 00:37:59,509 : INFO : topic diff=0.786618, rho=1.000000\n",
      "2019-10-29 00:37:59,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:37:59,970 : INFO : built Dictionary(429 unique tokens: ['specie', 'transition', 'refugee', 'focus', 'recommendation']...) from 5 documents (total 3140 corpus positions)\n",
      "2019-10-29 00:37:59,977 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:37:59,979 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:37:59,980 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:37:59,984 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:37:59,986 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:00,142 : INFO : -8.153 per-word bound, 284.7 perplexity estimate based on a held-out corpus of 5 documents with 3140 words\n",
      "2019-10-29 00:38:00,144 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:00,151 : INFO : topic #1 (0.100): 0.030*\"climate\" + 0.024*\"degree\" + 0.021*\"book\" + 0.019*\"change\" + 0.011*\"lynas\" + 0.009*\"world\" + 0.009*\"well\" + 0.009*\"reader\" + 0.008*\"future\" + 0.008*\"planet\"\n",
      "2019-10-29 00:38:00,152 : INFO : topic #7 (0.100): 0.030*\"climate\" + 0.026*\"book\" + 0.017*\"degree\" + 0.017*\"change\" + 0.014*\"lynas\" + 0.008*\"read\" + 0.008*\"well\" + 0.008*\"reader\" + 0.008*\"planet\" + 0.007*\"science\"\n",
      "2019-10-29 00:38:00,154 : INFO : topic #0 (0.100): 0.028*\"degree\" + 0.026*\"climate\" + 0.020*\"book\" + 0.017*\"change\" + 0.012*\"lynas\" + 0.008*\"read\" + 0.008*\"six\" + 0.007*\"suggested\" + 0.007*\"future\" + 0.007*\"cnn\"\n",
      "2019-10-29 00:38:00,155 : INFO : topic #2 (0.100): 0.026*\"climate\" + 0.024*\"book\" + 0.021*\"change\" + 0.020*\"degree\" + 0.013*\"lynas\" + 0.008*\"planet\" + 0.008*\"future\" + 0.008*\"read\" + 0.007*\"great\" + 0.007*\"cnn\"\n",
      "2019-10-29 00:38:00,157 : INFO : topic #5 (0.100): 0.025*\"book\" + 0.025*\"climate\" + 0.023*\"degree\" + 0.021*\"change\" + 0.010*\"lynas\" + 0.010*\"great\" + 0.010*\"future\" + 0.009*\"six\" + 0.008*\"reader\" + 0.007*\"well\"\n",
      "2019-10-29 00:38:00,159 : INFO : topic diff=0.810487, rho=1.000000\n",
      "2019-10-29 00:38:00,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:00,563 : INFO : built Dictionary(47 unique tokens: ['shopper', 'encouraged', 'holder', 'thought', 'hour']...) from 5 documents (total 330 corpus positions)\n",
      "2019-10-29 00:38:00,565 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:00,566 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:00,567 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:00,569 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:00,572 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:00,601 : INFO : -6.285 per-word bound, 78.0 perplexity estimate based on a held-out corpus of 5 documents with 330 words\n",
      "2019-10-29 00:38:00,603 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:00,612 : INFO : topic #3 (0.100): 0.077*\"charm\" + 0.067*\"avery\" + 0.053*\"james\" + 0.044*\"whataburger\" + 0.034*\"sold\" + 0.031*\"one\" + 0.030*\"time\" + 0.029*\"hour\" + 0.028*\"release\" + 0.020*\"hook\"\n",
      "2019-10-29 00:38:00,615 : INFO : topic #1 (0.100): 0.094*\"charm\" + 0.059*\"james\" + 0.058*\"avery\" + 0.039*\"whataburger\" + 0.032*\"release\" + 0.028*\"one\" + 0.026*\"hour\" + 0.024*\"time\" + 0.024*\"sold\" + 0.021*\"downright\"\n",
      "2019-10-29 00:38:00,619 : INFO : topic #9 (0.100): 0.085*\"charm\" + 0.057*\"avery\" + 0.053*\"james\" + 0.053*\"whataburger\" + 0.038*\"time\" + 0.029*\"sold\" + 0.028*\"hour\" + 0.025*\"release\" + 0.025*\"one\" + 0.021*\"necklace\"\n",
      "2019-10-29 00:38:00,622 : INFO : topic #2 (0.100): 0.090*\"charm\" + 0.063*\"avery\" + 0.060*\"whataburger\" + 0.055*\"james\" + 0.035*\"one\" + 0.033*\"sold\" + 0.032*\"time\" + 0.031*\"hour\" + 0.026*\"release\" + 0.019*\"soon\"\n",
      "2019-10-29 00:38:00,625 : INFO : topic #4 (0.100): 0.116*\"charm\" + 0.062*\"james\" + 0.052*\"avery\" + 0.047*\"whataburger\" + 0.033*\"hour\" + 0.032*\"time\" + 0.030*\"release\" + 0.028*\"one\" + 0.022*\"sold\" + 0.021*\"following\"\n",
      "2019-10-29 00:38:00,628 : INFO : topic diff=0.812520, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:01,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:01,116 : INFO : built Dictionary(319 unique tokens: ['harvested', 'story', 'cited', 'portion', 'campaign']...) from 5 documents (total 2925 corpus positions)\n",
      "2019-10-29 00:38:01,121 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:01,123 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:01,126 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:01,129 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:01,132 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:01,283 : INFO : -7.560 per-word bound, 188.7 perplexity estimate based on a held-out corpus of 5 documents with 2925 words\n",
      "2019-10-29 00:38:01,285 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:01,293 : INFO : topic #1 (0.100): 0.037*\"planned\" + 0.029*\"parenthood\" + 0.024*\"video\" + 0.023*\"daleiden\" + 0.020*\"fetus\" + 0.016*\"photo\" + 0.015*\"medical\" + 0.015*\"cnn\" + 0.011*\"aborted\" + 0.011*\"center\"\n",
      "2019-10-29 00:38:01,295 : INFO : topic #9 (0.100): 0.039*\"parenthood\" + 0.026*\"planned\" + 0.026*\"video\" + 0.018*\"fetus\" + 0.017*\"daleiden\" + 0.016*\"medical\" + 0.013*\"photo\" + 0.013*\"cnn\" + 0.010*\"sample\" + 0.010*\"tissue\"\n",
      "2019-10-29 00:38:01,299 : INFO : topic #7 (0.100): 0.038*\"planned\" + 0.035*\"parenthood\" + 0.034*\"video\" + 0.019*\"daleiden\" + 0.014*\"aborted\" + 0.013*\"medical\" + 0.013*\"fetus\" + 0.012*\"center\" + 0.012*\"photo\" + 0.012*\"cnn\"\n",
      "2019-10-29 00:38:01,302 : INFO : topic #2 (0.100): 0.046*\"parenthood\" + 0.030*\"video\" + 0.027*\"planned\" + 0.020*\"daleiden\" + 0.018*\"fetus\" + 0.016*\"medical\" + 0.014*\"photo\" + 0.014*\"aborted\" + 0.011*\"cnn\" + 0.011*\"center\"\n",
      "2019-10-29 00:38:01,307 : INFO : topic #3 (0.100): 0.040*\"planned\" + 0.034*\"parenthood\" + 0.032*\"video\" + 0.022*\"daleiden\" + 0.018*\"aborted\" + 0.016*\"medical\" + 0.015*\"fetus\" + 0.014*\"cnn\" + 0.012*\"photo\" + 0.011*\"center\"\n",
      "2019-10-29 00:38:01,311 : INFO : topic diff=0.907444, rho=1.000000\n",
      "2019-10-29 00:38:01,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:01,819 : INFO : built Dictionary(475 unique tokens: ['portion', 'laboratory', 'spot', 'wheel', 'planned']...) from 5 documents (total 7635 corpus positions)\n",
      "2019-10-29 00:38:01,828 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:01,831 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:01,834 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:01,838 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:01,841 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:01,997 : INFO : -7.391 per-word bound, 167.9 perplexity estimate based on a held-out corpus of 5 documents with 7635 words\n",
      "2019-10-29 00:38:01,999 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:02,008 : INFO : topic #6 (0.100): 0.080*\"rover\" + 0.071*\"curiosity\" + 0.057*\"mar\" + 0.042*\"photo\" + 0.035*\"hide\" + 0.031*\"caption\" + 0.022*\"image\" + 0.017*\"nasa\" + 0.015*\"camera\" + 0.014*\"taken\"\n",
      "2019-10-29 00:38:02,010 : INFO : topic #7 (0.100): 0.063*\"mar\" + 0.059*\"rover\" + 0.055*\"curiosity\" + 0.043*\"photo\" + 0.037*\"caption\" + 0.030*\"hide\" + 0.029*\"image\" + 0.017*\"nasa\" + 0.017*\"rock\" + 0.015*\"camera\"\n",
      "2019-10-29 00:38:02,011 : INFO : topic #3 (0.100): 0.078*\"rover\" + 0.072*\"curiosity\" + 0.039*\"mar\" + 0.039*\"photo\" + 0.029*\"caption\" + 0.023*\"hide\" + 0.021*\"image\" + 0.019*\"taken\" + 0.018*\"nasa\" + 0.016*\"camera\"\n",
      "2019-10-29 00:38:02,013 : INFO : topic #5 (0.100): 0.065*\"curiosity\" + 0.059*\"mar\" + 0.048*\"rover\" + 0.034*\"hide\" + 0.034*\"photo\" + 0.032*\"caption\" + 0.031*\"image\" + 0.018*\"camera\" + 0.017*\"taken\" + 0.016*\"rock\"\n",
      "2019-10-29 00:38:02,014 : INFO : topic #2 (0.100): 0.059*\"mar\" + 0.056*\"rover\" + 0.050*\"curiosity\" + 0.038*\"caption\" + 0.032*\"hide\" + 0.032*\"photo\" + 0.031*\"image\" + 0.019*\"rock\" + 0.018*\"nasa\" + 0.015*\"camera\"\n",
      "2019-10-29 00:38:02,017 : INFO : topic diff=1.211332, rho=1.000000\n",
      "2019-10-29 00:38:02,472 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:02,476 : INFO : built Dictionary(149 unique tokens: ['located', 'seal', 'mary', 'danish', 'opening']...) from 5 documents (total 1110 corpus positions)\n",
      "2019-10-29 00:38:02,484 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:02,490 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:02,495 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:02,499 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:02,502 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:02,573 : INFO : -7.146 per-word bound, 141.6 perplexity estimate based on a held-out corpus of 5 documents with 1110 words\n",
      "2019-10-29 00:38:02,574 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:02,580 : INFO : topic #4 (0.100): 0.072*\"lego\" + 0.045*\"house\" + 0.021*\"denmark\" + 0.016*\"skill\" + 0.014*\"billund\" + 0.014*\"play\" + 0.014*\"inside\" + 0.013*\"creativity\" + 0.012*\"building\" + 0.011*\"four\"\n",
      "2019-10-29 00:38:02,582 : INFO : topic #2 (0.100): 0.057*\"house\" + 0.056*\"lego\" + 0.017*\"danish\" + 0.017*\"skill\" + 0.015*\"denmark\" + 0.014*\"play\" + 0.013*\"inside\" + 0.012*\"four\" + 0.012*\"brick\" + 0.012*\"billund\"\n",
      "2019-10-29 00:38:02,585 : INFO : topic #8 (0.100): 0.084*\"lego\" + 0.065*\"house\" + 0.018*\"skill\" + 0.018*\"denmark\" + 0.017*\"building\" + 0.016*\"brick\" + 0.013*\"creativity\" + 0.013*\"inside\" + 0.013*\"billund\" + 0.012*\"four\"\n",
      "2019-10-29 00:38:02,588 : INFO : topic #9 (0.100): 0.086*\"house\" + 0.072*\"lego\" + 0.020*\"skill\" + 0.015*\"billund\" + 0.014*\"creativity\" + 0.014*\"inside\" + 0.014*\"building\" + 0.013*\"danish\" + 0.013*\"play\" + 0.012*\"brick\"\n",
      "2019-10-29 00:38:02,590 : INFO : topic #3 (0.100): 0.069*\"lego\" + 0.051*\"house\" + 0.018*\"denmark\" + 0.017*\"four\" + 0.015*\"skill\" + 0.015*\"danish\" + 0.014*\"billund\" + 0.014*\"building\" + 0.014*\"inside\" + 0.013*\"play\"\n",
      "2019-10-29 00:38:02,593 : INFO : topic diff=0.819386, rho=1.000000\n",
      "2019-10-29 00:38:03,099 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:03,114 : INFO : built Dictionary(446 unique tokens: ['extensive', 'party', 'fox', 'mounting', 'school']...) from 5 documents (total 3665 corpus positions)\n",
      "2019-10-29 00:38:03,122 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:03,126 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:03,129 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:03,133 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:03,136 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:03,364 : INFO : -8.022 per-word bound, 259.8 perplexity estimate based on a held-out corpus of 5 documents with 3665 words\n",
      "2019-10-29 00:38:03,367 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:03,378 : INFO : topic #0 (0.100): 0.023*\"working\" + 0.020*\"white\" + 0.019*\"said\" + 0.018*\"economy\" + 0.016*\"class\" + 0.010*\"feel\" + 0.010*\"american\" + 0.008*\"view\" + 0.008*\"mcguire\" + 0.007*\"related\"\n",
      "2019-10-29 00:38:03,381 : INFO : topic #2 (0.100): 0.025*\"white\" + 0.025*\"working\" + 0.022*\"said\" + 0.019*\"class\" + 0.015*\"economy\" + 0.009*\"american\" + 0.009*\"cnn\" + 0.008*\"feel\" + 0.008*\"related\" + 0.007*\"nation\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:03,384 : INFO : topic #6 (0.100): 0.031*\"working\" + 0.023*\"class\" + 0.020*\"said\" + 0.018*\"white\" + 0.013*\"feel\" + 0.011*\"economy\" + 0.009*\"nation\" + 0.008*\"job\" + 0.007*\"american\" + 0.007*\"economic\"\n",
      "2019-10-29 00:38:03,387 : INFO : topic #3 (0.100): 0.031*\"said\" + 0.027*\"working\" + 0.023*\"white\" + 0.014*\"economy\" + 0.013*\"class\" + 0.013*\"feel\" + 0.011*\"view\" + 0.009*\"cnn\" + 0.008*\"nation\" + 0.008*\"state\"\n",
      "2019-10-29 00:38:03,389 : INFO : topic #7 (0.100): 0.024*\"white\" + 0.024*\"class\" + 0.022*\"working\" + 0.018*\"said\" + 0.014*\"feel\" + 0.013*\"economy\" + 0.007*\"view\" + 0.007*\"people\" + 0.007*\"cnn\" + 0.007*\"economic\"\n",
      "2019-10-29 00:38:03,392 : INFO : topic diff=0.856346, rho=1.000000\n",
      "2019-10-29 00:38:03,895 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:03,901 : INFO : built Dictionary(185 unique tokens: ['josh', 'paradise', 'end', 'crest', 'subdivision']...) from 5 documents (total 2590 corpus positions)\n",
      "2019-10-29 00:38:03,904 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:03,905 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:03,906 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:03,910 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:03,914 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:04,007 : INFO : -6.586 per-word bound, 96.1 perplexity estimate based on a held-out corpus of 5 documents with 2590 words\n",
      "2019-10-29 00:38:04,009 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:04,015 : INFO : topic #0 (0.100): 0.066*\"wildfire\" + 0.065*\"photo\" + 0.064*\"hide\" + 0.063*\"blaze\" + 0.056*\"california\" + 0.053*\"october\" + 0.040*\"caption\" + 0.024*\"santa\" + 0.022*\"rosa\" + 0.018*\"napa\"\n",
      "2019-10-29 00:38:04,018 : INFO : topic #4 (0.100): 0.070*\"wildfire\" + 0.063*\"hide\" + 0.061*\"caption\" + 0.056*\"california\" + 0.056*\"october\" + 0.056*\"blaze\" + 0.046*\"photo\" + 0.021*\"santa\" + 0.019*\"rosa\" + 0.017*\"home\"\n",
      "2019-10-29 00:38:04,020 : INFO : topic #8 (0.100): 0.064*\"wildfire\" + 0.063*\"blaze\" + 0.059*\"caption\" + 0.058*\"hide\" + 0.052*\"october\" + 0.048*\"photo\" + 0.048*\"california\" + 0.025*\"santa\" + 0.023*\"home\" + 0.021*\"burn\"\n",
      "2019-10-29 00:38:04,022 : INFO : topic #9 (0.100): 0.077*\"california\" + 0.061*\"wildfire\" + 0.059*\"october\" + 0.051*\"hide\" + 0.051*\"caption\" + 0.048*\"photo\" + 0.044*\"blaze\" + 0.025*\"rosa\" + 0.019*\"santa\" + 0.017*\"home\"\n",
      "2019-10-29 00:38:04,024 : INFO : topic #2 (0.100): 0.075*\"wildfire\" + 0.069*\"california\" + 0.065*\"caption\" + 0.059*\"october\" + 0.055*\"blaze\" + 0.049*\"photo\" + 0.038*\"hide\" + 0.025*\"santa\" + 0.022*\"rosa\" + 0.018*\"home\"\n",
      "2019-10-29 00:38:04,026 : INFO : topic diff=1.234335, rho=1.000000\n",
      "2019-10-29 00:38:04,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:04,497 : INFO : built Dictionary(280 unique tokens: ['forward', 'even', 'span', 'book', 'banana']...) from 5 documents (total 2105 corpus positions)\n",
      "2019-10-29 00:38:04,502 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:04,503 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:04,505 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:04,512 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:04,515 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:04,648 : INFO : -7.707 per-word bound, 209.0 perplexity estimate based on a held-out corpus of 5 documents with 2105 words\n",
      "2019-10-29 00:38:04,650 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:04,657 : INFO : topic #6 (0.100): 0.025*\"work\" + 0.024*\"art\" + 0.024*\"artist\" + 0.022*\"sex\" + 0.015*\"feminist\" + 0.013*\"positive\" + 0.012*\"exhibition\" + 0.011*\"1970s\" + 0.011*\"frieze\" + 0.010*\"gingeras\"\n",
      "2019-10-29 00:38:04,662 : INFO : topic #2 (0.100): 0.035*\"artist\" + 0.027*\"work\" + 0.022*\"art\" + 0.022*\"sex\" + 0.018*\"feminist\" + 0.013*\"woman\" + 0.013*\"london\" + 0.013*\"exhibition\" + 0.010*\"gingeras\" + 0.010*\"positive\"\n",
      "2019-10-29 00:38:04,666 : INFO : topic #8 (0.100): 0.026*\"sex\" + 0.026*\"artist\" + 0.024*\"art\" + 0.023*\"work\" + 0.015*\"feminist\" + 0.013*\"positive\" + 0.012*\"frieze\" + 0.012*\"woman\" + 0.010*\"new\" + 0.009*\"1970s\"\n",
      "2019-10-29 00:38:04,671 : INFO : topic #5 (0.100): 0.029*\"work\" + 0.026*\"artist\" + 0.025*\"art\" + 0.019*\"sex\" + 0.016*\"feminist\" + 0.011*\"exhibition\" + 0.010*\"sexuality\" + 0.010*\"new\" + 0.010*\"frieze\" + 0.009*\"woman\"\n",
      "2019-10-29 00:38:04,673 : INFO : topic #0 (0.100): 0.027*\"art\" + 0.025*\"work\" + 0.022*\"artist\" + 0.021*\"sex\" + 0.017*\"feminist\" + 0.015*\"positive\" + 0.011*\"frieze\" + 0.011*\"new\" + 0.010*\"london\" + 0.010*\"woman\"\n",
      "2019-10-29 00:38:04,676 : INFO : topic diff=0.853903, rho=1.000000\n",
      "2019-10-29 00:38:05,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:05,114 : INFO : built Dictionary(218 unique tokens: ['let', 'launch', 'hanging', 'equipped', 'come']...) from 5 documents (total 1535 corpus positions)\n",
      "2019-10-29 00:38:05,116 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:05,117 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:05,118 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:05,122 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:05,123 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:05,203 : INFO : -7.582 per-word bound, 191.7 perplexity estimate based on a held-out corpus of 5 documents with 1535 words\n",
      "2019-10-29 00:38:05,205 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:05,214 : INFO : topic #2 (0.100): 0.055*\"tesla\" + 0.037*\"car\" + 0.028*\"dhanjani\" + 0.022*\"security\" + 0.021*\"password\" + 0.019*\"said\" + 0.012*\"computer\" + 0.011*\"also\" + 0.010*\"hacker\" + 0.010*\"attack\"\n",
      "2019-10-29 00:38:05,216 : INFO : topic #3 (0.100): 0.045*\"car\" + 0.043*\"tesla\" + 0.027*\"dhanjani\" + 0.022*\"security\" + 0.020*\"password\" + 0.016*\"said\" + 0.013*\"hacker\" + 0.011*\"computer\" + 0.010*\"also\" + 0.010*\"attack\"\n",
      "2019-10-29 00:38:05,218 : INFO : topic #0 (0.100): 0.039*\"car\" + 0.035*\"tesla\" + 0.029*\"dhanjani\" + 0.025*\"security\" + 0.019*\"password\" + 0.019*\"said\" + 0.014*\"also\" + 0.013*\"computer\" + 0.012*\"hacker\" + 0.008*\"attack\"\n",
      "2019-10-29 00:38:05,220 : INFO : topic #6 (0.100): 0.040*\"tesla\" + 0.029*\"car\" + 0.028*\"dhanjani\" + 0.023*\"security\" + 0.020*\"password\" + 0.016*\"said\" + 0.015*\"hacker\" + 0.013*\"also\" + 0.013*\"computer\" + 0.009*\"attack\"\n",
      "2019-10-29 00:38:05,222 : INFO : topic #8 (0.100): 0.042*\"car\" + 0.033*\"tesla\" + 0.026*\"dhanjani\" + 0.022*\"password\" + 0.017*\"said\" + 0.016*\"security\" + 0.013*\"hacker\" + 0.010*\"computer\" + 0.010*\"also\" + 0.008*\"take\"\n",
      "2019-10-29 00:38:05,224 : INFO : topic diff=0.802607, rho=1.000000\n",
      "2019-10-29 00:38:05,783 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:05,788 : INFO : built Dictionary(343 unique tokens: ['acceptable', 'party', 'focus', 'game', 'prime']...) from 5 documents (total 2570 corpus positions)\n",
      "2019-10-29 00:38:05,794 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:05,796 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:05,798 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:05,802 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:05,803 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:05,962 : INFO : -7.903 per-word bound, 239.4 perplexity estimate based on a held-out corpus of 5 documents with 2570 words\n",
      "2019-10-29 00:38:05,963 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:05,970 : INFO : topic #1 (0.100): 0.024*\"eu\" + 0.020*\"uk\" + 0.020*\"brexit\" + 0.017*\"may\" + 0.015*\"minister\" + 0.013*\"brussels\" + 0.013*\"deal\" + 0.011*\"britain\" + 0.009*\"even\" + 0.008*\"also\"\n",
      "2019-10-29 00:38:05,972 : INFO : topic #8 (0.100): 0.026*\"may\" + 0.026*\"eu\" + 0.022*\"deal\" + 0.021*\"brexit\" + 0.018*\"uk\" + 0.015*\"minister\" + 0.012*\"british\" + 0.011*\"britain\" + 0.010*\"even\" + 0.010*\"brussels\"\n",
      "2019-10-29 00:38:05,975 : INFO : topic #6 (0.100): 0.024*\"eu\" + 0.020*\"minister\" + 0.018*\"may\" + 0.016*\"uk\" + 0.016*\"deal\" + 0.015*\"britain\" + 0.015*\"brexit\" + 0.011*\"want\" + 0.011*\"brussels\" + 0.009*\"theresa\"\n",
      "2019-10-29 00:38:05,978 : INFO : topic #9 (0.100): 0.029*\"eu\" + 0.023*\"brexit\" + 0.021*\"may\" + 0.016*\"uk\" + 0.016*\"deal\" + 0.014*\"want\" + 0.013*\"minister\" + 0.013*\"britain\" + 0.011*\"prime\" + 0.010*\"british\"\n",
      "2019-10-29 00:38:05,981 : INFO : topic #5 (0.100): 0.025*\"may\" + 0.022*\"brexit\" + 0.020*\"eu\" + 0.019*\"uk\" + 0.014*\"deal\" + 0.014*\"minister\" + 0.013*\"want\" + 0.012*\"prime\" + 0.012*\"britain\" + 0.011*\"brussels\"\n",
      "2019-10-29 00:38:05,984 : INFO : topic diff=0.825928, rho=1.000000\n",
      "2019-10-29 00:38:06,499 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:06,508 : INFO : built Dictionary(349 unique tokens: ['party', 'francisco', 'cycle', 'trying', 'really']...) from 5 documents (total 3810 corpus positions)\n",
      "2019-10-29 00:38:06,514 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:06,518 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:06,521 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:06,526 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:06,533 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:06,689 : INFO : -7.437 per-word bound, 173.3 perplexity estimate based on a held-out corpus of 5 documents with 3810 words\n",
      "2019-10-29 00:38:06,690 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:06,699 : INFO : topic #3 (0.100): 0.057*\"woman\" + 0.036*\"fertility\" + 0.022*\"said\" + 0.021*\"age\" + 0.019*\"study\" + 0.019*\"level\" + 0.015*\"test\" + 0.012*\"infertility\" + 0.011*\"egg\" + 0.011*\"fsh\"\n",
      "2019-10-29 00:38:06,701 : INFO : topic #6 (0.100): 0.045*\"woman\" + 0.031*\"fertility\" + 0.029*\"said\" + 0.025*\"study\" + 0.020*\"level\" + 0.018*\"age\" + 0.015*\"egg\" + 0.013*\"fsh\" + 0.011*\"ovarian\" + 0.011*\"amh\"\n",
      "2019-10-29 00:38:06,703 : INFO : topic #7 (0.100): 0.055*\"woman\" + 0.028*\"fertility\" + 0.027*\"study\" + 0.023*\"said\" + 0.019*\"level\" + 0.015*\"age\" + 0.012*\"infertility\" + 0.010*\"fsh\" + 0.010*\"reserve\" + 0.010*\"test\"\n",
      "2019-10-29 00:38:06,705 : INFO : topic #4 (0.100): 0.046*\"woman\" + 0.034*\"fertility\" + 0.031*\"study\" + 0.020*\"age\" + 0.020*\"said\" + 0.015*\"amh\" + 0.013*\"level\" + 0.012*\"egg\" + 0.012*\"predict\" + 0.012*\"ovarian\"\n",
      "2019-10-29 00:38:06,707 : INFO : topic #8 (0.100): 0.055*\"woman\" + 0.037*\"fertility\" + 0.024*\"said\" + 0.023*\"study\" + 0.017*\"level\" + 0.016*\"age\" + 0.013*\"infertility\" + 0.011*\"amh\" + 0.011*\"test\" + 0.011*\"egg\"\n",
      "2019-10-29 00:38:06,709 : INFO : topic diff=1.012938, rho=1.000000\n",
      "2019-10-29 00:38:07,177 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:07,179 : INFO : built Dictionary(142 unique tokens: ['official', 'stated', 'life', 'quits', 'side']...) from 5 documents (total 975 corpus positions)\n",
      "2019-10-29 00:38:07,185 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:07,188 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:07,192 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:07,195 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:07,199 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:07,270 : INFO : -7.235 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 5 documents with 975 words\n",
      "2019-10-29 00:38:07,273 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:07,287 : INFO : topic #7 (0.100): 0.041*\"trump\" + 0.038*\"would\" + 0.033*\"president\" + 0.032*\"administration\" + 0.019*\"gone\" + 0.018*\"unacceptable\" + 0.014*\"secretary\" + 0.014*\"borger\" + 0.013*\"bos\" + 0.013*\"intolerable\"\n",
      "2019-10-29 00:38:07,289 : INFO : topic #8 (0.100): 0.034*\"would\" + 0.031*\"administration\" + 0.028*\"trump\" + 0.026*\"president\" + 0.019*\"gone\" + 0.017*\"borger\" + 0.015*\"world\" + 0.014*\"secretary\" + 0.013*\"unacceptable\" + 0.012*\"day\"\n",
      "2019-10-29 00:38:07,293 : INFO : topic #5 (0.100): 0.044*\"president\" + 0.036*\"administration\" + 0.035*\"would\" + 0.028*\"trump\" + 0.019*\"secretary\" + 0.019*\"unacceptable\" + 0.015*\"gone\" + 0.015*\"world\" + 0.012*\"official\" + 0.011*\"borger\"\n",
      "2019-10-29 00:38:07,300 : INFO : topic #2 (0.100): 0.032*\"trump\" + 0.029*\"president\" + 0.026*\"administration\" + 0.025*\"would\" + 0.018*\"gone\" + 0.015*\"borger\" + 0.013*\"secretary\" + 0.013*\"insubordination\" + 0.012*\"day\" + 0.012*\"chief\"\n",
      "2019-10-29 00:38:07,304 : INFO : topic #9 (0.100): 0.036*\"president\" + 0.035*\"trump\" + 0.032*\"would\" + 0.024*\"administration\" + 0.021*\"gone\" + 0.014*\"unacceptable\" + 0.013*\"world\" + 0.012*\"intolerable\" + 0.012*\"say\" + 0.012*\"men\"\n",
      "2019-10-29 00:38:07,310 : INFO : topic diff=0.779486, rho=1.000000\n",
      "2019-10-29 00:38:07,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:08,000 : INFO : built Dictionary(1071 unique tokens: ['although', 'earned', 'filed', 'median', 'advantage']...) from 5 documents (total 12810 corpus positions)\n",
      "2019-10-29 00:38:08,015 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:08,018 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:08,021 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:08,029 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:08,031 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:08,537 : INFO : -8.447 per-word bound, 348.9 perplexity estimate based on a held-out corpus of 5 documents with 12810 words\n",
      "2019-10-29 00:38:08,539 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:08,555 : INFO : topic #1 (0.100): 0.030*\"h\" + 0.025*\"1b\" + 0.024*\"worker\" + 0.017*\"job\" + 0.014*\"visa\" + 0.012*\"say\" + 0.012*\"american\" + 0.009*\"indian\" + 0.008*\"company\" + 0.008*\"diangelo\"\n",
      "2019-10-29 00:38:08,558 : INFO : topic #4 (0.100): 0.037*\"h\" + 0.029*\"1b\" + 0.017*\"visa\" + 0.014*\"worker\" + 0.014*\"job\" + 0.013*\"american\" + 0.012*\"say\" + 0.010*\"company\" + 0.009*\"diangelo\" + 0.008*\"year\"\n",
      "2019-10-29 00:38:08,561 : INFO : topic #3 (0.100): 0.028*\"1b\" + 0.025*\"h\" + 0.022*\"worker\" + 0.017*\"say\" + 0.015*\"visa\" + 0.014*\"job\" + 0.014*\"american\" + 0.011*\"diangelo\" + 0.008*\"company\" + 0.007*\"indian\"\n",
      "2019-10-29 00:38:08,564 : INFO : topic #0 (0.100): 0.025*\"1b\" + 0.025*\"h\" + 0.023*\"worker\" + 0.016*\"job\" + 0.016*\"say\" + 0.015*\"visa\" + 0.011*\"american\" + 0.010*\"company\" + 0.009*\"diangelo\" + 0.009*\"infosys\"\n",
      "2019-10-29 00:38:08,567 : INFO : topic #5 (0.100): 0.030*\"h\" + 0.021*\"1b\" + 0.021*\"worker\" + 0.017*\"say\" + 0.017*\"visa\" + 0.011*\"job\" + 0.010*\"indian\" + 0.010*\"diangelo\" + 0.010*\"company\" + 0.008*\"american\"\n",
      "2019-10-29 00:38:08,570 : INFO : topic diff=1.070765, rho=1.000000\n",
      "2019-10-29 00:38:09,286 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:09,298 : INFO : built Dictionary(593 unique tokens: ['although', 'anniversary', 'energy', 'deep', 'let']...) from 5 documents (total 5200 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:09,306 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:09,308 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:09,311 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:09,314 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:09,316 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:09,557 : INFO : -8.211 per-word bound, 296.3 perplexity estimate based on a held-out corpus of 5 documents with 5200 words\n",
      "2019-10-29 00:38:09,559 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:09,572 : INFO : topic #5 (0.100): 0.026*\"mh370\" + 0.017*\"narendran\" + 0.013*\"passenger\" + 0.013*\"photo\" + 0.012*\"remembering\" + 0.012*\"hide\" + 0.012*\"caption\" + 0.011*\"say\" + 0.011*\"search\" + 0.009*\"one\"\n",
      "2019-10-29 00:38:09,574 : INFO : topic #4 (0.100): 0.023*\"mh370\" + 0.016*\"photo\" + 0.014*\"passenger\" + 0.014*\"search\" + 0.012*\"remembering\" + 0.012*\"hide\" + 0.011*\"narendran\" + 0.010*\"day\" + 0.010*\"say\" + 0.008*\"plane\"\n",
      "2019-10-29 00:38:09,577 : INFO : topic #3 (0.100): 0.027*\"mh370\" + 0.017*\"passenger\" + 0.013*\"narendran\" + 0.012*\"search\" + 0.011*\"photo\" + 0.011*\"remembering\" + 0.011*\"hide\" + 0.010*\"say\" + 0.009*\"caption\" + 0.008*\"missing\"\n",
      "2019-10-29 00:38:09,580 : INFO : topic #6 (0.100): 0.021*\"mh370\" + 0.018*\"passenger\" + 0.013*\"photo\" + 0.011*\"narendran\" + 0.011*\"plane\" + 0.011*\"search\" + 0.010*\"remembering\" + 0.009*\"say\" + 0.009*\"caption\" + 0.009*\"hide\"\n",
      "2019-10-29 00:38:09,584 : INFO : topic #1 (0.100): 0.020*\"mh370\" + 0.014*\"passenger\" + 0.014*\"caption\" + 0.014*\"narendran\" + 0.013*\"photo\" + 0.013*\"search\" + 0.012*\"remembering\" + 0.010*\"say\" + 0.009*\"day\" + 0.009*\"plane\"\n",
      "2019-10-29 00:38:09,596 : INFO : topic diff=0.912276, rho=1.000000\n",
      "2019-10-29 00:38:10,101 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:10,106 : INFO : built Dictionary(166 unique tokens: ['muilenburg', 'prime', 'argues', 'campaign', 'aircraft']...) from 5 documents (total 1260 corpus positions)\n",
      "2019-10-29 00:38:10,109 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:10,111 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:10,112 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:10,116 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:10,117 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:10,196 : INFO : -7.210 per-word bound, 148.0 perplexity estimate based on a held-out corpus of 5 documents with 1260 words\n",
      "2019-10-29 00:38:10,198 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:10,208 : INFO : topic #9 (0.100): 0.060*\"u\" + 0.046*\"bombardier\" + 0.027*\"boeing\" + 0.018*\"also\" + 0.016*\"could\" + 0.014*\"k\" + 0.014*\"northern\" + 0.014*\"ireland\" + 0.014*\"c\" + 0.013*\"government\"\n",
      "2019-10-29 00:38:10,210 : INFO : topic #5 (0.100): 0.051*\"bombardier\" + 0.050*\"u\" + 0.028*\"boeing\" + 0.021*\"k\" + 0.019*\"c\" + 0.017*\"also\" + 0.017*\"call\" + 0.016*\"job\" + 0.014*\"could\" + 0.014*\"series\"\n",
      "2019-10-29 00:38:10,213 : INFO : topic #4 (0.100): 0.054*\"u\" + 0.041*\"bombardier\" + 0.021*\"boeing\" + 0.017*\"c\" + 0.016*\"k\" + 0.016*\"could\" + 0.016*\"also\" + 0.015*\"government\" + 0.015*\"series\" + 0.014*\"call\"\n",
      "2019-10-29 00:38:10,215 : INFO : topic #7 (0.100): 0.058*\"u\" + 0.036*\"bombardier\" + 0.030*\"boeing\" + 0.019*\"also\" + 0.018*\"job\" + 0.018*\"call\" + 0.017*\"k\" + 0.015*\"government\" + 0.014*\"c\" + 0.013*\"series\"\n",
      "2019-10-29 00:38:10,217 : INFO : topic #0 (0.100): 0.052*\"u\" + 0.031*\"bombardier\" + 0.025*\"boeing\" + 0.022*\"k\" + 0.019*\"also\" + 0.017*\"could\" + 0.015*\"company\" + 0.015*\"series\" + 0.015*\"job\" + 0.015*\"c\"\n",
      "2019-10-29 00:38:10,228 : INFO : topic diff=0.856899, rho=1.000000\n",
      "2019-10-29 00:38:10,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:10,863 : INFO : built Dictionary(240 unique tokens: ['energy', 'nature', 'equivalent', 'collect', 'come']...) from 5 documents (total 1710 corpus positions)\n",
      "2019-10-29 00:38:10,867 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:10,869 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:10,874 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:10,879 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:10,882 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:11,008 : INFO : -7.655 per-word bound, 201.6 perplexity estimate based on a held-out corpus of 5 documents with 1710 words\n",
      "2019-10-29 00:38:11,011 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:11,020 : INFO : topic #0 (0.100): 0.019*\"china\" + 0.018*\"forest\" + 0.017*\"project\" + 0.017*\"architecture\" + 0.016*\"boeri\" + 0.015*\"city\" + 0.014*\"said\" + 0.013*\"year\" + 0.013*\"ton\" + 0.013*\"building\"\n",
      "2019-10-29 00:38:11,023 : INFO : topic #6 (0.100): 0.024*\"boeri\" + 0.023*\"forest\" + 0.020*\"china\" + 0.019*\"project\" + 0.018*\"year\" + 0.017*\"city\" + 0.017*\"building\" + 0.016*\"said\" + 0.011*\"ton\" + 0.010*\"plan\"\n",
      "2019-10-29 00:38:11,026 : INFO : topic #9 (0.100): 0.020*\"china\" + 0.020*\"forest\" + 0.018*\"said\" + 0.018*\"boeri\" + 0.016*\"building\" + 0.014*\"architecture\" + 0.013*\"city\" + 0.012*\"urban\" + 0.012*\"ton\" + 0.011*\"project\"\n",
      "2019-10-29 00:38:11,031 : INFO : topic #1 (0.100): 0.022*\"china\" + 0.021*\"boeri\" + 0.018*\"forest\" + 0.016*\"building\" + 0.015*\"year\" + 0.014*\"city\" + 0.014*\"said\" + 0.011*\"ton\" + 0.011*\"architecture\" + 0.011*\"urban\"\n",
      "2019-10-29 00:38:11,034 : INFO : topic #3 (0.100): 0.022*\"china\" + 0.019*\"forest\" + 0.018*\"building\" + 0.017*\"city\" + 0.017*\"boeri\" + 0.015*\"architecture\" + 0.014*\"year\" + 0.014*\"said\" + 0.012*\"urban\" + 0.012*\"ton\"\n",
      "2019-10-29 00:38:11,037 : INFO : topic diff=0.786126, rho=1.000000\n",
      "2019-10-29 00:38:11,878 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:11,887 : INFO : built Dictionary(302 unique tokens: ['although', 'let', 'seems', 'weinstein', 'campaign']...) from 5 documents (total 2310 corpus positions)\n",
      "2019-10-29 00:38:11,894 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:11,898 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:11,900 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:11,911 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:11,919 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:12,113 : INFO : -7.757 per-word bound, 216.3 perplexity estimate based on a held-out corpus of 5 documents with 2310 words\n",
      "2019-10-29 00:38:12,115 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:12,127 : INFO : topic #9 (0.100): 0.021*\"trump\" + 0.015*\"woman\" + 0.014*\"said\" + 0.012*\"clinton\" + 0.012*\"weinstein\" + 0.012*\"voter\" + 0.012*\"bill\" + 0.011*\"allegation\" + 0.010*\"sexual\" + 0.010*\"powerful\"\n",
      "2019-10-29 00:38:12,130 : INFO : topic #6 (0.100): 0.019*\"woman\" + 0.017*\"trump\" + 0.014*\"voter\" + 0.012*\"clinton\" + 0.011*\"said\" + 0.009*\"sexual\" + 0.009*\"allegation\" + 0.009*\"day\" + 0.009*\"weinstein\" + 0.009*\"treatment\"\n",
      "2019-10-29 00:38:12,133 : INFO : topic #8 (0.100): 0.023*\"trump\" + 0.018*\"woman\" + 0.016*\"voter\" + 0.013*\"clinton\" + 0.012*\"weinstein\" + 0.010*\"allegation\" + 0.010*\"job\" + 0.009*\"public\" + 0.009*\"news\" + 0.008*\"bothered\"\n",
      "2019-10-29 00:38:12,135 : INFO : topic #3 (0.100): 0.023*\"woman\" + 0.019*\"trump\" + 0.014*\"said\" + 0.014*\"voter\" + 0.013*\"sexual\" + 0.012*\"clinton\" + 0.010*\"bill\" + 0.010*\"weinstein\" + 0.010*\"medium\" + 0.010*\"allegation\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:12,137 : INFO : topic #1 (0.100): 0.019*\"trump\" + 0.016*\"woman\" + 0.014*\"bill\" + 0.011*\"clinton\" + 0.011*\"said\" + 0.011*\"men\" + 0.010*\"allegation\" + 0.010*\"weinstein\" + 0.010*\"sexual\" + 0.009*\"bothered\"\n",
      "2019-10-29 00:38:12,142 : INFO : topic diff=0.822489, rho=1.000000\n",
      "2019-10-29 00:38:12,704 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:12,706 : INFO : built Dictionary(7 unique tokens: ['help', 'cushion', 'joint', 'lubricates', 'keep']...) from 5 documents (total 35 corpus positions)\n",
      "2019-10-29 00:38:12,711 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:12,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:12,715 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:12,717 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:12,718 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:12,730 : INFO : -6.298 per-word bound, 78.7 perplexity estimate based on a held-out corpus of 5 documents with 35 words\n",
      "2019-10-29 00:38:12,734 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:12,748 : INFO : topic #4 (0.100): 0.160*\"joint\" + 0.151*\"lubricates\" + 0.148*\"parallel\" + 0.141*\"keep\" + 0.137*\"help\" + 0.134*\"exercising\" + 0.130*\"cushion\"\n",
      "2019-10-29 00:38:12,751 : INFO : topic #8 (0.100): 0.153*\"joint\" + 0.147*\"keep\" + 0.143*\"help\" + 0.142*\"exercising\" + 0.142*\"parallel\" + 0.139*\"cushion\" + 0.134*\"lubricates\"\n",
      "2019-10-29 00:38:12,755 : INFO : topic #7 (0.100): 0.180*\"keep\" + 0.172*\"lubricates\" + 0.148*\"joint\" + 0.128*\"help\" + 0.127*\"cushion\" + 0.126*\"parallel\" + 0.119*\"exercising\"\n",
      "2019-10-29 00:38:12,761 : INFO : topic #0 (0.100): 0.179*\"exercising\" + 0.143*\"help\" + 0.141*\"parallel\" + 0.139*\"keep\" + 0.138*\"cushion\" + 0.133*\"lubricates\" + 0.127*\"joint\"\n",
      "2019-10-29 00:38:12,765 : INFO : topic #5 (0.100): 0.198*\"help\" + 0.162*\"keep\" + 0.142*\"cushion\" + 0.136*\"lubricates\" + 0.134*\"exercising\" + 0.133*\"parallel\" + 0.096*\"joint\"\n",
      "2019-10-29 00:38:12,768 : INFO : topic diff=0.492787, rho=1.000000\n",
      "2019-10-29 00:38:13,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:13,340 : INFO : built Dictionary(219 unique tokens: ['anniversary', 'translated', 'book', 'end', 'nation']...) from 5 documents (total 2180 corpus positions)\n",
      "2019-10-29 00:38:13,350 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:13,353 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:13,356 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:13,363 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:13,366 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:13,459 : INFO : -7.095 per-word bound, 136.7 perplexity estimate based on a held-out corpus of 5 documents with 2180 words\n",
      "2019-10-29 00:38:13,461 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:13,469 : INFO : topic #6 (0.100): 0.085*\"frank\" + 0.064*\"anne\" + 0.041*\"write\" + 0.036*\"girl\" + 0.033*\"diary\" + 0.032*\"wanted\" + 0.023*\"photo\" + 0.017*\"caption\" + 0.013*\"hide\" + 0.010*\"secret\"\n",
      "2019-10-29 00:38:13,472 : INFO : topic #5 (0.100): 0.074*\"frank\" + 0.067*\"anne\" + 0.041*\"diary\" + 0.040*\"wanted\" + 0.029*\"write\" + 0.029*\"photo\" + 0.025*\"girl\" + 0.020*\"hide\" + 0.013*\"caption\" + 0.010*\"otto\"\n",
      "2019-10-29 00:38:13,479 : INFO : topic #4 (0.100): 0.067*\"anne\" + 0.046*\"frank\" + 0.044*\"wanted\" + 0.042*\"girl\" + 0.040*\"diary\" + 0.030*\"write\" + 0.026*\"photo\" + 0.020*\"hide\" + 0.018*\"caption\" + 0.009*\"family\"\n",
      "2019-10-29 00:38:13,483 : INFO : topic #2 (0.100): 0.064*\"frank\" + 0.050*\"anne\" + 0.044*\"diary\" + 0.037*\"write\" + 0.033*\"wanted\" + 0.026*\"photo\" + 0.025*\"girl\" + 0.020*\"hide\" + 0.016*\"caption\" + 0.014*\"otto\"\n",
      "2019-10-29 00:38:13,488 : INFO : topic #1 (0.100): 0.060*\"frank\" + 0.059*\"anne\" + 0.036*\"wanted\" + 0.030*\"girl\" + 0.029*\"write\" + 0.026*\"diary\" + 0.020*\"photo\" + 0.020*\"hide\" + 0.014*\"otto\" + 0.014*\"caption\"\n",
      "2019-10-29 00:38:13,500 : INFO : topic diff=1.014485, rho=1.000000\n",
      "2019-10-29 00:38:14,027 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:14,036 : INFO : built Dictionary(280 unique tokens: ['let', 'product', 'hanging', 'happy', 'hero']...) from 5 documents (total 2210 corpus positions)\n",
      "2019-10-29 00:38:14,047 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:14,050 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:14,053 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:14,057 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:14,059 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:14,218 : INFO : -7.639 per-word bound, 199.3 perplexity estimate based on a held-out corpus of 5 documents with 2210 words\n",
      "2019-10-29 00:38:14,220 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:14,234 : INFO : topic #3 (0.100): 0.031*\"car\" + 0.027*\"valencia\" + 0.023*\"kid\" + 0.015*\"shop\" + 0.014*\"project\" + 0.012*\"learn\" + 0.011*\"cnn\" + 0.011*\"something\" + 0.010*\"classic\" + 0.010*\"said\"\n",
      "2019-10-29 00:38:14,239 : INFO : topic #1 (0.100): 0.029*\"valencia\" + 0.028*\"kid\" + 0.025*\"car\" + 0.018*\"learn\" + 0.013*\"said\" + 0.012*\"classic\" + 0.012*\"shop\" + 0.011*\"cnn\" + 0.010*\"child\" + 0.010*\"started\"\n",
      "2019-10-29 00:38:14,243 : INFO : topic #4 (0.100): 0.031*\"kid\" + 0.027*\"valencia\" + 0.023*\"car\" + 0.017*\"project\" + 0.016*\"learn\" + 0.013*\"something\" + 0.011*\"classic\" + 0.011*\"said\" + 0.011*\"child\" + 0.011*\"shop\"\n",
      "2019-10-29 00:38:14,255 : INFO : topic #5 (0.100): 0.031*\"car\" + 0.030*\"kid\" + 0.023*\"valencia\" + 0.016*\"shop\" + 0.013*\"cnn\" + 0.013*\"learn\" + 0.012*\"child\" + 0.011*\"project\" + 0.011*\"said\" + 0.010*\"something\"\n",
      "2019-10-29 00:38:14,260 : INFO : topic #6 (0.100): 0.034*\"kid\" + 0.029*\"car\" + 0.029*\"valencia\" + 0.013*\"cnn\" + 0.012*\"shop\" + 0.012*\"something\" + 0.012*\"said\" + 0.012*\"project\" + 0.012*\"child\" + 0.012*\"learn\"\n",
      "2019-10-29 00:38:14,264 : INFO : topic diff=0.864682, rho=1.000000\n",
      "2019-10-29 00:38:14,836 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:14,848 : INFO : built Dictionary(315 unique tokens: ['violence', 'let', 'trying', 'frozen', 'catalonia']...) from 5 documents (total 2910 corpus positions)\n",
      "2019-10-29 00:38:14,860 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:14,863 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:14,866 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:14,870 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:14,879 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:15,045 : INFO : -7.535 per-word bound, 185.5 perplexity estimate based on a held-out corpus of 5 documents with 2910 words\n",
      "2019-10-29 00:38:15,047 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:15,060 : INFO : topic #1 (0.100): 0.027*\"catalonia\" + 0.026*\"spain\" + 0.024*\"independence\" + 0.023*\"catalan\" + 0.019*\"said\" + 0.018*\"people\" + 0.011*\"crisis\" + 0.011*\"think\" + 0.010*\"spanish\" + 0.010*\"politician\"\n",
      "2019-10-29 00:38:15,064 : INFO : topic #7 (0.100): 0.030*\"spain\" + 0.022*\"catalonia\" + 0.022*\"catalan\" + 0.020*\"independence\" + 0.016*\"said\" + 0.014*\"referendum\" + 0.013*\"people\" + 0.011*\"spanish\" + 0.011*\"love\" + 0.009*\"street\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:15,068 : INFO : topic #6 (0.100): 0.036*\"spain\" + 0.035*\"catalonia\" + 0.021*\"people\" + 0.021*\"catalan\" + 0.016*\"independence\" + 0.013*\"spanish\" + 0.013*\"said\" + 0.009*\"love\" + 0.009*\"referendum\" + 0.009*\"would\"\n",
      "2019-10-29 00:38:15,071 : INFO : topic #8 (0.100): 0.035*\"catalonia\" + 0.032*\"catalan\" + 0.024*\"spain\" + 0.021*\"said\" + 0.017*\"independence\" + 0.014*\"people\" + 0.012*\"spanish\" + 0.011*\"referendum\" + 0.009*\"love\" + 0.009*\"need\"\n",
      "2019-10-29 00:38:15,073 : INFO : topic #9 (0.100): 0.029*\"catalonia\" + 0.029*\"spain\" + 0.022*\"independence\" + 0.020*\"catalan\" + 0.015*\"people\" + 0.012*\"said\" + 0.010*\"spanish\" + 0.010*\"love\" + 0.010*\"referendum\" + 0.009*\"crisis\"\n",
      "2019-10-29 00:38:15,077 : INFO : topic diff=0.855393, rho=1.000000\n",
      "2019-10-29 00:38:15,668 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:15,672 : INFO : built Dictionary(118 unique tokens: ['concern', 'could', 'positioned', 'size', 'nation']...) from 5 documents (total 770 corpus positions)\n",
      "2019-10-29 00:38:15,676 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:15,680 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:15,686 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:15,689 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:15,694 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:15,772 : INFO : -7.172 per-word bound, 144.2 perplexity estimate based on a held-out corpus of 5 documents with 770 words\n",
      "2019-10-29 00:38:15,777 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:15,788 : INFO : topic #5 (0.100): 0.041*\"china\" + 0.039*\"aid\" + 0.029*\"u\" + 0.021*\"report\" + 0.021*\"chinese\" + 0.019*\"project\" + 0.018*\"foreign\" + 0.017*\"country\" + 0.016*\"recipient\" + 0.014*\"policy\"\n",
      "2019-10-29 00:38:15,792 : INFO : topic #7 (0.100): 0.048*\"china\" + 0.039*\"aid\" + 0.023*\"chinese\" + 0.022*\"country\" + 0.021*\"u\" + 0.020*\"report\" + 0.018*\"foreign\" + 0.018*\"recipient\" + 0.016*\"almost\" + 0.016*\"world\"\n",
      "2019-10-29 00:38:15,796 : INFO : topic #9 (0.100): 0.046*\"china\" + 0.032*\"aid\" + 0.025*\"u\" + 0.019*\"foreign\" + 0.018*\"developing\" + 0.018*\"project\" + 0.017*\"report\" + 0.017*\"recipient\" + 0.016*\"country\" + 0.014*\"chinese\"\n",
      "2019-10-29 00:38:15,802 : INFO : topic #6 (0.100): 0.046*\"china\" + 0.031*\"aid\" + 0.021*\"chinese\" + 0.020*\"recipient\" + 0.018*\"country\" + 0.017*\"foreign\" + 0.016*\"u\" + 0.016*\"report\" + 0.016*\"project\" + 0.015*\"total\"\n",
      "2019-10-29 00:38:15,805 : INFO : topic #8 (0.100): 0.050*\"china\" + 0.029*\"aid\" + 0.022*\"recipient\" + 0.021*\"u\" + 0.020*\"chinese\" + 0.019*\"country\" + 0.018*\"report\" + 0.016*\"project\" + 0.015*\"policy\" + 0.014*\"foreign\"\n",
      "2019-10-29 00:38:15,810 : INFO : topic diff=0.766821, rho=1.000000\n",
      "2019-10-29 00:38:16,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:16,512 : INFO : built Dictionary(410 unique tokens: ['located', 'nature', 'portion', 'clientele', 'appreciation']...) from 5 documents (total 3400 corpus positions)\n",
      "2019-10-29 00:38:16,518 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:16,521 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:16,523 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:16,526 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:16,529 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:16,727 : INFO : -7.929 per-word bound, 243.6 perplexity estimate based on a held-out corpus of 5 documents with 3400 words\n",
      "2019-10-29 00:38:16,729 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:16,739 : INFO : topic #1 (0.100): 0.068*\"tea\" + 0.015*\"chinese\" + 0.014*\"china\" + 0.012*\"er\" + 0.012*\"pu\" + 0.009*\"oolong\" + 0.009*\"wuyi\" + 0.009*\"longjing\" + 0.007*\"tour\" + 0.007*\"mountain\"\n",
      "2019-10-29 00:38:16,741 : INFO : topic #3 (0.100): 0.091*\"tea\" + 0.017*\"china\" + 0.014*\"chinese\" + 0.012*\"pu\" + 0.012*\"er\" + 0.012*\"longjing\" + 0.008*\"oolong\" + 0.007*\"wuyi\" + 0.007*\"culture\" + 0.007*\"daily\"\n",
      "2019-10-29 00:38:16,744 : INFO : topic #4 (0.100): 0.093*\"tea\" + 0.017*\"china\" + 0.016*\"chinese\" + 0.012*\"pu\" + 0.009*\"longjing\" + 0.008*\"tour\" + 0.008*\"er\" + 0.008*\"year\" + 0.007*\"oolong\" + 0.007*\"mountain\"\n",
      "2019-10-29 00:38:16,747 : INFO : topic #7 (0.100): 0.089*\"tea\" + 0.017*\"chinese\" + 0.016*\"china\" + 0.011*\"er\" + 0.011*\"pu\" + 0.010*\"longjing\" + 0.009*\"oolong\" + 0.009*\"say\" + 0.008*\"year\" + 0.007*\"mountain\"\n",
      "2019-10-29 00:38:16,749 : INFO : topic #9 (0.100): 0.067*\"tea\" + 0.017*\"china\" + 0.015*\"chinese\" + 0.011*\"longjing\" + 0.011*\"er\" + 0.010*\"wuyi\" + 0.009*\"oolong\" + 0.009*\"pu\" + 0.008*\"mountain\" + 0.008*\"plantation\"\n",
      "2019-10-29 00:38:16,751 : INFO : topic diff=0.847013, rho=1.000000\n",
      "2019-10-29 00:38:17,357 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:17,361 : INFO : built Dictionary(79 unique tokens: ['deadly', 'roughly', 'camera', 'morning', 'time']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:38:17,368 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:17,371 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:17,377 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:17,380 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:17,382 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:17,431 : INFO : -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:38:17,434 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:17,441 : INFO : topic #3 (0.100): 0.062*\"hospital\" + 0.047*\"patient\" + 0.038*\"evacuated\" + 0.027*\"wildfire\" + 0.026*\"said\" + 0.026*\"kaiser\" + 0.025*\"statement\" + 0.023*\"least\" + 0.023*\"permanente\" + 0.022*\"monday\"\n",
      "2019-10-29 00:38:17,444 : INFO : topic #7 (0.100): 0.059*\"hospital\" + 0.040*\"patient\" + 0.037*\"wildfire\" + 0.029*\"evacuated\" + 0.028*\"northern\" + 0.024*\"monday\" + 0.023*\"least\" + 0.023*\"california\" + 0.023*\"statement\" + 0.021*\"permanente\"\n",
      "2019-10-29 00:38:17,448 : INFO : topic #2 (0.100): 0.056*\"hospital\" + 0.039*\"patient\" + 0.029*\"evacuated\" + 0.029*\"permanente\" + 0.025*\"wildfire\" + 0.024*\"monday\" + 0.024*\"health\" + 0.023*\"california\" + 0.023*\"northern\" + 0.022*\"said\"\n",
      "2019-10-29 00:38:17,455 : INFO : topic #5 (0.100): 0.053*\"patient\" + 0.045*\"hospital\" + 0.040*\"evacuated\" + 0.029*\"wildfire\" + 0.028*\"california\" + 0.025*\"said\" + 0.025*\"statement\" + 0.024*\"northern\" + 0.024*\"monday\" + 0.022*\"least\"\n",
      "2019-10-29 00:38:17,458 : INFO : topic #4 (0.100): 0.058*\"hospital\" + 0.041*\"patient\" + 0.035*\"evacuated\" + 0.031*\"wildfire\" + 0.027*\"california\" + 0.026*\"said\" + 0.022*\"least\" + 0.022*\"statement\" + 0.020*\"monday\" + 0.020*\"health\"\n",
      "2019-10-29 00:38:17,461 : INFO : topic diff=0.827331, rho=1.000000\n",
      "2019-10-29 00:38:17,985 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:17,992 : INFO : built Dictionary(145 unique tokens: ['realm', 'earned', 'colleague', 'others', 'beginning']...) from 5 documents (total 880 corpus positions)\n",
      "2019-10-29 00:38:17,997 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:18,000 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:18,007 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:18,012 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:18,015 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:18,152 : INFO : -7.488 per-word bound, 179.5 perplexity estimate based on a held-out corpus of 5 documents with 880 words\n",
      "2019-10-29 00:38:18,156 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:18,166 : INFO : topic #6 (0.100): 0.043*\"spielberg\" + 0.020*\"director\" + 0.018*\"movie\" + 0.017*\"film\" + 0.017*\"perhaps\" + 0.013*\"tv\" + 0.013*\"one\" + 0.013*\"best\" + 0.012*\"blockbuster\" + 0.012*\"portrait\"\n",
      "2019-10-29 00:38:18,171 : INFO : topic #9 (0.100): 0.045*\"spielberg\" + 0.022*\"director\" + 0.022*\"movie\" + 0.019*\"perhaps\" + 0.015*\"making\" + 0.013*\"film\" + 0.013*\"one\" + 0.013*\"best\" + 0.012*\"half\" + 0.012*\"tv\"\n",
      "2019-10-29 00:38:18,174 : INFO : topic #8 (0.100): 0.047*\"spielberg\" + 0.019*\"movie\" + 0.017*\"director\" + 0.016*\"one\" + 0.015*\"perhaps\" + 0.015*\"film\" + 0.013*\"making\" + 0.012*\"portrait\" + 0.012*\"helped\" + 0.011*\"early\"\n",
      "2019-10-29 00:38:18,177 : INFO : topic #4 (0.100): 0.050*\"spielberg\" + 0.027*\"movie\" + 0.020*\"director\" + 0.018*\"film\" + 0.014*\"perhaps\" + 0.014*\"one\" + 0.013*\"blockbuster\" + 0.012*\"best\" + 0.012*\"helped\" + 0.012*\"making\"\n",
      "2019-10-29 00:38:18,180 : INFO : topic #0 (0.100): 0.039*\"spielberg\" + 0.024*\"movie\" + 0.023*\"director\" + 0.020*\"film\" + 0.016*\"one\" + 0.013*\"perhaps\" + 0.013*\"documentary\" + 0.012*\"early\" + 0.011*\"portrait\" + 0.011*\"george\"\n",
      "2019-10-29 00:38:18,183 : INFO : topic diff=0.703171, rho=1.000000\n",
      "2019-10-29 00:38:18,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:18,788 : INFO : built Dictionary(251 unique tokens: ['energy', 'sodium', 'portion', 'container', 'muscle']...) from 5 documents (total 2640 corpus positions)\n",
      "2019-10-29 00:38:18,794 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:18,802 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:18,812 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:18,817 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:18,821 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:18,952 : INFO : -7.166 per-word bound, 143.6 perplexity estimate based on a held-out corpus of 5 documents with 2640 words\n",
      "2019-10-29 00:38:18,956 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:18,968 : INFO : topic #1 (0.100): 0.019*\"pick\" + 0.018*\"option\" + 0.018*\"gram\" + 0.017*\"chipotle\" + 0.017*\"sodium\" + 0.017*\"milligram\" + 0.016*\"kid\" + 0.015*\"lettuce\" + 0.015*\"fajita\" + 0.013*\"menu\"\n",
      "2019-10-29 00:38:18,979 : INFO : topic #7 (0.100): 0.022*\"sodium\" + 0.019*\"fat\" + 0.018*\"pick\" + 0.017*\"calorie\" + 0.016*\"chipotle\" + 0.015*\"bean\" + 0.014*\"milligram\" + 0.014*\"tortilla\" + 0.014*\"romaine\" + 0.014*\"gram\"\n",
      "2019-10-29 00:38:18,981 : INFO : topic #3 (0.100): 0.020*\"sodium\" + 0.020*\"milligram\" + 0.018*\"pick\" + 0.017*\"tortilla\" + 0.015*\"fat\" + 0.015*\"option\" + 0.014*\"calorie\" + 0.013*\"gram\" + 0.013*\"menu\" + 0.013*\"low\"\n",
      "2019-10-29 00:38:18,984 : INFO : topic #4 (0.100): 0.022*\"sodium\" + 0.018*\"pick\" + 0.017*\"milligram\" + 0.015*\"vegetable\" + 0.015*\"calorie\" + 0.015*\"gram\" + 0.015*\"taco\" + 0.015*\"chipotle\" + 0.014*\"option\" + 0.014*\"fat\"\n",
      "2019-10-29 00:38:18,986 : INFO : topic #8 (0.100): 0.021*\"milligram\" + 0.020*\"sodium\" + 0.018*\"chipotle\" + 0.016*\"option\" + 0.016*\"menu\" + 0.015*\"tortilla\" + 0.015*\"calorie\" + 0.014*\"pick\" + 0.013*\"fat\" + 0.012*\"chicken\"\n",
      "2019-10-29 00:38:18,994 : INFO : topic diff=1.008437, rho=1.000000\n",
      "2019-10-29 00:38:19,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:19,595 : INFO : built Dictionary(416 unique tokens: ['although', 'let', 'assignment', 'frustrates', 'francisco']...) from 5 documents (total 2830 corpus positions)\n",
      "2019-10-29 00:38:19,601 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:19,603 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:19,611 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:19,619 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:19,625 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:20,025 : INFO : -8.247 per-word bound, 303.8 perplexity estimate based on a held-out corpus of 5 documents with 2830 words\n",
      "2019-10-29 00:38:20,029 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:20,039 : INFO : topic #9 (0.100): 0.031*\"police\" + 0.016*\"enforcement\" + 0.013*\"law\" + 0.009*\"many\" + 0.009*\"protest\" + 0.008*\"song\" + 0.007*\"kaepernick\" + 0.007*\"take\" + 0.007*\"cop\" + 0.006*\"certainly\"\n",
      "2019-10-29 00:38:20,042 : INFO : topic #3 (0.100): 0.022*\"police\" + 0.016*\"enforcement\" + 0.011*\"protest\" + 0.011*\"law\" + 0.010*\"many\" + 0.008*\"take\" + 0.007*\"job\" + 0.007*\"song\" + 0.006*\"certainly\" + 0.006*\"cop\"\n",
      "2019-10-29 00:38:20,045 : INFO : topic #7 (0.100): 0.020*\"police\" + 0.014*\"law\" + 0.012*\"enforcement\" + 0.009*\"kaepernick\" + 0.009*\"many\" + 0.009*\"protest\" + 0.008*\"take\" + 0.008*\"song\" + 0.007*\"certainly\" + 0.007*\"job\"\n",
      "2019-10-29 00:38:20,048 : INFO : topic #0 (0.100): 0.022*\"police\" + 0.017*\"law\" + 0.014*\"enforcement\" + 0.010*\"protest\" + 0.009*\"many\" + 0.008*\"song\" + 0.008*\"certainly\" + 0.008*\"job\" + 0.007*\"kaepernick\" + 0.007*\"cop\"\n",
      "2019-10-29 00:38:20,050 : INFO : topic #2 (0.100): 0.023*\"police\" + 0.014*\"law\" + 0.013*\"enforcement\" + 0.012*\"protest\" + 0.009*\"many\" + 0.008*\"song\" + 0.008*\"kaepernick\" + 0.008*\"cop\" + 0.007*\"take\" + 0.007*\"certainly\"\n",
      "2019-10-29 00:38:20,053 : INFO : topic diff=0.762462, rho=1.000000\n",
      "2019-10-29 00:38:20,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:20,642 : INFO : built Dictionary(16 unique tokens: ['agreeing', 'night', 'harvey', 'changed', 'privacy']...) from 5 documents (total 100 corpus positions)\n",
      "2019-10-29 00:38:20,643 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:20,644 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:20,646 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:20,647 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:20,649 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:20,663 : INFO : -5.884 per-word bound, 59.1 perplexity estimate based on a held-out corpus of 5 documents with 100 words\n",
      "2019-10-29 00:38:20,664 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:20,669 : INFO : topic #8 (0.100): 0.120*\"policy\" + 0.109*\"service\" + 0.092*\"privacy\" + 0.078*\"term\" + 0.061*\"harvey\" + 0.060*\"agreeing\" + 0.057*\"weinstein\" + 0.055*\"changed\" + 0.049*\"continuing\" + 0.049*\"new\"\n",
      "2019-10-29 00:38:20,671 : INFO : topic #6 (0.100): 0.101*\"term\" + 0.094*\"privacy\" + 0.092*\"service\" + 0.092*\"policy\" + 0.063*\"weigh\" + 0.063*\"night\" + 0.056*\"new\" + 0.054*\"harvey\" + 0.054*\"late\" + 0.053*\"use\"\n",
      "2019-10-29 00:38:20,672 : INFO : topic #2 (0.100): 0.098*\"service\" + 0.091*\"term\" + 0.089*\"policy\" + 0.078*\"privacy\" + 0.064*\"changed\" + 0.061*\"site\" + 0.060*\"harvey\" + 0.059*\"continuing\" + 0.055*\"night\" + 0.052*\"weinstein\"\n",
      "2019-10-29 00:38:20,677 : INFO : topic #9 (0.100): 0.102*\"policy\" + 0.099*\"term\" + 0.095*\"service\" + 0.087*\"privacy\" + 0.071*\"host\" + 0.061*\"use\" + 0.060*\"changed\" + 0.057*\"weinstein\" + 0.055*\"agreeing\" + 0.052*\"site\"\n",
      "2019-10-29 00:38:20,680 : INFO : topic #1 (0.100): 0.109*\"term\" + 0.107*\"policy\" + 0.098*\"privacy\" + 0.076*\"service\" + 0.062*\"weigh\" + 0.059*\"use\" + 0.058*\"changed\" + 0.055*\"weinstein\" + 0.054*\"continuing\" + 0.054*\"night\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:20,682 : INFO : topic diff=0.636596, rho=1.000000\n",
      "2019-10-29 00:38:21,310 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:21,319 : INFO : built Dictionary(488 unique tokens: ['energy', 'fossil', 'review', 'benjamin', 'expert']...) from 5 documents (total 5230 corpus positions)\n",
      "2019-10-29 00:38:21,327 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:21,330 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:21,333 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:21,337 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:21,341 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:21,527 : INFO : -7.786 per-word bound, 220.7 perplexity estimate based on a held-out corpus of 5 documents with 5230 words\n",
      "2019-10-29 00:38:21,530 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:21,541 : INFO : topic #4 (0.100): 0.028*\"climate\" + 0.027*\"health\" + 0.023*\"said\" + 0.019*\"change\" + 0.011*\"sarfaty\" + 0.010*\"related\" + 0.010*\"according\" + 0.009*\"disease\" + 0.009*\"air\" + 0.008*\"world\"\n",
      "2019-10-29 00:38:21,545 : INFO : topic #7 (0.100): 0.027*\"climate\" + 0.026*\"health\" + 0.024*\"said\" + 0.015*\"change\" + 0.015*\"sarfaty\" + 0.013*\"disease\" + 0.010*\"related\" + 0.010*\"consortium\" + 0.009*\"report\" + 0.008*\"impact\"\n",
      "2019-10-29 00:38:21,548 : INFO : topic #3 (0.100): 0.036*\"climate\" + 0.022*\"health\" + 0.022*\"change\" + 0.019*\"said\" + 0.011*\"related\" + 0.010*\"wildfire\" + 0.010*\"sarfaty\" + 0.010*\"report\" + 0.009*\"according\" + 0.008*\"disease\"\n",
      "2019-10-29 00:38:21,551 : INFO : topic #0 (0.100): 0.030*\"climate\" + 0.025*\"health\" + 0.025*\"said\" + 0.022*\"change\" + 0.013*\"sarfaty\" + 0.011*\"wildfire\" + 0.010*\"report\" + 0.010*\"disease\" + 0.009*\"according\" + 0.009*\"air\"\n",
      "2019-10-29 00:38:21,555 : INFO : topic #9 (0.100): 0.030*\"climate\" + 0.025*\"said\" + 0.019*\"health\" + 0.016*\"change\" + 0.014*\"sarfaty\" + 0.013*\"related\" + 0.010*\"report\" + 0.010*\"disease\" + 0.010*\"wildfire\" + 0.008*\"impact\"\n",
      "2019-10-29 00:38:21,559 : INFO : topic diff=1.013462, rho=1.000000\n",
      "2019-10-29 00:38:22,194 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:22,210 : INFO : built Dictionary(666 unique tokens: ['specie', 'plight', 'deep', 'focus', 'asleep']...) from 5 documents (total 6205 corpus positions)\n",
      "2019-10-29 00:38:22,230 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:22,237 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:22,239 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:22,249 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:22,252 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:22,527 : INFO : -8.245 per-word bound, 303.4 perplexity estimate based on a held-out corpus of 5 documents with 6205 words\n",
      "2019-10-29 00:38:22,528 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:22,538 : INFO : topic #0 (0.100): 0.027*\"frog\" + 0.013*\"extinction\" + 0.010*\"pijanowski\" + 0.010*\"like\" + 0.010*\"sound\" + 0.009*\"whitfield\" + 0.008*\"forest\" + 0.008*\"recording\" + 0.008*\"amphibian\" + 0.007*\"la\"\n",
      "2019-10-29 00:38:22,540 : INFO : topic #8 (0.100): 0.032*\"frog\" + 0.013*\"whitfield\" + 0.010*\"like\" + 0.009*\"extinction\" + 0.009*\"forest\" + 0.009*\"sound\" + 0.009*\"pijanowski\" + 0.008*\"around\" + 0.007*\"selva\" + 0.007*\"change\"\n",
      "2019-10-29 00:38:22,542 : INFO : topic #6 (0.100): 0.026*\"frog\" + 0.014*\"extinction\" + 0.011*\"pijanowski\" + 0.010*\"forest\" + 0.009*\"sound\" + 0.009*\"like\" + 0.009*\"whitfield\" + 0.008*\"rainforest\" + 0.008*\"chit\" + 0.007*\"world\"\n",
      "2019-10-29 00:38:22,545 : INFO : topic #9 (0.100): 0.031*\"frog\" + 0.011*\"like\" + 0.010*\"extinction\" + 0.010*\"forest\" + 0.009*\"pijanowski\" + 0.009*\"sound\" + 0.008*\"selva\" + 0.008*\"whitfield\" + 0.008*\"amphibian\" + 0.007*\"one\"\n",
      "2019-10-29 00:38:22,547 : INFO : topic #5 (0.100): 0.033*\"frog\" + 0.010*\"sound\" + 0.010*\"extinction\" + 0.010*\"like\" + 0.009*\"pijanowski\" + 0.009*\"whitfield\" + 0.008*\"forest\" + 0.007*\"u\" + 0.007*\"one\" + 0.006*\"la\"\n",
      "2019-10-29 00:38:22,550 : INFO : topic diff=0.907131, rho=1.000000\n",
      "2019-10-29 00:38:22,946 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:22,952 : INFO : built Dictionary(257 unique tokens: ['let', 'sorry', 'take', 'wheel', 'spare']...) from 5 documents (total 1810 corpus positions)\n",
      "2019-10-29 00:38:22,955 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:22,956 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:22,957 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:22,960 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:22,962 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:23,051 : INFO : -7.736 per-word bound, 213.2 perplexity estimate based on a held-out corpus of 5 documents with 1810 words\n",
      "2019-10-29 00:38:23,053 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:23,060 : INFO : topic #9 (0.100): 0.019*\"abandoned\" + 0.012*\"u\" + 0.012*\"picture\" + 0.012*\"people\" + 0.012*\"went\" + 0.012*\"place\" + 0.012*\"find\" + 0.011*\"lot\" + 0.011*\"castle\" + 0.010*\"room\"\n",
      "2019-10-29 00:38:23,061 : INFO : topic #2 (0.100): 0.022*\"people\" + 0.017*\"abandoned\" + 0.017*\"lot\" + 0.013*\"decay\" + 0.012*\"thing\" + 0.011*\"castle\" + 0.011*\"u\" + 0.010*\"picture\" + 0.010*\"went\" + 0.010*\"building\"\n",
      "2019-10-29 00:38:23,063 : INFO : topic #3 (0.100): 0.017*\"abandoned\" + 0.016*\"people\" + 0.014*\"lot\" + 0.012*\"stuff\" + 0.012*\"castle\" + 0.012*\"find\" + 0.011*\"building\" + 0.010*\"see\" + 0.010*\"u\" + 0.009*\"decay\"\n",
      "2019-10-29 00:38:23,066 : INFO : topic #7 (0.100): 0.018*\"abandoned\" + 0.014*\"people\" + 0.012*\"u\" + 0.011*\"see\" + 0.011*\"place\" + 0.010*\"germany\" + 0.010*\"picture\" + 0.010*\"castle\" + 0.010*\"decay\" + 0.009*\"like\"\n",
      "2019-10-29 00:38:23,067 : INFO : topic #6 (0.100): 0.014*\"abandoned\" + 0.014*\"lot\" + 0.012*\"thing\" + 0.012*\"people\" + 0.011*\"picture\" + 0.011*\"place\" + 0.011*\"stuff\" + 0.010*\"u\" + 0.010*\"cost\" + 0.009*\"see\"\n",
      "2019-10-29 00:38:23,069 : INFO : topic diff=0.784019, rho=1.000000\n",
      "2019-10-29 00:38:23,471 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:23,474 : INFO : built Dictionary(223 unique tokens: ['although', 'fully', 'cambodian', 'watch', 'industry']...) from 5 documents (total 1840 corpus positions)\n",
      "2019-10-29 00:38:23,477 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:23,482 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:23,485 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:23,490 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:23,492 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:23,575 : INFO : -7.359 per-word bound, 164.2 perplexity estimate based on a held-out corpus of 5 documents with 1840 words\n",
      "2019-10-29 00:38:23,576 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:23,584 : INFO : topic #5 (0.100): 0.027*\"say\" + 0.023*\"trafficking\" + 0.021*\"mother\" + 0.018*\"police\" + 0.017*\"sex\" + 0.017*\"daughter\" + 0.016*\"money\" + 0.016*\"girl\" + 0.016*\"child\" + 0.014*\"sephak\"\n",
      "2019-10-29 00:38:23,585 : INFO : topic #0 (0.100): 0.022*\"say\" + 0.019*\"mother\" + 0.019*\"trafficking\" + 0.018*\"sex\" + 0.016*\"daughter\" + 0.016*\"police\" + 0.015*\"child\" + 0.014*\"cambodia\" + 0.013*\"svay\" + 0.013*\"people\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:23,586 : INFO : topic #4 (0.100): 0.025*\"trafficking\" + 0.022*\"sephak\" + 0.020*\"sex\" + 0.018*\"say\" + 0.017*\"mother\" + 0.017*\"money\" + 0.015*\"svay\" + 0.015*\"child\" + 0.015*\"girl\" + 0.015*\"police\"\n",
      "2019-10-29 00:38:23,588 : INFO : topic #9 (0.100): 0.028*\"say\" + 0.023*\"sex\" + 0.022*\"trafficking\" + 0.018*\"police\" + 0.017*\"sephak\" + 0.015*\"daughter\" + 0.014*\"girl\" + 0.014*\"svay\" + 0.014*\"aim\" + 0.013*\"money\"\n",
      "2019-10-29 00:38:23,590 : INFO : topic #7 (0.100): 0.028*\"trafficking\" + 0.022*\"sephak\" + 0.022*\"say\" + 0.017*\"mother\" + 0.016*\"money\" + 0.014*\"girl\" + 0.014*\"daughter\" + 0.014*\"pak\" + 0.014*\"work\" + 0.014*\"sex\"\n",
      "2019-10-29 00:38:23,595 : INFO : topic diff=0.869387, rho=1.000000\n",
      "2019-10-29 00:38:23,982 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:23,984 : INFO : built Dictionary(79 unique tokens: ['nigeria', 'issue', 'something', 'death', 'game']...) from 5 documents (total 615 corpus positions)\n",
      "2019-10-29 00:38:23,986 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:23,987 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:23,989 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:23,991 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:23,992 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:24,029 : INFO : -6.519 per-word bound, 91.7 perplexity estimate based on a held-out corpus of 5 documents with 615 words\n",
      "2019-10-29 00:38:24,031 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:24,037 : INFO : topic #6 (0.100): 0.049*\"okorafor\" + 0.049*\"black\" + 0.040*\"panther\" + 0.038*\"nnedi\" + 0.028*\"storyline\" + 0.028*\"marvel\" + 0.024*\"issue\" + 0.022*\"fantasy\" + 0.022*\"story\" + 0.019*\"writing\"\n",
      "2019-10-29 00:38:24,039 : INFO : topic #9 (0.100): 0.048*\"panther\" + 0.040*\"okorafor\" + 0.040*\"black\" + 0.036*\"nnedi\" + 0.029*\"issue\" + 0.024*\"american\" + 0.022*\"marvel\" + 0.021*\"set\" + 0.021*\"fantasy\" + 0.020*\"long\"\n",
      "2019-10-29 00:38:24,040 : INFO : topic #3 (0.100): 0.049*\"black\" + 0.046*\"okorafor\" + 0.043*\"panther\" + 0.032*\"nnedi\" + 0.029*\"story\" + 0.027*\"marvel\" + 0.027*\"issue\" + 0.024*\"storyline\" + 0.023*\"american\" + 0.023*\"fantasy\"\n",
      "2019-10-29 00:38:24,041 : INFO : topic #8 (0.100): 0.065*\"panther\" + 0.051*\"okorafor\" + 0.048*\"black\" + 0.029*\"issue\" + 0.028*\"marvel\" + 0.026*\"nnedi\" + 0.022*\"storyline\" + 0.022*\"american\" + 0.022*\"story\" + 0.022*\"fantasy\"\n",
      "2019-10-29 00:38:24,043 : INFO : topic #7 (0.100): 0.050*\"okorafor\" + 0.044*\"panther\" + 0.037*\"black\" + 0.036*\"nnedi\" + 0.029*\"story\" + 0.027*\"marvel\" + 0.024*\"fantasy\" + 0.022*\"issue\" + 0.022*\"storyline\" + 0.021*\"write\"\n",
      "2019-10-29 00:38:24,044 : INFO : topic diff=0.836809, rho=1.000000\n",
      "2019-10-29 00:38:24,479 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:24,486 : INFO : built Dictionary(369 unique tokens: ['energy', 'unforgivable', 'fox', 'spoke', 'way']...) from 5 documents (total 2935 corpus positions)\n",
      "2019-10-29 00:38:24,492 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:24,494 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:24,496 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:24,500 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:24,501 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:24,628 : INFO : -7.887 per-word bound, 236.7 perplexity estimate based on a held-out corpus of 5 documents with 2935 words\n",
      "2019-10-29 00:38:24,630 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:24,637 : INFO : topic #7 (0.100): 0.031*\"weinstein\" + 0.016*\"woman\" + 0.015*\"said\" + 0.012*\"tuesday\" + 0.011*\"harvey\" + 0.011*\"time\" + 0.010*\"board\" + 0.010*\"forward\" + 0.010*\"company\" + 0.009*\"new\"\n",
      "2019-10-29 00:38:24,639 : INFO : topic #8 (0.100): 0.034*\"weinstein\" + 0.013*\"said\" + 0.013*\"tuesday\" + 0.012*\"woman\" + 0.010*\"statement\" + 0.009*\"new\" + 0.009*\"harvey\" + 0.009*\"story\" + 0.009*\"come\" + 0.009*\"board\"\n",
      "2019-10-29 00:38:24,642 : INFO : topic #1 (0.100): 0.050*\"weinstein\" + 0.016*\"said\" + 0.014*\"new\" + 0.012*\"tuesday\" + 0.011*\"woman\" + 0.011*\"time\" + 0.010*\"forward\" + 0.009*\"story\" + 0.008*\"hollywood\" + 0.008*\"board\"\n",
      "2019-10-29 00:38:24,644 : INFO : topic #4 (0.100): 0.059*\"weinstein\" + 0.014*\"said\" + 0.012*\"harvey\" + 0.010*\"tuesday\" + 0.010*\"woman\" + 0.009*\"new\" + 0.009*\"hollywood\" + 0.009*\"board\" + 0.008*\"year\" + 0.008*\"allegation\"\n",
      "2019-10-29 00:38:24,647 : INFO : topic #5 (0.100): 0.054*\"weinstein\" + 0.016*\"said\" + 0.013*\"board\" + 0.013*\"hollywood\" + 0.010*\"woman\" + 0.010*\"new\" + 0.010*\"time\" + 0.009*\"come\" + 0.009*\"tuesday\" + 0.009*\"forward\"\n",
      "2019-10-29 00:38:24,649 : INFO : topic diff=0.850423, rho=1.000000\n",
      "2019-10-29 00:38:25,058 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:25,065 : INFO : built Dictionary(307 unique tokens: ['darkest', 'energy', 'kidding', 'campaign', 'focus']...) from 5 documents (total 2195 corpus positions)\n",
      "2019-10-29 00:38:25,071 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:25,074 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:25,077 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:25,081 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:25,084 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:25,197 : INFO : -7.880 per-word bound, 235.6 perplexity estimate based on a held-out corpus of 5 documents with 2195 words\n",
      "2019-10-29 00:38:25,198 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:25,206 : INFO : topic #2 (0.100): 0.056*\"trump\" + 0.017*\"corker\" + 0.014*\"people\" + 0.013*\"bully\" + 0.012*\"change\" + 0.010*\"like\" + 0.010*\"name\" + 0.010*\"said\" + 0.009*\"president\" + 0.008*\"republican\"\n",
      "2019-10-29 00:38:25,207 : INFO : topic #5 (0.100): 0.038*\"trump\" + 0.016*\"like\" + 0.015*\"bully\" + 0.013*\"people\" + 0.011*\"president\" + 0.009*\"campaign\" + 0.009*\"corker\" + 0.009*\"change\" + 0.009*\"name\" + 0.008*\"anything\"\n",
      "2019-10-29 00:38:25,209 : INFO : topic #6 (0.100): 0.042*\"trump\" + 0.017*\"like\" + 0.014*\"bully\" + 0.014*\"president\" + 0.012*\"people\" + 0.012*\"corker\" + 0.011*\"name\" + 0.010*\"change\" + 0.009*\"republican\" + 0.009*\"campaign\"\n",
      "2019-10-29 00:38:25,211 : INFO : topic #9 (0.100): 0.040*\"trump\" + 0.019*\"bully\" + 0.018*\"like\" + 0.012*\"people\" + 0.012*\"name\" + 0.010*\"corker\" + 0.009*\"president\" + 0.009*\"said\" + 0.008*\"change\" + 0.008*\"anything\"\n",
      "2019-10-29 00:38:25,213 : INFO : topic #3 (0.100): 0.030*\"trump\" + 0.019*\"corker\" + 0.015*\"like\" + 0.013*\"bully\" + 0.011*\"people\" + 0.011*\"name\" + 0.011*\"change\" + 0.010*\"president\" + 0.010*\"republican\" + 0.009*\"said\"\n",
      "2019-10-29 00:38:25,215 : INFO : topic diff=0.795345, rho=1.000000\n",
      "2019-10-29 00:38:25,633 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:25,639 : INFO : built Dictionary(276 unique tokens: ['forward', 'fox', 'immensely', 'end', 'nation']...) from 5 documents (total 2375 corpus positions)\n",
      "2019-10-29 00:38:25,642 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:25,643 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:25,644 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:25,649 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:25,651 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:25,733 : INFO : -7.500 per-word bound, 181.1 perplexity estimate based on a held-out corpus of 5 documents with 2375 words\n",
      "2019-10-29 00:38:25,734 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:25,742 : INFO : topic #0 (0.100): 0.032*\"would\" + 0.028*\"obamacare\" + 0.022*\"bill\" + 0.015*\"year\" + 0.014*\"replacement\" + 0.014*\"senate\" + 0.013*\"million\" + 0.013*\"repeal\" + 0.013*\"law\" + 0.012*\"house\"\n",
      "2019-10-29 00:38:25,743 : INFO : topic #1 (0.100): 0.038*\"would\" + 0.026*\"obamacare\" + 0.025*\"repeal\" + 0.024*\"bill\" + 0.020*\"senate\" + 0.015*\"year\" + 0.012*\"republican\" + 0.012*\"million\" + 0.012*\"people\" + 0.011*\"law\"\n",
      "2019-10-29 00:38:25,744 : INFO : topic #3 (0.100): 0.031*\"would\" + 0.024*\"obamacare\" + 0.021*\"bill\" + 0.019*\"repeal\" + 0.016*\"year\" + 0.013*\"people\" + 0.013*\"lawmaker\" + 0.012*\"million\" + 0.012*\"replacement\" + 0.011*\"senate\"\n",
      "2019-10-29 00:38:25,746 : INFO : topic #5 (0.100): 0.055*\"would\" + 0.021*\"obamacare\" + 0.021*\"repeal\" + 0.021*\"bill\" + 0.017*\"year\" + 0.014*\"senate\" + 0.013*\"people\" + 0.013*\"republican\" + 0.012*\"law\" + 0.012*\"million\"\n",
      "2019-10-29 00:38:25,749 : INFO : topic #2 (0.100): 0.032*\"would\" + 0.023*\"bill\" + 0.018*\"obamacare\" + 0.017*\"repeal\" + 0.014*\"replacement\" + 0.013*\"senate\" + 0.013*\"health\" + 0.012*\"year\" + 0.012*\"republican\" + 0.011*\"million\"\n",
      "2019-10-29 00:38:25,751 : INFO : topic diff=0.886019, rho=1.000000\n",
      "2019-10-29 00:38:26,133 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:26,135 : INFO : built Dictionary(98 unique tokens: ['game', 'break', 'aggressive', 'broke', 'door']...) from 5 documents (total 630 corpus positions)\n",
      "2019-10-29 00:38:26,137 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:26,138 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:26,140 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:26,142 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:26,143 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:26,188 : INFO : -7.034 per-word bound, 131.1 perplexity estimate based on a held-out corpus of 5 documents with 630 words\n",
      "2019-10-29 00:38:26,190 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:26,196 : INFO : topic #2 (0.100): 0.026*\"men\" + 0.026*\"two\" + 0.024*\"fort\" + 0.021*\"couple\" + 0.017*\"armed\" + 0.017*\"surveillance\" + 0.017*\"car\" + 0.017*\"com\" + 0.017*\"cbsdfw\" + 0.017*\"video\"\n",
      "2019-10-29 00:38:26,197 : INFO : topic #0 (0.100): 0.034*\"men\" + 0.029*\"couple\" + 0.022*\"two\" + 0.020*\"fort\" + 0.018*\"surveillance\" + 0.018*\"broke\" + 0.017*\"car\" + 0.017*\"worth\" + 0.016*\"money\" + 0.015*\"armed\"\n",
      "2019-10-29 00:38:26,199 : INFO : topic #9 (0.100): 0.032*\"men\" + 0.026*\"fort\" + 0.022*\"two\" + 0.021*\"couple\" + 0.019*\"suspect\" + 0.018*\"car\" + 0.017*\"kill\" + 0.017*\"video\" + 0.017*\"com\" + 0.017*\"foot\"\n",
      "2019-10-29 00:38:26,200 : INFO : topic #8 (0.100): 0.029*\"men\" + 0.022*\"two\" + 0.022*\"couple\" + 0.021*\"fort\" + 0.018*\"show\" + 0.017*\"suspect\" + 0.017*\"money\" + 0.017*\"tall\" + 0.017*\"described\" + 0.016*\"gun\"\n",
      "2019-10-29 00:38:26,202 : INFO : topic #5 (0.100): 0.024*\"couple\" + 0.021*\"men\" + 0.020*\"fort\" + 0.020*\"two\" + 0.018*\"car\" + 0.017*\"armed\" + 0.017*\"home\" + 0.017*\"build\" + 0.017*\"com\" + 0.016*\"kill\"\n",
      "2019-10-29 00:38:26,204 : INFO : topic diff=0.679429, rho=1.000000\n",
      "2019-10-29 00:38:26,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:26,609 : INFO : built Dictionary(108 unique tokens: ['deviate', 'language', 'negotiable', 'one', 'adviser']...) from 5 documents (total 705 corpus positions)\n",
      "2019-10-29 00:38:26,618 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:26,619 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:26,625 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:26,630 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:26,633 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:26,692 : INFO : -7.089 per-word bound, 136.2 perplexity estimate based on a held-out corpus of 5 documents with 705 words\n",
      "2019-10-29 00:38:26,695 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:26,701 : INFO : topic #4 (0.100): 0.040*\"korea\" + 0.034*\"north\" + 0.024*\"need\" + 0.021*\"u\" + 0.020*\"word\" + 0.019*\"state\" + 0.017*\"three\" + 0.017*\"signal\" + 0.017*\"un\" + 0.015*\"angry\"\n",
      "2019-10-29 00:38:26,704 : INFO : topic #6 (0.100): 0.034*\"korea\" + 0.029*\"north\" + 0.026*\"word\" + 0.023*\"need\" + 0.021*\"state\" + 0.019*\"three\" + 0.018*\"remark\" + 0.017*\"phrase\" + 0.016*\"former\" + 0.016*\"u\"\n",
      "2019-10-29 00:38:26,707 : INFO : topic #8 (0.100): 0.033*\"korea\" + 0.031*\"need\" + 0.025*\"north\" + 0.021*\"u\" + 0.021*\"three\" + 0.020*\"word\" + 0.017*\"phrase\" + 0.017*\"state\" + 0.015*\"angry\" + 0.015*\"trump\"\n",
      "2019-10-29 00:38:26,710 : INFO : topic #7 (0.100): 0.032*\"korea\" + 0.028*\"need\" + 0.025*\"north\" + 0.024*\"three\" + 0.020*\"word\" + 0.020*\"u\" + 0.019*\"state\" + 0.017*\"signal\" + 0.016*\"us\" + 0.016*\"trump\"\n",
      "2019-10-29 00:38:26,713 : INFO : topic #3 (0.100): 0.034*\"korea\" + 0.034*\"north\" + 0.033*\"need\" + 0.024*\"state\" + 0.022*\"u\" + 0.021*\"word\" + 0.018*\"three\" + 0.016*\"convey\" + 0.016*\"trump\" + 0.015*\"speaker\"\n",
      "2019-10-29 00:38:26,716 : INFO : topic diff=0.731890, rho=1.000000\n",
      "2019-10-29 00:38:27,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:27,166 : INFO : built Dictionary(271 unique tokens: ['energy', 'locked', 'watch', 'industry', 'consumerism']...) from 5 documents (total 2190 corpus positions)\n",
      "2019-10-29 00:38:27,170 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:27,171 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:27,172 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:27,175 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:27,177 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:27,274 : INFO : -7.571 per-word bound, 190.1 perplexity estimate based on a held-out corpus of 5 documents with 2190 words\n",
      "2019-10-29 00:38:27,276 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:27,283 : INFO : topic #1 (0.100): 0.042*\"climate\" + 0.033*\"change\" + 0.014*\"degree\" + 0.013*\"people\" + 0.012*\"warming\" + 0.012*\"world\" + 0.012*\"story\" + 0.011*\"country\" + 0.010*\"two\" + 0.010*\"gas\"\n",
      "2019-10-29 00:38:27,285 : INFO : topic #7 (0.100): 0.036*\"change\" + 0.030*\"climate\" + 0.018*\"degree\" + 0.018*\"warming\" + 0.015*\"country\" + 0.014*\"cnn\" + 0.013*\"list\" + 0.012*\"story\" + 0.012*\"celsius\" + 0.011*\"world\"\n",
      "2019-10-29 00:38:27,287 : INFO : topic #9 (0.100): 0.030*\"climate\" + 0.020*\"change\" + 0.016*\"warming\" + 0.015*\"degree\" + 0.012*\"cnn\" + 0.012*\"country\" + 0.011*\"world\" + 0.010*\"celsius\" + 0.010*\"people\" + 0.010*\"list\"\n",
      "2019-10-29 00:38:27,290 : INFO : topic #2 (0.100): 0.039*\"climate\" + 0.030*\"change\" + 0.019*\"country\" + 0.016*\"degree\" + 0.016*\"world\" + 0.014*\"warming\" + 0.012*\"list\" + 0.011*\"story\" + 0.011*\"celsius\" + 0.011*\"cnn\"\n",
      "2019-10-29 00:38:27,292 : INFO : topic #8 (0.100): 0.036*\"climate\" + 0.025*\"change\" + 0.018*\"warming\" + 0.016*\"degree\" + 0.015*\"world\" + 0.015*\"country\" + 0.013*\"people\" + 0.011*\"story\" + 0.011*\"united\" + 0.011*\"celsius\"\n",
      "2019-10-29 00:38:27,293 : INFO : topic diff=0.875226, rho=1.000000\n",
      "2019-10-29 00:38:27,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:27,730 : INFO : built Dictionary(532 unique tokens: ['although', 'energy', 'real', 'reach', 'party']...) from 5 documents (total 5060 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:27,736 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:27,737 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:27,738 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:27,742 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:27,745 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:27,894 : INFO : -8.002 per-word bound, 256.3 perplexity estimate based on a held-out corpus of 5 documents with 5060 words\n",
      "2019-10-29 00:38:27,896 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:27,905 : INFO : topic #0 (0.100): 0.039*\"sugar\" + 0.017*\"said\" + 0.013*\"day\" + 0.012*\"alpert\" + 0.012*\"week\" + 0.011*\"detox\" + 0.009*\"sweetener\" + 0.009*\"one\" + 0.009*\"also\" + 0.009*\"natural\"\n",
      "2019-10-29 00:38:27,906 : INFO : topic #6 (0.100): 0.052*\"sugar\" + 0.016*\"said\" + 0.016*\"alpert\" + 0.013*\"day\" + 0.010*\"also\" + 0.010*\"week\" + 0.010*\"food\" + 0.008*\"natural\" + 0.008*\"one\" + 0.008*\"sweetener\"\n",
      "2019-10-29 00:38:27,908 : INFO : topic #5 (0.100): 0.034*\"sugar\" + 0.017*\"said\" + 0.015*\"day\" + 0.012*\"alpert\" + 0.010*\"detox\" + 0.009*\"one\" + 0.008*\"fat\" + 0.008*\"natural\" + 0.008*\"also\" + 0.008*\"week\"\n",
      "2019-10-29 00:38:27,909 : INFO : topic #1 (0.100): 0.062*\"sugar\" + 0.017*\"day\" + 0.016*\"said\" + 0.010*\"alpert\" + 0.010*\"sweetener\" + 0.009*\"detox\" + 0.009*\"one\" + 0.008*\"week\" + 0.008*\"people\" + 0.007*\"natural\"\n",
      "2019-10-29 00:38:27,913 : INFO : topic #4 (0.100): 0.053*\"sugar\" + 0.015*\"alpert\" + 0.013*\"day\" + 0.012*\"detox\" + 0.011*\"week\" + 0.010*\"said\" + 0.009*\"one\" + 0.009*\"natural\" + 0.008*\"sweetener\" + 0.008*\"also\"\n",
      "2019-10-29 00:38:27,916 : INFO : topic diff=0.934059, rho=1.000000\n",
      "2019-10-29 00:38:28,350 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:28,353 : INFO : built Dictionary(82 unique tokens: ['saddened', 'weinstein', 'manipulate', 'time', 'know']...) from 5 documents (total 490 corpus positions)\n",
      "2019-10-29 00:38:28,355 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:28,357 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:28,358 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:28,360 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:28,361 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:28,401 : INFO : -7.034 per-word bound, 131.0 perplexity estimate based on a held-out corpus of 5 documents with 490 words\n",
      "2019-10-29 00:38:28,403 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:28,410 : INFO : topic #5 (0.100): 0.038*\"weinstein\" + 0.034*\"harvey\" + 0.028*\"affleck\" + 0.022*\"film\" + 0.020*\"produced\" + 0.019*\"harassment\" + 0.019*\"decade\" + 0.018*\"read\" + 0.017*\"ben\" + 0.016*\"lawrence\"\n",
      "2019-10-29 00:38:28,412 : INFO : topic #0 (0.100): 0.061*\"weinstein\" + 0.027*\"affleck\" + 0.027*\"harvey\" + 0.023*\"produced\" + 0.021*\"worked\" + 0.021*\"harassment\" + 0.021*\"lawrence\" + 0.019*\"decade\" + 0.016*\"read\" + 0.016*\"ben\"\n",
      "2019-10-29 00:38:28,415 : INFO : topic #1 (0.100): 0.050*\"weinstein\" + 0.027*\"harvey\" + 0.024*\"read\" + 0.024*\"affleck\" + 0.023*\"produced\" + 0.020*\"film\" + 0.019*\"lawrence\" + 0.018*\"worked\" + 0.017*\"decade\" + 0.017*\"ben\"\n",
      "2019-10-29 00:38:28,417 : INFO : topic #6 (0.100): 0.044*\"weinstein\" + 0.025*\"affleck\" + 0.023*\"worked\" + 0.022*\"ben\" + 0.022*\"harvey\" + 0.020*\"read\" + 0.020*\"harassment\" + 0.020*\"film\" + 0.019*\"lawrence\" + 0.018*\"decade\"\n",
      "2019-10-29 00:38:28,420 : INFO : topic #4 (0.100): 0.043*\"weinstein\" + 0.035*\"affleck\" + 0.025*\"harvey\" + 0.023*\"ben\" + 0.022*\"harassment\" + 0.022*\"film\" + 0.021*\"decade\" + 0.020*\"worked\" + 0.019*\"produced\" + 0.016*\"read\"\n",
      "2019-10-29 00:38:28,425 : INFO : topic diff=0.681055, rho=1.000000\n",
      "2019-10-29 00:38:28,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:28,819 : INFO : built Dictionary(13 unique tokens: ['agreeing', 'changed', 'privacy', 'policy', 'site']...) from 5 documents (total 85 corpus positions)\n",
      "2019-10-29 00:38:28,821 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:28,822 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:28,824 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:28,826 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:28,827 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:28,837 : INFO : -5.698 per-word bound, 51.9 perplexity estimate based on a held-out corpus of 5 documents with 85 words\n",
      "2019-10-29 00:38:28,839 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:28,845 : INFO : topic #5 (0.100): 0.133*\"policy\" + 0.131*\"privacy\" + 0.127*\"service\" + 0.104*\"term\" + 0.066*\"changed\" + 0.063*\"site\" + 0.062*\"use\" + 0.060*\"new\" + 0.055*\"marketplace\" + 0.055*\"middle\"\n",
      "2019-10-29 00:38:28,846 : INFO : topic #1 (0.100): 0.134*\"term\" + 0.115*\"service\" + 0.108*\"policy\" + 0.103*\"privacy\" + 0.072*\"marketplace\" + 0.068*\"agreeing\" + 0.066*\"continuing\" + 0.065*\"east\" + 0.062*\"changed\" + 0.056*\"site\"\n",
      "2019-10-29 00:38:28,848 : INFO : topic #3 (0.100): 0.121*\"policy\" + 0.110*\"service\" + 0.110*\"term\" + 0.089*\"privacy\" + 0.077*\"site\" + 0.074*\"agreeing\" + 0.067*\"marketplace\" + 0.065*\"continuing\" + 0.063*\"new\" + 0.058*\"use\"\n",
      "2019-10-29 00:38:28,849 : INFO : topic #0 (0.100): 0.125*\"policy\" + 0.118*\"service\" + 0.116*\"term\" + 0.105*\"privacy\" + 0.071*\"east\" + 0.070*\"middle\" + 0.061*\"continuing\" + 0.060*\"site\" + 0.060*\"changed\" + 0.059*\"new\"\n",
      "2019-10-29 00:38:28,851 : INFO : topic #4 (0.100): 0.141*\"policy\" + 0.115*\"privacy\" + 0.115*\"term\" + 0.113*\"service\" + 0.064*\"new\" + 0.061*\"use\" + 0.061*\"agreeing\" + 0.060*\"east\" + 0.059*\"site\" + 0.056*\"continuing\"\n",
      "2019-10-29 00:38:28,853 : INFO : topic diff=0.650104, rho=1.000000\n",
      "2019-10-29 00:38:29,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:29,247 : INFO : built Dictionary(79 unique tokens: ['administration', 'administrator', 'week', 'regulation', 'focus']...) from 5 documents (total 565 corpus positions)\n",
      "2019-10-29 00:38:29,250 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:29,251 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:29,253 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:29,255 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:29,256 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:29,292 : INFO : -6.661 per-word bound, 101.2 perplexity estimate based on a held-out corpus of 5 documents with 565 words\n",
      "2019-10-29 00:38:29,294 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:29,302 : INFO : topic #8 (0.100): 0.057*\"climate\" + 0.048*\"change\" + 0.035*\"plan\" + 0.032*\"agency\" + 0.024*\"epa\" + 0.022*\"strategic\" + 0.021*\"four\" + 0.019*\"document\" + 0.018*\"administrator\" + 0.018*\"priority\"\n",
      "2019-10-29 00:38:29,303 : INFO : topic #4 (0.100): 0.048*\"change\" + 0.044*\"climate\" + 0.032*\"plan\" + 0.030*\"strategic\" + 0.029*\"agency\" + 0.029*\"epa\" + 0.027*\"four\" + 0.027*\"year\" + 0.022*\"appear\" + 0.018*\"environmental\"\n",
      "2019-10-29 00:38:29,304 : INFO : topic #0 (0.100): 0.049*\"change\" + 0.040*\"plan\" + 0.035*\"climate\" + 0.031*\"agency\" + 0.025*\"year\" + 0.025*\"strategic\" + 0.024*\"four\" + 0.023*\"epa\" + 0.020*\"priority\" + 0.020*\"public\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:29,306 : INFO : topic #3 (0.100): 0.048*\"change\" + 0.048*\"climate\" + 0.042*\"plan\" + 0.036*\"agency\" + 0.030*\"year\" + 0.023*\"epa\" + 0.023*\"four\" + 0.021*\"document\" + 0.020*\"strategic\" + 0.018*\"appear\"\n",
      "2019-10-29 00:38:29,311 : INFO : topic #2 (0.100): 0.053*\"change\" + 0.046*\"climate\" + 0.040*\"plan\" + 0.027*\"four\" + 0.026*\"year\" + 0.025*\"strategic\" + 0.024*\"epa\" + 0.024*\"agency\" + 0.022*\"environmental\" + 0.022*\"priority\"\n",
      "2019-10-29 00:38:29,312 : INFO : topic diff=0.807846, rho=1.000000\n",
      "2019-10-29 00:38:29,776 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:29,785 : INFO : built Dictionary(733 unique tokens: ['let', 'wave', 'velocity', 'blanket', 'frantically']...) from 5 documents (total 7220 corpus positions)\n",
      "2019-10-29 00:38:29,794 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:29,795 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:29,797 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:29,802 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:29,806 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:30,022 : INFO : -8.274 per-word bound, 309.6 perplexity estimate based on a held-out corpus of 5 documents with 7220 words\n",
      "2019-10-29 00:38:30,024 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:30,036 : INFO : topic #2 (0.100): 0.020*\"victim\" + 0.018*\"said\" + 0.013*\"hospital\" + 0.012*\"people\" + 0.010*\"patient\" + 0.008*\"one\" + 0.008*\"room\" + 0.007*\"blood\" + 0.007*\"padgett\" + 0.006*\"nurse\"\n",
      "2019-10-29 00:38:30,037 : INFO : topic #8 (0.100): 0.025*\"said\" + 0.015*\"people\" + 0.015*\"hospital\" + 0.012*\"patient\" + 0.011*\"victim\" + 0.009*\"blood\" + 0.009*\"one\" + 0.008*\"room\" + 0.007*\"kole\" + 0.007*\"padgett\"\n",
      "2019-10-29 00:38:30,039 : INFO : topic #4 (0.100): 0.017*\"said\" + 0.015*\"patient\" + 0.014*\"hospital\" + 0.013*\"people\" + 0.011*\"victim\" + 0.009*\"blood\" + 0.007*\"one\" + 0.007*\"told\" + 0.007*\"room\" + 0.007*\"trauma\"\n",
      "2019-10-29 00:38:30,041 : INFO : topic #7 (0.100): 0.018*\"said\" + 0.017*\"victim\" + 0.017*\"hospital\" + 0.014*\"people\" + 0.010*\"blood\" + 0.009*\"patient\" + 0.008*\"one\" + 0.007*\"room\" + 0.006*\"told\" + 0.006*\"could\"\n",
      "2019-10-29 00:38:30,043 : INFO : topic #5 (0.100): 0.024*\"said\" + 0.015*\"people\" + 0.011*\"hospital\" + 0.010*\"one\" + 0.010*\"victim\" + 0.008*\"patient\" + 0.006*\"doctor\" + 0.006*\"blood\" + 0.006*\"shot\" + 0.006*\"nurse\"\n",
      "2019-10-29 00:38:30,044 : INFO : topic diff=0.929480, rho=1.000000\n",
      "2019-10-29 00:38:30,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:30,462 : INFO : built Dictionary(264 unique tokens: ['although', 'fox', 'seriously', 'come', 'tax']...) from 5 documents (total 2420 corpus positions)\n",
      "2019-10-29 00:38:30,466 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:30,468 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:30,470 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:30,473 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:30,474 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:30,579 : INFO : -7.367 per-word bound, 165.1 perplexity estimate based on a held-out corpus of 5 documents with 2420 words\n",
      "2019-10-29 00:38:30,580 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:30,589 : INFO : topic #8 (0.100): 0.085*\"tax\" + 0.046*\"would\" + 0.035*\"flat\" + 0.030*\"paul\" + 0.017*\"income\" + 0.016*\"rate\" + 0.010*\"wage\" + 0.008*\"one\" + 0.008*\"pay\" + 0.008*\"free\"\n",
      "2019-10-29 00:38:30,591 : INFO : topic #0 (0.100): 0.099*\"tax\" + 0.047*\"would\" + 0.034*\"paul\" + 0.031*\"flat\" + 0.017*\"income\" + 0.011*\"year\" + 0.010*\"rate\" + 0.009*\"make\" + 0.009*\"free\" + 0.008*\"one\"\n",
      "2019-10-29 00:38:30,593 : INFO : topic #6 (0.100): 0.092*\"tax\" + 0.050*\"would\" + 0.035*\"flat\" + 0.027*\"paul\" + 0.020*\"income\" + 0.016*\"rate\" + 0.011*\"year\" + 0.009*\"one\" + 0.008*\"make\" + 0.008*\"pay\"\n",
      "2019-10-29 00:38:30,596 : INFO : topic #4 (0.100): 0.079*\"tax\" + 0.043*\"would\" + 0.030*\"flat\" + 0.030*\"paul\" + 0.017*\"rate\" + 0.017*\"income\" + 0.015*\"year\" + 0.008*\"make\" + 0.008*\"pay\" + 0.008*\"effective\"\n",
      "2019-10-29 00:38:30,599 : INFO : topic #2 (0.100): 0.080*\"tax\" + 0.047*\"would\" + 0.045*\"flat\" + 0.036*\"paul\" + 0.016*\"income\" + 0.013*\"rate\" + 0.012*\"year\" + 0.009*\"make\" + 0.009*\"pay\" + 0.009*\"wage\"\n",
      "2019-10-29 00:38:30,602 : INFO : topic diff=0.923684, rho=1.000000\n",
      "2019-10-29 00:38:30,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:30,996 : INFO : built Dictionary(208 unique tokens: ['inspecting', 'concern', 'product', 'revealed', 'industry']...) from 5 documents (total 1510 corpus positions)\n",
      "2019-10-29 00:38:30,999 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:31,001 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:31,002 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:31,004 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:31,006 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:31,074 : INFO : -7.491 per-word bound, 179.9 perplexity estimate based on a held-out corpus of 5 documents with 1510 words\n",
      "2019-10-29 00:38:31,075 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:31,081 : INFO : topic #4 (0.100): 0.027*\"kobe\" + 0.022*\"steel\" + 0.022*\"scandal\" + 0.017*\"said\" + 0.016*\"also\" + 0.011*\"boeing\" + 0.011*\"product\" + 0.010*\"mitsubishi\" + 0.010*\"spokesman\" + 0.010*\"industry\"\n",
      "2019-10-29 00:38:31,082 : INFO : topic #8 (0.100): 0.041*\"kobe\" + 0.021*\"steel\" + 0.021*\"scandal\" + 0.014*\"said\" + 0.012*\"boeing\" + 0.010*\"subaru\" + 0.010*\"spokesman\" + 0.010*\"medd\" + 0.010*\"industry\" + 0.010*\"used\"\n",
      "2019-10-29 00:38:31,084 : INFO : topic #9 (0.100): 0.029*\"kobe\" + 0.025*\"steel\" + 0.020*\"scandal\" + 0.017*\"said\" + 0.012*\"also\" + 0.012*\"subaru\" + 0.011*\"product\" + 0.011*\"boeing\" + 0.011*\"data\" + 0.009*\"used\"\n",
      "2019-10-29 00:38:31,086 : INFO : topic #1 (0.100): 0.036*\"kobe\" + 0.023*\"said\" + 0.022*\"steel\" + 0.020*\"scandal\" + 0.015*\"boeing\" + 0.012*\"also\" + 0.011*\"data\" + 0.010*\"subaru\" + 0.010*\"product\" + 0.010*\"spokesman\"\n",
      "2019-10-29 00:38:31,090 : INFO : topic #0 (0.100): 0.039*\"kobe\" + 0.022*\"steel\" + 0.020*\"scandal\" + 0.016*\"said\" + 0.013*\"also\" + 0.013*\"boeing\" + 0.011*\"used\" + 0.011*\"medd\" + 0.011*\"year\" + 0.009*\"industry\"\n",
      "2019-10-29 00:38:31,095 : INFO : topic diff=0.762830, rho=1.000000\n",
      "2019-10-29 00:38:31,520 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:31,522 : INFO : built Dictionary(17 unique tokens: ['ambush', 'barbara', 'first', 'cnn', 'starr']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:38:31,523 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:31,524 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:31,529 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:31,533 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:31,536 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:31,549 : INFO : -5.729 per-word bound, 53.0 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:38:31,552 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:31,558 : INFO : topic #1 (0.100): 0.094*\"isi\" + 0.091*\"u\" + 0.091*\"soldier\" + 0.076*\"taken\" + 0.073*\"killed\" + 0.066*\"report\" + 0.061*\"alive\" + 0.053*\"niger\" + 0.052*\"starr\" + 0.049*\"cnn\"\n",
      "2019-10-29 00:38:31,561 : INFO : topic #6 (0.100): 0.104*\"killed\" + 0.101*\"alive\" + 0.079*\"taken\" + 0.072*\"soldier\" + 0.070*\"u\" + 0.065*\"isi\" + 0.055*\"first\" + 0.054*\"ambush\" + 0.049*\"one\" + 0.049*\"four\"\n",
      "2019-10-29 00:38:31,564 : INFO : topic #2 (0.100): 0.093*\"isi\" + 0.093*\"taken\" + 0.092*\"killed\" + 0.079*\"u\" + 0.063*\"barbara\" + 0.059*\"soldier\" + 0.059*\"one\" + 0.057*\"alive\" + 0.052*\"cnn\" + 0.049*\"starr\"\n",
      "2019-10-29 00:38:31,567 : INFO : topic #4 (0.100): 0.099*\"alive\" + 0.094*\"u\" + 0.085*\"killed\" + 0.075*\"soldier\" + 0.072*\"isi\" + 0.068*\"taken\" + 0.055*\"ambush\" + 0.054*\"niger\" + 0.053*\"one\" + 0.051*\"cnn\"\n",
      "2019-10-29 00:38:31,570 : INFO : topic #5 (0.100): 0.089*\"taken\" + 0.087*\"alive\" + 0.086*\"u\" + 0.083*\"killed\" + 0.083*\"soldier\" + 0.081*\"isi\" + 0.058*\"four\" + 0.053*\"cnn\" + 0.048*\"possibly\" + 0.046*\"niger\"\n",
      "2019-10-29 00:38:31,573 : INFO : topic diff=0.626233, rho=1.000000\n",
      "2019-10-29 00:38:31,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:31,955 : INFO : built Dictionary(42 unique tokens: ['early', 'book', 'something', 'knew', 'get']...) from 5 documents (total 235 corpus positions)\n",
      "2019-10-29 00:38:31,956 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:31,957 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:31,959 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:31,961 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:31,962 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:31,987 : INFO : -6.683 per-word bound, 102.7 perplexity estimate based on a held-out corpus of 5 documents with 235 words\n",
      "2019-10-29 00:38:31,988 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:31,994 : INFO : topic #6 (0.100): 0.062*\"would\" + 0.042*\"outlet\" + 0.040*\"dancing\" + 0.035*\"creative\" + 0.029*\"everything\" + 0.026*\"team\" + 0.026*\"dance\" + 0.025*\"remember\" + 0.024*\"world\" + 0.024*\"innovator\"\n",
      "2019-10-29 00:38:31,996 : INFO : topic #4 (0.100): 0.051*\"would\" + 0.041*\"dancing\" + 0.037*\"creative\" + 0.036*\"outlet\" + 0.028*\"city\" + 0.028*\"fitness\" + 0.026*\"ask\" + 0.026*\"team\" + 0.025*\"everything\" + 0.025*\"knew\"\n",
      "2019-10-29 00:38:32,000 : INFO : topic #1 (0.100): 0.052*\"would\" + 0.043*\"dancing\" + 0.041*\"creative\" + 0.041*\"outlet\" + 0.027*\"stress\" + 0.026*\"something\" + 0.026*\"knew\" + 0.026*\"studio\" + 0.026*\"payal\" + 0.025*\"innovator\"\n",
      "2019-10-29 00:38:32,003 : INFO : topic #8 (0.100): 0.065*\"would\" + 0.048*\"outlet\" + 0.040*\"creative\" + 0.029*\"dancing\" + 0.027*\"lost\" + 0.027*\"performing\" + 0.025*\"everything\" + 0.025*\"something\" + 0.024*\"dance\" + 0.024*\"even\"\n",
      "2019-10-29 00:38:32,006 : INFO : topic #5 (0.100): 0.063*\"would\" + 0.046*\"outlet\" + 0.043*\"dancing\" + 0.042*\"creative\" + 0.028*\"early\" + 0.026*\"founder\" + 0.026*\"fitness\" + 0.025*\"become\" + 0.025*\"get\" + 0.024*\"around\"\n",
      "2019-10-29 00:38:32,008 : INFO : topic diff=0.627546, rho=1.000000\n",
      "2019-10-29 00:38:32,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:32,418 : INFO : built Dictionary(232 unique tokens: ['extensive', 'campaign', 'fox', 'grounded', 'democrat']...) from 5 documents (total 2280 corpus positions)\n",
      "2019-10-29 00:38:32,421 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:32,423 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:32,424 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:32,426 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:32,427 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:32,529 : INFO : -7.171 per-word bound, 144.1 perplexity estimate based on a held-out corpus of 5 documents with 2280 words\n",
      "2019-10-29 00:38:32,531 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:32,539 : INFO : topic #9 (0.100): 0.043*\"white\" + 0.042*\"working\" + 0.029*\"class\" + 0.028*\"immigrant\" + 0.021*\"trump\" + 0.021*\"muslim\" + 0.020*\"attack\" + 0.019*\"country\" + 0.018*\"say\" + 0.015*\"new\"\n",
      "2019-10-29 00:38:32,542 : INFO : topic #3 (0.100): 0.036*\"white\" + 0.028*\"class\" + 0.026*\"working\" + 0.023*\"trump\" + 0.022*\"immigrant\" + 0.022*\"say\" + 0.020*\"muslim\" + 0.020*\"country\" + 0.019*\"attack\" + 0.016*\"terrorism\"\n",
      "2019-10-29 00:38:32,545 : INFO : topic #2 (0.100): 0.029*\"white\" + 0.028*\"immigrant\" + 0.025*\"working\" + 0.024*\"muslim\" + 0.022*\"class\" + 0.020*\"attack\" + 0.020*\"trump\" + 0.020*\"country\" + 0.019*\"say\" + 0.018*\"view\"\n",
      "2019-10-29 00:38:32,548 : INFO : topic #7 (0.100): 0.039*\"white\" + 0.031*\"class\" + 0.027*\"muslim\" + 0.025*\"country\" + 0.024*\"immigrant\" + 0.022*\"attack\" + 0.019*\"working\" + 0.019*\"trump\" + 0.017*\"say\" + 0.017*\"terrorism\"\n",
      "2019-10-29 00:38:32,550 : INFO : topic #8 (0.100): 0.038*\"white\" + 0.031*\"working\" + 0.026*\"trump\" + 0.026*\"class\" + 0.025*\"immigrant\" + 0.023*\"attack\" + 0.022*\"country\" + 0.020*\"say\" + 0.017*\"muslim\" + 0.015*\"terrorism\"\n",
      "2019-10-29 00:38:32,553 : INFO : topic diff=0.978325, rho=1.000000\n",
      "2019-10-29 00:38:33,030 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:33,036 : INFO : built Dictionary(287 unique tokens: ['stadium', 'significant', 'nigeria', 'nation', 'relax']...) from 5 documents (total 2180 corpus positions)\n",
      "2019-10-29 00:38:33,042 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:33,044 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:33,047 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:33,052 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:33,055 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:33,172 : INFO : -7.714 per-word bound, 210.0 perplexity estimate based on a held-out corpus of 5 documents with 2180 words\n",
      "2019-10-29 00:38:33,174 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:33,182 : INFO : topic #3 (0.100): 0.031*\"cup\" + 0.026*\"egypt\" + 0.025*\"world\" + 0.015*\"time\" + 0.014*\"salah\" + 0.012*\"country\" + 0.011*\"el\" + 0.010*\"since\" + 0.009*\"team\" + 0.009*\"hadary\"\n",
      "2019-10-29 00:38:33,184 : INFO : topic #2 (0.100): 0.027*\"cup\" + 0.027*\"world\" + 0.023*\"egypt\" + 0.016*\"salah\" + 0.012*\"time\" + 0.011*\"team\" + 0.011*\"player\" + 0.011*\"national\" + 0.011*\"el\" + 0.010*\"game\"\n",
      "2019-10-29 00:38:33,188 : INFO : topic #5 (0.100): 0.026*\"cup\" + 0.022*\"world\" + 0.021*\"egypt\" + 0.015*\"game\" + 0.014*\"time\" + 0.014*\"el\" + 0.013*\"country\" + 0.012*\"salah\" + 0.011*\"com\" + 0.009*\"team\"\n",
      "2019-10-29 00:38:33,190 : INFO : topic #1 (0.100): 0.023*\"world\" + 0.023*\"egypt\" + 0.018*\"cup\" + 0.016*\"el\" + 0.014*\"time\" + 0.014*\"game\" + 0.012*\"salah\" + 0.011*\"team\" + 0.009*\"country\" + 0.009*\"since\"\n",
      "2019-10-29 00:38:33,193 : INFO : topic #8 (0.100): 0.028*\"world\" + 0.024*\"cup\" + 0.019*\"egypt\" + 0.013*\"el\" + 0.013*\"salah\" + 0.013*\"team\" + 0.012*\"time\" + 0.010*\"country\" + 0.010*\"year\" + 0.009*\"game\"\n",
      "2019-10-29 00:38:33,196 : INFO : topic diff=0.834051, rho=1.000000\n",
      "2019-10-29 00:38:33,612 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:33,616 : INFO : built Dictionary(313 unique tokens: ['deli', 'renovation', 'school', 'take', 'relax']...) from 5 documents (total 2245 corpus positions)\n",
      "2019-10-29 00:38:33,620 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:33,621 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:33,623 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:33,627 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:33,629 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:33,723 : INFO : -7.889 per-word bound, 237.1 perplexity estimate based on a held-out corpus of 5 documents with 2245 words\n",
      "2019-10-29 00:38:33,724 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:33,732 : INFO : topic #0 (0.100): 0.046*\"park\" + 0.025*\"central\" + 0.022*\"new\" + 0.021*\"york\" + 0.014*\"ny\" + 0.013*\"museum\" + 0.011*\"city\" + 0.010*\"get\" + 0.009*\"green\" + 0.007*\"along\"\n",
      "2019-10-29 00:38:33,734 : INFO : topic #9 (0.100): 0.046*\"park\" + 0.022*\"new\" + 0.019*\"york\" + 0.018*\"museum\" + 0.017*\"central\" + 0.010*\"ny\" + 0.010*\"city\" + 0.010*\"get\" + 0.009*\"green\" + 0.008*\"along\"\n",
      "2019-10-29 00:38:33,737 : INFO : topic #1 (0.100): 0.050*\"park\" + 0.028*\"york\" + 0.023*\"new\" + 0.021*\"central\" + 0.017*\"museum\" + 0.008*\"ny\" + 0.008*\"green\" + 0.008*\"city\" + 0.007*\"get\" + 0.007*\"fountain\"\n",
      "2019-10-29 00:38:33,739 : INFO : topic #3 (0.100): 0.062*\"park\" + 0.024*\"new\" + 0.022*\"york\" + 0.019*\"central\" + 0.014*\"museum\" + 0.010*\"city\" + 0.009*\"ny\" + 0.007*\"green\" + 0.007*\"get\" + 0.007*\"two\"\n",
      "2019-10-29 00:38:33,742 : INFO : topic #4 (0.100): 0.046*\"park\" + 0.025*\"york\" + 0.024*\"new\" + 0.016*\"central\" + 0.014*\"museum\" + 0.010*\"city\" + 0.008*\"ny\" + 0.007*\"green\" + 0.007*\"get\" + 0.007*\"ave\"\n",
      "2019-10-29 00:38:33,745 : INFO : topic diff=0.786613, rho=1.000000\n",
      "2019-10-29 00:38:34,147 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:34,152 : INFO : built Dictionary(312 unique tokens: ['even', 'school', 'small', 'end', 'hero']...) from 5 documents (total 2655 corpus positions)\n",
      "2019-10-29 00:38:34,156 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:34,158 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:34,159 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:34,163 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:34,165 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:34,260 : INFO : -7.638 per-word bound, 199.2 perplexity estimate based on a held-out corpus of 5 documents with 2655 words\n",
      "2019-10-29 00:38:34,262 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:34,270 : INFO : topic #8 (0.100): 0.086*\"bear\" + 0.050*\"sun\" + 0.025*\"wong\" + 0.016*\"cnn\" + 0.015*\"forest\" + 0.013*\"animal\" + 0.009*\"conservation\" + 0.009*\"also\" + 0.008*\"said\" + 0.008*\"centre\"\n",
      "2019-10-29 00:38:34,272 : INFO : topic #0 (0.100): 0.089*\"bear\" + 0.037*\"sun\" + 0.023*\"wong\" + 0.011*\"cnn\" + 0.011*\"animal\" + 0.011*\"forest\" + 0.010*\"conservation\" + 0.009*\"also\" + 0.009*\"many\" + 0.009*\"said\"\n",
      "2019-10-29 00:38:34,274 : INFO : topic #5 (0.100): 0.080*\"bear\" + 0.046*\"sun\" + 0.026*\"wong\" + 0.014*\"animal\" + 0.014*\"cnn\" + 0.013*\"forest\" + 0.010*\"conservation\" + 0.009*\"said\" + 0.007*\"people\" + 0.007*\"many\"\n",
      "2019-10-29 00:38:34,276 : INFO : topic #2 (0.100): 0.068*\"bear\" + 0.033*\"sun\" + 0.031*\"wong\" + 0.015*\"forest\" + 0.011*\"cnn\" + 0.011*\"animal\" + 0.010*\"also\" + 0.010*\"people\" + 0.009*\"many\" + 0.008*\"release\"\n",
      "2019-10-29 00:38:34,278 : INFO : topic #7 (0.100): 0.064*\"bear\" + 0.041*\"sun\" + 0.021*\"wong\" + 0.015*\"animal\" + 0.014*\"cnn\" + 0.014*\"forest\" + 0.011*\"people\" + 0.009*\"said\" + 0.008*\"bornean\" + 0.008*\"also\"\n",
      "2019-10-29 00:38:34,280 : INFO : topic diff=0.916708, rho=1.000000\n",
      "2019-10-29 00:38:34,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:34,746 : INFO : built Dictionary(63 unique tokens: ['catholic', 'week', 'time', 'thought', 'series']...) from 5 documents (total 435 corpus positions)\n",
      "2019-10-29 00:38:34,748 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:34,749 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:34,750 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:34,753 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:34,759 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:34,792 : INFO : -6.538 per-word bound, 92.9 perplexity estimate based on a held-out corpus of 5 documents with 435 words\n",
      "2019-10-29 00:38:34,794 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:34,799 : INFO : topic #9 (0.100): 0.074*\"week\" + 0.065*\"read\" + 0.033*\"story\" + 0.031*\"thought\" + 0.031*\"bible\" + 0.026*\"cnn\" + 0.025*\"catholic\" + 0.025*\"much\" + 0.022*\"reading\" + 0.020*\"matthew\"\n",
      "2019-10-29 00:38:34,802 : INFO : topic #1 (0.100): 0.069*\"read\" + 0.062*\"week\" + 0.034*\"bible\" + 0.034*\"thought\" + 0.028*\"story\" + 0.026*\"reading\" + 0.025*\"matthew\" + 0.023*\"catholic\" + 0.022*\"cnn\" + 0.020*\"much\"\n",
      "2019-10-29 00:38:34,805 : INFO : topic #0 (0.100): 0.064*\"week\" + 0.055*\"read\" + 0.033*\"thought\" + 0.032*\"story\" + 0.027*\"mass\" + 0.027*\"bible\" + 0.025*\"slightly\" + 0.025*\"cnn\" + 0.023*\"catholic\" + 0.022*\"bernardini\"\n",
      "2019-10-29 00:38:34,807 : INFO : topic #4 (0.100): 0.085*\"week\" + 0.062*\"read\" + 0.039*\"story\" + 0.036*\"bible\" + 0.033*\"thought\" + 0.028*\"much\" + 0.025*\"slightly\" + 0.023*\"mass\" + 0.023*\"catholic\" + 0.023*\"cnn\"\n",
      "2019-10-29 00:38:34,810 : INFO : topic #2 (0.100): 0.062*\"week\" + 0.044*\"read\" + 0.035*\"bible\" + 0.032*\"story\" + 0.026*\"bernardini\" + 0.025*\"thought\" + 0.025*\"matthew\" + 0.024*\"mass\" + 0.022*\"much\" + 0.022*\"catholic\"\n",
      "2019-10-29 00:38:34,812 : INFO : topic diff=0.783508, rho=1.000000\n",
      "2019-10-29 00:38:35,209 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:35,210 : INFO : built Dictionary(14 unique tokens: ['happening', 'heisman', 'trophy', 'messenger', 'tackled']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:38:35,214 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:35,216 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:35,217 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:35,220 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:35,221 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:35,232 : INFO : -6.431 per-word bound, 86.3 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:38:35,233 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:35,239 : INFO : topic #5 (0.100): 0.092*\"winner\" + 0.086*\"find\" + 0.077*\"unfolds\" + 0.076*\"chat\" + 0.074*\"messenger\" + 0.072*\"vp\" + 0.072*\"world\" + 0.069*\"u\" + 0.068*\"tackled\" + 0.068*\"know\"\n",
      "2019-10-29 00:38:35,241 : INFO : topic #0 (0.100): 0.091*\"find\" + 0.078*\"chat\" + 0.078*\"vp\" + 0.076*\"winner\" + 0.075*\"tackled\" + 0.074*\"heisman\" + 0.074*\"trophy\" + 0.072*\"know\" + 0.070*\"world\" + 0.066*\"happening\"\n",
      "2019-10-29 00:38:35,242 : INFO : topic #9 (0.100): 0.083*\"winner\" + 0.082*\"chat\" + 0.077*\"trophy\" + 0.077*\"vp\" + 0.077*\"unfolds\" + 0.076*\"happening\" + 0.075*\"u\" + 0.073*\"world\" + 0.067*\"find\" + 0.067*\"heisman\"\n",
      "2019-10-29 00:38:35,244 : INFO : topic #4 (0.100): 0.095*\"find\" + 0.079*\"u\" + 0.078*\"facebook\" + 0.077*\"winner\" + 0.077*\"know\" + 0.075*\"heisman\" + 0.071*\"happening\" + 0.071*\"world\" + 0.070*\"messenger\" + 0.066*\"trophy\"\n",
      "2019-10-29 00:38:35,245 : INFO : topic #8 (0.100): 0.089*\"heisman\" + 0.087*\"unfolds\" + 0.086*\"tackled\" + 0.083*\"world\" + 0.071*\"facebook\" + 0.070*\"messenger\" + 0.068*\"find\" + 0.067*\"vp\" + 0.065*\"trophy\" + 0.065*\"happening\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:35,247 : INFO : topic diff=0.505645, rho=1.000000\n",
      "2019-10-29 00:38:35,630 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:35,632 : INFO : built Dictionary(79 unique tokens: ['administration', 'administrator', 'week', 'regulation', 'focus']...) from 5 documents (total 565 corpus positions)\n",
      "2019-10-29 00:38:35,634 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:35,635 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:35,636 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:35,638 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:35,639 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:35,679 : INFO : -6.665 per-word bound, 101.5 perplexity estimate based on a held-out corpus of 5 documents with 565 words\n",
      "2019-10-29 00:38:35,680 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:35,687 : INFO : topic #3 (0.100): 0.068*\"change\" + 0.051*\"climate\" + 0.033*\"plan\" + 0.027*\"agency\" + 0.026*\"year\" + 0.025*\"four\" + 0.020*\"strategic\" + 0.020*\"epa\" + 0.019*\"document\" + 0.018*\"priority\"\n",
      "2019-10-29 00:38:35,690 : INFO : topic #0 (0.100): 0.049*\"climate\" + 0.045*\"change\" + 0.040*\"plan\" + 0.038*\"agency\" + 0.033*\"four\" + 0.030*\"strategic\" + 0.024*\"year\" + 0.023*\"epa\" + 0.019*\"comment\" + 0.018*\"public\"\n",
      "2019-10-29 00:38:35,692 : INFO : topic #1 (0.100): 0.045*\"change\" + 0.044*\"plan\" + 0.038*\"climate\" + 0.033*\"agency\" + 0.025*\"year\" + 0.025*\"strategic\" + 0.025*\"four\" + 0.024*\"epa\" + 0.021*\"priority\" + 0.021*\"environmental\"\n",
      "2019-10-29 00:38:35,695 : INFO : topic #6 (0.100): 0.061*\"climate\" + 0.040*\"plan\" + 0.039*\"change\" + 0.034*\"agency\" + 0.026*\"strategic\" + 0.025*\"year\" + 0.024*\"four\" + 0.023*\"epa\" + 0.020*\"administrator\" + 0.019*\"environmental\"\n",
      "2019-10-29 00:38:35,698 : INFO : topic #8 (0.100): 0.050*\"change\" + 0.047*\"climate\" + 0.040*\"plan\" + 0.033*\"agency\" + 0.032*\"epa\" + 0.026*\"year\" + 0.022*\"air\" + 0.021*\"strategic\" + 0.020*\"priority\" + 0.018*\"four\"\n",
      "2019-10-29 00:38:35,700 : INFO : topic diff=0.810750, rho=1.000000\n",
      "2019-10-29 00:38:36,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:36,118 : INFO : built Dictionary(253 unique tokens: ['concern', 'product', 'filed', 'industry', 'prove']...) from 5 documents (total 1865 corpus positions)\n",
      "2019-10-29 00:38:36,121 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:36,123 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:36,124 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:36,130 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:36,133 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:36,221 : INFO : -7.649 per-word bound, 200.7 perplexity estimate based on a held-out corpus of 5 documents with 1865 words\n",
      "2019-10-29 00:38:36,223 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:36,230 : INFO : topic #2 (0.100): 0.026*\"cobalt\" + 0.024*\"tungsten\" + 0.020*\"electric\" + 0.016*\"metal\" + 0.016*\"production\" + 0.013*\"world\" + 0.013*\"car\" + 0.011*\"according\" + 0.009*\"price\" + 0.009*\"battery\"\n",
      "2019-10-29 00:38:36,233 : INFO : topic #1 (0.100): 0.045*\"cobalt\" + 0.020*\"tungsten\" + 0.019*\"metal\" + 0.015*\"electric\" + 0.015*\"car\" + 0.013*\"production\" + 0.010*\"supply\" + 0.010*\"also\" + 0.010*\"battery\" + 0.009*\"price\"\n",
      "2019-10-29 00:38:36,236 : INFO : topic #7 (0.100): 0.036*\"cobalt\" + 0.020*\"metal\" + 0.019*\"tungsten\" + 0.017*\"car\" + 0.015*\"electric\" + 0.014*\"production\" + 0.012*\"price\" + 0.012*\"battery\" + 0.011*\"according\" + 0.009*\"firm\"\n",
      "2019-10-29 00:38:36,239 : INFO : topic #9 (0.100): 0.034*\"cobalt\" + 0.023*\"tungsten\" + 0.019*\"car\" + 0.015*\"metal\" + 0.014*\"production\" + 0.013*\"price\" + 0.011*\"electric\" + 0.011*\"according\" + 0.010*\"china\" + 0.010*\"world\"\n",
      "2019-10-29 00:38:36,242 : INFO : topic #0 (0.100): 0.031*\"cobalt\" + 0.022*\"tungsten\" + 0.019*\"metal\" + 0.015*\"car\" + 0.014*\"price\" + 0.013*\"according\" + 0.013*\"electric\" + 0.012*\"production\" + 0.011*\"battery\" + 0.011*\"world\"\n",
      "2019-10-29 00:38:36,244 : INFO : topic diff=0.820542, rho=1.000000\n",
      "2019-10-29 00:38:36,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:36,676 : INFO : built Dictionary(452 unique tokens: ['previously', 'residency', 'refugee', 'expansion', 'asked']...) from 5 documents (total 4075 corpus positions)\n",
      "2019-10-29 00:38:36,681 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:36,683 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:36,684 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:36,688 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:36,689 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:36,838 : INFO : -7.912 per-word bound, 240.9 perplexity estimate based on a held-out corpus of 5 documents with 4075 words\n",
      "2019-10-29 00:38:36,840 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:36,848 : INFO : topic #9 (0.100): 0.029*\"immigration\" + 0.016*\"dhs\" + 0.015*\"u\" + 0.013*\"administration\" + 0.013*\"could\" + 0.011*\"policy\" + 0.009*\"source\" + 0.008*\"legal\" + 0.008*\"protection\" + 0.008*\"even\"\n",
      "2019-10-29 00:38:36,849 : INFO : topic #0 (0.100): 0.041*\"immigration\" + 0.025*\"u\" + 0.012*\"dhs\" + 0.011*\"administration\" + 0.011*\"could\" + 0.008*\"even\" + 0.008*\"source\" + 0.008*\"policy\" + 0.008*\"legal\" + 0.008*\"program\"\n",
      "2019-10-29 00:38:36,851 : INFO : topic #2 (0.100): 0.026*\"immigration\" + 0.020*\"dhs\" + 0.020*\"u\" + 0.014*\"policy\" + 0.012*\"administration\" + 0.009*\"protection\" + 0.009*\"executive\" + 0.009*\"legal\" + 0.009*\"said\" + 0.008*\"also\"\n",
      "2019-10-29 00:38:36,852 : INFO : topic #4 (0.100): 0.030*\"immigration\" + 0.018*\"u\" + 0.013*\"dhs\" + 0.013*\"administration\" + 0.012*\"policy\" + 0.011*\"protection\" + 0.010*\"could\" + 0.010*\"also\" + 0.009*\"change\" + 0.009*\"legal\"\n",
      "2019-10-29 00:38:36,853 : INFO : topic #3 (0.100): 0.023*\"immigration\" + 0.019*\"policy\" + 0.016*\"u\" + 0.013*\"dhs\" + 0.011*\"administration\" + 0.010*\"protection\" + 0.010*\"also\" + 0.009*\"congress\" + 0.009*\"could\" + 0.009*\"program\"\n",
      "2019-10-29 00:38:36,856 : INFO : topic diff=0.891097, rho=1.000000\n",
      "2019-10-29 00:38:37,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:37,262 : INFO : built Dictionary(211 unique tokens: ['concern', 'enterprise', 'willems', 'book', 'wont']...) from 5 documents (total 1780 corpus positions)\n",
      "2019-10-29 00:38:37,265 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:37,266 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:37,267 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:37,270 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:37,271 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:37,351 : INFO : -7.280 per-word bound, 155.5 perplexity estimate based on a held-out corpus of 5 documents with 1780 words\n",
      "2019-10-29 00:38:37,353 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:37,361 : INFO : topic #9 (0.100): 0.046*\"mural\" + 0.035*\"museum\" + 0.030*\"seuss\" + 0.021*\"dr\" + 0.019*\"springfield\" + 0.018*\"author\" + 0.016*\"letter\" + 0.015*\"picknelly\" + 0.014*\"said\" + 0.014*\"book\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:37,364 : INFO : topic #4 (0.100): 0.044*\"museum\" + 0.039*\"seuss\" + 0.038*\"mural\" + 0.024*\"springfield\" + 0.022*\"dr\" + 0.018*\"said\" + 0.015*\"book\" + 0.014*\"letter\" + 0.013*\"author\" + 0.013*\"read\"\n",
      "2019-10-29 00:38:37,367 : INFO : topic #3 (0.100): 0.040*\"mural\" + 0.040*\"museum\" + 0.027*\"seuss\" + 0.024*\"dr\" + 0.018*\"springfield\" + 0.016*\"said\" + 0.016*\"book\" + 0.016*\"author\" + 0.013*\"letter\" + 0.012*\"yee\"\n",
      "2019-10-29 00:38:37,370 : INFO : topic #7 (0.100): 0.036*\"mural\" + 0.033*\"museum\" + 0.023*\"dr\" + 0.022*\"seuss\" + 0.021*\"author\" + 0.020*\"springfield\" + 0.016*\"said\" + 0.014*\"book\" + 0.014*\"child\" + 0.013*\"letter\"\n",
      "2019-10-29 00:38:37,373 : INFO : topic #6 (0.100): 0.041*\"mural\" + 0.038*\"museum\" + 0.025*\"dr\" + 0.024*\"springfield\" + 0.022*\"seuss\" + 0.017*\"author\" + 0.016*\"book\" + 0.014*\"said\" + 0.014*\"three\" + 0.013*\"asian\"\n",
      "2019-10-29 00:38:37,376 : INFO : topic diff=0.922031, rho=1.000000\n",
      "2019-10-29 00:38:37,851 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:37,856 : INFO : built Dictionary(170 unique tokens: ['museum', 'energy', 'word', 'danish', 'come']...) from 5 documents (total 1135 corpus positions)\n",
      "2019-10-29 00:38:37,858 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:37,860 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:37,864 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:37,868 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:37,871 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:37,942 : INFO : -7.449 per-word bound, 174.8 perplexity estimate based on a held-out corpus of 5 documents with 1135 words\n",
      "2019-10-29 00:38:37,943 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:37,950 : INFO : topic #9 (0.100): 0.026*\"ingels\" + 0.023*\"museum\" + 0.019*\"bunker\" + 0.017*\"design\" + 0.017*\"open\" + 0.016*\"bjarke\" + 0.016*\"denmark\" + 0.014*\"think\" + 0.014*\"dune\" + 0.013*\"new\"\n",
      "2019-10-29 00:38:37,952 : INFO : topic #7 (0.100): 0.029*\"ingels\" + 0.024*\"museum\" + 0.023*\"denmark\" + 0.019*\"heritage\" + 0.018*\"bunker\" + 0.016*\"bjarke\" + 0.015*\"open\" + 0.014*\"blåvand\" + 0.013*\"sand\" + 0.013*\"design\"\n",
      "2019-10-29 00:38:37,954 : INFO : topic #4 (0.100): 0.027*\"museum\" + 0.026*\"denmark\" + 0.021*\"ingels\" + 0.017*\"design\" + 0.016*\"bunker\" + 0.015*\"bjarke\" + 0.014*\"open\" + 0.014*\"tirpitz\" + 0.013*\"dune\" + 0.012*\"think\"\n",
      "2019-10-29 00:38:37,957 : INFO : topic #3 (0.100): 0.029*\"museum\" + 0.027*\"ingels\" + 0.020*\"bunker\" + 0.019*\"design\" + 0.016*\"denmark\" + 0.015*\"bjarke\" + 0.015*\"sand\" + 0.015*\"open\" + 0.013*\"tirpitz\" + 0.012*\"new\"\n",
      "2019-10-29 00:38:37,960 : INFO : topic #0 (0.100): 0.034*\"ingels\" + 0.022*\"denmark\" + 0.019*\"bjarke\" + 0.018*\"open\" + 0.016*\"bunker\" + 0.016*\"design\" + 0.016*\"museum\" + 0.013*\"tirpitz\" + 0.013*\"think\" + 0.012*\"new\"\n",
      "2019-10-29 00:38:37,962 : INFO : topic diff=0.775861, rho=1.000000\n",
      "2019-10-29 00:38:38,364 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:38,369 : INFO : built Dictionary(340 unique tokens: ['anniversary', 'miracle', 'enterprise', 'digit', 'nation']...) from 5 documents (total 2515 corpus positions)\n",
      "2019-10-29 00:38:38,373 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:38,374 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:38,376 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:38,379 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:38,381 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:38,481 : INFO : -7.918 per-word bound, 241.9 perplexity estimate based on a held-out corpus of 5 documents with 2515 words\n",
      "2019-10-29 00:38:38,483 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:38,491 : INFO : topic #3 (0.100): 0.019*\"art\" + 0.019*\"london\" + 0.017*\"gallery\" + 0.016*\"credit\" + 0.013*\"courtesy\" + 0.012*\"serpentine\" + 0.011*\"message\" + 0.009*\"colen\" + 0.009*\"work\" + 0.009*\"arthur\"\n",
      "2019-10-29 00:38:38,492 : INFO : topic #5 (0.100): 0.019*\"art\" + 0.017*\"london\" + 0.014*\"gallery\" + 0.013*\"courtesy\" + 0.012*\"credit\" + 0.011*\"installation\" + 0.010*\"jafa\" + 0.009*\"arthur\" + 0.009*\"serpentine\" + 0.009*\"work\"\n",
      "2019-10-29 00:38:38,494 : INFO : topic #6 (0.100): 0.020*\"credit\" + 0.018*\"courtesy\" + 0.017*\"art\" + 0.016*\"gallery\" + 0.016*\"london\" + 0.012*\"installation\" + 0.012*\"serpentine\" + 0.011*\"message\" + 0.010*\"marianna\" + 0.010*\"jafa\"\n",
      "2019-10-29 00:38:38,496 : INFO : topic #4 (0.100): 0.017*\"london\" + 0.017*\"credit\" + 0.016*\"art\" + 0.016*\"gallery\" + 0.014*\"courtesy\" + 0.012*\"installation\" + 0.011*\"serpentine\" + 0.011*\"message\" + 0.010*\"jafa\" + 0.010*\"work\"\n",
      "2019-10-29 00:38:38,497 : INFO : topic #0 (0.100): 0.017*\"gallery\" + 0.016*\"courtesy\" + 0.015*\"art\" + 0.013*\"london\" + 0.011*\"message\" + 0.011*\"installation\" + 0.011*\"credit\" + 0.010*\"arthur\" + 0.010*\"serpentine\" + 0.009*\"jafa\"\n",
      "2019-10-29 00:38:38,500 : INFO : topic diff=0.810781, rho=1.000000\n",
      "2019-10-29 00:38:38,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:38,899 : INFO : built Dictionary(68 unique tokens: ['isaac', 'space', 'jaxa', 'time', 'module']...) from 5 documents (total 445 corpus positions)\n",
      "2019-10-29 00:38:38,900 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:38,901 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:38,902 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:38,904 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:38,905 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:38,943 : INFO : -6.704 per-word bound, 104.3 perplexity estimate based on a held-out corpus of 5 documents with 445 words\n",
      "2019-10-29 00:38:38,943 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:38,952 : INFO : topic #3 (0.100): 0.049*\"space\" + 0.044*\"ball\" + 0.035*\"drone\" + 0.028*\"japanese\" + 0.027*\"int\" + 0.024*\"fully\" + 0.024*\"communication\" + 0.023*\"earth\" + 0.023*\"bb\" + 0.023*\"war\"\n",
      "2019-10-29 00:38:38,953 : INFO : topic #9 (0.100): 0.041*\"space\" + 0.036*\"ball\" + 0.035*\"japanese\" + 0.031*\"drone\" + 0.027*\"int\" + 0.025*\"communication\" + 0.025*\"gravity\" + 0.022*\"bb\" + 0.022*\"fully\" + 0.021*\"zero\"\n",
      "2019-10-29 00:38:38,954 : INFO : topic #2 (0.100): 0.040*\"space\" + 0.039*\"ball\" + 0.033*\"int\" + 0.031*\"japanese\" + 0.031*\"drone\" + 0.024*\"astronaut\" + 0.024*\"war\" + 0.024*\"bb\" + 0.023*\"earth\" + 0.020*\"zero\"\n",
      "2019-10-29 00:38:38,956 : INFO : topic #8 (0.100): 0.043*\"ball\" + 0.042*\"space\" + 0.034*\"drone\" + 0.028*\"int\" + 0.025*\"japanese\" + 0.024*\"earth\" + 0.022*\"gravity\" + 0.022*\"star\" + 0.021*\"war\" + 0.021*\"fully\"\n",
      "2019-10-29 00:38:38,958 : INFO : topic #0 (0.100): 0.041*\"space\" + 0.034*\"int\" + 0.031*\"drone\" + 0.030*\"japanese\" + 0.029*\"ball\" + 0.023*\"earth\" + 0.023*\"bb\" + 0.022*\"star\" + 0.021*\"communication\" + 0.021*\"gravity\"\n",
      "2019-10-29 00:38:38,959 : INFO : topic diff=0.732317, rho=1.000000\n",
      "2019-10-29 00:38:39,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:39,392 : INFO : built Dictionary(477 unique tokens: ['previously', 'person', 'party', 'concern', 'regime']...) from 5 documents (total 4230 corpus positions)\n",
      "2019-10-29 00:38:39,397 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:39,399 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:39,406 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:39,410 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:39,413 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:39,562 : INFO : -7.984 per-word bound, 253.2 perplexity estimate based on a held-out corpus of 5 documents with 4230 words\n",
      "2019-10-29 00:38:39,564 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:39,572 : INFO : topic #9 (0.100): 0.029*\"kim\" + 0.027*\"u\" + 0.024*\"north\" + 0.021*\"said\" + 0.017*\"korea\" + 0.014*\"lee\" + 0.012*\"regime\" + 0.010*\"korean\" + 0.009*\"military\" + 0.009*\"state\"\n",
      "2019-10-29 00:38:39,574 : INFO : topic #2 (0.100): 0.030*\"kim\" + 0.028*\"north\" + 0.024*\"u\" + 0.022*\"said\" + 0.022*\"korea\" + 0.019*\"lee\" + 0.011*\"un\" + 0.011*\"nuclear\" + 0.010*\"korean\" + 0.009*\"state\"\n",
      "2019-10-29 00:38:39,576 : INFO : topic #1 (0.100): 0.028*\"u\" + 0.026*\"kim\" + 0.022*\"said\" + 0.021*\"korea\" + 0.017*\"north\" + 0.014*\"lee\" + 0.012*\"regime\" + 0.011*\"state\" + 0.010*\"jong\" + 0.009*\"korean\"\n",
      "2019-10-29 00:38:39,578 : INFO : topic #3 (0.100): 0.029*\"north\" + 0.028*\"kim\" + 0.025*\"u\" + 0.022*\"said\" + 0.015*\"korea\" + 0.012*\"lee\" + 0.010*\"korean\" + 0.009*\"state\" + 0.009*\"regime\" + 0.009*\"jong\"\n",
      "2019-10-29 00:38:39,579 : INFO : topic #7 (0.100): 0.024*\"u\" + 0.023*\"kim\" + 0.022*\"korea\" + 0.022*\"north\" + 0.017*\"said\" + 0.013*\"lee\" + 0.012*\"nuclear\" + 0.010*\"long\" + 0.009*\"korean\" + 0.009*\"regime\"\n",
      "2019-10-29 00:38:39,581 : INFO : topic diff=0.942275, rho=1.000000\n",
      "2019-10-29 00:38:40,046 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:40,053 : INFO : built Dictionary(400 unique tokens: ['franco', 'violence', 'retrieve', 'mayor', 'clash']...) from 5 documents (total 7090 corpus positions)\n",
      "2019-10-29 00:38:40,060 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:40,062 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:40,063 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:40,066 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:40,067 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:40,189 : INFO : -7.165 per-word bound, 143.6 perplexity estimate based on a held-out corpus of 5 documents with 7090 words\n",
      "2019-10-29 00:38:40,190 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:40,199 : INFO : topic #5 (0.100): 0.033*\"spain\" + 0.033*\"october\" + 0.032*\"barcelona\" + 0.031*\"people\" + 0.028*\"referendum\" + 0.025*\"police\" + 0.021*\"catalan\" + 0.020*\"spanish\" + 0.017*\"independence\" + 0.016*\"said\"\n",
      "2019-10-29 00:38:40,201 : INFO : topic #9 (0.100): 0.033*\"barcelona\" + 0.032*\"catalan\" + 0.030*\"spain\" + 0.028*\"police\" + 0.025*\"independence\" + 0.023*\"october\" + 0.022*\"people\" + 0.016*\"referendum\" + 0.016*\"said\" + 0.015*\"spanish\"\n",
      "2019-10-29 00:38:40,203 : INFO : topic #8 (0.100): 0.035*\"october\" + 0.032*\"catalan\" + 0.030*\"barcelona\" + 0.026*\"people\" + 0.025*\"independence\" + 0.025*\"police\" + 0.024*\"spain\" + 0.019*\"referendum\" + 0.018*\"said\" + 0.017*\"station\"\n",
      "2019-10-29 00:38:40,205 : INFO : topic #4 (0.100): 0.037*\"catalan\" + 0.032*\"police\" + 0.029*\"october\" + 0.029*\"spain\" + 0.028*\"barcelona\" + 0.028*\"referendum\" + 0.022*\"people\" + 0.018*\"station\" + 0.018*\"polling\" + 0.016*\"independence\"\n",
      "2019-10-29 00:38:40,208 : INFO : topic #1 (0.100): 0.030*\"spain\" + 0.030*\"people\" + 0.029*\"referendum\" + 0.029*\"catalan\" + 0.028*\"police\" + 0.024*\"station\" + 0.023*\"october\" + 0.022*\"barcelona\" + 0.020*\"polling\" + 0.017*\"spanish\"\n",
      "2019-10-29 00:38:40,210 : INFO : topic diff=0.977116, rho=1.000000\n",
      "2019-10-29 00:38:40,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:40,611 : INFO : built Dictionary(261 unique tokens: ['product', 'sierra', 'size', 'genetically', 'come']...) from 5 documents (total 2140 corpus positions)\n",
      "2019-10-29 00:38:40,615 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:40,617 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:40,619 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:40,622 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:40,623 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:40,745 : INFO : -7.513 per-word bound, 182.7 perplexity estimate based on a held-out corpus of 5 documents with 2140 words\n",
      "2019-10-29 00:38:40,748 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:40,756 : INFO : topic #7 (0.100): 0.030*\"sapelo\" + 0.027*\"island\" + 0.027*\"pea\" + 0.026*\"red\" + 0.017*\"crop\" + 0.016*\"year\" + 0.016*\"dixon\" + 0.014*\"georgia\" + 0.013*\"said\" + 0.012*\"culture\"\n",
      "2019-10-29 00:38:40,759 : INFO : topic #4 (0.100): 0.041*\"pea\" + 0.037*\"sapelo\" + 0.035*\"island\" + 0.022*\"red\" + 0.016*\"year\" + 0.014*\"georgia\" + 0.012*\"crop\" + 0.012*\"dixon\" + 0.011*\"heirloom\" + 0.010*\"bailey\"\n",
      "2019-10-29 00:38:40,762 : INFO : topic #0 (0.100): 0.034*\"sapelo\" + 0.032*\"island\" + 0.024*\"pea\" + 0.021*\"red\" + 0.018*\"crop\" + 0.014*\"resident\" + 0.014*\"dixon\" + 0.013*\"georgia\" + 0.012*\"said\" + 0.012*\"bailey\"\n",
      "2019-10-29 00:38:40,765 : INFO : topic #6 (0.100): 0.030*\"pea\" + 0.026*\"sapelo\" + 0.024*\"island\" + 0.022*\"red\" + 0.015*\"georgia\" + 0.015*\"resident\" + 0.014*\"dixon\" + 0.014*\"crop\" + 0.012*\"year\" + 0.011*\"said\"\n",
      "2019-10-29 00:38:40,768 : INFO : topic #3 (0.100): 0.041*\"sapelo\" + 0.037*\"island\" + 0.025*\"pea\" + 0.021*\"red\" + 0.018*\"year\" + 0.018*\"crop\" + 0.016*\"dixon\" + 0.014*\"resident\" + 0.012*\"said\" + 0.011*\"bailey\"\n",
      "2019-10-29 00:38:40,771 : INFO : topic diff=0.876375, rho=1.000000\n",
      "2019-10-29 00:38:41,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:41,216 : INFO : built Dictionary(131 unique tokens: ['single', 'skeptical', 'come', 'bland', 'professor']...) from 5 documents (total 765 corpus positions)\n",
      "2019-10-29 00:38:41,218 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:41,219 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:41,221 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:41,224 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:41,225 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:41,278 : INFO : -7.472 per-word bound, 177.5 perplexity estimate based on a held-out corpus of 5 documents with 765 words\n",
      "2019-10-29 00:38:41,280 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:41,287 : INFO : topic #0 (0.100): 0.022*\"black\" + 0.021*\"national\" + 0.019*\"community\" + 0.015*\"street\" + 0.014*\"activist\" + 0.014*\"america\" + 0.013*\"medium\" + 0.013*\"name\" + 0.012*\"story\" + 0.012*\"disruptors\"\n",
      "2019-10-29 00:38:41,291 : INFO : topic #6 (0.100): 0.020*\"black\" + 0.019*\"community\" + 0.017*\"national\" + 0.016*\"activist\" + 0.015*\"social\" + 0.014*\"movement\" + 0.013*\"medium\" + 0.013*\"name\" + 0.013*\"change\" + 0.012*\"america\"\n",
      "2019-10-29 00:38:41,293 : INFO : topic #5 (0.100): 0.023*\"black\" + 0.020*\"community\" + 0.017*\"activist\" + 0.015*\"national\" + 0.014*\"america\" + 0.014*\"rallying\" + 0.014*\"name\" + 0.014*\"many\" + 0.014*\"street\" + 0.014*\"story\"\n",
      "2019-10-29 00:38:41,296 : INFO : topic #3 (0.100): 0.025*\"black\" + 0.022*\"activist\" + 0.017*\"community\" + 0.017*\"national\" + 0.014*\"change\" + 0.014*\"disruptors\" + 0.013*\"say\" + 0.012*\"rallying\" + 0.012*\"street\" + 0.011*\"candidate\"\n",
      "2019-10-29 00:38:41,299 : INFO : topic #7 (0.100): 0.024*\"black\" + 0.018*\"national\" + 0.016*\"change\" + 0.016*\"activist\" + 0.016*\"community\" + 0.015*\"rallying\" + 0.014*\"social\" + 0.012*\"say\" + 0.012*\"many\" + 0.011*\"medium\"\n",
      "2019-10-29 00:38:41,302 : INFO : topic diff=0.652514, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:41,684 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:41,685 : INFO : built Dictionary(35 unique tokens: ['story', 'business', 'see', 'cnn', 'get']...) from 5 documents (total 220 corpus positions)\n",
      "2019-10-29 00:38:41,687 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:41,688 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:41,690 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:41,692 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:41,693 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:41,719 : INFO : -6.307 per-word bound, 79.2 perplexity estimate based on a held-out corpus of 5 documents with 220 words\n",
      "2019-10-29 00:38:41,720 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:41,726 : INFO : topic #0 (0.100): 0.088*\"bachelor\" + 0.064*\"kraus\" + 0.053*\"peter\" + 0.049*\"franchise\" + 0.038*\"favorite\" + 0.034*\"coming\" + 0.028*\"highlight\" + 0.028*\"spinoff\" + 0.027*\"runner\" + 0.026*\"another\"\n",
      "2019-10-29 00:38:41,728 : INFO : topic #3 (0.100): 0.084*\"bachelor\" + 0.061*\"kraus\" + 0.051*\"franchise\" + 0.045*\"coming\" + 0.039*\"peter\" + 0.032*\"fan\" + 0.032*\"favorite\" + 0.031*\"hand\" + 0.030*\"read\" + 0.030*\"chance\"\n",
      "2019-10-29 00:38:41,731 : INFO : topic #5 (0.100): 0.085*\"kraus\" + 0.082*\"bachelor\" + 0.043*\"coming\" + 0.042*\"franchise\" + 0.040*\"peter\" + 0.029*\"jr\" + 0.028*\"luyendyk\" + 0.028*\"favorite\" + 0.028*\"story\" + 0.028*\"went\"\n",
      "2019-10-29 00:38:41,735 : INFO : topic #2 (0.100): 0.076*\"bachelor\" + 0.069*\"kraus\" + 0.047*\"favorite\" + 0.041*\"coming\" + 0.041*\"franchise\" + 0.032*\"peter\" + 0.031*\"chance\" + 0.030*\"instead\" + 0.029*\"bachlorette\" + 0.028*\"honor\"\n",
      "2019-10-29 00:38:41,737 : INFO : topic #7 (0.100): 0.072*\"kraus\" + 0.068*\"bachelor\" + 0.051*\"favorite\" + 0.051*\"franchise\" + 0.048*\"coming\" + 0.046*\"peter\" + 0.027*\"new\" + 0.027*\"hand\" + 0.026*\"read\" + 0.026*\"spinoff\"\n",
      "2019-10-29 00:38:41,739 : INFO : topic diff=0.716651, rho=1.000000\n",
      "2019-10-29 00:38:42,148 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:42,151 : INFO : built Dictionary(119 unique tokens: ['paris', 'commissioned', 'industry', 'home', 'get']...) from 5 documents (total 910 corpus positions)\n",
      "2019-10-29 00:38:42,154 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:42,156 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:42,158 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:42,162 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:42,165 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:42,222 : INFO : -6.902 per-word bound, 119.6 perplexity estimate based on a held-out corpus of 5 documents with 910 words\n",
      "2019-10-29 00:38:42,223 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:42,229 : INFO : topic #8 (0.100): 0.056*\"gold\" + 0.035*\"swiss\" + 0.027*\"water\" + 0.020*\"waste\" + 0.020*\"sewage\" + 0.019*\"year\" + 0.019*\"silver\" + 0.017*\"found\" + 0.017*\"scientist\" + 0.017*\"worth\"\n",
      "2019-10-29 00:38:42,231 : INFO : topic #6 (0.100): 0.046*\"gold\" + 0.041*\"swiss\" + 0.027*\"water\" + 0.026*\"waste\" + 0.022*\"sewage\" + 0.020*\"flushed\" + 0.018*\"researcher\" + 0.018*\"million\" + 0.015*\"worth\" + 0.014*\"year\"\n",
      "2019-10-29 00:38:42,234 : INFO : topic #5 (0.100): 0.066*\"gold\" + 0.031*\"swiss\" + 0.028*\"water\" + 0.024*\"waste\" + 0.019*\"sewage\" + 0.018*\"found\" + 0.017*\"worth\" + 0.015*\"price\" + 0.015*\"researcher\" + 0.014*\"flushed\"\n",
      "2019-10-29 00:38:42,237 : INFO : topic #3 (0.100): 0.059*\"gold\" + 0.040*\"swiss\" + 0.026*\"water\" + 0.021*\"million\" + 0.020*\"sewage\" + 0.020*\"flushed\" + 0.019*\"year\" + 0.019*\"waste\" + 0.016*\"scientist\" + 0.015*\"worth\"\n",
      "2019-10-29 00:38:42,239 : INFO : topic #7 (0.100): 0.063*\"gold\" + 0.037*\"swiss\" + 0.028*\"waste\" + 0.027*\"water\" + 0.020*\"scientist\" + 0.019*\"million\" + 0.019*\"sewage\" + 0.016*\"found\" + 0.016*\"year\" + 0.014*\"researcher\"\n",
      "2019-10-29 00:38:42,241 : INFO : topic diff=0.814603, rho=1.000000\n",
      "2019-10-29 00:38:42,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:42,664 : INFO : built Dictionary(418 unique tokens: ['previously', 'real', 'place', 'veracity', 'troll']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:38:42,670 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:42,672 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:42,676 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:42,681 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:42,684 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:42,824 : INFO : -7.989 per-word bound, 254.1 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:38:42,826 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:42,833 : INFO : topic #0 (0.100): 0.018*\"company\" + 0.017*\"information\" + 0.015*\"content\" + 0.015*\"user\" + 0.013*\"tech\" + 0.012*\"platform\" + 0.010*\"need\" + 0.010*\"facebook\" + 0.010*\"u\" + 0.010*\"medium\"\n",
      "2019-10-29 00:38:42,835 : INFO : topic #2 (0.100): 0.018*\"information\" + 0.017*\"company\" + 0.016*\"platform\" + 0.014*\"medium\" + 0.014*\"facebook\" + 0.013*\"need\" + 0.013*\"content\" + 0.012*\"tech\" + 0.011*\"user\" + 0.011*\"google\"\n",
      "2019-10-29 00:38:42,837 : INFO : topic #9 (0.100): 0.016*\"company\" + 0.014*\"medium\" + 0.014*\"facebook\" + 0.014*\"user\" + 0.014*\"information\" + 0.014*\"platform\" + 0.012*\"google\" + 0.011*\"content\" + 0.010*\"need\" + 0.010*\"tech\"\n",
      "2019-10-29 00:38:42,840 : INFO : topic #6 (0.100): 0.016*\"content\" + 0.016*\"user\" + 0.015*\"information\" + 0.014*\"medium\" + 0.014*\"company\" + 0.013*\"platform\" + 0.012*\"attention\" + 0.011*\"social\" + 0.011*\"tech\" + 0.011*\"facebook\"\n",
      "2019-10-29 00:38:42,843 : INFO : topic #4 (0.100): 0.019*\"information\" + 0.017*\"company\" + 0.013*\"need\" + 0.013*\"user\" + 0.013*\"facebook\" + 0.012*\"content\" + 0.012*\"medium\" + 0.011*\"u\" + 0.011*\"platform\" + 0.011*\"tech\"\n",
      "2019-10-29 00:38:42,845 : INFO : topic diff=0.882918, rho=1.000000\n",
      "2019-10-29 00:38:43,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:43,253 : INFO : built Dictionary(118 unique tokens: ['online', 'adhered', 'bone', 'relatively', 'side']...) from 5 documents (total 860 corpus positions)\n",
      "2019-10-29 00:38:43,256 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:43,257 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:43,259 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:43,262 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:43,264 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:43,323 : INFO : -6.971 per-word bound, 125.4 perplexity estimate based on a held-out corpus of 5 documents with 860 words\n",
      "2019-10-29 00:38:43,325 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:43,331 : INFO : topic #2 (0.100): 0.064*\"diet\" + 0.034*\"woman\" + 0.034*\"study\" + 0.034*\"mediterranean\" + 0.029*\"fracture\" + 0.022*\"hip\" + 0.020*\"health\" + 0.020*\"researcher\" + 0.020*\"bone\" + 0.012*\"healthy\"\n",
      "2019-10-29 00:38:43,334 : INFO : topic #8 (0.100): 0.076*\"diet\" + 0.054*\"mediterranean\" + 0.036*\"woman\" + 0.033*\"study\" + 0.024*\"health\" + 0.022*\"hip\" + 0.018*\"fracture\" + 0.017*\"researcher\" + 0.016*\"bone\" + 0.014*\"dietary\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:43,337 : INFO : topic #9 (0.100): 0.056*\"diet\" + 0.039*\"woman\" + 0.038*\"mediterranean\" + 0.031*\"study\" + 0.028*\"bone\" + 0.026*\"fracture\" + 0.022*\"hip\" + 0.019*\"health\" + 0.014*\"researcher\" + 0.013*\"le\"\n",
      "2019-10-29 00:38:43,340 : INFO : topic #7 (0.100): 0.086*\"diet\" + 0.032*\"woman\" + 0.030*\"study\" + 0.028*\"mediterranean\" + 0.028*\"fracture\" + 0.024*\"health\" + 0.022*\"bone\" + 0.019*\"hip\" + 0.017*\"researcher\" + 0.013*\"healthy\"\n",
      "2019-10-29 00:38:43,342 : INFO : topic #6 (0.100): 0.058*\"diet\" + 0.034*\"mediterranean\" + 0.032*\"woman\" + 0.032*\"study\" + 0.028*\"fracture\" + 0.026*\"hip\" + 0.026*\"health\" + 0.019*\"bone\" + 0.015*\"researcher\" + 0.014*\"case\"\n",
      "2019-10-29 00:38:43,344 : INFO : topic diff=0.858375, rho=1.000000\n",
      "2019-10-29 00:38:43,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:43,801 : INFO : built Dictionary(298 unique tokens: ['violence', 'even', 'single', 'book', 'campaign']...) from 5 documents (total 1975 corpus positions)\n",
      "2019-10-29 00:38:43,804 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:43,807 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:43,810 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:43,814 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:43,816 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:43,947 : INFO : -7.975 per-word bound, 251.7 perplexity estimate based on a held-out corpus of 5 documents with 1975 words\n",
      "2019-10-29 00:38:43,950 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:43,959 : INFO : topic #3 (0.100): 0.023*\"sirleaf\" + 0.016*\"country\" + 0.015*\"liberia\" + 0.011*\"world\" + 0.011*\"africa\" + 0.010*\"year\" + 0.010*\"leader\" + 0.009*\"first\" + 0.009*\"major\" + 0.009*\"peace\"\n",
      "2019-10-29 00:38:43,962 : INFO : topic #4 (0.100): 0.019*\"sirleaf\" + 0.016*\"country\" + 0.012*\"liberia\" + 0.011*\"first\" + 0.011*\"peace\" + 0.011*\"africa\" + 0.011*\"leader\" + 0.008*\"year\" + 0.008*\"major\" + 0.008*\"population\"\n",
      "2019-10-29 00:38:43,966 : INFO : topic #1 (0.100): 0.025*\"sirleaf\" + 0.015*\"country\" + 0.014*\"liberia\" + 0.012*\"leader\" + 0.010*\"peace\" + 0.010*\"year\" + 0.010*\"africa\" + 0.010*\"world\" + 0.009*\"iron\" + 0.008*\"population\"\n",
      "2019-10-29 00:38:43,969 : INFO : topic #7 (0.100): 0.019*\"sirleaf\" + 0.012*\"country\" + 0.012*\"liberia\" + 0.011*\"major\" + 0.010*\"leader\" + 0.010*\"world\" + 0.010*\"africa\" + 0.010*\"first\" + 0.009*\"year\" + 0.009*\"peace\"\n",
      "2019-10-29 00:38:43,972 : INFO : topic #8 (0.100): 0.015*\"sirleaf\" + 0.013*\"liberia\" + 0.013*\"leader\" + 0.012*\"country\" + 0.011*\"peace\" + 0.010*\"year\" + 0.010*\"major\" + 0.010*\"first\" + 0.010*\"africa\" + 0.008*\"world\"\n",
      "2019-10-29 00:38:43,976 : INFO : topic diff=0.748967, rho=1.000000\n",
      "2019-10-29 00:38:44,407 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:44,412 : INFO : built Dictionary(317 unique tokens: ['extensive', 'employing', 'wave', 'across', 'size']...) from 5 documents (total 2730 corpus positions)\n",
      "2019-10-29 00:38:44,416 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:44,418 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:44,419 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:44,427 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:44,430 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:44,542 : INFO : -7.630 per-word bound, 198.1 perplexity estimate based on a held-out corpus of 5 documents with 2730 words\n",
      "2019-10-29 00:38:44,544 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:44,552 : INFO : topic #9 (0.100): 0.034*\"wave\" + 0.033*\"gravitational\" + 0.019*\"detector\" + 0.016*\"mass\" + 0.015*\"ligo\" + 0.014*\"hole\" + 0.014*\"black\" + 0.011*\"virgo\" + 0.011*\"time\" + 0.010*\"scientist\"\n",
      "2019-10-29 00:38:44,553 : INFO : topic #7 (0.100): 0.027*\"detector\" + 0.024*\"black\" + 0.023*\"gravitational\" + 0.022*\"wave\" + 0.021*\"hole\" + 0.019*\"mass\" + 0.014*\"ligo\" + 0.013*\"scientist\" + 0.013*\"two\" + 0.012*\"virgo\"\n",
      "2019-10-29 00:38:44,555 : INFO : topic #8 (0.100): 0.038*\"gravitational\" + 0.023*\"hole\" + 0.021*\"black\" + 0.019*\"detector\" + 0.019*\"mass\" + 0.018*\"wave\" + 0.015*\"scientist\" + 0.012*\"observation\" + 0.012*\"ligo\" + 0.011*\"two\"\n",
      "2019-10-29 00:38:44,557 : INFO : topic #4 (0.100): 0.033*\"gravitational\" + 0.025*\"wave\" + 0.025*\"detector\" + 0.020*\"hole\" + 0.018*\"black\" + 0.018*\"ligo\" + 0.015*\"mass\" + 0.010*\"observation\" + 0.010*\"two\" + 0.009*\"first\"\n",
      "2019-10-29 00:38:44,558 : INFO : topic #1 (0.100): 0.034*\"gravitational\" + 0.034*\"wave\" + 0.023*\"detector\" + 0.020*\"mass\" + 0.020*\"black\" + 0.019*\"hole\" + 0.014*\"ligo\" + 0.012*\"two\" + 0.012*\"virgo\" + 0.010*\"telescope\"\n",
      "2019-10-29 00:38:44,561 : INFO : topic diff=0.881875, rho=1.000000\n",
      "2019-10-29 00:38:44,963 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:44,965 : INFO : built Dictionary(154 unique tokens: ['harsh', 'supposed', 'recently', 'nation', 'come']...) from 5 documents (total 1075 corpus positions)\n",
      "2019-10-29 00:38:44,967 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:44,970 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:44,971 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:44,973 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:44,975 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:45,044 : INFO : -7.279 per-word bound, 155.3 perplexity estimate based on a held-out corpus of 5 documents with 1075 words\n",
      "2019-10-29 00:38:45,045 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:45,050 : INFO : topic #9 (0.100): 0.030*\"cummings\" + 0.022*\"wjz\" + 0.021*\"say\" + 0.021*\"said\" + 0.020*\"hospital\" + 0.017*\"tell\" + 0.016*\"medical\" + 0.016*\"vic\" + 0.016*\"know\" + 0.015*\"wanted\"\n",
      "2019-10-29 00:38:45,052 : INFO : topic #8 (0.100): 0.039*\"cummings\" + 0.022*\"tell\" + 0.021*\"said\" + 0.021*\"wjz\" + 0.018*\"medical\" + 0.017*\"say\" + 0.016*\"hospital\" + 0.016*\"vic\" + 0.015*\"going\" + 0.015*\"wanted\"\n",
      "2019-10-29 00:38:45,054 : INFO : topic #7 (0.100): 0.038*\"cummings\" + 0.022*\"wjz\" + 0.022*\"tell\" + 0.019*\"said\" + 0.017*\"vic\" + 0.017*\"hospital\" + 0.016*\"say\" + 0.015*\"medical\" + 0.014*\"came\" + 0.014*\"know\"\n",
      "2019-10-29 00:38:45,056 : INFO : topic #2 (0.100): 0.040*\"cummings\" + 0.023*\"said\" + 0.020*\"medical\" + 0.019*\"wjz\" + 0.019*\"vic\" + 0.018*\"say\" + 0.017*\"hospital\" + 0.017*\"tell\" + 0.016*\"lady\" + 0.014*\"much\"\n",
      "2019-10-29 00:38:45,058 : INFO : topic #1 (0.100): 0.039*\"cummings\" + 0.025*\"said\" + 0.023*\"vic\" + 0.022*\"tell\" + 0.022*\"wjz\" + 0.017*\"say\" + 0.016*\"medical\" + 0.015*\"hospital\" + 0.015*\"wanted\" + 0.013*\"came\"\n",
      "2019-10-29 00:38:45,060 : INFO : topic diff=0.795829, rho=1.000000\n",
      "2019-10-29 00:38:45,441 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:45,443 : INFO : built Dictionary(50 unique tokens: ['administration', 'previously', 'arrival', 'party', 'daughter']...) from 5 documents (total 405 corpus positions)\n",
      "2019-10-29 00:38:45,445 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:45,447 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:45,448 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:45,450 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:45,451 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:45,478 : INFO : -6.088 per-word bound, 68.0 perplexity estimate based on a held-out corpus of 5 documents with 405 words\n",
      "2019-10-29 00:38:45,479 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:45,485 : INFO : topic #4 (0.100): 0.098*\"house\" + 0.082*\"white\" + 0.054*\"secretary\" + 0.044*\"press\" + 0.039*\"gidley\" + 0.029*\"former\" + 0.027*\"spicer\" + 0.026*\"joining\" + 0.025*\"cnn\" + 0.024*\"huckabee\"\n",
      "2019-10-29 00:38:45,486 : INFO : topic #1 (0.100): 0.101*\"house\" + 0.071*\"white\" + 0.046*\"press\" + 0.043*\"gidley\" + 0.040*\"secretary\" + 0.033*\"former\" + 0.030*\"huckabee\" + 0.026*\"sander\" + 0.025*\"cnn\" + 0.023*\"spicer\"\n",
      "2019-10-29 00:38:45,492 : INFO : topic #3 (0.100): 0.115*\"white\" + 0.057*\"secretary\" + 0.056*\"house\" + 0.055*\"press\" + 0.043*\"gidley\" + 0.024*\"joining\" + 0.023*\"former\" + 0.023*\"cnn\" + 0.023*\"director\" + 0.023*\"hogan\"\n",
      "2019-10-29 00:38:45,494 : INFO : topic #8 (0.100): 0.087*\"white\" + 0.074*\"house\" + 0.053*\"gidley\" + 0.045*\"secretary\" + 0.044*\"press\" + 0.029*\"hogan\" + 0.027*\"cnn\" + 0.027*\"sander\" + 0.026*\"director\" + 0.026*\"spicer\"\n",
      "2019-10-29 00:38:45,497 : INFO : topic #6 (0.100): 0.091*\"house\" + 0.066*\"white\" + 0.060*\"gidley\" + 0.047*\"press\" + 0.047*\"secretary\" + 0.030*\"joining\" + 0.026*\"former\" + 0.025*\"director\" + 0.025*\"sander\" + 0.023*\"huckabee\"\n",
      "2019-10-29 00:38:45,500 : INFO : topic diff=0.873733, rho=1.000000\n",
      "2019-10-29 00:38:45,915 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:45,921 : INFO : built Dictionary(410 unique tokens: ['energy', 'advantage', 'prime', 'expert', 'supported']...) from 5 documents (total 3635 corpus positions)\n",
      "2019-10-29 00:38:45,926 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:45,928 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:45,929 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:45,932 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:45,933 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:46,057 : INFO : -7.843 per-word bound, 229.7 perplexity estimate based on a held-out corpus of 5 documents with 3635 words\n",
      "2019-10-29 00:38:46,059 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:46,066 : INFO : topic #9 (0.100): 0.030*\"hour\" + 0.030*\"day\" + 0.020*\"work\" + 0.020*\"four\" + 0.016*\"working\" + 0.015*\"employee\" + 0.015*\"many\" + 0.014*\"workweek\" + 0.014*\"schedule\" + 0.011*\"time\"\n",
      "2019-10-29 00:38:46,069 : INFO : topic #6 (0.100): 0.033*\"hour\" + 0.032*\"day\" + 0.025*\"four\" + 0.020*\"work\" + 0.018*\"working\" + 0.015*\"schedule\" + 0.014*\"employee\" + 0.013*\"time\" + 0.011*\"workweek\" + 0.010*\"risk\"\n",
      "2019-10-29 00:38:46,072 : INFO : topic #1 (0.100): 0.034*\"day\" + 0.032*\"work\" + 0.028*\"hour\" + 0.021*\"four\" + 0.018*\"working\" + 0.017*\"schedule\" + 0.015*\"employee\" + 0.014*\"workweek\" + 0.009*\"week\" + 0.009*\"risk\"\n",
      "2019-10-29 00:38:46,074 : INFO : topic #7 (0.100): 0.040*\"day\" + 0.036*\"hour\" + 0.021*\"schedule\" + 0.020*\"work\" + 0.019*\"four\" + 0.018*\"working\" + 0.017*\"employee\" + 0.014*\"time\" + 0.012*\"week\" + 0.012*\"workweek\"\n",
      "2019-10-29 00:38:46,076 : INFO : topic #0 (0.100): 0.033*\"hour\" + 0.026*\"four\" + 0.025*\"day\" + 0.021*\"work\" + 0.019*\"working\" + 0.015*\"schedule\" + 0.014*\"employee\" + 0.012*\"time\" + 0.011*\"workweek\" + 0.011*\"health\"\n",
      "2019-10-29 00:38:46,078 : INFO : topic diff=0.950030, rho=1.000000\n",
      "2019-10-29 00:38:46,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:46,492 : INFO : built Dictionary(387 unique tokens: ['mirrored', 'let', 'energy', 'happy', 'party']...) from 5 documents (total 2990 corpus positions)\n",
      "2019-10-29 00:38:46,496 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:46,497 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:46,499 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:46,503 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:46,504 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:46,616 : INFO : -7.973 per-word bound, 251.3 perplexity estimate based on a held-out corpus of 5 documents with 2990 words\n",
      "2019-10-29 00:38:46,618 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:46,626 : INFO : topic #8 (0.100): 0.036*\"show\" + 0.021*\"de\" + 0.021*\"fashion\" + 0.020*\"betak\" + 0.018*\"paris\" + 0.015*\"production\" + 0.012*\"new\" + 0.010*\"rodarte\" + 0.009*\"mulleavy\" + 0.007*\"around\"\n",
      "2019-10-29 00:38:46,629 : INFO : topic #2 (0.100): 0.039*\"show\" + 0.027*\"betak\" + 0.021*\"de\" + 0.019*\"fashion\" + 0.012*\"paris\" + 0.010*\"rodarte\" + 0.009*\"production\" + 0.009*\"mulleavy\" + 0.009*\"new\" + 0.009*\"big\"\n",
      "2019-10-29 00:38:46,631 : INFO : topic #0 (0.100): 0.030*\"show\" + 0.025*\"de\" + 0.024*\"betak\" + 0.021*\"fashion\" + 0.014*\"production\" + 0.014*\"paris\" + 0.010*\"new\" + 0.008*\"big\" + 0.008*\"rodarte\" + 0.008*\"year\"\n",
      "2019-10-29 00:38:46,633 : INFO : topic #6 (0.100): 0.040*\"show\" + 0.029*\"fashion\" + 0.028*\"de\" + 0.021*\"betak\" + 0.012*\"production\" + 0.011*\"paris\" + 0.011*\"new\" + 0.009*\"mulleavy\" + 0.009*\"rodarte\" + 0.008*\"time\"\n",
      "2019-10-29 00:38:46,634 : INFO : topic #9 (0.100): 0.032*\"betak\" + 0.027*\"fashion\" + 0.026*\"de\" + 0.019*\"show\" + 0.016*\"paris\" + 0.011*\"production\" + 0.009*\"mulleavy\" + 0.009*\"new\" + 0.008*\"designer\" + 0.008*\"big\"\n",
      "2019-10-29 00:38:46,637 : INFO : topic diff=0.844860, rho=1.000000\n",
      "2019-10-29 00:38:47,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:47,107 : INFO : built Dictionary(346 unique tokens: ['reluctant', 'school', 'expert', 'label', 'new']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:38:47,115 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:47,118 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:47,120 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:47,124 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:47,126 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:47,308 : INFO : -7.566 per-word bound, 189.5 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:38:47,310 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:47,320 : INFO : topic #3 (0.100): 0.032*\"child\" + 0.028*\"parent\" + 0.028*\"said\" + 0.019*\"kazdin\" + 0.019*\"get\" + 0.017*\"say\" + 0.014*\"behavior\" + 0.011*\"way\" + 0.011*\"defiant\" + 0.010*\"praise\"\n",
      "2019-10-29 00:38:47,324 : INFO : topic #2 (0.100): 0.043*\"child\" + 0.034*\"said\" + 0.025*\"parent\" + 0.019*\"get\" + 0.017*\"say\" + 0.016*\"kazdin\" + 0.014*\"behavior\" + 0.011*\"put\" + 0.011*\"way\" + 0.010*\"daughter\"\n",
      "2019-10-29 00:38:47,327 : INFO : topic #4 (0.100): 0.038*\"child\" + 0.024*\"parent\" + 0.021*\"kazdin\" + 0.020*\"said\" + 0.019*\"say\" + 0.019*\"behavior\" + 0.015*\"defiant\" + 0.013*\"get\" + 0.011*\"way\" + 0.010*\"put\"\n",
      "2019-10-29 00:38:47,331 : INFO : topic #0 (0.100): 0.034*\"child\" + 0.030*\"said\" + 0.022*\"behavior\" + 0.020*\"kazdin\" + 0.019*\"parent\" + 0.018*\"say\" + 0.016*\"get\" + 0.013*\"defiant\" + 0.011*\"estes\" + 0.011*\"parenting\"\n",
      "2019-10-29 00:38:47,334 : INFO : topic #9 (0.100): 0.031*\"said\" + 0.029*\"child\" + 0.025*\"parent\" + 0.021*\"say\" + 0.021*\"kazdin\" + 0.018*\"get\" + 0.012*\"behavior\" + 0.010*\"choice\" + 0.010*\"way\" + 0.010*\"put\"\n",
      "2019-10-29 00:38:47,337 : INFO : topic diff=0.944516, rho=1.000000\n",
      "2019-10-29 00:38:47,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:47,749 : INFO : built Dictionary(53 unique tokens: ['beat', 'rico', 'friend', 'loud', 'clock']...) from 5 documents (total 335 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:47,750 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:47,753 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:47,755 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:47,757 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:47,758 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:47,786 : INFO : -6.578 per-word bound, 95.5 perplexity estimate based on a held-out corpus of 5 documents with 335 words\n",
      "2019-10-29 00:38:47,787 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:47,796 : INFO : topic #0 (0.100): 0.050*\"puerto\" + 0.040*\"rico\" + 0.037*\"miranda\" + 0.036*\"praying\" + 0.036*\"song\" + 0.030*\"manuel\" + 0.029*\"like\" + 0.027*\"almost\" + 0.025*\"say\" + 0.021*\"lin\"\n",
      "2019-10-29 00:38:47,799 : INFO : topic #6 (0.100): 0.050*\"rico\" + 0.042*\"puerto\" + 0.038*\"song\" + 0.035*\"miranda\" + 0.029*\"like\" + 0.028*\"praying\" + 0.025*\"lin\" + 0.025*\"almost\" + 0.021*\"say\" + 0.021*\"manuel\"\n",
      "2019-10-29 00:38:47,801 : INFO : topic #3 (0.100): 0.046*\"song\" + 0.040*\"miranda\" + 0.039*\"rico\" + 0.031*\"almost\" + 0.030*\"like\" + 0.030*\"manuel\" + 0.030*\"puerto\" + 0.025*\"say\" + 0.025*\"praying\" + 0.023*\"lin\"\n",
      "2019-10-29 00:38:47,803 : INFO : topic #2 (0.100): 0.052*\"song\" + 0.047*\"rico\" + 0.043*\"puerto\" + 0.040*\"miranda\" + 0.033*\"praying\" + 0.031*\"lin\" + 0.029*\"say\" + 0.028*\"manuel\" + 0.026*\"like\" + 0.024*\"almost\"\n",
      "2019-10-29 00:38:47,806 : INFO : topic #9 (0.100): 0.041*\"rico\" + 0.038*\"like\" + 0.036*\"lin\" + 0.034*\"puerto\" + 0.034*\"song\" + 0.030*\"almost\" + 0.029*\"say\" + 0.028*\"miranda\" + 0.026*\"manuel\" + 0.022*\"praying\"\n",
      "2019-10-29 00:38:47,810 : INFO : topic diff=0.701870, rho=1.000000\n",
      "2019-10-29 00:38:48,215 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:48,219 : INFO : built Dictionary(214 unique tokens: ['let', 'harsh', 'person', 'deep', 'come']...) from 5 documents (total 1590 corpus positions)\n",
      "2019-10-29 00:38:48,221 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:48,223 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:48,225 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:48,228 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:48,229 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:48,305 : INFO : -7.482 per-word bound, 178.7 perplexity estimate based on a held-out corpus of 5 documents with 1590 words\n",
      "2019-10-29 00:38:48,307 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:48,314 : INFO : topic #4 (0.100): 0.050*\"iq\" + 0.040*\"realdonaldtrump\" + 0.022*\"may\" + 0.019*\"much\" + 0.017*\"test\" + 0.017*\"higher\" + 0.015*\"think\" + 0.013*\"april\" + 0.012*\"trump\" + 0.012*\"q\"\n",
      "2019-10-29 00:38:48,317 : INFO : topic #8 (0.100): 0.054*\"iq\" + 0.034*\"realdonaldtrump\" + 0.027*\"much\" + 0.026*\"may\" + 0.019*\"think\" + 0.018*\"higher\" + 0.018*\"q\" + 0.014*\"trump\" + 0.014*\"test\" + 0.013*\"know\"\n",
      "2019-10-29 00:38:48,318 : INFO : topic #7 (0.100): 0.074*\"iq\" + 0.038*\"realdonaldtrump\" + 0.023*\"trump\" + 0.022*\"may\" + 0.017*\"much\" + 0.016*\"higher\" + 0.015*\"think\" + 0.014*\"q\" + 0.013*\"test\" + 0.013*\"april\"\n",
      "2019-10-29 00:38:48,322 : INFO : topic #5 (0.100): 0.055*\"iq\" + 0.030*\"may\" + 0.028*\"realdonaldtrump\" + 0.023*\"much\" + 0.018*\"higher\" + 0.016*\"test\" + 0.013*\"q\" + 0.013*\"trump\" + 0.013*\"think\" + 0.012*\"know\"\n",
      "2019-10-29 00:38:48,325 : INFO : topic #2 (0.100): 0.069*\"iq\" + 0.026*\"may\" + 0.024*\"realdonaldtrump\" + 0.023*\"much\" + 0.020*\"trump\" + 0.018*\"higher\" + 0.016*\"q\" + 0.012*\"test\" + 0.012*\"know\" + 0.012*\"think\"\n",
      "2019-10-29 00:38:48,328 : INFO : topic diff=0.865980, rho=1.000000\n",
      "2019-10-29 00:38:48,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:48,840 : INFO : built Dictionary(791 unique tokens: ['let', 'fultz', 'fide', 'focus', 'protector']...) from 5 documents (total 6705 corpus positions)\n",
      "2019-10-29 00:38:48,847 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:48,848 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:48,853 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:48,859 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:48,862 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:49,091 : INFO : -8.532 per-word bound, 370.2 perplexity estimate based on a held-out corpus of 5 documents with 6705 words\n",
      "2019-10-29 00:38:49,093 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:49,106 : INFO : topic #2 (0.100): 0.029*\"simmons\" + 0.016*\"ben\" + 0.011*\"one\" + 0.010*\"sixer\" + 0.010*\"sean\" + 0.009*\"say\" + 0.008*\"game\" + 0.007*\"like\" + 0.007*\"would\" + 0.007*\"season\"\n",
      "2019-10-29 00:38:49,107 : INFO : topic #9 (0.100): 0.024*\"simmons\" + 0.012*\"ben\" + 0.011*\"say\" + 0.010*\"game\" + 0.009*\"like\" + 0.009*\"one\" + 0.008*\"would\" + 0.008*\"sixer\" + 0.007*\"sean\" + 0.006*\"brown\"\n",
      "2019-10-29 00:38:49,108 : INFO : topic #8 (0.100): 0.021*\"simmons\" + 0.020*\"ben\" + 0.012*\"game\" + 0.011*\"say\" + 0.010*\"one\" + 0.009*\"sean\" + 0.008*\"sixer\" + 0.007*\"would\" + 0.007*\"like\" + 0.006*\"r\"\n",
      "2019-10-29 00:38:49,109 : INFO : topic #7 (0.100): 0.028*\"simmons\" + 0.026*\"ben\" + 0.012*\"say\" + 0.009*\"one\" + 0.008*\"game\" + 0.008*\"sean\" + 0.007*\"season\" + 0.007*\"time\" + 0.006*\"like\" + 0.006*\"would\"\n",
      "2019-10-29 00:38:49,111 : INFO : topic #1 (0.100): 0.025*\"simmons\" + 0.016*\"ben\" + 0.014*\"say\" + 0.009*\"game\" + 0.009*\"sean\" + 0.008*\"one\" + 0.008*\"would\" + 0.008*\"brown\" + 0.007*\"season\" + 0.007*\"sixer\"\n",
      "2019-10-29 00:38:49,114 : INFO : topic diff=0.899052, rho=1.000000\n",
      "2019-10-29 00:38:49,501 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:49,502 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:38:49,504 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:49,505 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:49,507 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:49,509 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:49,510 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:49,527 : INFO : -6.051 per-word bound, 66.3 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:38:49,529 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:49,534 : INFO : topic #2 (0.100): 0.146*\"transcript\" + 0.059*\"note\" + 0.053*\"cnn\" + 0.052*\"october\" + 0.050*\"become\" + 0.049*\"check\" + 0.049*\"new\" + 0.048*\"cannot\" + 0.048*\"page\" + 0.047*\"continually\"\n",
      "2019-10-29 00:38:49,537 : INFO : topic #1 (0.100): 0.125*\"transcript\" + 0.079*\"page\" + 0.059*\"later\" + 0.057*\"return\" + 0.055*\"become\" + 0.051*\"find\" + 0.050*\"note\" + 0.046*\"new\" + 0.045*\"cnn\" + 0.045*\"updated\"\n",
      "2019-10-29 00:38:49,538 : INFO : topic #5 (0.100): 0.177*\"transcript\" + 0.104*\"page\" + 0.053*\"main\" + 0.052*\"later\" + 0.045*\"specific\" + 0.044*\"cnn\" + 0.044*\"segment\" + 0.044*\"become\" + 0.044*\"note\" + 0.044*\"updated\"\n",
      "2019-10-29 00:38:49,539 : INFO : topic #9 (0.100): 0.193*\"transcript\" + 0.067*\"page\" + 0.053*\"main\" + 0.051*\"back\" + 0.050*\"specific\" + 0.049*\"cannot\" + 0.049*\"return\" + 0.048*\"find\" + 0.046*\"check\" + 0.045*\"become\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:49,540 : INFO : topic #4 (0.100): 0.145*\"transcript\" + 0.079*\"page\" + 0.057*\"segment\" + 0.056*\"check\" + 0.050*\"continually\" + 0.050*\"available\" + 0.048*\"october\" + 0.047*\"return\" + 0.046*\"find\" + 0.046*\"back\"\n",
      "2019-10-29 00:38:49,541 : INFO : topic diff=0.718285, rho=1.000000\n",
      "2019-10-29 00:38:49,928 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:49,929 : INFO : built Dictionary(16 unique tokens: ['agree', 'privacy', 'policy', 'havana', 'continuing']...) from 5 documents (total 85 corpus positions)\n",
      "2019-10-29 00:38:49,930 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:49,931 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:49,933 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:49,935 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:49,936 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:49,948 : INFO : -6.298 per-word bound, 78.7 perplexity estimate based on a held-out corpus of 5 documents with 85 words\n",
      "2019-10-29 00:38:49,950 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:49,955 : INFO : topic #1 (0.100): 0.111*\"cooky\" + 0.076*\"agree\" + 0.065*\"term\" + 0.064*\"service\" + 0.064*\"beyond\" + 0.064*\"havana\" + 0.063*\"site\" + 0.062*\"photo\" + 0.061*\"cuba\" + 0.061*\"continuing\"\n",
      "2019-10-29 00:38:49,961 : INFO : topic #2 (0.100): 0.088*\"cooky\" + 0.080*\"service\" + 0.079*\"havana\" + 0.072*\"policy\" + 0.063*\"beyond\" + 0.063*\"browse\" + 0.063*\"privacy\" + 0.062*\"information\" + 0.060*\"agree\" + 0.060*\"site\"\n",
      "2019-10-29 00:38:49,963 : INFO : topic #9 (0.100): 0.116*\"cooky\" + 0.078*\"continuing\" + 0.071*\"revised\" + 0.068*\"information\" + 0.066*\"use\" + 0.065*\"service\" + 0.064*\"term\" + 0.062*\"site\" + 0.057*\"browse\" + 0.055*\"agree\"\n",
      "2019-10-29 00:38:49,965 : INFO : topic #5 (0.100): 0.124*\"cooky\" + 0.077*\"policy\" + 0.069*\"browse\" + 0.062*\"site\" + 0.061*\"agree\" + 0.061*\"use\" + 0.061*\"term\" + 0.059*\"privacy\" + 0.059*\"service\" + 0.057*\"information\"\n",
      "2019-10-29 00:38:49,968 : INFO : topic #7 (0.100): 0.095*\"cooky\" + 0.085*\"cuba\" + 0.070*\"use\" + 0.066*\"policy\" + 0.063*\"photo\" + 0.063*\"privacy\" + 0.062*\"havana\" + 0.062*\"service\" + 0.058*\"browse\" + 0.058*\"revised\"\n",
      "2019-10-29 00:38:49,970 : INFO : topic diff=0.557324, rho=1.000000\n",
      "2019-10-29 00:38:50,380 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:50,384 : INFO : built Dictionary(233 unique tokens: ['significant', 'radiating', 'jamie', 'focus', 'serious']...) from 5 documents (total 1830 corpus positions)\n",
      "2019-10-29 00:38:50,388 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:50,390 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:50,393 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:50,401 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:50,402 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:50,505 : INFO : -7.470 per-word bound, 177.3 perplexity estimate based on a held-out corpus of 5 documents with 1830 words\n",
      "2019-10-29 00:38:50,506 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:50,512 : INFO : topic #1 (0.100): 0.031*\"woodward\" + 0.025*\"said\" + 0.022*\"animal\" + 0.019*\"show\" + 0.019*\"handler\" + 0.018*\"also\" + 0.015*\"pig\" + 0.011*\"cow\" + 0.011*\"portrait\" + 0.011*\"people\"\n",
      "2019-10-29 00:38:50,514 : INFO : topic #6 (0.100): 0.037*\"woodward\" + 0.023*\"show\" + 0.020*\"said\" + 0.015*\"animal\" + 0.015*\"pig\" + 0.014*\"handler\" + 0.012*\"also\" + 0.011*\"competition\" + 0.011*\"people\" + 0.010*\"photographer\"\n",
      "2019-10-29 00:38:50,517 : INFO : topic #0 (0.100): 0.030*\"said\" + 0.029*\"woodward\" + 0.025*\"show\" + 0.023*\"animal\" + 0.014*\"handler\" + 0.013*\"pig\" + 0.012*\"also\" + 0.011*\"people\" + 0.010*\"cow\" + 0.010*\"competition\"\n",
      "2019-10-29 00:38:50,520 : INFO : topic #4 (0.100): 0.041*\"woodward\" + 0.022*\"said\" + 0.022*\"animal\" + 0.021*\"show\" + 0.017*\"also\" + 0.012*\"handler\" + 0.011*\"photo\" + 0.011*\"pig\" + 0.011*\"competition\" + 0.011*\"well\"\n",
      "2019-10-29 00:38:50,523 : INFO : topic #9 (0.100): 0.025*\"woodward\" + 0.025*\"said\" + 0.020*\"show\" + 0.019*\"animal\" + 0.015*\"handler\" + 0.014*\"also\" + 0.013*\"portrait\" + 0.012*\"cow\" + 0.012*\"pig\" + 0.011*\"competition\"\n",
      "2019-10-29 00:38:50,526 : INFO : topic diff=0.829302, rho=1.000000\n",
      "2019-10-29 00:38:50,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:50,934 : INFO : built Dictionary(238 unique tokens: ['trying', 'vague', 'de', 'party', 'come']...) from 5 documents (total 1900 corpus positions)\n",
      "2019-10-29 00:38:50,938 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:50,939 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:50,940 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:50,943 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:50,945 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:51,038 : INFO : -7.466 per-word bound, 176.8 perplexity estimate based on a held-out corpus of 5 documents with 1900 words\n",
      "2019-10-29 00:38:51,039 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:51,046 : INFO : topic #3 (0.100): 0.027*\"turkey\" + 0.022*\"fsa\" + 0.019*\"group\" + 0.017*\"turkish\" + 0.017*\"al\" + 0.017*\"idlib\" + 0.016*\"said\" + 0.013*\"province\" + 0.013*\"force\" + 0.011*\"rebel\"\n",
      "2019-10-29 00:38:51,048 : INFO : topic #2 (0.100): 0.021*\"turkey\" + 0.019*\"fsa\" + 0.017*\"turkish\" + 0.016*\"group\" + 0.016*\"force\" + 0.016*\"said\" + 0.015*\"al\" + 0.013*\"idlib\" + 0.013*\"rebel\" + 0.012*\"syria\"\n",
      "2019-10-29 00:38:51,051 : INFO : topic #4 (0.100): 0.024*\"turkey\" + 0.020*\"group\" + 0.020*\"turkish\" + 0.017*\"idlib\" + 0.017*\"said\" + 0.017*\"rebel\" + 0.015*\"al\" + 0.014*\"fsa\" + 0.013*\"area\" + 0.013*\"syrian\"\n",
      "2019-10-29 00:38:51,054 : INFO : topic #0 (0.100): 0.023*\"turkey\" + 0.022*\"turkish\" + 0.017*\"group\" + 0.017*\"al\" + 0.016*\"rebel\" + 0.015*\"said\" + 0.015*\"province\" + 0.014*\"syrian\" + 0.014*\"idlib\" + 0.013*\"fsa\"\n",
      "2019-10-29 00:38:51,056 : INFO : topic #8 (0.100): 0.024*\"turkey\" + 0.020*\"fsa\" + 0.020*\"idlib\" + 0.019*\"al\" + 0.017*\"group\" + 0.016*\"syrian\" + 0.016*\"rebel\" + 0.016*\"turkish\" + 0.015*\"said\" + 0.012*\"russian\"\n",
      "2019-10-29 00:38:51,058 : INFO : topic diff=0.836475, rho=1.000000\n",
      "2019-10-29 00:38:51,445 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:51,447 : INFO : built Dictionary(30 unique tokens: ['b', 'affected', 'made', 'celebrity', 'cnn']...) from 5 documents (total 185 corpus positions)\n",
      "2019-10-29 00:38:51,448 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:51,449 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:51,451 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:51,453 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:51,454 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:51,474 : INFO : -6.241 per-word bound, 75.6 perplexity estimate based on a held-out corpus of 5 documents with 185 words\n",
      "2019-10-29 00:38:51,475 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:51,482 : INFO : topic #4 (0.100): 0.087*\"black\" + 0.086*\"realized\" + 0.080*\"first\" + 0.054*\"time\" + 0.032*\"reporter\" + 0.031*\"realizediwasblack\" + 0.030*\"w\" + 0.030*\"color\" + 0.029*\"bois\" + 0.029*\"skin\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:51,483 : INFO : topic #3 (0.100): 0.086*\"first\" + 0.066*\"realized\" + 0.059*\"time\" + 0.056*\"black\" + 0.036*\"asked\" + 0.033*\"celebrity\" + 0.033*\"realizediwasblack\" + 0.033*\"color\" + 0.032*\"e\" + 0.031*\"du\"\n",
      "2019-10-29 00:38:51,484 : INFO : topic #6 (0.100): 0.074*\"first\" + 0.067*\"realized\" + 0.065*\"black\" + 0.044*\"time\" + 0.040*\"anchor\" + 0.034*\"folk\" + 0.033*\"affected\" + 0.032*\"realizediwasblack\" + 0.031*\"others\" + 0.031*\"color\"\n",
      "2019-10-29 00:38:51,486 : INFO : topic #8 (0.100): 0.081*\"realized\" + 0.078*\"first\" + 0.069*\"black\" + 0.067*\"time\" + 0.033*\"others\" + 0.031*\"reporter\" + 0.031*\"folk\" + 0.030*\"bois\" + 0.030*\"asked\" + 0.030*\"skin\"\n",
      "2019-10-29 00:38:51,488 : INFO : topic #9 (0.100): 0.082*\"first\" + 0.081*\"black\" + 0.078*\"realized\" + 0.038*\"time\" + 0.034*\"cnn\" + 0.033*\"different\" + 0.032*\"people\" + 0.032*\"reporter\" + 0.031*\"celebrity\" + 0.031*\"tell\"\n",
      "2019-10-29 00:38:51,490 : INFO : topic diff=0.715157, rho=1.000000\n",
      "2019-10-29 00:38:51,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:51,942 : INFO : built Dictionary(585 unique tokens: ['jazz', 'lamentably', 'diaz', 'seen', 'deep']...) from 5 documents (total 4565 corpus positions)\n",
      "2019-10-29 00:38:51,948 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:51,950 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:51,951 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:51,955 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:51,957 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:52,133 : INFO : -8.351 per-word bound, 326.6 perplexity estimate based on a held-out corpus of 5 documents with 4565 words\n",
      "2019-10-29 00:38:52,135 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:52,146 : INFO : topic #2 (0.100): 0.027*\"basquiat\" + 0.021*\"art\" + 0.018*\"painting\" + 0.011*\"work\" + 0.010*\"samo\" + 0.009*\"exhibition\" + 0.008*\"graffiti\" + 0.006*\"artist\" + 0.006*\"barbican\" + 0.006*\"white\"\n",
      "2019-10-29 00:38:52,148 : INFO : topic #1 (0.100): 0.033*\"basquiat\" + 0.021*\"art\" + 0.016*\"work\" + 0.016*\"painting\" + 0.010*\"exhibition\" + 0.008*\"samo\" + 0.007*\"graffiti\" + 0.007*\"lower\" + 0.006*\"street\" + 0.006*\"act\"\n",
      "2019-10-29 00:38:52,151 : INFO : topic #6 (0.100): 0.023*\"art\" + 0.021*\"basquiat\" + 0.014*\"painting\" + 0.013*\"work\" + 0.009*\"exhibition\" + 0.009*\"samo\" + 0.007*\"graffiti\" + 0.007*\"barbican\" + 0.006*\"lower\" + 0.006*\"area\"\n",
      "2019-10-29 00:38:52,152 : INFO : topic #5 (0.100): 0.033*\"basquiat\" + 0.020*\"painting\" + 0.019*\"art\" + 0.014*\"work\" + 0.009*\"exhibition\" + 0.008*\"barbican\" + 0.008*\"samo\" + 0.007*\"graffiti\" + 0.007*\"street\" + 0.006*\"area\"\n",
      "2019-10-29 00:38:52,154 : INFO : topic #8 (0.100): 0.022*\"basquiat\" + 0.018*\"art\" + 0.017*\"painting\" + 0.013*\"work\" + 0.008*\"samo\" + 0.008*\"graffiti\" + 0.008*\"exhibition\" + 0.008*\"white\" + 0.006*\"act\" + 0.006*\"artist\"\n",
      "2019-10-29 00:38:52,156 : INFO : topic diff=0.864305, rho=1.000000\n",
      "2019-10-29 00:38:52,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:52,639 : INFO : built Dictionary(995 unique tokens: ['let', 'remained', 'planned', 'expert', 'hatred']...) from 5 documents (total 7560 corpus positions)\n",
      "2019-10-29 00:38:52,648 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:52,649 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:52,651 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:52,657 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:52,659 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:52,969 : INFO : -8.916 per-word bound, 483.1 perplexity estimate based on a held-out corpus of 5 documents with 7560 words\n",
      "2019-10-29 00:38:52,971 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:52,985 : INFO : topic #7 (0.100): 0.009*\"german\" + 0.009*\"russian\" + 0.008*\"west\" + 0.008*\"germany\" + 0.008*\"kgb\" + 0.007*\"one\" + 0.006*\"american\" + 0.006*\"right\" + 0.005*\"anti\" + 0.005*\"agent\"\n",
      "2019-10-29 00:38:52,988 : INFO : topic #3 (0.100): 0.014*\"russian\" + 0.010*\"west\" + 0.007*\"anti\" + 0.007*\"german\" + 0.007*\"one\" + 0.006*\"even\" + 0.006*\"right\" + 0.006*\"facebook\" + 0.005*\"american\" + 0.005*\"kgb\"\n",
      "2019-10-29 00:38:52,991 : INFO : topic #2 (0.100): 0.011*\"west\" + 0.010*\"kgb\" + 0.009*\"anti\" + 0.008*\"german\" + 0.008*\"russian\" + 0.008*\"one\" + 0.007*\"american\" + 0.006*\"facebook\" + 0.006*\"germany\" + 0.006*\"even\"\n",
      "2019-10-29 00:38:52,993 : INFO : topic #8 (0.100): 0.012*\"west\" + 0.010*\"russian\" + 0.008*\"agayants\" + 0.008*\"german\" + 0.007*\"anti\" + 0.007*\"american\" + 0.006*\"kgb\" + 0.006*\"one\" + 0.006*\"even\" + 0.005*\"year\"\n",
      "2019-10-29 00:38:52,996 : INFO : topic #5 (0.100): 0.013*\"west\" + 0.008*\"american\" + 0.008*\"russian\" + 0.007*\"german\" + 0.007*\"kgb\" + 0.007*\"germany\" + 0.006*\"anti\" + 0.006*\"agayants\" + 0.006*\"u\" + 0.006*\"agent\"\n",
      "2019-10-29 00:38:52,999 : INFO : topic diff=0.844299, rho=1.000000\n",
      "2019-10-29 00:38:53,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:53,432 : INFO : built Dictionary(254 unique tokens: ['violence', 'offered', 'ghanaians', 'campaign', 'relative']...) from 5 documents (total 2255 corpus positions)\n",
      "2019-10-29 00:38:53,436 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:53,438 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:53,443 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:53,448 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:53,451 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:53,609 : INFO : -7.385 per-word bound, 167.2 perplexity estimate based on a held-out corpus of 5 documents with 2255 words\n",
      "2019-10-29 00:38:53,611 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:53,620 : INFO : topic #2 (0.100): 0.031*\"country\" + 0.031*\"vote\" + 0.027*\"people\" + 0.025*\"election\" + 0.022*\"trust\" + 0.020*\"say\" + 0.016*\"penar\" + 0.016*\"may\" + 0.015*\"voter\" + 0.012*\"african\"\n",
      "2019-10-29 00:38:53,622 : INFO : topic #0 (0.100): 0.029*\"election\" + 0.029*\"people\" + 0.024*\"vote\" + 0.021*\"trust\" + 0.019*\"penar\" + 0.018*\"say\" + 0.015*\"voter\" + 0.013*\"country\" + 0.012*\"researcher\" + 0.011*\"face\"\n",
      "2019-10-29 00:38:53,624 : INFO : topic #5 (0.100): 0.029*\"election\" + 0.026*\"people\" + 0.024*\"trust\" + 0.023*\"vote\" + 0.021*\"country\" + 0.019*\"say\" + 0.014*\"penar\" + 0.014*\"commission\" + 0.013*\"voter\" + 0.012*\"may\"\n",
      "2019-10-29 00:38:53,626 : INFO : topic #9 (0.100): 0.029*\"vote\" + 0.028*\"election\" + 0.027*\"trust\" + 0.026*\"country\" + 0.018*\"people\" + 0.017*\"penar\" + 0.015*\"voter\" + 0.014*\"say\" + 0.012*\"researcher\" + 0.012*\"may\"\n",
      "2019-10-29 00:38:53,628 : INFO : topic #6 (0.100): 0.025*\"people\" + 0.024*\"country\" + 0.023*\"election\" + 0.022*\"trust\" + 0.021*\"penar\" + 0.021*\"vote\" + 0.018*\"say\" + 0.016*\"african\" + 0.014*\"voter\" + 0.013*\"may\"\n",
      "2019-10-29 00:38:53,630 : INFO : topic diff=0.913240, rho=1.000000\n",
      "2019-10-29 00:38:54,049 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:54,053 : INFO : built Dictionary(256 unique tokens: ['liability', 'let', 'trying', 'filed', 'bone']...) from 5 documents (total 2065 corpus positions)\n",
      "2019-10-29 00:38:54,057 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:54,058 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:54,060 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:54,063 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:54,064 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:54,161 : INFO : -7.523 per-word bound, 183.9 perplexity estimate based on a held-out corpus of 5 documents with 2065 words\n",
      "2019-10-29 00:38:54,163 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:54,170 : INFO : topic #9 (0.100): 0.042*\"said\" + 0.030*\"loo\" + 0.021*\"baseball\" + 0.016*\"eye\" + 0.013*\"fan\" + 0.013*\"ball\" + 0.013*\"area\" + 0.013*\"lawsuit\" + 0.011*\"foul\" + 0.011*\"league\"\n",
      "2019-10-29 00:38:54,173 : INFO : topic #0 (0.100): 0.027*\"said\" + 0.024*\"loo\" + 0.021*\"baseball\" + 0.018*\"major\" + 0.017*\"ball\" + 0.016*\"league\" + 0.014*\"eye\" + 0.014*\"game\" + 0.013*\"cub\" + 0.012*\"area\"\n",
      "2019-10-29 00:38:54,176 : INFO : topic #1 (0.100): 0.048*\"said\" + 0.027*\"loo\" + 0.018*\"league\" + 0.017*\"baseball\" + 0.015*\"ball\" + 0.012*\"major\" + 0.012*\"foul\" + 0.012*\"fan\" + 0.011*\"game\" + 0.011*\"netting\"\n",
      "2019-10-29 00:38:54,179 : INFO : topic #2 (0.100): 0.034*\"said\" + 0.025*\"loo\" + 0.020*\"ball\" + 0.020*\"baseball\" + 0.016*\"eye\" + 0.015*\"major\" + 0.013*\"lawsuit\" + 0.012*\"cub\" + 0.012*\"fan\" + 0.012*\"u\"\n",
      "2019-10-29 00:38:54,181 : INFO : topic #5 (0.100): 0.037*\"said\" + 0.026*\"loo\" + 0.016*\"ball\" + 0.016*\"baseball\" + 0.015*\"major\" + 0.013*\"u\" + 0.013*\"game\" + 0.013*\"eye\" + 0.013*\"lawsuit\" + 0.012*\"area\"\n",
      "2019-10-29 00:38:54,184 : INFO : topic diff=0.862784, rho=1.000000\n",
      "2019-10-29 00:38:54,659 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:54,664 : INFO : built Dictionary(308 unique tokens: ['although', 'let', 'theft', 'person', 'caution']...) from 5 documents (total 2375 corpus positions)\n",
      "2019-10-29 00:38:54,668 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:54,669 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:54,670 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:54,672 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:54,673 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:54,789 : INFO : -7.760 per-word bound, 216.8 perplexity estimate based on a held-out corpus of 5 documents with 2375 words\n",
      "2019-10-29 00:38:54,791 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:54,798 : INFO : topic #5 (0.100): 0.018*\"said\" + 0.018*\"say\" + 0.017*\"victim\" + 0.014*\"told\" + 0.013*\"camus\" + 0.013*\"irs\" + 0.012*\"money\" + 0.011*\"call\" + 0.011*\"scam\" + 0.010*\"department\"\n",
      "2019-10-29 00:38:54,801 : INFO : topic #8 (0.100): 0.023*\"say\" + 0.021*\"victim\" + 0.017*\"said\" + 0.012*\"irs\" + 0.012*\"told\" + 0.011*\"scam\" + 0.011*\"treasury\" + 0.010*\"money\" + 0.010*\"never\" + 0.010*\"call\"\n",
      "2019-10-29 00:38:54,803 : INFO : topic #0 (0.100): 0.023*\"say\" + 0.022*\"victim\" + 0.014*\"said\" + 0.012*\"irs\" + 0.012*\"never\" + 0.011*\"scam\" + 0.010*\"camus\" + 0.009*\"call\" + 0.009*\"treasury\" + 0.009*\"told\"\n",
      "2019-10-29 00:38:54,804 : INFO : topic #6 (0.100): 0.019*\"victim\" + 0.019*\"said\" + 0.016*\"say\" + 0.014*\"camus\" + 0.012*\"told\" + 0.012*\"scam\" + 0.011*\"money\" + 0.010*\"treasury\" + 0.009*\"one\" + 0.009*\"department\"\n",
      "2019-10-29 00:38:54,806 : INFO : topic #2 (0.100): 0.022*\"victim\" + 0.018*\"say\" + 0.016*\"said\" + 0.015*\"irs\" + 0.015*\"told\" + 0.013*\"camus\" + 0.012*\"money\" + 0.011*\"department\" + 0.010*\"never\" + 0.009*\"treasury\"\n",
      "2019-10-29 00:38:54,807 : INFO : topic diff=0.838669, rho=1.000000\n",
      "2019-10-29 00:38:55,236 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:55,238 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:38:55,239 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:55,240 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:55,241 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:55,242 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:55,243 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:55,253 : INFO : -6.043 per-word bound, 65.9 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:38:55,254 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:55,258 : INFO : topic #6 (0.100): 0.125*\"transcript\" + 0.097*\"page\" + 0.059*\"become\" + 0.058*\"segment\" + 0.054*\"note\" + 0.050*\"cnn\" + 0.050*\"continually\" + 0.049*\"later\" + 0.048*\"available\" + 0.046*\"updated\"\n",
      "2019-10-29 00:38:55,259 : INFO : topic #1 (0.100): 0.132*\"transcript\" + 0.089*\"page\" + 0.059*\"find\" + 0.053*\"segment\" + 0.050*\"available\" + 0.049*\"return\" + 0.049*\"later\" + 0.048*\"note\" + 0.047*\"check\" + 0.047*\"become\"\n",
      "2019-10-29 00:38:55,260 : INFO : topic #0 (0.100): 0.158*\"transcript\" + 0.084*\"page\" + 0.056*\"back\" + 0.051*\"cnn\" + 0.050*\"available\" + 0.050*\"become\" + 0.046*\"main\" + 0.046*\"continually\" + 0.046*\"cannot\" + 0.045*\"october\"\n",
      "2019-10-29 00:38:55,261 : INFO : topic #7 (0.100): 0.207*\"transcript\" + 0.055*\"cannot\" + 0.051*\"specific\" + 0.050*\"main\" + 0.048*\"new\" + 0.047*\"page\" + 0.047*\"later\" + 0.045*\"available\" + 0.045*\"back\" + 0.044*\"find\"\n",
      "2019-10-29 00:38:55,262 : INFO : topic #8 (0.100): 0.169*\"transcript\" + 0.095*\"page\" + 0.051*\"later\" + 0.049*\"updated\" + 0.047*\"october\" + 0.046*\"check\" + 0.046*\"return\" + 0.046*\"continually\" + 0.045*\"find\" + 0.045*\"segment\"\n",
      "2019-10-29 00:38:55,263 : INFO : topic diff=0.708256, rho=1.000000\n",
      "2019-10-29 00:38:55,860 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:55,866 : INFO : built Dictionary(406 unique tokens: ['josh', 'forecast', 'crest', 'francisco', 'utility']...) from 5 documents (total 4815 corpus positions)\n",
      "2019-10-29 00:38:55,871 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:55,873 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:55,874 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:55,878 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:55,879 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:56,051 : INFO : -7.500 per-word bound, 181.0 perplexity estimate based on a held-out corpus of 5 documents with 4815 words\n",
      "2019-10-29 00:38:56,053 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:56,065 : INFO : topic #7 (0.100): 0.040*\"fire\" + 0.036*\"hide\" + 0.035*\"wildfire\" + 0.033*\"blaze\" + 0.030*\"photo\" + 0.029*\"october\" + 0.028*\"caption\" + 0.026*\"california\" + 0.015*\"wind\" + 0.012*\"santa\"\n",
      "2019-10-29 00:38:56,066 : INFO : topic #9 (0.100): 0.056*\"california\" + 0.035*\"fire\" + 0.032*\"wildfire\" + 0.032*\"october\" + 0.031*\"hide\" + 0.030*\"blaze\" + 0.030*\"photo\" + 0.030*\"caption\" + 0.014*\"santa\" + 0.011*\"wind\"\n",
      "2019-10-29 00:38:56,069 : INFO : topic #2 (0.100): 0.046*\"wildfire\" + 0.037*\"california\" + 0.037*\"fire\" + 0.037*\"photo\" + 0.036*\"blaze\" + 0.032*\"october\" + 0.027*\"caption\" + 0.026*\"hide\" + 0.011*\"rosa\" + 0.011*\"wind\"\n",
      "2019-10-29 00:38:56,071 : INFO : topic #1 (0.100): 0.046*\"california\" + 0.040*\"blaze\" + 0.036*\"wildfire\" + 0.034*\"caption\" + 0.030*\"fire\" + 0.026*\"photo\" + 0.025*\"october\" + 0.022*\"hide\" + 0.016*\"wind\" + 0.013*\"santa\"\n",
      "2019-10-29 00:38:56,073 : INFO : topic #4 (0.100): 0.041*\"wildfire\" + 0.039*\"fire\" + 0.036*\"california\" + 0.032*\"photo\" + 0.030*\"hide\" + 0.029*\"caption\" + 0.028*\"blaze\" + 0.024*\"october\" + 0.015*\"napa\" + 0.012*\"rosa\"\n",
      "2019-10-29 00:38:56,075 : INFO : topic diff=1.100690, rho=1.000000\n",
      "2019-10-29 00:38:56,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:56,491 : INFO : built Dictionary(79 unique tokens: ['every', 'sit', 'hayes', 'watch', 'relax']...) from 5 documents (total 500 corpus positions)\n",
      "2019-10-29 00:38:56,493 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:56,494 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:56,496 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:56,499 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:56,500 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:56,546 : INFO : -6.886 per-word bound, 118.3 perplexity estimate based on a held-out corpus of 5 documents with 500 words\n",
      "2019-10-29 00:38:56,549 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:56,557 : INFO : topic #9 (0.100): 0.039*\"irish\" + 0.029*\"pony\" + 0.028*\"doolough\" + 0.028*\"ireland\" + 0.027*\"cnn\" + 0.024*\"racing\" + 0.022*\"watch\" + 0.021*\"coast\" + 0.021*\"sand\" + 0.020*\"jockey\"\n",
      "2019-10-29 00:38:56,560 : INFO : topic #7 (0.100): 0.032*\"doolough\" + 0.031*\"pony\" + 0.028*\"racing\" + 0.026*\"cnn\" + 0.025*\"irish\" + 0.022*\"county\" + 0.021*\"watch\" + 0.021*\"coast\" + 0.020*\"jockey\" + 0.019*\"geesala\"\n",
      "2019-10-29 00:38:56,563 : INFO : topic #1 (0.100): 0.033*\"doolough\" + 0.032*\"racing\" + 0.031*\"ireland\" + 0.029*\"irish\" + 0.027*\"pony\" + 0.026*\"cnn\" + 0.022*\"mayo\" + 0.022*\"jockey\" + 0.021*\"coast\" + 0.020*\"watch\"\n",
      "2019-10-29 00:38:56,566 : INFO : topic #2 (0.100): 0.031*\"irish\" + 0.030*\"cnn\" + 0.028*\"doolough\" + 0.025*\"ireland\" + 0.025*\"jockey\" + 0.025*\"pony\" + 0.024*\"festival\" + 0.022*\"sand\" + 0.022*\"place\" + 0.022*\"county\"\n",
      "2019-10-29 00:38:56,569 : INFO : topic #4 (0.100): 0.032*\"ireland\" + 0.030*\"cnn\" + 0.029*\"racing\" + 0.028*\"doolough\" + 0.027*\"irish\" + 0.027*\"pony\" + 0.022*\"place\" + 0.022*\"county\" + 0.021*\"sand\" + 0.019*\"mayo\"\n",
      "2019-10-29 00:38:56,571 : INFO : topic diff=0.705558, rho=1.000000\n",
      "2019-10-29 00:38:57,018 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:57,021 : INFO : built Dictionary(56 unique tokens: ['story', 'issue', 'time', 'life', 'joe']...) from 5 documents (total 360 corpus positions)\n",
      "2019-10-29 00:38:57,024 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:57,027 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:57,030 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:57,032 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:57,035 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:57,067 : INFO : -6.585 per-word bound, 96.0 perplexity estimate based on a held-out corpus of 5 documents with 360 words\n",
      "2019-10-29 00:38:57,070 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:57,076 : INFO : topic #3 (0.100): 0.072*\"tyler\" + 0.065*\"heart\" + 0.037*\"tour\" + 0.036*\"said\" + 0.031*\"seizure\" + 0.029*\"attack\" + 0.029*\"steven\" + 0.024*\"issue\" + 0.018*\"announced\" + 0.017*\"condition\"\n",
      "2019-10-29 00:38:57,079 : INFO : topic #9 (0.100): 0.072*\"tyler\" + 0.054*\"heart\" + 0.039*\"tour\" + 0.038*\"attack\" + 0.028*\"steven\" + 0.027*\"seizure\" + 0.025*\"issue\" + 0.024*\"said\" + 0.020*\"certainly\" + 0.020*\"four\"\n",
      "2019-10-29 00:38:57,083 : INFO : topic #6 (0.100): 0.064*\"tyler\" + 0.062*\"heart\" + 0.037*\"tour\" + 0.036*\"attack\" + 0.030*\"seizure\" + 0.024*\"steven\" + 0.024*\"issue\" + 0.019*\"band\" + 0.019*\"vederci\" + 0.018*\"condition\"\n",
      "2019-10-29 00:38:57,086 : INFO : topic #5 (0.100): 0.061*\"tyler\" + 0.059*\"heart\" + 0.039*\"said\" + 0.036*\"attack\" + 0.036*\"tour\" + 0.031*\"issue\" + 0.021*\"seizure\" + 0.021*\"steven\" + 0.018*\"perry\" + 0.018*\"insists\"\n",
      "2019-10-29 00:38:57,089 : INFO : topic #1 (0.100): 0.065*\"tyler\" + 0.058*\"heart\" + 0.043*\"tour\" + 0.032*\"attack\" + 0.030*\"seizure\" + 0.029*\"said\" + 0.028*\"issue\" + 0.026*\"steven\" + 0.019*\"speculation\" + 0.018*\"actually\"\n",
      "2019-10-29 00:38:57,092 : INFO : topic diff=0.756741, rho=1.000000\n",
      "2019-10-29 00:38:57,646 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:57,658 : INFO : built Dictionary(695 unique tokens: ['trifecta', 'portion', 'median', 'subdivision', 'used']...) from 5 documents (total 6140 corpus positions)\n",
      "2019-10-29 00:38:57,667 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:57,669 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:57,671 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:57,674 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:57,677 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:57,901 : INFO : -8.357 per-word bound, 327.9 perplexity estimate based on a held-out corpus of 5 documents with 6140 words\n",
      "2019-10-29 00:38:57,903 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:57,917 : INFO : topic #5 (0.100): 0.020*\"city\" + 0.019*\"new\" + 0.015*\"disaster\" + 0.013*\"orleans\" + 0.010*\"community\" + 0.008*\"flood\" + 0.008*\"infrastructure\" + 0.007*\"natural\" + 0.007*\"capacity\" + 0.007*\"change\"\n",
      "2019-10-29 00:38:57,920 : INFO : topic #1 (0.100): 0.018*\"city\" + 0.018*\"new\" + 0.015*\"orleans\" + 0.013*\"disaster\" + 0.010*\"flood\" + 0.009*\"community\" + 0.009*\"public\" + 0.009*\"infrastructure\" + 0.008*\"natural\" + 0.008*\"houston\"\n",
      "2019-10-29 00:38:57,923 : INFO : topic #0 (0.100): 0.019*\"new\" + 0.019*\"disaster\" + 0.019*\"city\" + 0.014*\"orleans\" + 0.011*\"flood\" + 0.011*\"infrastructure\" + 0.011*\"community\" + 0.008*\"natural\" + 0.008*\"public\" + 0.007*\"houston\"\n",
      "2019-10-29 00:38:57,926 : INFO : topic #9 (0.100): 0.026*\"city\" + 0.017*\"new\" + 0.015*\"disaster\" + 0.009*\"community\" + 0.009*\"orleans\" + 0.009*\"infrastructure\" + 0.007*\"houston\" + 0.007*\"area\" + 0.007*\"local\" + 0.007*\"federal\"\n",
      "2019-10-29 00:38:57,929 : INFO : topic #3 (0.100): 0.017*\"disaster\" + 0.016*\"new\" + 0.016*\"city\" + 0.013*\"orleans\" + 0.011*\"flood\" + 0.010*\"infrastructure\" + 0.010*\"community\" + 0.008*\"houston\" + 0.008*\"public\" + 0.007*\"change\"\n",
      "2019-10-29 00:38:57,931 : INFO : topic diff=0.905157, rho=1.000000\n",
      "2019-10-29 00:38:58,342 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:58,344 : INFO : built Dictionary(11 unique tokens: ['chat', 'undercutting', 'unfolds', 'facebook', 'messenger']...) from 5 documents (total 55 corpus positions)\n",
      "2019-10-29 00:38:58,346 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:58,349 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:58,352 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:58,356 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:58,359 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:58,371 : INFO : -6.374 per-word bound, 82.9 perplexity estimate based on a held-out corpus of 5 documents with 55 words\n",
      "2019-10-29 00:38:58,374 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:58,380 : INFO : topic #2 (0.100): 0.105*\"facebook\" + 0.102*\"undercutting\" + 0.097*\"u\" + 0.094*\"chat\" + 0.093*\"find\" + 0.090*\"messenger\" + 0.090*\"trump\" + 0.088*\"happening\" + 0.086*\"world\" + 0.081*\"tillerson\"\n",
      "2019-10-29 00:38:58,382 : INFO : topic #7 (0.100): 0.112*\"tillerson\" + 0.105*\"trump\" + 0.105*\"messenger\" + 0.096*\"unfolds\" + 0.093*\"chat\" + 0.091*\"happening\" + 0.089*\"undercutting\" + 0.083*\"u\" + 0.080*\"find\" + 0.076*\"facebook\"\n",
      "2019-10-29 00:38:58,386 : INFO : topic #0 (0.100): 0.108*\"trump\" + 0.100*\"find\" + 0.099*\"facebook\" + 0.096*\"world\" + 0.095*\"tillerson\" + 0.093*\"chat\" + 0.090*\"undercutting\" + 0.086*\"unfolds\" + 0.082*\"happening\" + 0.078*\"messenger\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:38:58,389 : INFO : topic #8 (0.100): 0.123*\"unfolds\" + 0.100*\"messenger\" + 0.100*\"find\" + 0.099*\"facebook\" + 0.095*\"u\" + 0.086*\"happening\" + 0.085*\"chat\" + 0.082*\"world\" + 0.079*\"trump\" + 0.077*\"undercutting\"\n",
      "2019-10-29 00:38:58,392 : INFO : topic #9 (0.100): 0.106*\"messenger\" + 0.105*\"find\" + 0.101*\"undercutting\" + 0.097*\"world\" + 0.097*\"u\" + 0.093*\"chat\" + 0.091*\"facebook\" + 0.087*\"tillerson\" + 0.084*\"unfolds\" + 0.075*\"trump\"\n",
      "2019-10-29 00:38:58,394 : INFO : topic diff=0.513185, rho=1.000000\n",
      "2019-10-29 00:38:58,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:58,976 : INFO : built Dictionary(1012 unique tokens: ['let', 'wave', 'happy', 'focus', 'asleep']...) from 5 documents (total 11765 corpus positions)\n",
      "2019-10-29 00:38:58,998 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:59,000 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:59,004 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:59,009 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:59,012 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:38:59,425 : INFO : -8.414 per-word bound, 341.1 perplexity estimate based on a held-out corpus of 5 documents with 11765 words\n",
      "2019-10-29 00:38:59,427 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:38:59,442 : INFO : topic #2 (0.100): 0.020*\"batulo\" + 0.019*\"abdalla\" + 0.015*\"refugee\" + 0.012*\"family\" + 0.010*\"phone\" + 0.009*\"day\" + 0.007*\"say\" + 0.007*\"daughter\" + 0.006*\"kakuma\" + 0.006*\"one\"\n",
      "2019-10-29 00:38:59,445 : INFO : topic #1 (0.100): 0.018*\"family\" + 0.015*\"abdalla\" + 0.014*\"batulo\" + 0.012*\"refugee\" + 0.009*\"day\" + 0.007*\"say\" + 0.007*\"phone\" + 0.007*\"face\" + 0.006*\"still\" + 0.006*\"kakuma\"\n",
      "2019-10-29 00:38:59,448 : INFO : topic #7 (0.100): 0.016*\"family\" + 0.013*\"abdalla\" + 0.012*\"refugee\" + 0.010*\"batulo\" + 0.009*\"say\" + 0.009*\"day\" + 0.008*\"phone\" + 0.007*\"daughter\" + 0.007*\"one\" + 0.006*\"kakuma\"\n",
      "2019-10-29 00:38:59,451 : INFO : topic #9 (0.100): 0.019*\"abdalla\" + 0.015*\"family\" + 0.014*\"refugee\" + 0.012*\"batulo\" + 0.008*\"day\" + 0.007*\"phone\" + 0.007*\"say\" + 0.006*\"camp\" + 0.006*\"united\" + 0.006*\"one\"\n",
      "2019-10-29 00:38:59,453 : INFO : topic #4 (0.100): 0.019*\"batulo\" + 0.018*\"family\" + 0.016*\"abdalla\" + 0.012*\"refugee\" + 0.009*\"daughter\" + 0.009*\"say\" + 0.008*\"phone\" + 0.007*\"like\" + 0.007*\"away\" + 0.006*\"new\"\n",
      "2019-10-29 00:38:59,456 : INFO : topic diff=1.055462, rho=1.000000\n",
      "2019-10-29 00:38:59,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:38:59,922 : INFO : built Dictionary(314 unique tokens: ['recover', 'revitalize', 'de', 'prove', 'victory']...) from 5 documents (total 2600 corpus positions)\n",
      "2019-10-29 00:38:59,928 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:38:59,929 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:38:59,931 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:38:59,938 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:38:59,941 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:00,121 : INFO : -7.680 per-word bound, 205.0 perplexity estimate based on a held-out corpus of 5 documents with 2600 words\n",
      "2019-10-29 00:39:00,123 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:00,133 : INFO : topic #4 (0.100): 0.036*\"canfranc\" + 0.031*\"station\" + 0.017*\"say\" + 0.014*\"spain\" + 0.013*\"tourism\" + 0.011*\"world\" + 0.011*\"gold\" + 0.011*\"sánchez\" + 0.011*\"morale\" + 0.010*\"war\"\n",
      "2019-10-29 00:39:00,136 : INFO : topic #6 (0.100): 0.043*\"canfranc\" + 0.036*\"station\" + 0.013*\"war\" + 0.013*\"tourism\" + 0.013*\"gold\" + 0.012*\"world\" + 0.012*\"nazi\" + 0.012*\"sánchez\" + 0.012*\"morale\" + 0.011*\"say\"\n",
      "2019-10-29 00:39:00,140 : INFO : topic #8 (0.100): 0.041*\"canfranc\" + 0.036*\"station\" + 0.015*\"say\" + 0.013*\"spain\" + 0.012*\"tourism\" + 0.011*\"world\" + 0.011*\"nazi\" + 0.011*\"morale\" + 0.011*\"sánchez\" + 0.011*\"gold\"\n",
      "2019-10-29 00:39:00,143 : INFO : topic #0 (0.100): 0.036*\"canfranc\" + 0.023*\"station\" + 0.016*\"say\" + 0.015*\"spain\" + 0.013*\"sánchez\" + 0.011*\"campo\" + 0.011*\"nazi\" + 0.011*\"gold\" + 0.010*\"also\" + 0.010*\"morale\"\n",
      "2019-10-29 00:39:00,146 : INFO : topic #9 (0.100): 0.044*\"canfranc\" + 0.029*\"station\" + 0.016*\"say\" + 0.015*\"tourism\" + 0.014*\"spain\" + 0.013*\"sánchez\" + 0.013*\"morale\" + 0.011*\"gold\" + 0.011*\"world\" + 0.010*\"fraile\"\n",
      "2019-10-29 00:39:00,149 : INFO : topic diff=0.865341, rho=1.000000\n",
      "2019-10-29 00:39:00,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:00,569 : INFO : built Dictionary(324 unique tokens: ['concern', 'employing', 'segregate', 'reach', 'end']...) from 5 documents (total 2470 corpus positions)\n",
      "2019-10-29 00:39:00,572 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:00,574 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:00,575 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:00,579 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:00,580 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:00,686 : INFO : -7.826 per-word bound, 226.9 perplexity estimate based on a held-out corpus of 5 documents with 2470 words\n",
      "2019-10-29 00:39:00,687 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:00,695 : INFO : topic #2 (0.100): 0.029*\"pilgrim\" + 0.027*\"hajj\" + 0.024*\"muslim\" + 0.019*\"pilgrimage\" + 0.011*\"woman\" + 0.011*\"hajji\" + 0.010*\"worshipper\" + 0.010*\"mecca\" + 0.010*\"city\" + 0.009*\"day\"\n",
      "2019-10-29 00:39:00,697 : INFO : topic #0 (0.100): 0.030*\"hajj\" + 0.025*\"pilgrim\" + 0.022*\"muslim\" + 0.015*\"pilgrimage\" + 0.013*\"men\" + 0.011*\"woman\" + 0.010*\"saudi\" + 0.009*\"year\" + 0.009*\"white\" + 0.009*\"hajji\"\n",
      "2019-10-29 00:39:00,698 : INFO : topic #3 (0.100): 0.027*\"hajj\" + 0.023*\"muslim\" + 0.018*\"pilgrim\" + 0.017*\"pilgrimage\" + 0.016*\"woman\" + 0.012*\"mecca\" + 0.011*\"hajji\" + 0.011*\"city\" + 0.009*\"worshipper\" + 0.008*\"ritual\"\n",
      "2019-10-29 00:39:00,700 : INFO : topic #9 (0.100): 0.025*\"hajj\" + 0.025*\"pilgrim\" + 0.020*\"muslim\" + 0.017*\"pilgrimage\" + 0.012*\"year\" + 0.012*\"woman\" + 0.011*\"mecca\" + 0.009*\"saudi\" + 0.009*\"million\" + 0.009*\"worshipper\"\n",
      "2019-10-29 00:39:00,702 : INFO : topic #5 (0.100): 0.026*\"muslim\" + 0.024*\"hajj\" + 0.021*\"pilgrim\" + 0.014*\"woman\" + 0.013*\"pilgrimage\" + 0.013*\"mecca\" + 0.011*\"men\" + 0.010*\"city\" + 0.010*\"worshipper\" + 0.009*\"saudi\"\n",
      "2019-10-29 00:39:00,704 : INFO : topic diff=0.842239, rho=1.000000\n",
      "2019-10-29 00:39:01,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:01,290 : INFO : built Dictionary(1242 unique tokens: ['dating', 'filed', 'portion', 'shower', 'drinking']...) from 5 documents (total 16285 corpus positions)\n",
      "2019-10-29 00:39:01,306 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:01,308 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:01,309 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:01,315 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:01,318 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:01,683 : INFO : -8.505 per-word bound, 363.3 perplexity estimate based on a held-out corpus of 5 documents with 16285 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:01,684 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:01,701 : INFO : topic #9 (0.100): 0.018*\"abuse\" + 0.015*\"facility\" + 0.012*\"nursing\" + 0.012*\"sexual\" + 0.012*\"home\" + 0.011*\"resident\" + 0.011*\"allegation\" + 0.010*\"state\" + 0.010*\"victim\" + 0.009*\"cnn\"\n",
      "2019-10-29 00:39:01,703 : INFO : topic #2 (0.100): 0.018*\"abuse\" + 0.017*\"nursing\" + 0.016*\"facility\" + 0.013*\"cnn\" + 0.013*\"case\" + 0.011*\"victim\" + 0.011*\"resident\" + 0.010*\"said\" + 0.010*\"allegation\" + 0.010*\"sexual\"\n",
      "2019-10-29 00:39:01,705 : INFO : topic #0 (0.100): 0.024*\"facility\" + 0.017*\"nursing\" + 0.012*\"cnn\" + 0.012*\"case\" + 0.011*\"abuse\" + 0.011*\"said\" + 0.010*\"state\" + 0.010*\"sexual\" + 0.010*\"allegation\" + 0.010*\"resident\"\n",
      "2019-10-29 00:39:01,707 : INFO : topic #8 (0.100): 0.020*\"facility\" + 0.017*\"abuse\" + 0.015*\"nursing\" + 0.014*\"resident\" + 0.014*\"sexual\" + 0.012*\"home\" + 0.011*\"victim\" + 0.010*\"cnn\" + 0.009*\"report\" + 0.009*\"allegation\"\n",
      "2019-10-29 00:39:01,709 : INFO : topic #5 (0.100): 0.024*\"facility\" + 0.016*\"nursing\" + 0.015*\"abuse\" + 0.014*\"resident\" + 0.011*\"sexual\" + 0.011*\"state\" + 0.010*\"said\" + 0.010*\"allegation\" + 0.010*\"case\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:39:01,711 : INFO : topic diff=1.102177, rho=1.000000\n",
      "2019-10-29 00:39:02,102 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:02,106 : INFO : built Dictionary(142 unique tokens: ['tax', 'u', 'death', 'get', 'criticized']...) from 5 documents (total 905 corpus positions)\n",
      "2019-10-29 00:39:02,109 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:02,111 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:02,112 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:02,115 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:02,117 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:02,175 : INFO : -7.375 per-word bound, 166.0 perplexity estimate based on a held-out corpus of 5 documents with 905 words\n",
      "2019-10-29 00:39:02,176 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:02,181 : INFO : topic #0 (0.100): 0.017*\"tuesday\" + 0.017*\"first\" + 0.017*\"monday\" + 0.016*\"higher\" + 0.016*\"market\" + 0.015*\"u\" + 0.015*\"trading\" + 0.015*\"ended\" + 0.014*\"economy\" + 0.013*\"month\"\n",
      "2019-10-29 00:39:02,184 : INFO : topic #3 (0.100): 0.025*\"market\" + 0.021*\"tuesday\" + 0.017*\"ended\" + 0.014*\"first\" + 0.013*\"higher\" + 0.013*\"monday\" + 0.013*\"spring\" + 0.013*\"related\" + 0.012*\"month\" + 0.012*\"premarkets\"\n",
      "2019-10-29 00:39:02,186 : INFO : topic #1 (0.100): 0.021*\"market\" + 0.017*\"tuesday\" + 0.016*\"trading\" + 0.016*\"ended\" + 0.016*\"u\" + 0.015*\"monday\" + 0.014*\"higher\" + 0.014*\"stock\" + 0.013*\"reserve\" + 0.013*\"rose\"\n",
      "2019-10-29 00:39:02,189 : INFO : topic #6 (0.100): 0.023*\"first\" + 0.021*\"tuesday\" + 0.020*\"market\" + 0.018*\"u\" + 0.017*\"ended\" + 0.016*\"trading\" + 0.015*\"monday\" + 0.013*\"higher\" + 0.013*\"sale\" + 0.013*\"stock\"\n",
      "2019-10-29 00:39:02,192 : INFO : topic #5 (0.100): 0.020*\"ended\" + 0.019*\"tuesday\" + 0.017*\"higher\" + 0.017*\"monday\" + 0.015*\"market\" + 0.015*\"trading\" + 0.014*\"first\" + 0.012*\"tax\" + 0.012*\"u\" + 0.012*\"index\"\n",
      "2019-10-29 00:39:02,194 : INFO : topic diff=0.709952, rho=1.000000\n",
      "2019-10-29 00:39:02,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:02,632 : INFO : built Dictionary(387 unique tokens: ['although', 'dating', 'innovation', 'daniel', 'expert']...) from 5 documents (total 4045 corpus positions)\n",
      "2019-10-29 00:39:02,636 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:02,638 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:02,639 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:02,643 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:02,644 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:02,776 : INFO : -7.585 per-word bound, 192.0 perplexity estimate based on a held-out corpus of 5 documents with 4045 words\n",
      "2019-10-29 00:39:02,777 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:02,785 : INFO : topic #4 (0.100): 0.050*\"hiv\" + 0.023*\"dating\" + 0.019*\"said\" + 0.017*\"people\" + 0.016*\"user\" + 0.015*\"status\" + 0.015*\"filter\" + 0.014*\"app\" + 0.012*\"std\" + 0.011*\"could\"\n",
      "2019-10-29 00:39:02,788 : INFO : topic #1 (0.100): 0.038*\"hiv\" + 0.025*\"said\" + 0.019*\"dating\" + 0.018*\"user\" + 0.014*\"people\" + 0.014*\"could\" + 0.013*\"std\" + 0.013*\"filter\" + 0.013*\"status\" + 0.012*\"apps\"\n",
      "2019-10-29 00:39:02,790 : INFO : topic #9 (0.100): 0.053*\"hiv\" + 0.021*\"said\" + 0.020*\"people\" + 0.020*\"user\" + 0.019*\"dating\" + 0.015*\"status\" + 0.013*\"apps\" + 0.012*\"positive\" + 0.012*\"std\" + 0.011*\"app\"\n",
      "2019-10-29 00:39:02,793 : INFO : topic #2 (0.100): 0.043*\"hiv\" + 0.019*\"filter\" + 0.018*\"said\" + 0.018*\"dating\" + 0.017*\"people\" + 0.016*\"user\" + 0.016*\"std\" + 0.015*\"status\" + 0.013*\"apps\" + 0.012*\"app\"\n",
      "2019-10-29 00:39:02,795 : INFO : topic #8 (0.100): 0.058*\"hiv\" + 0.022*\"dating\" + 0.018*\"said\" + 0.017*\"user\" + 0.017*\"status\" + 0.013*\"positive\" + 0.013*\"people\" + 0.013*\"apps\" + 0.012*\"std\" + 0.012*\"negative\"\n",
      "2019-10-29 00:39:02,797 : INFO : topic diff=1.000451, rho=1.000000\n",
      "2019-10-29 00:39:03,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:03,224 : INFO : built Dictionary(262 unique tokens: ['violence', 'let', 'acceptable', 'practicing', 'democratic']...) from 5 documents (total 1715 corpus positions)\n",
      "2019-10-29 00:39:03,230 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:03,232 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:03,236 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:03,240 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:03,243 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:03,341 : INFO : -7.877 per-word bound, 235.0 perplexity estimate based on a held-out corpus of 5 documents with 1715 words\n",
      "2019-10-29 00:39:03,343 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:03,348 : INFO : topic #8 (0.100): 0.016*\"let\" + 0.014*\"president\" + 0.013*\"republican\" + 0.013*\"trump\" + 0.011*\"cnn\" + 0.011*\"political\" + 0.010*\"democrat\" + 0.010*\"many\" + 0.010*\"medium\" + 0.009*\"donald\"\n",
      "2019-10-29 00:39:03,351 : INFO : topic #2 (0.100): 0.016*\"trump\" + 0.014*\"many\" + 0.012*\"let\" + 0.012*\"republican\" + 0.011*\"president\" + 0.011*\"rhetoric\" + 0.011*\"donald\" + 0.010*\"baseball\" + 0.010*\"become\" + 0.009*\"event\"\n",
      "2019-10-29 00:39:03,353 : INFO : topic #4 (0.100): 0.017*\"trump\" + 0.016*\"president\" + 0.014*\"many\" + 0.013*\"political\" + 0.012*\"republican\" + 0.012*\"let\" + 0.011*\"medium\" + 0.010*\"democrat\" + 0.010*\"cnn\" + 0.009*\"member\"\n",
      "2019-10-29 00:39:03,355 : INFO : topic #5 (0.100): 0.019*\"president\" + 0.017*\"many\" + 0.016*\"trump\" + 0.014*\"cnn\" + 0.012*\"republican\" + 0.011*\"let\" + 0.010*\"political\" + 0.009*\"today\" + 0.009*\"rhetoric\" + 0.008*\"hate\"\n",
      "2019-10-29 00:39:03,358 : INFO : topic #3 (0.100): 0.016*\"let\" + 0.015*\"many\" + 0.014*\"president\" + 0.014*\"trump\" + 0.013*\"republican\" + 0.011*\"member\" + 0.010*\"attack\" + 0.010*\"political\" + 0.009*\"cnn\" + 0.009*\"politician\"\n",
      "2019-10-29 00:39:03,360 : INFO : topic diff=0.743598, rho=1.000000\n",
      "2019-10-29 00:39:03,838 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:03,847 : INFO : built Dictionary(670 unique tokens: ['conforming', 'let', 'energy', 'assignment', 'innovation']...) from 5 documents (total 6190 corpus positions)\n",
      "2019-10-29 00:39:03,854 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:03,856 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:03,857 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:03,861 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:03,863 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:04,048 : INFO : -8.265 per-word bound, 307.7 perplexity estimate based on a held-out corpus of 5 documents with 6190 words\n",
      "2019-10-29 00:39:04,050 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:04,061 : INFO : topic #9 (0.100): 0.046*\"school\" + 0.020*\"student\" + 0.014*\"portfolio\" + 0.012*\"said\" + 0.012*\"child\" + 0.011*\"time\" + 0.008*\"hide\" + 0.008*\"photo\" + 0.008*\"learning\" + 0.007*\"classroom\"\n",
      "2019-10-29 00:39:04,063 : INFO : topic #7 (0.100): 0.044*\"school\" + 0.022*\"student\" + 0.012*\"said\" + 0.011*\"hide\" + 0.011*\"child\" + 0.009*\"classroom\" + 0.009*\"time\" + 0.009*\"portfolio\" + 0.009*\"caption\" + 0.008*\"photo\"\n",
      "2019-10-29 00:39:04,064 : INFO : topic #2 (0.100): 0.047*\"school\" + 0.026*\"student\" + 0.011*\"time\" + 0.009*\"learning\" + 0.009*\"portfolio\" + 0.009*\"child\" + 0.009*\"said\" + 0.008*\"classroom\" + 0.008*\"traditional\" + 0.007*\"caption\"\n",
      "2019-10-29 00:39:04,067 : INFO : topic #1 (0.100): 0.045*\"school\" + 0.018*\"student\" + 0.013*\"time\" + 0.011*\"portfolio\" + 0.011*\"said\" + 0.010*\"child\" + 0.008*\"photo\" + 0.008*\"hide\" + 0.008*\"traditional\" + 0.007*\"caption\"\n",
      "2019-10-29 00:39:04,068 : INFO : topic #5 (0.100): 0.040*\"school\" + 0.027*\"student\" + 0.013*\"portfolio\" + 0.011*\"said\" + 0.009*\"time\" + 0.008*\"child\" + 0.008*\"photo\" + 0.007*\"based\" + 0.007*\"learning\" + 0.006*\"learn\"\n",
      "2019-10-29 00:39:04,070 : INFO : topic diff=0.923199, rho=1.000000\n",
      "2019-10-29 00:39:04,465 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:04,469 : INFO : built Dictionary(270 unique tokens: ['stick', 'violence', 'prime', 'supposed', 'swallow']...) from 5 documents (total 1765 corpus positions)\n",
      "2019-10-29 00:39:04,472 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:04,474 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:04,475 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:04,478 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:04,480 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:04,561 : INFO : -7.909 per-word bound, 240.3 perplexity estimate based on a held-out corpus of 5 documents with 1765 words\n",
      "2019-10-29 00:39:04,562 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:04,570 : INFO : topic #8 (0.100): 0.023*\"trump\" + 0.018*\"one\" + 0.013*\"president\" + 0.012*\"country\" + 0.012*\"week\" + 0.011*\"last\" + 0.010*\"speech\" + 0.010*\"enough\" + 0.009*\"many\" + 0.009*\"well\"\n",
      "2019-10-29 00:39:04,573 : INFO : topic #4 (0.100): 0.026*\"trump\" + 0.014*\"last\" + 0.013*\"president\" + 0.012*\"speech\" + 0.011*\"country\" + 0.010*\"week\" + 0.009*\"one\" + 0.009*\"people\" + 0.009*\"enough\" + 0.008*\"well\"\n",
      "2019-10-29 00:39:04,577 : INFO : topic #9 (0.100): 0.035*\"trump\" + 0.014*\"president\" + 0.014*\"week\" + 0.012*\"well\" + 0.011*\"last\" + 0.010*\"speech\" + 0.010*\"one\" + 0.010*\"country\" + 0.009*\"white\" + 0.008*\"enough\"\n",
      "2019-10-29 00:39:04,579 : INFO : topic #7 (0.100): 0.026*\"trump\" + 0.014*\"speech\" + 0.012*\"last\" + 0.012*\"president\" + 0.010*\"week\" + 0.010*\"well\" + 0.009*\"one\" + 0.009*\"enough\" + 0.009*\"many\" + 0.008*\"country\"\n",
      "2019-10-29 00:39:04,583 : INFO : topic #3 (0.100): 0.017*\"trump\" + 0.016*\"president\" + 0.013*\"well\" + 0.013*\"speech\" + 0.013*\"week\" + 0.011*\"last\" + 0.011*\"country\" + 0.011*\"one\" + 0.010*\"people\" + 0.009*\"even\"\n",
      "2019-10-29 00:39:04,587 : INFO : topic diff=0.734646, rho=1.000000\n",
      "2019-10-29 00:39:05,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:05,004 : INFO : built Dictionary(64 unique tokens: ['administration', 'way', 'wide', 'described', 'foreign']...) from 5 documents (total 365 corpus positions)\n",
      "2019-10-29 00:39:05,006 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:05,008 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:05,010 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:05,013 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:05,014 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:05,055 : INFO : -6.940 per-word bound, 122.8 perplexity estimate based on a held-out corpus of 5 documents with 365 words\n",
      "2019-10-29 00:39:05,057 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:05,063 : INFO : topic #0 (0.100): 0.060*\"tillerson\" + 0.040*\"president\" + 0.034*\"trump\" + 0.027*\"calling\" + 0.027*\"report\" + 0.024*\"said\" + 0.018*\"make\" + 0.016*\"dissension\" + 0.016*\"remark\" + 0.016*\"u\"\n",
      "2019-10-29 00:39:05,066 : INFO : topic #9 (0.100): 0.056*\"tillerson\" + 0.030*\"president\" + 0.030*\"calling\" + 0.026*\"report\" + 0.025*\"trump\" + 0.025*\"said\" + 0.019*\"penny\" + 0.018*\"undermine\" + 0.018*\"nonsense\" + 0.017*\"stay\"\n",
      "2019-10-29 00:39:05,069 : INFO : topic #6 (0.100): 0.048*\"tillerson\" + 0.039*\"president\" + 0.030*\"calling\" + 0.028*\"trump\" + 0.025*\"said\" + 0.019*\"u\" + 0.019*\"report\" + 0.018*\"make\" + 0.017*\"urge\" + 0.017*\"mike\"\n",
      "2019-10-29 00:39:05,072 : INFO : topic #7 (0.100): 0.043*\"tillerson\" + 0.040*\"president\" + 0.030*\"said\" + 0.026*\"calling\" + 0.023*\"trump\" + 0.021*\"report\" + 0.020*\"question\" + 0.018*\"press\" + 0.017*\"pointed\" + 0.017*\"photo\"\n",
      "2019-10-29 00:39:05,074 : INFO : topic #2 (0.100): 0.054*\"tillerson\" + 0.035*\"president\" + 0.032*\"report\" + 0.027*\"said\" + 0.027*\"trump\" + 0.021*\"calling\" + 0.018*\"wednesday\" + 0.018*\"press\" + 0.017*\"publicly\" + 0.017*\"moron\"\n",
      "2019-10-29 00:39:05,077 : INFO : topic diff=0.648443, rho=1.000000\n",
      "2019-10-29 00:39:05,529 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:05,533 : INFO : built Dictionary(115 unique tokens: ['special', 'way', 'series', 'harrison', 'one']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:39:05,536 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:05,539 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:05,541 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:05,544 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:05,546 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:05,606 : INFO : -7.467 per-word bound, 176.9 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:39:05,608 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:05,614 : INFO : topic #3 (0.100): 0.036*\"blade\" + 0.022*\"runner\" + 0.018*\"westworld\" + 0.017*\"character\" + 0.016*\"k\" + 0.015*\"original\" + 0.014*\"movie\" + 0.013*\"even\" + 0.010*\"hbo\" + 0.010*\"viewpoint\"\n",
      "2019-10-29 00:39:05,617 : INFO : topic #9 (0.100): 0.036*\"blade\" + 0.030*\"runner\" + 0.027*\"westworld\" + 0.017*\"even\" + 0.015*\"k\" + 0.013*\"character\" + 0.013*\"original\" + 0.012*\"movie\" + 0.011*\"quite\" + 0.010*\"first\"\n",
      "2019-10-29 00:39:05,620 : INFO : topic #7 (0.100): 0.030*\"runner\" + 0.027*\"blade\" + 0.019*\"westworld\" + 0.017*\"original\" + 0.015*\"movie\" + 0.015*\"character\" + 0.015*\"even\" + 0.013*\"k\" + 0.011*\"artificial\" + 0.011*\"might\"\n",
      "2019-10-29 00:39:05,624 : INFO : topic #6 (0.100): 0.031*\"blade\" + 0.030*\"runner\" + 0.018*\"westworld\" + 0.017*\"k\" + 0.016*\"original\" + 0.015*\"character\" + 0.014*\"even\" + 0.014*\"movie\" + 0.011*\"amusement\" + 0.010*\"replicant\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:05,627 : INFO : topic #5 (0.100): 0.029*\"runner\" + 0.026*\"blade\" + 0.021*\"westworld\" + 0.017*\"character\" + 0.017*\"original\" + 0.014*\"k\" + 0.014*\"even\" + 0.013*\"movie\" + 0.011*\"plot\" + 0.011*\"creation\"\n",
      "2019-10-29 00:39:05,629 : INFO : topic diff=0.642877, rho=1.000000\n",
      "2019-10-29 00:39:06,019 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:06,021 : INFO : built Dictionary(47 unique tokens: ['creating', 'dating', 'comparing', 'time', 'focus']...) from 5 documents (total 310 corpus positions)\n",
      "2019-10-29 00:39:06,023 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:06,024 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:06,026 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:06,027 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:06,029 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:06,056 : INFO : -6.404 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 310 words\n",
      "2019-10-29 00:39:06,058 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:06,067 : INFO : topic #9 (0.100): 0.043*\"build\" + 0.042*\"wolfe\" + 0.039*\"austin\" + 0.038*\"next\" + 0.037*\"make\" + 0.036*\"allowed\" + 0.034*\"company\" + 0.034*\"said\" + 0.031*\"u\" + 0.028*\"versus\"\n",
      "2019-10-29 00:39:06,070 : INFO : topic #7 (0.100): 0.057*\"build\" + 0.045*\"wolfe\" + 0.044*\"company\" + 0.044*\"austin\" + 0.039*\"make\" + 0.034*\"next\" + 0.033*\"would\" + 0.033*\"u\" + 0.027*\"said\" + 0.025*\"versus\"\n",
      "2019-10-29 00:39:06,072 : INFO : topic #5 (0.100): 0.055*\"austin\" + 0.039*\"company\" + 0.037*\"build\" + 0.037*\"wolfe\" + 0.037*\"said\" + 0.034*\"versus\" + 0.034*\"make\" + 0.031*\"u\" + 0.030*\"would\" + 0.029*\"allowed\"\n",
      "2019-10-29 00:39:06,075 : INFO : topic #1 (0.100): 0.060*\"company\" + 0.051*\"austin\" + 0.042*\"versus\" + 0.042*\"wolfe\" + 0.038*\"said\" + 0.035*\"next\" + 0.034*\"build\" + 0.033*\"would\" + 0.033*\"u\" + 0.030*\"allowed\"\n",
      "2019-10-29 00:39:06,080 : INFO : topic #2 (0.100): 0.051*\"wolfe\" + 0.047*\"build\" + 0.039*\"austin\" + 0.038*\"company\" + 0.034*\"make\" + 0.032*\"versus\" + 0.032*\"would\" + 0.030*\"next\" + 0.029*\"allowed\" + 0.025*\"said\"\n",
      "2019-10-29 00:39:06,083 : INFO : topic diff=0.710132, rho=1.000000\n",
      "2019-10-29 00:39:06,526 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:06,530 : INFO : built Dictionary(290 unique tokens: ['relation', 'end', 'party', 'come', 'recent']...) from 5 documents (total 1940 corpus positions)\n",
      "2019-10-29 00:39:06,533 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:06,535 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:06,539 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:06,545 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:06,548 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:06,654 : INFO : -7.934 per-word bound, 244.6 perplexity estimate based on a held-out corpus of 5 documents with 1940 words\n",
      "2019-10-29 00:39:06,656 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:06,663 : INFO : topic #8 (0.100): 0.031*\"turkey\" + 0.027*\"turkish\" + 0.019*\"united\" + 0.018*\"u\" + 0.016*\"state\" + 0.012*\"erdogan\" + 0.011*\"syrian\" + 0.010*\"russia\" + 0.009*\"gulen\" + 0.009*\"fethullah\"\n",
      "2019-10-29 00:39:06,665 : INFO : topic #4 (0.100): 0.021*\"turkey\" + 0.021*\"state\" + 0.019*\"united\" + 0.019*\"u\" + 0.018*\"turkish\" + 0.013*\"erdogan\" + 0.010*\"gulen\" + 0.009*\"russia\" + 0.009*\"syrian\" + 0.008*\"relation\"\n",
      "2019-10-29 00:39:06,668 : INFO : topic #9 (0.100): 0.027*\"turkey\" + 0.022*\"state\" + 0.021*\"turkish\" + 0.018*\"erdogan\" + 0.017*\"u\" + 0.013*\"united\" + 0.009*\"gulen\" + 0.009*\"policy\" + 0.009*\"friend\" + 0.009*\"russia\"\n",
      "2019-10-29 00:39:06,670 : INFO : topic #7 (0.100): 0.038*\"turkey\" + 0.021*\"united\" + 0.020*\"u\" + 0.018*\"turkish\" + 0.018*\"state\" + 0.014*\"erdogan\" + 0.012*\"russia\" + 0.009*\"gulen\" + 0.009*\"syrian\" + 0.008*\"relation\"\n",
      "2019-10-29 00:39:06,672 : INFO : topic #2 (0.100): 0.045*\"turkey\" + 0.024*\"turkish\" + 0.020*\"united\" + 0.017*\"u\" + 0.015*\"state\" + 0.012*\"erdogan\" + 0.010*\"syrian\" + 0.010*\"friend\" + 0.008*\"extradition\" + 0.008*\"gulen\"\n",
      "2019-10-29 00:39:06,675 : INFO : topic diff=0.774441, rho=1.000000\n",
      "2019-10-29 00:39:07,056 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:07,058 : INFO : built Dictionary(72 unique tokens: ['blocked', 'fox', 'story', 'weinstein', 'prominent']...) from 5 documents (total 470 corpus positions)\n",
      "2019-10-29 00:39:07,059 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:07,061 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:07,062 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:07,064 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:07,066 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:07,113 : INFO : -6.755 per-word bound, 108.0 perplexity estimate based on a held-out corpus of 5 documents with 470 words\n",
      "2019-10-29 00:39:07,116 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:07,125 : INFO : topic #8 (0.100): 0.050*\"sivan\" + 0.046*\"said\" + 0.030*\"weinstein\" + 0.026*\"story\" + 0.025*\"brought\" + 0.023*\"accuser\" + 0.023*\"secret\" + 0.022*\"restaurant\" + 0.020*\"new\" + 0.020*\"anyone\"\n",
      "2019-10-29 00:39:07,128 : INFO : topic #1 (0.100): 0.044*\"sivan\" + 0.037*\"said\" + 0.026*\"weinstein\" + 0.025*\"story\" + 0.025*\"new\" + 0.023*\"restaurant\" + 0.022*\"many\" + 0.021*\"camerota\" + 0.021*\"cnn\" + 0.020*\"told\"\n",
      "2019-10-29 00:39:07,131 : INFO : topic #2 (0.100): 0.038*\"sivan\" + 0.036*\"weinstein\" + 0.035*\"said\" + 0.026*\"new\" + 0.026*\"story\" + 0.026*\"many\" + 0.024*\"camerota\" + 0.022*\"anyone\" + 0.021*\"accuser\" + 0.020*\"harvey\"\n",
      "2019-10-29 00:39:07,139 : INFO : topic #0 (0.100): 0.054*\"sivan\" + 0.039*\"said\" + 0.034*\"story\" + 0.024*\"secret\" + 0.024*\"anyone\" + 0.023*\"weinstein\" + 0.023*\"told\" + 0.020*\"camerota\" + 0.020*\"harvey\" + 0.019*\"cnn\"\n",
      "2019-10-29 00:39:07,147 : INFO : topic #4 (0.100): 0.050*\"sivan\" + 0.040*\"said\" + 0.031*\"story\" + 0.029*\"weinstein\" + 0.026*\"told\" + 0.022*\"brought\" + 0.022*\"cnn\" + 0.022*\"accuser\" + 0.021*\"anyone\" + 0.020*\"secret\"\n",
      "2019-10-29 00:39:07,150 : INFO : topic diff=0.722867, rho=1.000000\n",
      "2019-10-29 00:39:07,534 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:07,536 : INFO : built Dictionary(75 unique tokens: ['online', 'help', 'deadly', 'reconnect', 'come']...) from 5 documents (total 495 corpus positions)\n",
      "2019-10-29 00:39:07,538 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:07,539 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:07,541 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:07,543 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:07,545 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:07,582 : INFO : -6.769 per-word bound, 109.1 perplexity estimate based on a held-out corpus of 5 documents with 495 words\n",
      "2019-10-29 00:39:07,584 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:07,591 : INFO : topic #7 (0.100): 0.044*\"john\" + 0.038*\"homeless\" + 0.037*\"help\" + 0.028*\"samuel\" + 0.027*\"say\" + 0.026*\"group\" + 0.023*\"alaska\" + 0.022*\"anchorage\" + 0.021*\"started\" + 0.020*\"family\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:07,594 : INFO : topic #8 (0.100): 0.056*\"john\" + 0.046*\"help\" + 0.032*\"homeless\" + 0.030*\"samuel\" + 0.029*\"group\" + 0.029*\"say\" + 0.022*\"member\" + 0.022*\"individual\" + 0.019*\"facebook\" + 0.018*\"family\"\n",
      "2019-10-29 00:39:07,596 : INFO : topic #4 (0.100): 0.045*\"john\" + 0.038*\"homeless\" + 0.035*\"help\" + 0.028*\"samuel\" + 0.026*\"started\" + 0.026*\"facebook\" + 0.025*\"group\" + 0.024*\"individual\" + 0.023*\"say\" + 0.020*\"forget\"\n",
      "2019-10-29 00:39:07,599 : INFO : topic #6 (0.100): 0.041*\"john\" + 0.041*\"homeless\" + 0.034*\"group\" + 0.030*\"help\" + 0.028*\"say\" + 0.026*\"samuel\" + 0.024*\"member\" + 0.023*\"alaska\" + 0.022*\"family\" + 0.020*\"forget\"\n",
      "2019-10-29 00:39:07,601 : INFO : topic #1 (0.100): 0.042*\"help\" + 0.039*\"homeless\" + 0.032*\"group\" + 0.031*\"john\" + 0.024*\"say\" + 0.022*\"family\" + 0.021*\"anchorage\" + 0.021*\"started\" + 0.021*\"individual\" + 0.020*\"samuel\"\n",
      "2019-10-29 00:39:07,604 : INFO : topic diff=0.761790, rho=1.000000\n",
      "2019-10-29 00:39:08,006 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:08,009 : INFO : built Dictionary(129 unique tokens: ['trying', 'praised', 'sit', 'making', 'u']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:39:08,012 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:08,013 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:08,014 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:08,017 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:08,022 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:08,073 : INFO : -6.787 per-word bound, 110.4 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:39:08,074 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:08,080 : INFO : topic #4 (0.100): 0.046*\"nfl\" + 0.045*\"player\" + 0.032*\"anthem\" + 0.032*\"national\" + 0.026*\"goodell\" + 0.026*\"trump\" + 0.024*\"stand\" + 0.021*\"protest\" + 0.021*\"said\" + 0.016*\"league\"\n",
      "2019-10-29 00:39:08,081 : INFO : topic #3 (0.100): 0.045*\"player\" + 0.038*\"nfl\" + 0.037*\"anthem\" + 0.030*\"protest\" + 0.028*\"goodell\" + 0.024*\"national\" + 0.023*\"said\" + 0.023*\"trump\" + 0.019*\"stand\" + 0.018*\"commissioner\"\n",
      "2019-10-29 00:39:08,085 : INFO : topic #1 (0.100): 0.049*\"player\" + 0.040*\"anthem\" + 0.040*\"nfl\" + 0.027*\"trump\" + 0.027*\"goodell\" + 0.027*\"stand\" + 0.025*\"protest\" + 0.024*\"said\" + 0.023*\"national\" + 0.020*\"commissioner\"\n",
      "2019-10-29 00:39:08,089 : INFO : topic #9 (0.100): 0.050*\"player\" + 0.050*\"anthem\" + 0.037*\"nfl\" + 0.028*\"said\" + 0.028*\"trump\" + 0.025*\"protest\" + 0.024*\"goodell\" + 0.022*\"national\" + 0.020*\"commissioner\" + 0.019*\"letter\"\n",
      "2019-10-29 00:39:08,093 : INFO : topic #5 (0.100): 0.048*\"nfl\" + 0.039*\"player\" + 0.036*\"anthem\" + 0.035*\"trump\" + 0.030*\"said\" + 0.023*\"stand\" + 0.023*\"protest\" + 0.022*\"goodell\" + 0.022*\"commissioner\" + 0.020*\"national\"\n",
      "2019-10-29 00:39:08,096 : INFO : topic diff=0.905533, rho=1.000000\n",
      "2019-10-29 00:39:08,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:08,519 : INFO : built Dictionary(406 unique tokens: ['although', 'size', 'drinking', 'burly', 'perhaps']...) from 5 documents (total 3245 corpus positions)\n",
      "2019-10-29 00:39:08,523 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:08,525 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:08,526 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:08,531 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:08,532 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:08,665 : INFO : -7.968 per-word bound, 250.4 perplexity estimate based on a held-out corpus of 5 documents with 3245 words\n",
      "2019-10-29 00:39:08,666 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:08,673 : INFO : topic #6 (0.100): 0.034*\"celebrity\" + 0.033*\"photo\" + 0.027*\"caption\" + 0.026*\"hide\" + 0.025*\"transformation\" + 0.014*\"pound\" + 0.010*\"weight\" + 0.010*\"said\" + 0.010*\"lost\" + 0.009*\"left\"\n",
      "2019-10-29 00:39:08,676 : INFO : topic #3 (0.100): 0.038*\"caption\" + 0.037*\"photo\" + 0.036*\"celebrity\" + 0.033*\"transformation\" + 0.032*\"hide\" + 0.012*\"weight\" + 0.010*\"star\" + 0.010*\"lost\" + 0.009*\"actor\" + 0.008*\"pound\"\n",
      "2019-10-29 00:39:08,678 : INFO : topic #5 (0.100): 0.038*\"hide\" + 0.037*\"photo\" + 0.036*\"transformation\" + 0.028*\"celebrity\" + 0.022*\"caption\" + 0.015*\"pound\" + 0.015*\"lost\" + 0.012*\"weight\" + 0.009*\"star\" + 0.009*\"left\"\n",
      "2019-10-29 00:39:08,681 : INFO : topic #4 (0.100): 0.037*\"photo\" + 0.034*\"transformation\" + 0.031*\"caption\" + 0.030*\"celebrity\" + 0.030*\"hide\" + 0.012*\"pound\" + 0.012*\"lost\" + 0.011*\"weight\" + 0.010*\"star\" + 0.009*\"said\"\n",
      "2019-10-29 00:39:08,683 : INFO : topic #8 (0.100): 0.035*\"transformation\" + 0.033*\"photo\" + 0.029*\"hide\" + 0.029*\"caption\" + 0.027*\"celebrity\" + 0.012*\"weight\" + 0.012*\"lost\" + 0.010*\"left\" + 0.010*\"pound\" + 0.008*\"new\"\n",
      "2019-10-29 00:39:08,686 : INFO : topic diff=0.896265, rho=1.000000\n",
      "2019-10-29 00:39:09,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:09,077 : INFO : built Dictionary(83 unique tokens: ['b', 'military', 'bomber', 'simulated', 'warplane']...) from 5 documents (total 845 corpus positions)\n",
      "2019-10-29 00:39:09,080 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:09,082 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:09,083 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:09,085 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:09,086 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:09,121 : INFO : -6.190 per-word bound, 73.0 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:39:09,124 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:09,128 : INFO : topic #0 (0.100): 0.060*\"force\" + 0.051*\"south\" + 0.048*\"korean\" + 0.043*\"air\" + 0.041*\"u\" + 0.039*\"bomber\" + 0.036*\"said\" + 0.028*\"korea\" + 0.028*\"drill\" + 0.026*\"b\"\n",
      "2019-10-29 00:39:09,131 : INFO : topic #9 (0.100): 0.055*\"force\" + 0.050*\"korean\" + 0.045*\"u\" + 0.038*\"air\" + 0.036*\"said\" + 0.033*\"south\" + 0.033*\"military\" + 0.032*\"drill\" + 0.032*\"bomber\" + 0.030*\"korea\"\n",
      "2019-10-29 00:39:09,133 : INFO : topic #6 (0.100): 0.068*\"force\" + 0.055*\"korean\" + 0.046*\"u\" + 0.039*\"air\" + 0.038*\"south\" + 0.033*\"military\" + 0.027*\"bomber\" + 0.026*\"said\" + 0.024*\"drill\" + 0.024*\"peninsula\"\n",
      "2019-10-29 00:39:09,136 : INFO : topic #7 (0.100): 0.054*\"u\" + 0.051*\"korean\" + 0.048*\"force\" + 0.046*\"south\" + 0.033*\"air\" + 0.033*\"military\" + 0.030*\"bomber\" + 0.030*\"said\" + 0.026*\"drill\" + 0.022*\"exercise\"\n",
      "2019-10-29 00:39:09,140 : INFO : topic #4 (0.100): 0.068*\"korean\" + 0.047*\"south\" + 0.043*\"u\" + 0.041*\"said\" + 0.039*\"force\" + 0.036*\"air\" + 0.031*\"bomber\" + 0.029*\"peninsula\" + 0.025*\"b\" + 0.024*\"military\"\n",
      "2019-10-29 00:39:09,142 : INFO : topic diff=1.034417, rho=1.000000\n",
      "2019-10-29 00:39:09,572 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:09,576 : INFO : built Dictionary(236 unique tokens: ['school', 'sticker', 'campaign', 'focus', 'proud']...) from 5 documents (total 1995 corpus positions)\n",
      "2019-10-29 00:39:09,580 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:09,583 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:09,586 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:09,591 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:09,594 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:09,699 : INFO : -7.379 per-word bound, 166.4 perplexity estimate based on a held-out corpus of 5 documents with 1995 words\n",
      "2019-10-29 00:39:09,701 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:09,708 : INFO : topic #3 (0.100): 0.037*\"trump\" + 0.027*\"moss\" + 0.023*\"health\" + 0.020*\"said\" + 0.020*\"campaign\" + 0.017*\"bill\" + 0.015*\"treatment\" + 0.015*\"son\" + 0.014*\"last\" + 0.012*\"people\"\n",
      "2019-10-29 00:39:09,710 : INFO : topic #6 (0.100): 0.037*\"trump\" + 0.031*\"moss\" + 0.024*\"health\" + 0.017*\"said\" + 0.017*\"campaign\" + 0.017*\"bill\" + 0.015*\"son\" + 0.012*\"year\" + 0.012*\"care\" + 0.012*\"treatment\"\n",
      "2019-10-29 00:39:09,713 : INFO : topic #0 (0.100): 0.049*\"trump\" + 0.039*\"moss\" + 0.021*\"health\" + 0.020*\"campaign\" + 0.017*\"said\" + 0.017*\"bill\" + 0.015*\"treatment\" + 0.014*\"service\" + 0.014*\"last\" + 0.011*\"year\"\n",
      "2019-10-29 00:39:09,716 : INFO : topic #8 (0.100): 0.043*\"trump\" + 0.028*\"moss\" + 0.026*\"health\" + 0.020*\"said\" + 0.018*\"bill\" + 0.016*\"last\" + 0.016*\"treatment\" + 0.014*\"son\" + 0.014*\"campaign\" + 0.013*\"year\"\n",
      "2019-10-29 00:39:09,719 : INFO : topic #5 (0.100): 0.047*\"trump\" + 0.033*\"moss\" + 0.017*\"said\" + 0.016*\"health\" + 0.015*\"treatment\" + 0.015*\"campaign\" + 0.015*\"son\" + 0.015*\"last\" + 0.013*\"bill\" + 0.012*\"year\"\n",
      "2019-10-29 00:39:09,721 : INFO : topic diff=0.849218, rho=1.000000\n",
      "2019-10-29 00:39:10,178 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:10,181 : INFO : built Dictionary(178 unique tokens: ['consent', 'watch', 'let', 'mayor', 'job']...) from 5 documents (total 1500 corpus positions)\n",
      "2019-10-29 00:39:10,184 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:10,185 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:10,187 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:10,190 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:10,191 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:10,250 : INFO : -7.120 per-word bound, 139.1 perplexity estimate based on a held-out corpus of 5 documents with 1500 words\n",
      "2019-10-29 00:39:10,252 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:10,257 : INFO : topic #9 (0.100): 0.043*\"police\" + 0.031*\"officer\" + 0.026*\"payne\" + 0.023*\"said\" + 0.018*\"blood\" + 0.017*\"wubbels\" + 0.017*\"nurse\" + 0.014*\"patient\" + 0.014*\"policy\" + 0.012*\"lake\"\n",
      "2019-10-29 00:39:10,259 : INFO : topic #6 (0.100): 0.043*\"police\" + 0.030*\"officer\" + 0.025*\"said\" + 0.023*\"payne\" + 0.020*\"blood\" + 0.018*\"nurse\" + 0.017*\"wubbels\" + 0.013*\"patient\" + 0.013*\"policy\" + 0.012*\"city\"\n",
      "2019-10-29 00:39:10,262 : INFO : topic #5 (0.100): 0.045*\"police\" + 0.028*\"payne\" + 0.027*\"officer\" + 0.025*\"said\" + 0.019*\"blood\" + 0.018*\"nurse\" + 0.017*\"wubbels\" + 0.015*\"patient\" + 0.013*\"hospital\" + 0.013*\"utah\"\n",
      "2019-10-29 00:39:10,264 : INFO : topic #4 (0.100): 0.040*\"police\" + 0.035*\"said\" + 0.029*\"payne\" + 0.027*\"officer\" + 0.022*\"blood\" + 0.019*\"wubbels\" + 0.016*\"hospital\" + 0.014*\"nurse\" + 0.012*\"city\" + 0.011*\"patient\"\n",
      "2019-10-29 00:39:10,266 : INFO : topic #3 (0.100): 0.039*\"police\" + 0.033*\"officer\" + 0.026*\"said\" + 0.023*\"payne\" + 0.021*\"nurse\" + 0.018*\"blood\" + 0.017*\"wubbels\" + 0.014*\"policy\" + 0.012*\"car\" + 0.012*\"department\"\n",
      "2019-10-29 00:39:10,268 : INFO : topic diff=0.844604, rho=1.000000\n",
      "2019-10-29 00:39:10,649 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:10,651 : INFO : built Dictionary(102 unique tokens: ['portion', 'size', 'milk', 'may', 'calorie']...) from 5 documents (total 745 corpus positions)\n",
      "2019-10-29 00:39:10,653 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:10,654 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:10,656 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:10,658 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:10,659 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:10,703 : INFO : -6.846 per-word bound, 115.1 perplexity estimate based on a held-out corpus of 5 documents with 745 words\n",
      "2019-10-29 00:39:10,704 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:10,711 : INFO : topic #8 (0.100): 0.073*\"chocolate\" + 0.044*\"flavanols\" + 0.036*\"dark\" + 0.034*\"cocoa\" + 0.025*\"flavor\" + 0.023*\"compound\" + 0.019*\"lower\" + 0.016*\"health\" + 0.016*\"including\" + 0.015*\"make\"\n",
      "2019-10-29 00:39:10,713 : INFO : topic #3 (0.100): 0.057*\"chocolate\" + 0.037*\"dark\" + 0.033*\"flavanols\" + 0.032*\"cocoa\" + 0.026*\"flavor\" + 0.022*\"compound\" + 0.018*\"lower\" + 0.016*\"blood\" + 0.016*\"hartings\" + 0.015*\"improve\"\n",
      "2019-10-29 00:39:10,716 : INFO : topic #5 (0.100): 0.046*\"chocolate\" + 0.046*\"flavanols\" + 0.030*\"cocoa\" + 0.028*\"compound\" + 0.028*\"dark\" + 0.023*\"flavor\" + 0.017*\"lower\" + 0.015*\"cognition\" + 0.015*\"cholesterol\" + 0.014*\"pressure\"\n",
      "2019-10-29 00:39:10,719 : INFO : topic #7 (0.100): 0.071*\"chocolate\" + 0.041*\"dark\" + 0.034*\"cocoa\" + 0.028*\"flavanols\" + 0.023*\"flavor\" + 0.022*\"compound\" + 0.015*\"lower\" + 0.015*\"shown\" + 0.015*\"cholesterol\" + 0.014*\"give\"\n",
      "2019-10-29 00:39:10,721 : INFO : topic #2 (0.100): 0.064*\"chocolate\" + 0.039*\"dark\" + 0.036*\"flavanols\" + 0.026*\"cocoa\" + 0.025*\"flavor\" + 0.023*\"compound\" + 0.022*\"lower\" + 0.017*\"pressure\" + 0.017*\"make\" + 0.014*\"give\"\n",
      "2019-10-29 00:39:10,724 : INFO : topic diff=0.802571, rho=1.000000\n",
      "2019-10-29 00:39:11,104 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:11,106 : INFO : built Dictionary(20 unique tokens: ['give', 'vega', '32nd', 'account', 'goer']...) from 5 documents (total 120 corpus positions)\n",
      "2019-10-29 00:39:11,108 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:11,112 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:11,115 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:11,119 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:11,122 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:11,138 : INFO : -6.088 per-word bound, 68.0 perplexity estimate based on a held-out corpus of 5 documents with 120 words\n",
      "2019-10-29 00:39:11,144 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:11,150 : INFO : topic #8 (0.100): 0.091*\"account\" + 0.080*\"give\" + 0.072*\"hotel\" + 0.071*\"worker\" + 0.054*\"goer\" + 0.051*\"vega\" + 0.048*\"stephen\" + 0.046*\"bay\" + 0.046*\"resort\" + 0.044*\"fired\"\n",
      "2019-10-29 00:39:11,152 : INFO : topic #3 (0.100): 0.092*\"worker\" + 0.091*\"hotel\" + 0.074*\"account\" + 0.066*\"give\" + 0.056*\"happened\" + 0.052*\"bay\" + 0.051*\"floor\" + 0.045*\"casino\" + 0.044*\"vega\" + 0.044*\"crowd\"\n",
      "2019-10-29 00:39:11,155 : INFO : topic #6 (0.100): 0.084*\"worker\" + 0.075*\"hotel\" + 0.065*\"give\" + 0.062*\"account\" + 0.057*\"maintenance\" + 0.053*\"crowd\" + 0.051*\"concert\" + 0.051*\"happened\" + 0.048*\"fired\" + 0.046*\"mandalay\"\n",
      "2019-10-29 00:39:11,164 : INFO : topic #7 (0.100): 0.093*\"give\" + 0.092*\"worker\" + 0.077*\"hotel\" + 0.070*\"account\" + 0.051*\"maintenance\" + 0.047*\"crowd\" + 0.047*\"concert\" + 0.047*\"floor\" + 0.047*\"bay\" + 0.042*\"goer\"\n",
      "2019-10-29 00:39:11,167 : INFO : topic #1 (0.100): 0.087*\"give\" + 0.085*\"account\" + 0.075*\"worker\" + 0.069*\"hotel\" + 0.048*\"stephen\" + 0.048*\"casino\" + 0.047*\"resort\" + 0.046*\"fired\" + 0.045*\"crowd\" + 0.044*\"floor\"\n",
      "2019-10-29 00:39:11,170 : INFO : topic diff=0.638892, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:11,595 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:11,606 : INFO : built Dictionary(218 unique tokens: ['school', 'reinforce', 'book', 'happy', 'rather']...) from 5 documents (total 1595 corpus positions)\n",
      "2019-10-29 00:39:11,611 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:11,615 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:11,619 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:11,623 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:11,629 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:11,699 : INFO : -7.520 per-word bound, 183.5 perplexity estimate based on a held-out corpus of 5 documents with 1595 words\n",
      "2019-10-29 00:39:11,701 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:11,707 : INFO : topic #3 (0.100): 0.038*\"kid\" + 0.020*\"something\" + 0.016*\"game\" + 0.014*\"character\" + 0.014*\"medium\" + 0.013*\"social\" + 0.012*\"important\" + 0.011*\"perseverance\" + 0.010*\"share\" + 0.010*\"twitter\"\n",
      "2019-10-29 00:39:11,709 : INFO : topic #9 (0.100): 0.029*\"kid\" + 0.019*\"medium\" + 0.014*\"game\" + 0.014*\"character\" + 0.011*\"something\" + 0.011*\"social\" + 0.010*\"share\" + 0.010*\"different\" + 0.010*\"hope\" + 0.010*\"twitter\"\n",
      "2019-10-29 00:39:11,712 : INFO : topic #5 (0.100): 0.027*\"kid\" + 0.017*\"medium\" + 0.017*\"character\" + 0.013*\"share\" + 0.012*\"social\" + 0.012*\"video\" + 0.011*\"something\" + 0.011*\"work\" + 0.010*\"facebook\" + 0.010*\"game\"\n",
      "2019-10-29 00:39:11,715 : INFO : topic #0 (0.100): 0.025*\"kid\" + 0.017*\"medium\" + 0.013*\"social\" + 0.012*\"game\" + 0.011*\"facebook\" + 0.011*\"character\" + 0.011*\"twitter\" + 0.010*\"something\" + 0.010*\"share\" + 0.010*\"hope\"\n",
      "2019-10-29 00:39:11,717 : INFO : topic #6 (0.100): 0.035*\"kid\" + 0.017*\"medium\" + 0.015*\"game\" + 0.013*\"character\" + 0.011*\"communication\" + 0.011*\"something\" + 0.011*\"teamwork\" + 0.010*\"social\" + 0.010*\"point\" + 0.010*\"different\"\n",
      "2019-10-29 00:39:11,720 : INFO : topic diff=0.767844, rho=1.000000\n",
      "2019-10-29 00:39:12,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:12,141 : INFO : built Dictionary(313 unique tokens: ['previously', 'shell', 'perhaps', 'tax', 'campaign']...) from 5 documents (total 2445 corpus positions)\n",
      "2019-10-29 00:39:12,145 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:12,146 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:12,148 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:12,153 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:12,156 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:12,257 : INFO : -7.755 per-word bound, 216.0 perplexity estimate based on a held-out corpus of 5 documents with 2445 words\n",
      "2019-10-29 00:39:12,258 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:12,265 : INFO : topic #3 (0.100): 0.034*\"trump\" + 0.024*\"eminem\" + 0.019*\"cause\" + 0.013*\"president\" + 0.011*\"war\" + 0.011*\"like\" + 0.009*\"line\" + 0.009*\"freestyle\" + 0.008*\"come\" + 0.008*\"tax\"\n",
      "2019-10-29 00:39:12,267 : INFO : topic #0 (0.100): 0.035*\"trump\" + 0.022*\"eminem\" + 0.021*\"cause\" + 0.013*\"president\" + 0.011*\"like\" + 0.010*\"war\" + 0.009*\"attack\" + 0.008*\"come\" + 0.008*\"tax\" + 0.008*\"verse\"\n",
      "2019-10-29 00:39:12,270 : INFO : topic #6 (0.100): 0.029*\"cause\" + 0.027*\"trump\" + 0.016*\"come\" + 0.016*\"eminem\" + 0.015*\"president\" + 0.010*\"like\" + 0.010*\"war\" + 0.009*\"verse\" + 0.008*\"rapper\" + 0.008*\"kaepernick\"\n",
      "2019-10-29 00:39:12,272 : INFO : topic #7 (0.100): 0.031*\"trump\" + 0.026*\"eminem\" + 0.017*\"cause\" + 0.011*\"war\" + 0.011*\"president\" + 0.009*\"come\" + 0.009*\"rapper\" + 0.008*\"freestyle\" + 0.008*\"line\" + 0.008*\"tax\"\n",
      "2019-10-29 00:39:12,275 : INFO : topic #4 (0.100): 0.031*\"trump\" + 0.022*\"cause\" + 0.022*\"eminem\" + 0.014*\"like\" + 0.014*\"come\" + 0.013*\"president\" + 0.009*\"war\" + 0.008*\"b\" + 0.008*\"freestyle\" + 0.008*\"full\"\n",
      "2019-10-29 00:39:12,278 : INFO : topic diff=0.793113, rho=1.000000\n",
      "2019-10-29 00:39:12,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:12,726 : INFO : built Dictionary(244 unique tokens: ['dating', 'inbox', 'happy', 'advantage', 'settling']...) from 5 documents (total 2110 corpus positions)\n",
      "2019-10-29 00:39:12,732 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:12,735 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:12,738 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:12,742 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:12,745 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:12,857 : INFO : -7.371 per-word bound, 165.5 perplexity estimate based on a held-out corpus of 5 documents with 2110 words\n",
      "2019-10-29 00:39:12,859 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:12,866 : INFO : topic #0 (0.100): 0.058*\"woman\" + 0.035*\"make\" + 0.032*\"move\" + 0.026*\"first\" + 0.019*\"men\" + 0.016*\"dating\" + 0.016*\"go\" + 0.014*\"said\" + 0.014*\"message\" + 0.013*\"get\"\n",
      "2019-10-29 00:39:12,868 : INFO : topic #8 (0.100): 0.051*\"woman\" + 0.036*\"make\" + 0.032*\"first\" + 0.027*\"move\" + 0.021*\"dating\" + 0.018*\"said\" + 0.018*\"message\" + 0.015*\"men\" + 0.015*\"get\" + 0.015*\"want\"\n",
      "2019-10-29 00:39:12,871 : INFO : topic #9 (0.100): 0.067*\"woman\" + 0.041*\"first\" + 0.032*\"move\" + 0.030*\"make\" + 0.023*\"men\" + 0.019*\"said\" + 0.016*\"message\" + 0.013*\"dating\" + 0.012*\"want\" + 0.012*\"get\"\n",
      "2019-10-29 00:39:12,873 : INFO : topic #4 (0.100): 0.059*\"woman\" + 0.046*\"first\" + 0.038*\"make\" + 0.030*\"move\" + 0.017*\"said\" + 0.016*\"dating\" + 0.016*\"men\" + 0.013*\"want\" + 0.013*\"get\" + 0.012*\"message\"\n",
      "2019-10-29 00:39:12,876 : INFO : topic #3 (0.100): 0.068*\"woman\" + 0.050*\"first\" + 0.030*\"make\" + 0.030*\"move\" + 0.015*\"said\" + 0.015*\"message\" + 0.015*\"men\" + 0.014*\"go\" + 0.014*\"want\" + 0.013*\"dating\"\n",
      "2019-10-29 00:39:12,878 : INFO : topic diff=0.933117, rho=1.000000\n",
      "2019-10-29 00:39:13,287 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:13,292 : INFO : built Dictionary(178 unique tokens: ['let', 'energy', 'happy', 'cañete', 'new']...) from 5 documents (total 1405 corpus positions)\n",
      "2019-10-29 00:39:13,297 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:13,300 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:13,302 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:13,305 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:13,308 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:13,367 : INFO : -7.219 per-word bound, 149.0 perplexity estimate based on a held-out corpus of 5 documents with 1405 words\n",
      "2019-10-29 00:39:13,369 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:13,375 : INFO : topic #7 (0.100): 0.034*\"car\" + 0.026*\"electric\" + 0.026*\"said\" + 0.026*\"emission\" + 0.023*\"new\" + 0.018*\"vehicle\" + 0.016*\"require\" + 0.013*\"co2\" + 0.012*\"target\" + 0.012*\"european\"\n",
      "2019-10-29 00:39:13,377 : INFO : topic #5 (0.100): 0.035*\"car\" + 0.032*\"emission\" + 0.026*\"electric\" + 0.022*\"vehicle\" + 0.022*\"said\" + 0.021*\"new\" + 0.014*\"automaker\" + 0.013*\"co2\" + 0.012*\"nissan\" + 0.012*\"target\"\n",
      "2019-10-29 00:39:13,380 : INFO : topic #0 (0.100): 0.038*\"car\" + 0.035*\"emission\" + 0.031*\"new\" + 0.027*\"vehicle\" + 0.025*\"electric\" + 0.022*\"said\" + 0.015*\"co2\" + 0.012*\"target\" + 0.012*\"automaker\" + 0.012*\"require\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:13,382 : INFO : topic #4 (0.100): 0.043*\"car\" + 0.028*\"emission\" + 0.026*\"said\" + 0.026*\"new\" + 0.025*\"electric\" + 0.019*\"vehicle\" + 0.013*\"automaker\" + 0.013*\"require\" + 0.012*\"target\" + 0.011*\"co2\"\n",
      "2019-10-29 00:39:13,385 : INFO : topic #3 (0.100): 0.033*\"new\" + 0.033*\"emission\" + 0.031*\"car\" + 0.031*\"said\" + 0.018*\"electric\" + 0.017*\"require\" + 0.016*\"automaker\" + 0.015*\"vehicle\" + 0.015*\"target\" + 0.013*\"co2\"\n",
      "2019-10-29 00:39:13,388 : INFO : topic diff=0.839707, rho=1.000000\n",
      "2019-10-29 00:39:13,777 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:13,781 : INFO : built Dictionary(104 unique tokens: ['school', 'significant', 'special', 'severely', 'regulation']...) from 5 documents (total 740 corpus positions)\n",
      "2019-10-29 00:39:13,782 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:13,784 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:13,786 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:13,788 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:13,790 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:13,837 : INFO : -6.898 per-word bound, 119.3 perplexity estimate based on a held-out corpus of 5 documents with 740 words\n",
      "2019-10-29 00:39:13,839 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:13,845 : INFO : topic #1 (0.100): 0.039*\"doctor\" + 0.029*\"heroin\" + 0.027*\"access\" + 0.024*\"health\" + 0.021*\"treatment\" + 0.021*\"addicted\" + 0.020*\"canada\" + 0.018*\"diacetylmorphine\" + 0.017*\"special\" + 0.017*\"regulation\"\n",
      "2019-10-29 00:39:13,848 : INFO : topic #9 (0.100): 0.033*\"heroin\" + 0.027*\"treatment\" + 0.027*\"diacetylmorphine\" + 0.026*\"doctor\" + 0.024*\"health\" + 0.023*\"regulation\" + 0.020*\"access\" + 0.019*\"canada\" + 0.018*\"patient\" + 0.017*\"allow\"\n",
      "2019-10-29 00:39:13,851 : INFO : topic #0 (0.100): 0.037*\"heroin\" + 0.031*\"doctor\" + 0.027*\"regulation\" + 0.022*\"health\" + 0.022*\"treatment\" + 0.020*\"diacetylmorphine\" + 0.019*\"addicted\" + 0.019*\"access\" + 0.017*\"canada\" + 0.017*\"joekes\"\n",
      "2019-10-29 00:39:13,854 : INFO : topic #2 (0.100): 0.046*\"heroin\" + 0.032*\"doctor\" + 0.029*\"diacetylmorphine\" + 0.028*\"regulation\" + 0.025*\"access\" + 0.025*\"health\" + 0.025*\"treatment\" + 0.024*\"patient\" + 0.023*\"canada\" + 0.017*\"addicted\"\n",
      "2019-10-29 00:39:13,857 : INFO : topic #6 (0.100): 0.040*\"heroin\" + 0.032*\"regulation\" + 0.029*\"treatment\" + 0.027*\"doctor\" + 0.026*\"diacetylmorphine\" + 0.026*\"access\" + 0.023*\"health\" + 0.020*\"addicted\" + 0.018*\"canada\" + 0.016*\"patient\"\n",
      "2019-10-29 00:39:13,859 : INFO : topic diff=0.784209, rho=1.000000\n",
      "2019-10-29 00:39:14,284 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:14,290 : INFO : built Dictionary(349 unique tokens: ['party', 'francisco', 'cycle', 'trying', 'really']...) from 5 documents (total 3810 corpus positions)\n",
      "2019-10-29 00:39:14,295 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:14,296 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:14,297 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:14,303 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:14,307 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:14,451 : INFO : -7.440 per-word bound, 173.7 perplexity estimate based on a held-out corpus of 5 documents with 3810 words\n",
      "2019-10-29 00:39:14,453 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:14,462 : INFO : topic #6 (0.100): 0.055*\"woman\" + 0.029*\"study\" + 0.027*\"fertility\" + 0.021*\"said\" + 0.016*\"age\" + 0.015*\"level\" + 0.013*\"egg\" + 0.012*\"infertility\" + 0.012*\"test\" + 0.012*\"ovarian\"\n",
      "2019-10-29 00:39:14,465 : INFO : topic #9 (0.100): 0.057*\"woman\" + 0.033*\"study\" + 0.030*\"fertility\" + 0.021*\"said\" + 0.017*\"age\" + 0.017*\"level\" + 0.013*\"fsh\" + 0.011*\"egg\" + 0.011*\"test\" + 0.010*\"reserve\"\n",
      "2019-10-29 00:39:14,468 : INFO : topic #0 (0.100): 0.060*\"woman\" + 0.026*\"said\" + 0.026*\"fertility\" + 0.022*\"age\" + 0.022*\"study\" + 0.017*\"level\" + 0.014*\"test\" + 0.014*\"ovarian\" + 0.013*\"amh\" + 0.012*\"egg\"\n",
      "2019-10-29 00:39:14,470 : INFO : topic #8 (0.100): 0.046*\"woman\" + 0.037*\"fertility\" + 0.026*\"study\" + 0.019*\"said\" + 0.018*\"level\" + 0.015*\"age\" + 0.014*\"fsh\" + 0.013*\"amh\" + 0.013*\"infertility\" + 0.010*\"egg\"\n",
      "2019-10-29 00:39:14,473 : INFO : topic #3 (0.100): 0.055*\"woman\" + 0.032*\"fertility\" + 0.027*\"study\" + 0.020*\"said\" + 0.015*\"age\" + 0.015*\"egg\" + 0.014*\"level\" + 0.011*\"ovarian\" + 0.011*\"fsh\" + 0.010*\"amh\"\n",
      "2019-10-29 00:39:14,477 : INFO : topic diff=1.009171, rho=1.000000\n",
      "2019-10-29 00:39:14,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:14,892 : INFO : built Dictionary(351 unique tokens: ['let', 'energy', 'described', 'francisco', 'sadly']...) from 5 documents (total 2710 corpus positions)\n",
      "2019-10-29 00:39:14,896 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:14,897 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:14,899 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:14,901 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:14,902 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:15,005 : INFO : -7.885 per-word bound, 236.4 perplexity estimate based on a held-out corpus of 5 documents with 2710 words\n",
      "2019-10-29 00:39:15,006 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:15,013 : INFO : topic #3 (0.100): 0.043*\"marijuana\" + 0.029*\"medical\" + 0.014*\"research\" + 0.013*\"study\" + 0.013*\"dea\" + 0.010*\"benefit\" + 0.010*\"potential\" + 0.010*\"schedule\" + 0.009*\"door\" + 0.009*\"even\"\n",
      "2019-10-29 00:39:15,015 : INFO : topic #5 (0.100): 0.047*\"marijuana\" + 0.023*\"medical\" + 0.018*\"dea\" + 0.016*\"research\" + 0.013*\"study\" + 0.011*\"benefit\" + 0.011*\"door\" + 0.010*\"abuse\" + 0.009*\"potential\" + 0.009*\"still\"\n",
      "2019-10-29 00:39:15,016 : INFO : topic #4 (0.100): 0.044*\"marijuana\" + 0.026*\"medical\" + 0.014*\"research\" + 0.013*\"study\" + 0.012*\"door\" + 0.012*\"potential\" + 0.011*\"dea\" + 0.011*\"even\" + 0.010*\"benefit\" + 0.009*\"substance\"\n",
      "2019-10-29 00:39:15,017 : INFO : topic #0 (0.100): 0.064*\"marijuana\" + 0.033*\"medical\" + 0.021*\"research\" + 0.014*\"dea\" + 0.012*\"door\" + 0.010*\"study\" + 0.010*\"benefit\" + 0.009*\"even\" + 0.008*\"still\" + 0.008*\"today\"\n",
      "2019-10-29 00:39:15,019 : INFO : topic #1 (0.100): 0.045*\"marijuana\" + 0.029*\"medical\" + 0.018*\"study\" + 0.011*\"door\" + 0.011*\"research\" + 0.010*\"benefit\" + 0.009*\"dea\" + 0.009*\"potential\" + 0.009*\"still\" + 0.009*\"even\"\n",
      "2019-10-29 00:39:15,021 : INFO : topic diff=0.864930, rho=1.000000\n",
      "2019-10-29 00:39:15,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:15,460 : INFO : built Dictionary(312 unique tokens: ['product', 'campaign', 'maintenance', 'come', 'conjunction']...) from 5 documents (total 2880 corpus positions)\n",
      "2019-10-29 00:39:15,467 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:15,468 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:15,470 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:15,474 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:15,477 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:15,574 : INFO : -7.522 per-word bound, 183.8 perplexity estimate based on a held-out corpus of 5 documents with 2880 words\n",
      "2019-10-29 00:39:15,576 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:15,583 : INFO : topic #6 (0.100): 0.034*\"woman\" + 0.032*\"implant\" + 0.031*\"iud\" + 0.026*\"said\" + 0.024*\"method\" + 0.014*\"birth\" + 0.014*\"control\" + 0.013*\"pregnancy\" + 0.012*\"may\" + 0.010*\"health\"\n",
      "2019-10-29 00:39:15,586 : INFO : topic #9 (0.100): 0.042*\"woman\" + 0.040*\"iud\" + 0.029*\"implant\" + 0.026*\"method\" + 0.025*\"said\" + 0.014*\"control\" + 0.013*\"effective\" + 0.013*\"birth\" + 0.010*\"may\" + 0.010*\"pregnancy\"\n",
      "2019-10-29 00:39:15,587 : INFO : topic #1 (0.100): 0.040*\"iud\" + 0.040*\"woman\" + 0.024*\"said\" + 0.021*\"implant\" + 0.016*\"method\" + 0.016*\"birth\" + 0.015*\"effective\" + 0.013*\"pregnancy\" + 0.012*\"control\" + 0.012*\"may\"\n",
      "2019-10-29 00:39:15,589 : INFO : topic #2 (0.100): 0.036*\"woman\" + 0.035*\"iud\" + 0.035*\"said\" + 0.027*\"method\" + 0.021*\"implant\" + 0.014*\"pregnancy\" + 0.013*\"control\" + 0.010*\"ehrlich\" + 0.010*\"care\" + 0.010*\"birth\"\n",
      "2019-10-29 00:39:15,591 : INFO : topic #3 (0.100): 0.037*\"woman\" + 0.032*\"iud\" + 0.030*\"said\" + 0.028*\"implant\" + 0.023*\"method\" + 0.013*\"effective\" + 0.013*\"birth\" + 0.013*\"pregnancy\" + 0.012*\"may\" + 0.012*\"control\"\n",
      "2019-10-29 00:39:15,592 : INFO : topic diff=0.938063, rho=1.000000\n",
      "2019-10-29 00:39:16,135 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:16,142 : INFO : built Dictionary(482 unique tokens: ['catholic', 'filed', 'median', 'party', 'doc']...) from 5 documents (total 5095 corpus positions)\n",
      "2019-10-29 00:39:16,150 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:16,153 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:16,156 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:16,161 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:16,164 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:16,333 : INFO : -7.787 per-word bound, 220.9 perplexity estimate based on a held-out corpus of 5 documents with 5095 words\n",
      "2019-10-29 00:39:16,335 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:16,347 : INFO : topic #5 (0.100): 0.034*\"haiti\" + 0.021*\"president\" + 0.014*\"government\" + 0.011*\"state\" + 0.011*\"aristide\" + 0.010*\"u\" + 0.010*\"election\" + 0.009*\"february\" + 0.009*\"new\" + 0.009*\"united\"\n",
      "2019-10-29 00:39:16,354 : INFO : topic #9 (0.100): 0.038*\"haiti\" + 0.023*\"president\" + 0.015*\"aristide\" + 0.013*\"haitian\" + 0.012*\"government\" + 0.012*\"state\" + 0.011*\"united\" + 0.010*\"former\" + 0.010*\"u\" + 0.009*\"election\"\n",
      "2019-10-29 00:39:16,357 : INFO : topic #1 (0.100): 0.045*\"haiti\" + 0.026*\"president\" + 0.014*\"aristide\" + 0.012*\"united\" + 0.011*\"u\" + 0.009*\"election\" + 0.009*\"haitian\" + 0.009*\"state\" + 0.009*\"government\" + 0.008*\"new\"\n",
      "2019-10-29 00:39:16,360 : INFO : topic #0 (0.100): 0.030*\"haiti\" + 0.021*\"president\" + 0.017*\"aristide\" + 0.013*\"united\" + 0.011*\"government\" + 0.011*\"new\" + 0.011*\"haitian\" + 0.010*\"february\" + 0.010*\"u\" + 0.009*\"election\"\n",
      "2019-10-29 00:39:16,363 : INFO : topic #8 (0.100): 0.041*\"haiti\" + 0.027*\"president\" + 0.016*\"aristide\" + 0.016*\"united\" + 0.012*\"election\" + 0.011*\"haitian\" + 0.010*\"u\" + 0.010*\"february\" + 0.009*\"state\" + 0.009*\"new\"\n",
      "2019-10-29 00:39:16,365 : INFO : topic diff=0.942909, rho=1.000000\n",
      "2019-10-29 00:39:16,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:16,746 : INFO : built Dictionary(63 unique tokens: ['amid', 'finding', 'book', 'end', 'favorable']...) from 5 documents (total 380 corpus positions)\n",
      "2019-10-29 00:39:16,748 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:16,749 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:16,750 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:16,752 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:16,754 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:16,789 : INFO : -6.805 per-word bound, 111.8 perplexity estimate based on a held-out corpus of 5 documents with 380 words\n",
      "2019-10-29 00:39:16,791 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:16,796 : INFO : topic #3 (0.100): 0.051*\"world\" + 0.043*\"america\" + 0.035*\"post\" + 0.028*\"presidency\" + 0.026*\"trump\" + 0.026*\"american\" + 0.025*\"percent\" + 0.022*\"people\" + 0.019*\"faster\" + 0.017*\"cnn\"\n",
      "2019-10-29 00:39:16,799 : INFO : topic #2 (0.100): 0.051*\"world\" + 0.051*\"america\" + 0.032*\"post\" + 0.030*\"people\" + 0.025*\"presidency\" + 0.025*\"percent\" + 0.024*\"trump\" + 0.021*\"american\" + 0.017*\"foreign\" + 0.017*\"idea\"\n",
      "2019-10-29 00:39:16,801 : INFO : topic #1 (0.100): 0.058*\"world\" + 0.040*\"post\" + 0.038*\"america\" + 0.030*\"trump\" + 0.028*\"people\" + 0.025*\"percent\" + 0.024*\"presidency\" + 0.022*\"american\" + 0.017*\"well\" + 0.017*\"surveyed\"\n",
      "2019-10-29 00:39:16,804 : INFO : topic #8 (0.100): 0.059*\"america\" + 0.039*\"world\" + 0.033*\"post\" + 0.028*\"people\" + 0.026*\"presidency\" + 0.024*\"american\" + 0.023*\"trump\" + 0.022*\"percent\" + 0.017*\"rise\" + 0.017*\"favorable\"\n",
      "2019-10-29 00:39:16,807 : INFO : topic #6 (0.100): 0.046*\"world\" + 0.044*\"america\" + 0.035*\"post\" + 0.028*\"percent\" + 0.028*\"people\" + 0.026*\"american\" + 0.026*\"presidency\" + 0.026*\"trump\" + 0.018*\"u\" + 0.018*\"say\"\n",
      "2019-10-29 00:39:16,810 : INFO : topic diff=0.687391, rho=1.000000\n",
      "2019-10-29 00:39:17,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:17,285 : INFO : built Dictionary(868 unique tokens: ['rage', 'pediatrician', 'wave', 'darvena', 'staten']...) from 5 documents (total 7910 corpus positions)\n",
      "2019-10-29 00:39:17,294 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:17,295 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:17,297 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:17,302 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:17,304 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:17,561 : INFO : -8.532 per-word bound, 370.1 perplexity estimate based on a held-out corpus of 5 documents with 7910 words\n",
      "2019-10-29 00:39:17,563 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:17,576 : INFO : topic #7 (0.100): 0.030*\"kim\" + 0.018*\"rubella\" + 0.016*\"family\" + 0.011*\"say\" + 0.009*\"home\" + 0.008*\"florence\" + 0.008*\"like\" + 0.008*\"cooper\" + 0.008*\"child\" + 0.007*\"baby\"\n",
      "2019-10-29 00:39:17,578 : INFO : topic #5 (0.100): 0.027*\"kim\" + 0.017*\"rubella\" + 0.015*\"family\" + 0.010*\"year\" + 0.010*\"cooper\" + 0.009*\"like\" + 0.009*\"baby\" + 0.009*\"child\" + 0.009*\"florence\" + 0.009*\"say\"\n",
      "2019-10-29 00:39:17,582 : INFO : topic #4 (0.100): 0.025*\"kim\" + 0.018*\"rubella\" + 0.014*\"family\" + 0.010*\"child\" + 0.010*\"baby\" + 0.008*\"say\" + 0.008*\"time\" + 0.007*\"home\" + 0.007*\"florence\" + 0.007*\"need\"\n",
      "2019-10-29 00:39:17,585 : INFO : topic #3 (0.100): 0.030*\"kim\" + 0.017*\"rubella\" + 0.012*\"family\" + 0.011*\"child\" + 0.010*\"home\" + 0.009*\"time\" + 0.009*\"say\" + 0.008*\"baby\" + 0.008*\"florence\" + 0.007*\"need\"\n",
      "2019-10-29 00:39:17,588 : INFO : topic #8 (0.100): 0.029*\"kim\" + 0.016*\"rubella\" + 0.015*\"family\" + 0.010*\"child\" + 0.009*\"florence\" + 0.009*\"home\" + 0.009*\"say\" + 0.007*\"baby\" + 0.007*\"need\" + 0.007*\"syndrome\"\n",
      "2019-10-29 00:39:17,591 : INFO : topic diff=0.926182, rho=1.000000\n",
      "2019-10-29 00:39:17,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:17,999 : INFO : built Dictionary(199 unique tokens: ['violence', 'deep', 'refuse', 'vice', 'dru']...) from 5 documents (total 1370 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:18,002 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:18,003 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:18,004 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:18,006 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:18,008 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:18,081 : INFO : -7.537 per-word bound, 185.7 perplexity estimate based on a held-out corpus of 5 documents with 1370 words\n",
      "2019-10-29 00:39:18,083 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:18,092 : INFO : topic #2 (0.100): 0.026*\"vega\" + 0.024*\"la\" + 0.017*\"shooting\" + 0.016*\"today\" + 0.016*\"friend\" + 0.015*\"love\" + 0.015*\"orlando\" + 0.014*\"country\" + 0.014*\"people\" + 0.012*\"need\"\n",
      "2019-10-29 00:39:18,095 : INFO : topic #7 (0.100): 0.026*\"la\" + 0.023*\"vega\" + 0.018*\"friend\" + 0.017*\"shooting\" + 0.016*\"people\" + 0.016*\"need\" + 0.015*\"today\" + 0.015*\"love\" + 0.013*\"back\" + 0.012*\"frantic\"\n",
      "2019-10-29 00:39:18,098 : INFO : topic #3 (0.100): 0.030*\"la\" + 0.027*\"vega\" + 0.018*\"friend\" + 0.015*\"country\" + 0.014*\"love\" + 0.013*\"nightclub\" + 0.013*\"orlando\" + 0.013*\"people\" + 0.012*\"need\" + 0.012*\"thought\"\n",
      "2019-10-29 00:39:18,100 : INFO : topic #0 (0.100): 0.024*\"la\" + 0.021*\"friend\" + 0.019*\"vega\" + 0.015*\"shooting\" + 0.014*\"need\" + 0.014*\"orlando\" + 0.013*\"country\" + 0.013*\"love\" + 0.012*\"people\" + 0.011*\"pulse\"\n",
      "2019-10-29 00:39:18,103 : INFO : topic #1 (0.100): 0.029*\"vega\" + 0.026*\"la\" + 0.015*\"need\" + 0.015*\"today\" + 0.015*\"people\" + 0.015*\"friend\" + 0.014*\"orlando\" + 0.013*\"thought\" + 0.012*\"country\" + 0.011*\"pulse\"\n",
      "2019-10-29 00:39:18,106 : INFO : topic diff=0.783498, rho=1.000000\n",
      "2019-10-29 00:39:18,532 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:18,538 : INFO : built Dictionary(408 unique tokens: ['size', 'cycle', 'stop', 'stuffy', 'new']...) from 5 documents (total 3885 corpus positions)\n",
      "2019-10-29 00:39:18,543 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:18,544 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:18,545 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:18,550 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:18,552 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:18,678 : INFO : -7.747 per-word bound, 214.8 perplexity estimate based on a held-out corpus of 5 documents with 3885 words\n",
      "2019-10-29 00:39:18,679 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:18,687 : INFO : topic #9 (0.100): 0.043*\"headache\" + 0.023*\"migraine\" + 0.020*\"pain\" + 0.013*\"patient\" + 0.013*\"said\" + 0.012*\"people\" + 0.010*\"medication\" + 0.010*\"monteith\" + 0.008*\"lyden\" + 0.008*\"head\"\n",
      "2019-10-29 00:39:18,690 : INFO : topic #4 (0.100): 0.048*\"headache\" + 0.029*\"migraine\" + 0.026*\"pain\" + 0.016*\"said\" + 0.012*\"people\" + 0.012*\"patient\" + 0.010*\"lyden\" + 0.009*\"visual\" + 0.009*\"according\" + 0.008*\"form\"\n",
      "2019-10-29 00:39:18,692 : INFO : topic #7 (0.100): 0.034*\"headache\" + 0.026*\"pain\" + 0.023*\"migraine\" + 0.012*\"said\" + 0.011*\"common\" + 0.010*\"one\" + 0.010*\"form\" + 0.010*\"people\" + 0.009*\"patient\" + 0.008*\"monteith\"\n",
      "2019-10-29 00:39:18,695 : INFO : topic #6 (0.100): 0.039*\"headache\" + 0.020*\"migraine\" + 0.017*\"pain\" + 0.014*\"said\" + 0.013*\"patient\" + 0.011*\"people\" + 0.010*\"one\" + 0.009*\"monteith\" + 0.009*\"medication\" + 0.009*\"cluster\"\n",
      "2019-10-29 00:39:18,698 : INFO : topic #0 (0.100): 0.039*\"headache\" + 0.028*\"migraine\" + 0.023*\"pain\" + 0.018*\"said\" + 0.012*\"people\" + 0.012*\"common\" + 0.010*\"cluster\" + 0.010*\"lyden\" + 0.009*\"monteith\" + 0.009*\"patient\"\n",
      "2019-10-29 00:39:18,700 : INFO : topic diff=0.922226, rho=1.000000\n",
      "2019-10-29 00:39:19,116 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:19,118 : INFO : built Dictionary(19 unique tokens: ['agree', 'abandoned', 'privacy', 'canfranc', 'france']...) from 5 documents (total 100 corpus positions)\n",
      "2019-10-29 00:39:19,120 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:19,123 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:19,127 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:19,130 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:19,134 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:19,150 : INFO : -6.398 per-word bound, 84.4 perplexity estimate based on a held-out corpus of 5 documents with 100 words\n",
      "2019-10-29 00:39:19,152 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:19,163 : INFO : topic #8 (0.100): 0.113*\"cooky\" + 0.057*\"information\" + 0.053*\"revised\" + 0.053*\"station\" + 0.052*\"agree\" + 0.051*\"continuing\" + 0.050*\"photo\" + 0.049*\"use\" + 0.049*\"abandoned\" + 0.049*\"privacy\"\n",
      "2019-10-29 00:39:19,166 : INFO : topic #1 (0.100): 0.103*\"cooky\" + 0.064*\"privacy\" + 0.058*\"station\" + 0.057*\"policy\" + 0.056*\"term\" + 0.056*\"service\" + 0.054*\"browse\" + 0.052*\"revised\" + 0.051*\"agree\" + 0.051*\"border\"\n",
      "2019-10-29 00:39:19,169 : INFO : topic #4 (0.100): 0.078*\"cooky\" + 0.059*\"revised\" + 0.059*\"photo\" + 0.057*\"browse\" + 0.056*\"use\" + 0.054*\"privacy\" + 0.053*\"policy\" + 0.051*\"france\" + 0.051*\"agree\" + 0.051*\"site\"\n",
      "2019-10-29 00:39:19,172 : INFO : topic #0 (0.100): 0.084*\"cooky\" + 0.065*\"border\" + 0.058*\"browse\" + 0.058*\"canfranc\" + 0.055*\"agree\" + 0.053*\"continuing\" + 0.053*\"information\" + 0.053*\"service\" + 0.052*\"privacy\" + 0.051*\"policy\"\n",
      "2019-10-29 00:39:19,175 : INFO : topic #6 (0.100): 0.110*\"cooky\" + 0.067*\"use\" + 0.058*\"station\" + 0.056*\"abandoned\" + 0.052*\"photo\" + 0.051*\"border\" + 0.051*\"privacy\" + 0.051*\"site\" + 0.049*\"france\" + 0.049*\"canfranc\"\n",
      "2019-10-29 00:39:19,178 : INFO : topic diff=0.560302, rho=1.000000\n",
      "2019-10-29 00:39:19,601 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:19,606 : INFO : built Dictionary(343 unique tokens: ['let', 'catholic', 'filed', 'involved', 'focus']...) from 5 documents (total 3010 corpus positions)\n",
      "2019-10-29 00:39:19,611 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:19,612 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:19,613 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:19,617 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:19,618 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:19,722 : INFO : -7.682 per-word bound, 205.3 perplexity estimate based on a held-out corpus of 5 documents with 3010 words\n",
      "2019-10-29 00:39:19,723 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:19,731 : INFO : topic #0 (0.100): 0.021*\"woman\" + 0.019*\"control\" + 0.016*\"rule\" + 0.015*\"religious\" + 0.014*\"coverage\" + 0.014*\"birth\" + 0.013*\"said\" + 0.013*\"health\" + 0.011*\"could\" + 0.010*\"contraceptive\"\n",
      "2019-10-29 00:39:19,734 : INFO : topic #3 (0.100): 0.021*\"woman\" + 0.018*\"control\" + 0.018*\"religious\" + 0.016*\"birth\" + 0.015*\"said\" + 0.015*\"rule\" + 0.015*\"health\" + 0.014*\"coverage\" + 0.013*\"contraceptive\" + 0.011*\"could\"\n",
      "2019-10-29 00:39:19,736 : INFO : topic #2 (0.100): 0.024*\"religious\" + 0.019*\"woman\" + 0.019*\"said\" + 0.017*\"health\" + 0.016*\"birth\" + 0.014*\"control\" + 0.014*\"coverage\" + 0.013*\"rule\" + 0.013*\"contraceptive\" + 0.011*\"new\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:19,738 : INFO : topic #4 (0.100): 0.026*\"woman\" + 0.020*\"health\" + 0.018*\"birth\" + 0.017*\"religious\" + 0.015*\"control\" + 0.015*\"said\" + 0.011*\"rule\" + 0.011*\"new\" + 0.010*\"employer\" + 0.009*\"would\"\n",
      "2019-10-29 00:39:19,741 : INFO : topic #9 (0.100): 0.029*\"woman\" + 0.023*\"health\" + 0.021*\"religious\" + 0.019*\"birth\" + 0.019*\"control\" + 0.017*\"said\" + 0.013*\"rule\" + 0.011*\"could\" + 0.010*\"contraceptive\" + 0.010*\"coverage\"\n",
      "2019-10-29 00:39:19,743 : INFO : topic diff=0.909206, rho=1.000000\n",
      "2019-10-29 00:39:20,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:20,126 : INFO : built Dictionary(77 unique tokens: ['thanked', 'deadly', 'performing', 'visit', 'time']...) from 5 documents (total 525 corpus positions)\n",
      "2019-10-29 00:39:20,128 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:20,130 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:20,131 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:20,134 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:20,135 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:20,183 : INFO : -6.723 per-word bound, 105.6 perplexity estimate based on a held-out corpus of 5 documents with 525 words\n",
      "2019-10-29 00:39:20,185 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:20,191 : INFO : topic #4 (0.100): 0.049*\"aldean\" + 0.035*\"visit\" + 0.034*\"jason\" + 0.034*\"vega\" + 0.025*\"music\" + 0.025*\"country\" + 0.025*\"shooting\" + 0.023*\"mass\" + 0.022*\"center\" + 0.018*\"la\"\n",
      "2019-10-29 00:39:20,193 : INFO : topic #3 (0.100): 0.047*\"jason\" + 0.044*\"aldean\" + 0.038*\"visit\" + 0.032*\"music\" + 0.028*\"country\" + 0.027*\"shooting\" + 0.024*\"la\" + 0.023*\"vega\" + 0.021*\"mass\" + 0.021*\"center\"\n",
      "2019-10-29 00:39:20,198 : INFO : topic #2 (0.100): 0.062*\"aldean\" + 0.045*\"visit\" + 0.036*\"country\" + 0.034*\"la\" + 0.024*\"jason\" + 0.024*\"music\" + 0.023*\"shooting\" + 0.023*\"vega\" + 0.021*\"victim\" + 0.020*\"posted\"\n",
      "2019-10-29 00:39:20,201 : INFO : topic #6 (0.100): 0.048*\"aldean\" + 0.038*\"vega\" + 0.034*\"visit\" + 0.032*\"jason\" + 0.029*\"la\" + 0.028*\"music\" + 0.027*\"shooting\" + 0.027*\"country\" + 0.018*\"posted\" + 0.018*\"gratitude\"\n",
      "2019-10-29 00:39:20,204 : INFO : topic #9 (0.100): 0.057*\"aldean\" + 0.033*\"jason\" + 0.032*\"visit\" + 0.030*\"shooting\" + 0.027*\"country\" + 0.027*\"music\" + 0.025*\"la\" + 0.022*\"vega\" + 0.022*\"sunday\" + 0.021*\"posted\"\n",
      "2019-10-29 00:39:20,207 : INFO : topic diff=0.780426, rho=1.000000\n",
      "2019-10-29 00:39:20,620 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:20,624 : INFO : built Dictionary(146 unique tokens: ['affected', 'afterward', 'come', 'focus', 'retains']...) from 5 documents (total 1065 corpus positions)\n",
      "2019-10-29 00:39:20,627 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:20,629 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:20,633 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:20,637 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:20,639 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:20,719 : INFO : -7.158 per-word bound, 142.9 perplexity estimate based on a held-out corpus of 5 documents with 1065 words\n",
      "2019-10-29 00:39:20,721 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:20,728 : INFO : topic #9 (0.100): 0.045*\"exercise\" + 0.026*\"doms\" + 0.026*\"muscle\" + 0.022*\"soreness\" + 0.021*\"pain\" + 0.016*\"day\" + 0.014*\"lactic\" + 0.014*\"stronger\" + 0.014*\"acid\" + 0.013*\"occur\"\n",
      "2019-10-29 00:39:20,731 : INFO : topic #7 (0.100): 0.039*\"exercise\" + 0.034*\"soreness\" + 0.030*\"doms\" + 0.028*\"muscle\" + 0.021*\"pain\" + 0.019*\"acid\" + 0.017*\"day\" + 0.016*\"lactic\" + 0.015*\"stronger\" + 0.013*\"sign\"\n",
      "2019-10-29 00:39:20,734 : INFO : topic #8 (0.100): 0.043*\"muscle\" + 0.037*\"exercise\" + 0.033*\"doms\" + 0.025*\"soreness\" + 0.024*\"pain\" + 0.019*\"day\" + 0.018*\"lactic\" + 0.018*\"acid\" + 0.015*\"occur\" + 0.014*\"stronger\"\n",
      "2019-10-29 00:39:20,737 : INFO : topic #6 (0.100): 0.042*\"exercise\" + 0.031*\"doms\" + 0.029*\"muscle\" + 0.022*\"pain\" + 0.019*\"day\" + 0.019*\"lactic\" + 0.018*\"acid\" + 0.018*\"soreness\" + 0.013*\"body\" + 0.013*\"stronger\"\n",
      "2019-10-29 00:39:20,740 : INFO : topic #0 (0.100): 0.042*\"exercise\" + 0.041*\"muscle\" + 0.037*\"doms\" + 0.025*\"soreness\" + 0.024*\"pain\" + 0.021*\"day\" + 0.016*\"lactic\" + 0.016*\"occur\" + 0.015*\"acid\" + 0.014*\"sign\"\n",
      "2019-10-29 00:39:20,742 : INFO : topic diff=0.808933, rho=1.000000\n",
      "2019-10-29 00:39:21,144 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:21,146 : INFO : built Dictionary(107 unique tokens: ['gifted', 'hire', 'come', 'series', 'cbs']...) from 5 documents (total 650 corpus positions)\n",
      "2019-10-29 00:39:21,148 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:21,149 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:21,150 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:21,153 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:21,154 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:21,199 : INFO : -7.223 per-word bound, 149.4 perplexity estimate based on a held-out corpus of 5 documents with 650 words\n",
      "2019-10-29 00:39:21,201 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:21,207 : INFO : topic #8 (0.100): 0.027*\"study\" + 0.022*\"said\" + 0.020*\"child\" + 0.020*\"parent\" + 0.018*\"money\" + 0.016*\"philadelphia\" + 0.016*\"woman\" + 0.016*\"favorite\" + 0.015*\"female\" + 0.015*\"sex\"\n",
      "2019-10-29 00:39:21,209 : INFO : topic #0 (0.100): 0.021*\"study\" + 0.020*\"child\" + 0.020*\"said\" + 0.018*\"favorite\" + 0.018*\"female\" + 0.017*\"philadelphia\" + 0.016*\"male\" + 0.016*\"money\" + 0.016*\"family\" + 0.015*\"hire\"\n",
      "2019-10-29 00:39:21,211 : INFO : topic #2 (0.100): 0.024*\"said\" + 0.023*\"parent\" + 0.019*\"study\" + 0.019*\"hire\" + 0.019*\"child\" + 0.018*\"experiment\" + 0.016*\"sex\" + 0.016*\"philadelphia\" + 0.015*\"hiring\" + 0.015*\"new\"\n",
      "2019-10-29 00:39:21,213 : INFO : topic #7 (0.100): 0.023*\"said\" + 0.020*\"study\" + 0.019*\"sex\" + 0.019*\"parent\" + 0.017*\"male\" + 0.017*\"new\" + 0.016*\"family\" + 0.016*\"researcher\" + 0.016*\"child\" + 0.015*\"woman\"\n",
      "2019-10-29 00:39:21,215 : INFO : topic #1 (0.100): 0.026*\"child\" + 0.024*\"parent\" + 0.020*\"study\" + 0.018*\"said\" + 0.017*\"new\" + 0.017*\"hiring\" + 0.016*\"think\" + 0.016*\"money\" + 0.015*\"experiment\" + 0.015*\"woman\"\n",
      "2019-10-29 00:39:21,217 : INFO : topic diff=0.668955, rho=1.000000\n",
      "2019-10-29 00:39:21,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:21,643 : INFO : built Dictionary(273 unique tokens: ['blocked', 'prescription', 'sorry', 'person', 'watch']...) from 5 documents (total 2210 corpus positions)\n",
      "2019-10-29 00:39:21,648 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:21,650 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:21,653 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:21,658 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:21,661 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:21,743 : INFO : -7.575 per-word bound, 190.7 perplexity estimate based on a held-out corpus of 5 documents with 2210 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:21,744 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:21,750 : INFO : topic #7 (0.100): 0.023*\"buy\" + 0.023*\"gun\" + 0.015*\"sudafed\" + 0.013*\"two\" + 0.011*\"nevada\" + 0.011*\"purchase\" + 0.010*\"law\" + 0.010*\"year\" + 0.009*\"medicine\" + 0.009*\"drug\"\n",
      "2019-10-29 00:39:21,752 : INFO : topic #4 (0.100): 0.028*\"buy\" + 0.020*\"gun\" + 0.015*\"sudafed\" + 0.012*\"purchase\" + 0.011*\"nevada\" + 0.011*\"two\" + 0.010*\"state\" + 0.010*\"ammunition\" + 0.010*\"pseudoephedrine\" + 0.010*\"rifle\"\n",
      "2019-10-29 00:39:21,755 : INFO : topic #8 (0.100): 0.032*\"buy\" + 0.025*\"gun\" + 0.022*\"sudafed\" + 0.010*\"day\" + 0.010*\"purchase\" + 0.010*\"firearm\" + 0.010*\"law\" + 0.010*\"medicine\" + 0.010*\"state\" + 0.010*\"nevada\"\n",
      "2019-10-29 00:39:21,757 : INFO : topic #1 (0.100): 0.027*\"buy\" + 0.026*\"gun\" + 0.012*\"purchase\" + 0.011*\"year\" + 0.011*\"sudafed\" + 0.011*\"nevada\" + 0.011*\"two\" + 0.010*\"pse\" + 0.010*\"drug\" + 0.009*\"rifle\"\n",
      "2019-10-29 00:39:21,760 : INFO : topic #3 (0.100): 0.023*\"gun\" + 0.020*\"sudafed\" + 0.019*\"buy\" + 0.015*\"purchase\" + 0.014*\"nevada\" + 0.012*\"year\" + 0.011*\"two\" + 0.010*\"pse\" + 0.009*\"rifle\" + 0.009*\"drug\"\n",
      "2019-10-29 00:39:21,763 : INFO : topic diff=0.814142, rho=1.000000\n",
      "2019-10-29 00:39:22,180 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:22,184 : INFO : built Dictionary(218 unique tokens: ['school', 'reinforce', 'book', 'happy', 'rather']...) from 5 documents (total 1595 corpus positions)\n",
      "2019-10-29 00:39:22,188 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:22,189 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:22,191 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:22,193 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:22,198 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:22,279 : INFO : -7.520 per-word bound, 183.6 perplexity estimate based on a held-out corpus of 5 documents with 1595 words\n",
      "2019-10-29 00:39:22,281 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:22,288 : INFO : topic #3 (0.100): 0.027*\"kid\" + 0.017*\"game\" + 0.014*\"share\" + 0.012*\"medium\" + 0.011*\"character\" + 0.011*\"teamwork\" + 0.011*\"different\" + 0.011*\"life\" + 0.010*\"social\" + 0.010*\"point\"\n",
      "2019-10-29 00:39:22,294 : INFO : topic #9 (0.100): 0.028*\"kid\" + 0.017*\"game\" + 0.017*\"medium\" + 0.013*\"character\" + 0.011*\"hope\" + 0.011*\"say\" + 0.010*\"something\" + 0.010*\"important\" + 0.009*\"share\" + 0.009*\"lesson\"\n",
      "2019-10-29 00:39:22,298 : INFO : topic #6 (0.100): 0.035*\"kid\" + 0.018*\"medium\" + 0.012*\"game\" + 0.011*\"character\" + 0.011*\"something\" + 0.011*\"point\" + 0.011*\"teamwork\" + 0.011*\"share\" + 0.010*\"movie\" + 0.010*\"communication\"\n",
      "2019-10-29 00:39:22,301 : INFO : topic #5 (0.100): 0.032*\"kid\" + 0.021*\"medium\" + 0.016*\"game\" + 0.013*\"character\" + 0.013*\"social\" + 0.011*\"share\" + 0.010*\"movie\" + 0.010*\"important\" + 0.010*\"point\" + 0.010*\"hope\"\n",
      "2019-10-29 00:39:22,304 : INFO : topic #2 (0.100): 0.034*\"kid\" + 0.019*\"medium\" + 0.014*\"something\" + 0.013*\"social\" + 0.012*\"character\" + 0.011*\"communication\" + 0.011*\"game\" + 0.010*\"twitter\" + 0.010*\"share\" + 0.010*\"movie\"\n",
      "2019-10-29 00:39:22,307 : INFO : topic diff=0.774921, rho=1.000000\n",
      "2019-10-29 00:39:22,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:22,707 : INFO : built Dictionary(288 unique tokens: ['cortex', 'single', 'size', 'zurich', 'come']...) from 5 documents (total 2460 corpus positions)\n",
      "2019-10-29 00:39:22,711 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:22,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:22,714 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:22,718 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:22,719 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:22,808 : INFO : -7.551 per-word bound, 187.5 perplexity estimate based on a held-out corpus of 5 documents with 2460 words\n",
      "2019-10-29 00:39:22,809 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:22,817 : INFO : topic #9 (0.100): 0.024*\"brain\" + 0.022*\"female\" + 0.021*\"male\" + 0.021*\"men\" + 0.018*\"said\" + 0.018*\"woman\" + 0.017*\"study\" + 0.012*\"murphy\" + 0.012*\"dopamine\" + 0.011*\"system\"\n",
      "2019-10-29 00:39:22,820 : INFO : topic #4 (0.100): 0.024*\"brain\" + 0.023*\"men\" + 0.022*\"female\" + 0.020*\"woman\" + 0.019*\"male\" + 0.017*\"said\" + 0.014*\"tobler\" + 0.013*\"dopamine\" + 0.013*\"study\" + 0.012*\"behavior\"\n",
      "2019-10-29 00:39:22,822 : INFO : topic #6 (0.100): 0.025*\"brain\" + 0.024*\"female\" + 0.021*\"male\" + 0.020*\"woman\" + 0.020*\"men\" + 0.016*\"said\" + 0.015*\"study\" + 0.014*\"dopamine\" + 0.013*\"behavior\" + 0.013*\"difference\"\n",
      "2019-10-29 00:39:22,824 : INFO : topic #5 (0.100): 0.022*\"female\" + 0.021*\"men\" + 0.020*\"brain\" + 0.020*\"woman\" + 0.015*\"dopamine\" + 0.015*\"male\" + 0.015*\"said\" + 0.014*\"study\" + 0.014*\"murphy\" + 0.012*\"difference\"\n",
      "2019-10-29 00:39:22,827 : INFO : topic #2 (0.100): 0.021*\"male\" + 0.021*\"brain\" + 0.019*\"dopamine\" + 0.018*\"men\" + 0.018*\"woman\" + 0.017*\"female\" + 0.016*\"said\" + 0.013*\"difference\" + 0.013*\"tobler\" + 0.013*\"murphy\"\n",
      "2019-10-29 00:39:22,829 : INFO : topic diff=0.853778, rho=1.000000\n",
      "2019-10-29 00:39:23,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:23,226 : INFO : built Dictionary(49 unique tokens: ['type', 'help', 'cap', 'campaign', 'game']...) from 5 documents (total 435 corpus positions)\n",
      "2019-10-29 00:39:23,228 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:23,230 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:23,231 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:23,233 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:23,235 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:23,259 : INFO : -5.931 per-word bound, 61.0 perplexity estimate based on a held-out corpus of 5 documents with 435 words\n",
      "2019-10-29 00:39:23,260 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:23,269 : INFO : topic #5 (0.100): 0.084*\"packer\" + 0.076*\"cancer\" + 0.063*\"campaign\" + 0.037*\"awareness\" + 0.031*\"lombardi\" + 0.030*\"v\" + 0.028*\"fund\" + 0.028*\"vince\" + 0.027*\"oct\" + 0.027*\"help\"\n",
      "2019-10-29 00:39:23,271 : INFO : topic #2 (0.100): 0.108*\"packer\" + 0.064*\"campaign\" + 0.064*\"cancer\" + 0.034*\"awareness\" + 0.033*\"v\" + 0.032*\"vince\" + 0.029*\"lombardi\" + 0.027*\"fan\" + 0.027*\"underway\" + 0.025*\"donate\"\n",
      "2019-10-29 00:39:23,272 : INFO : topic #8 (0.100): 0.088*\"cancer\" + 0.074*\"packer\" + 0.051*\"campaign\" + 0.035*\"v\" + 0.035*\"awareness\" + 0.033*\"lombardi\" + 0.029*\"foundation\" + 0.027*\"fan\" + 0.027*\"donate\" + 0.026*\"vince\"\n",
      "2019-10-29 00:39:23,273 : INFO : topic #6 (0.100): 0.101*\"packer\" + 0.092*\"cancer\" + 0.045*\"campaign\" + 0.038*\"vince\" + 0.037*\"v\" + 0.032*\"lombardi\" + 0.029*\"awareness\" + 0.028*\"research\" + 0.026*\"go\" + 0.024*\"raise\"\n",
      "2019-10-29 00:39:23,276 : INFO : topic #0 (0.100): 0.107*\"packer\" + 0.066*\"cancer\" + 0.052*\"campaign\" + 0.041*\"vince\" + 0.032*\"v\" + 0.031*\"lombardi\" + 0.028*\"awareness\" + 0.028*\"foundation\" + 0.024*\"oct\" + 0.024*\"help\"\n",
      "2019-10-29 00:39:23,277 : INFO : topic diff=0.843933, rho=1.000000\n",
      "2019-10-29 00:39:23,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:23,743 : INFO : built Dictionary(490 unique tokens: ['dating', 'let', 'tasty', 'francisco', 'raise']...) from 5 documents (total 4695 corpus positions)\n",
      "2019-10-29 00:39:23,749 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:23,751 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:23,756 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:23,760 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:23,762 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:23,904 : INFO : -7.915 per-word bound, 241.4 perplexity estimate based on a held-out corpus of 5 documents with 4695 words\n",
      "2019-10-29 00:39:23,906 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:23,914 : INFO : topic #3 (0.100): 0.035*\"heart\" + 0.035*\"sugar\" + 0.027*\"disease\" + 0.016*\"research\" + 0.013*\"industry\" + 0.013*\"said\" + 0.012*\"health\" + 0.010*\"new\" + 0.010*\"fat\" + 0.010*\"risk\"\n",
      "2019-10-29 00:39:23,917 : INFO : topic #2 (0.100): 0.042*\"sugar\" + 0.029*\"disease\" + 0.024*\"heart\" + 0.017*\"research\" + 0.016*\"said\" + 0.012*\"industry\" + 0.011*\"risk\" + 0.011*\"new\" + 0.010*\"fat\" + 0.010*\"health\"\n",
      "2019-10-29 00:39:23,919 : INFO : topic #1 (0.100): 0.051*\"sugar\" + 0.034*\"heart\" + 0.027*\"disease\" + 0.021*\"research\" + 0.016*\"said\" + 0.016*\"industry\" + 0.013*\"risk\" + 0.012*\"fat\" + 0.012*\"new\" + 0.011*\"health\"\n",
      "2019-10-29 00:39:23,922 : INFO : topic #7 (0.100): 0.045*\"sugar\" + 0.025*\"disease\" + 0.023*\"research\" + 0.023*\"heart\" + 0.015*\"said\" + 0.014*\"health\" + 0.011*\"industry\" + 0.009*\"fat\" + 0.009*\"new\" + 0.007*\"document\"\n",
      "2019-10-29 00:39:23,923 : INFO : topic #6 (0.100): 0.041*\"sugar\" + 0.028*\"disease\" + 0.026*\"heart\" + 0.025*\"research\" + 0.020*\"said\" + 0.014*\"industry\" + 0.011*\"new\" + 0.011*\"health\" + 0.008*\"fat\" + 0.007*\"risk\"\n",
      "2019-10-29 00:39:23,925 : INFO : topic diff=0.939260, rho=1.000000\n",
      "2019-10-29 00:39:24,349 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:24,354 : INFO : built Dictionary(328 unique tokens: ['although', 'acceptable', 'person', 'skeptical', 'come']...) from 5 documents (total 2230 corpus positions)\n",
      "2019-10-29 00:39:24,359 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:24,361 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:24,362 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:24,368 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:24,371 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:24,470 : INFO : -8.019 per-word bound, 259.4 perplexity estimate based on a held-out corpus of 5 documents with 2230 words\n",
      "2019-10-29 00:39:24,471 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:24,480 : INFO : topic #5 (0.100): 0.026*\"ford\" + 0.021*\"disease\" + 0.019*\"rob\" + 0.013*\"addiction\" + 0.013*\"cancer\" + 0.012*\"family\" + 0.009*\"want\" + 0.009*\"drug\" + 0.009*\"u\" + 0.008*\"people\"\n",
      "2019-10-29 00:39:24,482 : INFO : topic #2 (0.100): 0.024*\"disease\" + 0.019*\"rob\" + 0.016*\"ford\" + 0.015*\"cancer\" + 0.014*\"addiction\" + 0.012*\"people\" + 0.010*\"drug\" + 0.009*\"family\" + 0.009*\"want\" + 0.009*\"sympathy\"\n",
      "2019-10-29 00:39:24,485 : INFO : topic #8 (0.100): 0.027*\"ford\" + 0.023*\"disease\" + 0.021*\"addiction\" + 0.013*\"cancer\" + 0.013*\"rob\" + 0.012*\"drug\" + 0.009*\"people\" + 0.009*\"family\" + 0.009*\"sympathy\" + 0.008*\"one\"\n",
      "2019-10-29 00:39:24,487 : INFO : topic #0 (0.100): 0.028*\"ford\" + 0.018*\"addiction\" + 0.018*\"disease\" + 0.015*\"rob\" + 0.013*\"cancer\" + 0.011*\"drug\" + 0.010*\"people\" + 0.010*\"family\" + 0.009*\"want\" + 0.009*\"one\"\n",
      "2019-10-29 00:39:24,490 : INFO : topic #1 (0.100): 0.020*\"disease\" + 0.017*\"ford\" + 0.017*\"rob\" + 0.016*\"cancer\" + 0.015*\"addiction\" + 0.012*\"drug\" + 0.011*\"even\" + 0.010*\"people\" + 0.010*\"sympathy\" + 0.008*\"family\"\n",
      "2019-10-29 00:39:24,493 : INFO : topic diff=0.790212, rho=1.000000\n",
      "2019-10-29 00:39:24,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:24,908 : INFO : built Dictionary(418 unique tokens: ['previously', 'real', 'place', 'veracity', 'troll']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:39:24,912 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:24,914 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:24,915 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:24,919 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:24,921 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:25,059 : INFO : -7.987 per-word bound, 253.7 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:39:25,060 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:25,068 : INFO : topic #5 (0.100): 0.017*\"company\" + 0.015*\"information\" + 0.013*\"need\" + 0.013*\"user\" + 0.012*\"platform\" + 0.011*\"u\" + 0.011*\"content\" + 0.011*\"medium\" + 0.010*\"social\" + 0.010*\"facebook\"\n",
      "2019-10-29 00:39:25,070 : INFO : topic #2 (0.100): 0.020*\"content\" + 0.019*\"information\" + 0.017*\"company\" + 0.016*\"user\" + 0.013*\"facebook\" + 0.013*\"platform\" + 0.012*\"medium\" + 0.012*\"u\" + 0.011*\"tech\" + 0.010*\"attention\"\n",
      "2019-10-29 00:39:25,073 : INFO : topic #8 (0.100): 0.018*\"information\" + 0.016*\"user\" + 0.016*\"platform\" + 0.014*\"company\" + 0.014*\"tech\" + 0.012*\"social\" + 0.012*\"facebook\" + 0.011*\"google\" + 0.010*\"need\" + 0.010*\"attention\"\n",
      "2019-10-29 00:39:25,075 : INFO : topic #4 (0.100): 0.016*\"information\" + 0.016*\"tech\" + 0.016*\"medium\" + 0.013*\"company\" + 0.012*\"facebook\" + 0.012*\"content\" + 0.012*\"need\" + 0.011*\"attention\" + 0.011*\"user\" + 0.011*\"google\"\n",
      "2019-10-29 00:39:25,078 : INFO : topic #0 (0.100): 0.017*\"information\" + 0.016*\"content\" + 0.015*\"platform\" + 0.013*\"company\" + 0.012*\"facebook\" + 0.012*\"user\" + 0.011*\"medium\" + 0.011*\"u\" + 0.011*\"google\" + 0.011*\"need\"\n",
      "2019-10-29 00:39:25,080 : INFO : topic diff=0.877586, rho=1.000000\n",
      "2019-10-29 00:39:25,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:25,567 : INFO : built Dictionary(253 unique tokens: ['previously', 'person', 'laboratory', 'come', 'radioactivity']...) from 5 documents (total 1885 corpus positions)\n",
      "2019-10-29 00:39:25,569 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:25,570 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:25,571 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:25,575 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:25,576 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:25,666 : INFO : -7.633 per-word bound, 198.5 perplexity estimate based on a held-out corpus of 5 documents with 1885 words\n",
      "2019-10-29 00:39:25,667 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:25,675 : INFO : topic #7 (0.100): 0.018*\"electron\" + 0.016*\"said\" + 0.016*\"biomolecules\" + 0.016*\"nobel\" + 0.015*\"work\" + 0.015*\"prize\" + 0.014*\"development\" + 0.014*\"university\" + 0.012*\"molecule\" + 0.011*\"cryo\"\n",
      "2019-10-29 00:39:25,677 : INFO : topic #4 (0.100): 0.023*\"electron\" + 0.020*\"said\" + 0.015*\"prize\" + 0.014*\"nobel\" + 0.014*\"biomolecules\" + 0.012*\"frank\" + 0.012*\"university\" + 0.012*\"awarded\" + 0.012*\"development\" + 0.011*\"work\"\n",
      "2019-10-29 00:39:25,679 : INFO : topic #9 (0.100): 0.021*\"nobel\" + 0.018*\"electron\" + 0.018*\"development\" + 0.017*\"work\" + 0.016*\"prize\" + 0.015*\"said\" + 0.012*\"microscopy\" + 0.011*\"awarded\" + 0.010*\"henderson\" + 0.010*\"chemistry\"\n",
      "2019-10-29 00:39:25,681 : INFO : topic #2 (0.100): 0.019*\"nobel\" + 0.016*\"prize\" + 0.015*\"electron\" + 0.014*\"work\" + 0.014*\"development\" + 0.013*\"said\" + 0.013*\"chemistry\" + 0.013*\"professor\" + 0.011*\"awarded\" + 0.011*\"molecule\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:25,683 : INFO : topic #1 (0.100): 0.019*\"nobel\" + 0.018*\"said\" + 0.015*\"development\" + 0.015*\"electron\" + 0.014*\"work\" + 0.013*\"prize\" + 0.012*\"biomolecules\" + 0.011*\"cryo\" + 0.011*\"chemistry\" + 0.010*\"awarded\"\n",
      "2019-10-29 00:39:25,685 : INFO : topic diff=0.808860, rho=1.000000\n",
      "2019-10-29 00:39:26,146 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:26,156 : INFO : built Dictionary(711 unique tokens: ['scmuley', 'offend', 'astoria', 'anger', 'entitled']...) from 5 documents (total 7380 corpus positions)\n",
      "2019-10-29 00:39:26,163 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:26,165 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:26,166 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:26,171 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:26,174 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:26,385 : INFO : -8.189 per-word bound, 291.9 perplexity estimate based on a held-out corpus of 5 documents with 7380 words\n",
      "2019-10-29 00:39:26,388 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:26,402 : INFO : topic #0 (0.100): 0.038*\"cruz\" + 0.025*\"photo\" + 0.025*\"caption\" + 0.019*\"ted\" + 0.015*\"moment\" + 0.015*\"hide\" + 0.015*\"debate\" + 0.011*\"career\" + 0.011*\"republican\" + 0.008*\"new\"\n",
      "2019-10-29 00:39:26,405 : INFO : topic #9 (0.100): 0.039*\"cruz\" + 0.026*\"hide\" + 0.023*\"photo\" + 0.021*\"caption\" + 0.019*\"ted\" + 0.018*\"moment\" + 0.016*\"debate\" + 0.016*\"republican\" + 0.013*\"career\" + 0.009*\"charleston\"\n",
      "2019-10-29 00:39:26,409 : INFO : topic #5 (0.100): 0.029*\"cruz\" + 0.022*\"hide\" + 0.022*\"photo\" + 0.021*\"debate\" + 0.018*\"career\" + 0.018*\"ted\" + 0.017*\"republican\" + 0.015*\"moment\" + 0.014*\"caption\" + 0.010*\"north\"\n",
      "2019-10-29 00:39:26,412 : INFO : topic #1 (0.100): 0.035*\"cruz\" + 0.026*\"photo\" + 0.021*\"caption\" + 0.020*\"republican\" + 0.019*\"ted\" + 0.019*\"hide\" + 0.018*\"moment\" + 0.017*\"career\" + 0.012*\"debate\" + 0.010*\"charleston\"\n",
      "2019-10-29 00:39:26,415 : INFO : topic #7 (0.100): 0.044*\"cruz\" + 0.028*\"caption\" + 0.020*\"hide\" + 0.018*\"photo\" + 0.017*\"ted\" + 0.017*\"moment\" + 0.015*\"republican\" + 0.014*\"career\" + 0.012*\"debate\" + 0.009*\"said\"\n",
      "2019-10-29 00:39:26,419 : INFO : topic diff=0.999561, rho=1.000000\n",
      "2019-10-29 00:39:26,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:26,991 : INFO : built Dictionary(712 unique tokens: ['earned', 'wave', 'camp', 'defection', 'let']...) from 5 documents (total 7600 corpus positions)\n",
      "2019-10-29 00:39:26,999 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:27,001 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:27,002 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:27,007 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:27,010 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:27,227 : INFO : -8.157 per-word bound, 285.4 perplexity estimate based on a held-out corpus of 5 documents with 7600 words\n",
      "2019-10-29 00:39:27,229 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:27,239 : INFO : topic #7 (0.100): 0.058*\"mccain\" + 0.026*\"photo\" + 0.024*\"sen\" + 0.021*\"caption\" + 0.021*\"john\" + 0.021*\"hide\" + 0.019*\"career\" + 0.018*\"life\" + 0.013*\"senator\" + 0.009*\"senate\"\n",
      "2019-10-29 00:39:27,241 : INFO : topic #1 (0.100): 0.046*\"mccain\" + 0.033*\"sen\" + 0.027*\"life\" + 0.027*\"john\" + 0.022*\"photo\" + 0.021*\"hide\" + 0.019*\"caption\" + 0.017*\"career\" + 0.016*\"senator\" + 0.011*\"senate\"\n",
      "2019-10-29 00:39:27,242 : INFO : topic #3 (0.100): 0.088*\"mccain\" + 0.028*\"sen\" + 0.026*\"john\" + 0.024*\"photo\" + 0.022*\"life\" + 0.020*\"career\" + 0.020*\"caption\" + 0.011*\"hide\" + 0.009*\"senator\" + 0.009*\"senate\"\n",
      "2019-10-29 00:39:27,245 : INFO : topic #5 (0.100): 0.059*\"mccain\" + 0.032*\"john\" + 0.027*\"caption\" + 0.027*\"sen\" + 0.021*\"hide\" + 0.020*\"career\" + 0.018*\"photo\" + 0.017*\"life\" + 0.012*\"senator\" + 0.007*\"senate\"\n",
      "2019-10-29 00:39:27,246 : INFO : topic #2 (0.100): 0.071*\"mccain\" + 0.030*\"career\" + 0.028*\"sen\" + 0.026*\"john\" + 0.026*\"photo\" + 0.025*\"hide\" + 0.022*\"life\" + 0.017*\"caption\" + 0.009*\"senator\" + 0.009*\"senate\"\n",
      "2019-10-29 00:39:27,248 : INFO : topic diff=1.002226, rho=1.000000\n",
      "2019-10-29 00:39:27,655 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:27,659 : INFO : built Dictionary(273 unique tokens: ['fox', 'person', 'campaign', 'industry', 'racked']...) from 5 documents (total 1975 corpus positions)\n",
      "2019-10-29 00:39:27,663 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:27,664 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:27,665 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:27,669 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:27,671 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:27,757 : INFO : -7.748 per-word bound, 215.0 perplexity estimate based on a held-out corpus of 5 documents with 1975 words\n",
      "2019-10-29 00:39:27,758 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:27,766 : INFO : topic #1 (0.100): 0.023*\"woman\" + 0.020*\"weinstein\" + 0.015*\"right\" + 0.013*\"harvey\" + 0.012*\"editor\" + 0.010*\"time\" + 0.010*\"like\" + 0.009*\"workplace\" + 0.009*\"break\" + 0.008*\"allegation\"\n",
      "2019-10-29 00:39:27,767 : INFO : topic #8 (0.100): 0.026*\"woman\" + 0.020*\"weinstein\" + 0.016*\"right\" + 0.014*\"time\" + 0.011*\"allegation\" + 0.011*\"harvey\" + 0.011*\"power\" + 0.010*\"silence\" + 0.010*\"culture\" + 0.010*\"editor\"\n",
      "2019-10-29 00:39:27,769 : INFO : topic #9 (0.100): 0.026*\"woman\" + 0.020*\"weinstein\" + 0.015*\"right\" + 0.014*\"harvey\" + 0.011*\"allegation\" + 0.010*\"time\" + 0.010*\"editor\" + 0.010*\"harassment\" + 0.009*\"sexual\" + 0.009*\"culture\"\n",
      "2019-10-29 00:39:27,771 : INFO : topic #3 (0.100): 0.027*\"woman\" + 0.017*\"weinstein\" + 0.012*\"right\" + 0.012*\"time\" + 0.012*\"harvey\" + 0.011*\"allegation\" + 0.011*\"harassment\" + 0.010*\"power\" + 0.009*\"like\" + 0.009*\"good\"\n",
      "2019-10-29 00:39:27,773 : INFO : topic #5 (0.100): 0.024*\"woman\" + 0.020*\"weinstein\" + 0.014*\"right\" + 0.011*\"harassment\" + 0.011*\"allegation\" + 0.011*\"time\" + 0.009*\"like\" + 0.009*\"culture\" + 0.009*\"power\" + 0.009*\"story\"\n",
      "2019-10-29 00:39:27,775 : INFO : topic diff=0.778352, rho=1.000000\n",
      "2019-10-29 00:39:28,166 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:28,168 : INFO : built Dictionary(94 unique tokens: ['security', 'campaign', 'sideline', 'pursue', 'critical']...) from 5 documents (total 690 corpus positions)\n",
      "2019-10-29 00:39:28,172 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:28,173 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:28,174 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:28,177 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:28,179 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:28,226 : INFO : -6.766 per-word bound, 108.8 perplexity estimate based on a held-out corpus of 5 documents with 690 words\n",
      "2019-10-29 00:39:28,228 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:28,233 : INFO : topic #7 (0.100): 0.035*\"obama\" + 0.034*\"security\" + 0.032*\"national\" + 0.029*\"president\" + 0.026*\"adviser\" + 0.025*\"council\" + 0.023*\"gibbs\" + 0.021*\"axelrod\" + 0.020*\"spicer\" + 0.020*\"senior\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:28,235 : INFO : topic #9 (0.100): 0.029*\"axelrod\" + 0.029*\"national\" + 0.027*\"chief\" + 0.026*\"obama\" + 0.025*\"security\" + 0.024*\"gibbs\" + 0.023*\"council\" + 0.023*\"spicer\" + 0.022*\"adviser\" + 0.021*\"president\"\n",
      "2019-10-29 00:39:28,238 : INFO : topic #2 (0.100): 0.029*\"obama\" + 0.028*\"president\" + 0.027*\"national\" + 0.027*\"security\" + 0.025*\"council\" + 0.023*\"axelrod\" + 0.022*\"spicer\" + 0.021*\"chief\" + 0.021*\"senior\" + 0.020*\"adviser\"\n",
      "2019-10-29 00:39:28,241 : INFO : topic #5 (0.100): 0.033*\"national\" + 0.029*\"axelrod\" + 0.029*\"security\" + 0.028*\"president\" + 0.028*\"obama\" + 0.025*\"council\" + 0.024*\"adviser\" + 0.020*\"senior\" + 0.020*\"chief\" + 0.018*\"spicer\"\n",
      "2019-10-29 00:39:28,244 : INFO : topic #4 (0.100): 0.036*\"council\" + 0.026*\"president\" + 0.024*\"obama\" + 0.024*\"security\" + 0.023*\"gibbs\" + 0.023*\"national\" + 0.022*\"axelrod\" + 0.021*\"spicer\" + 0.020*\"adviser\" + 0.019*\"chief\"\n",
      "2019-10-29 00:39:28,246 : INFO : topic diff=0.783717, rho=1.000000\n",
      "2019-10-29 00:39:28,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:28,745 : INFO : built Dictionary(995 unique tokens: ['let', 'remained', 'planned', 'expert', 'hatred']...) from 5 documents (total 7560 corpus positions)\n",
      "2019-10-29 00:39:28,756 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:28,757 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:28,759 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:28,766 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:28,768 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:29,046 : INFO : -8.914 per-word bound, 482.2 perplexity estimate based on a held-out corpus of 5 documents with 7560 words\n",
      "2019-10-29 00:39:29,047 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:29,060 : INFO : topic #8 (0.100): 0.011*\"russian\" + 0.009*\"german\" + 0.008*\"west\" + 0.008*\"american\" + 0.008*\"kgb\" + 0.007*\"one\" + 0.006*\"agayants\" + 0.006*\"germany\" + 0.006*\"anti\" + 0.005*\"even\"\n",
      "2019-10-29 00:39:29,063 : INFO : topic #2 (0.100): 0.012*\"russian\" + 0.012*\"west\" + 0.008*\"one\" + 0.008*\"american\" + 0.007*\"germany\" + 0.007*\"even\" + 0.007*\"anti\" + 0.007*\"german\" + 0.006*\"agayants\" + 0.006*\"right\"\n",
      "2019-10-29 00:39:29,066 : INFO : topic #1 (0.100): 0.012*\"west\" + 0.010*\"russian\" + 0.007*\"german\" + 0.007*\"kgb\" + 0.007*\"anti\" + 0.007*\"one\" + 0.007*\"germany\" + 0.006*\"right\" + 0.006*\"american\" + 0.005*\"facebook\"\n",
      "2019-10-29 00:39:29,068 : INFO : topic #5 (0.100): 0.011*\"west\" + 0.009*\"russian\" + 0.008*\"german\" + 0.007*\"one\" + 0.007*\"kgb\" + 0.007*\"germany\" + 0.006*\"american\" + 0.006*\"anti\" + 0.005*\"facebook\" + 0.005*\"u\"\n",
      "2019-10-29 00:39:29,071 : INFO : topic #3 (0.100): 0.009*\"russian\" + 0.009*\"west\" + 0.008*\"german\" + 0.007*\"kgb\" + 0.007*\"american\" + 0.007*\"agayants\" + 0.006*\"germany\" + 0.005*\"one\" + 0.005*\"facebook\" + 0.005*\"state\"\n",
      "2019-10-29 00:39:29,073 : INFO : topic diff=0.840011, rho=1.000000\n",
      "2019-10-29 00:39:29,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:29,492 : INFO : built Dictionary(283 unique tokens: ['energy', 'wave', 'end', 'maintenance', 'advantage']...) from 5 documents (total 2385 corpus positions)\n",
      "2019-10-29 00:39:29,496 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:29,501 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:29,504 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:29,507 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:29,510 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:29,641 : INFO : -7.550 per-word bound, 187.4 perplexity estimate based on a held-out corpus of 5 documents with 2385 words\n",
      "2019-10-29 00:39:29,643 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:29,653 : INFO : topic #1 (0.100): 0.048*\"energy\" + 0.033*\"wave\" + 0.022*\"renewable\" + 0.022*\"said\" + 0.017*\"technology\" + 0.017*\"power\" + 0.013*\"peretz\" + 0.013*\"yam\" + 0.011*\"company\" + 0.011*\"pro\"\n",
      "2019-10-29 00:39:29,656 : INFO : topic #3 (0.100): 0.052*\"energy\" + 0.032*\"wave\" + 0.018*\"renewable\" + 0.018*\"said\" + 0.018*\"technology\" + 0.016*\"power\" + 0.013*\"ghana\" + 0.013*\"peretz\" + 0.012*\"company\" + 0.011*\"yam\"\n",
      "2019-10-29 00:39:29,659 : INFO : topic #7 (0.100): 0.058*\"energy\" + 0.031*\"wave\" + 0.020*\"renewable\" + 0.019*\"said\" + 0.018*\"power\" + 0.016*\"technology\" + 0.012*\"company\" + 0.012*\"yam\" + 0.011*\"pro\" + 0.011*\"peretz\"\n",
      "2019-10-29 00:39:29,661 : INFO : topic #4 (0.100): 0.044*\"energy\" + 0.035*\"wave\" + 0.023*\"power\" + 0.019*\"said\" + 0.018*\"renewable\" + 0.018*\"technology\" + 0.015*\"company\" + 0.013*\"ghana\" + 0.013*\"peretz\" + 0.012*\"yam\"\n",
      "2019-10-29 00:39:29,664 : INFO : topic #6 (0.100): 0.071*\"energy\" + 0.021*\"wave\" + 0.020*\"said\" + 0.019*\"technology\" + 0.017*\"power\" + 0.015*\"renewable\" + 0.013*\"yam\" + 0.012*\"ghana\" + 0.011*\"pro\" + 0.011*\"peretz\"\n",
      "2019-10-29 00:39:29,668 : INFO : topic diff=0.891354, rho=1.000000\n",
      "2019-10-29 00:39:30,272 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:30,291 : INFO : built Dictionary(510 unique tokens: ['let', 'experiencing', 'deep', 'timing', 'offered']...) from 5 documents (total 5510 corpus positions)\n",
      "2019-10-29 00:39:30,308 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:30,332 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:30,336 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:30,341 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:30,344 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:30,528 : INFO : -7.818 per-word bound, 225.6 perplexity estimate based on a held-out corpus of 5 documents with 5510 words\n",
      "2019-10-29 00:39:30,529 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:30,539 : INFO : topic #7 (0.100): 0.029*\"leave\" + 0.023*\"paid\" + 0.018*\"said\" + 0.016*\"week\" + 0.012*\"time\" + 0.012*\"month\" + 0.011*\"six\" + 0.010*\"schulte\" + 0.010*\"study\" + 0.010*\"infant\"\n",
      "2019-10-29 00:39:30,542 : INFO : topic #9 (0.100): 0.037*\"leave\" + 0.027*\"paid\" + 0.018*\"week\" + 0.016*\"six\" + 0.015*\"schulte\" + 0.014*\"said\" + 0.014*\"month\" + 0.012*\"year\" + 0.010*\"health\" + 0.010*\"study\"\n",
      "2019-10-29 00:39:30,545 : INFO : topic #4 (0.100): 0.045*\"leave\" + 0.023*\"week\" + 0.021*\"paid\" + 0.014*\"six\" + 0.013*\"said\" + 0.013*\"schulte\" + 0.011*\"infant\" + 0.011*\"year\" + 0.010*\"health\" + 0.010*\"time\"\n",
      "2019-10-29 00:39:30,547 : INFO : topic #5 (0.100): 0.040*\"leave\" + 0.037*\"paid\" + 0.018*\"week\" + 0.016*\"schulte\" + 0.015*\"said\" + 0.013*\"study\" + 0.012*\"six\" + 0.010*\"woman\" + 0.009*\"report\" + 0.009*\"year\"\n",
      "2019-10-29 00:39:30,550 : INFO : topic #8 (0.100): 0.033*\"leave\" + 0.027*\"paid\" + 0.020*\"schulte\" + 0.019*\"week\" + 0.013*\"month\" + 0.013*\"said\" + 0.012*\"time\" + 0.010*\"year\" + 0.009*\"six\" + 0.009*\"woman\"\n",
      "2019-10-29 00:39:30,553 : INFO : topic diff=1.033498, rho=1.000000\n",
      "2019-10-29 00:39:31,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:31,042 : INFO : built Dictionary(324 unique tokens: ['rage', 'offered', 'proceeding', 'averaged', 'de']...) from 5 documents (total 2610 corpus positions)\n",
      "2019-10-29 00:39:31,049 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:31,052 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:31,056 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:31,059 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:31,062 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:31,264 : INFO : -7.744 per-word bound, 214.4 perplexity estimate based on a held-out corpus of 5 documents with 2610 words\n",
      "2019-10-29 00:39:31,266 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:31,277 : INFO : topic #7 (0.100): 0.027*\"said\" + 0.024*\"paddock\" + 0.015*\"night\" + 0.010*\"asked\" + 0.010*\"casino\" + 0.010*\"prescribed\" + 0.010*\"time\" + 0.009*\"much\" + 0.009*\"vega\" + 0.007*\"day\"\n",
      "2019-10-29 00:39:31,280 : INFO : topic #4 (0.100): 0.029*\"said\" + 0.025*\"paddock\" + 0.012*\"time\" + 0.010*\"asked\" + 0.010*\"la\" + 0.009*\"much\" + 0.009*\"prescribed\" + 0.009*\"room\" + 0.008*\"day\" + 0.008*\"night\"\n",
      "2019-10-29 00:39:31,283 : INFO : topic #1 (0.100): 0.028*\"paddock\" + 0.027*\"said\" + 0.014*\"night\" + 0.012*\"asked\" + 0.011*\"time\" + 0.011*\"vega\" + 0.009*\"much\" + 0.009*\"prescribed\" + 0.009*\"would\" + 0.009*\"video\"\n",
      "2019-10-29 00:39:31,288 : INFO : topic #6 (0.100): 0.039*\"paddock\" + 0.019*\"said\" + 0.013*\"time\" + 0.011*\"room\" + 0.011*\"vega\" + 0.010*\"asked\" + 0.009*\"night\" + 0.008*\"winkler\" + 0.008*\"would\" + 0.008*\"prescribed\"\n",
      "2019-10-29 00:39:31,290 : INFO : topic #9 (0.100): 0.021*\"paddock\" + 0.019*\"said\" + 0.017*\"night\" + 0.014*\"time\" + 0.013*\"asked\" + 0.011*\"vega\" + 0.010*\"much\" + 0.010*\"la\" + 0.010*\"prescribed\" + 0.009*\"room\"\n",
      "2019-10-29 00:39:31,294 : INFO : topic diff=0.829692, rho=1.000000\n",
      "2019-10-29 00:39:31,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:31,934 : INFO : built Dictionary(84 unique tokens: ['civilian', 'affected', 'prime', 'completely', 'click']...) from 5 documents (total 520 corpus positions)\n",
      "2019-10-29 00:39:31,938 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:31,941 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:31,944 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:31,948 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:31,951 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:32,001 : INFO : -6.984 per-word bound, 126.6 perplexity estimate based on a held-out corpus of 5 documents with 520 words\n",
      "2019-10-29 00:39:32,008 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:32,017 : INFO : topic #4 (0.100): 0.058*\"iraqi\" + 0.047*\"mosul\" + 0.029*\"people\" + 0.022*\"isi\" + 0.020*\"help\" + 0.020*\"iraq\" + 0.017*\"city\" + 0.017*\"affected\" + 0.014*\"crisis\" + 0.013*\"un\"\n",
      "2019-10-29 00:39:32,020 : INFO : topic #9 (0.100): 0.069*\"mosul\" + 0.046*\"iraqi\" + 0.035*\"people\" + 0.023*\"iraq\" + 0.021*\"city\" + 0.020*\"affected\" + 0.018*\"help\" + 0.017*\"crisis\" + 0.017*\"isi\" + 0.014*\"un\"\n",
      "2019-10-29 00:39:32,023 : INFO : topic #3 (0.100): 0.070*\"mosul\" + 0.047*\"iraqi\" + 0.030*\"people\" + 0.029*\"iraq\" + 0.021*\"affected\" + 0.020*\"crisis\" + 0.020*\"city\" + 0.018*\"help\" + 0.017*\"isi\" + 0.012*\"largest\"\n",
      "2019-10-29 00:39:32,026 : INFO : topic #8 (0.100): 0.068*\"iraqi\" + 0.064*\"mosul\" + 0.028*\"iraq\" + 0.024*\"people\" + 0.020*\"affected\" + 0.020*\"isi\" + 0.019*\"help\" + 0.017*\"crisis\" + 0.016*\"city\" + 0.013*\"caught\"\n",
      "2019-10-29 00:39:32,028 : INFO : topic #2 (0.100): 0.056*\"mosul\" + 0.053*\"iraqi\" + 0.030*\"iraq\" + 0.023*\"people\" + 0.022*\"affected\" + 0.021*\"crisis\" + 0.019*\"help\" + 0.016*\"city\" + 0.014*\"isi\" + 0.013*\"clean\"\n",
      "2019-10-29 00:39:32,032 : INFO : topic diff=0.729708, rho=1.000000\n",
      "2019-10-29 00:39:32,494 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:32,503 : INFO : built Dictionary(623 unique tokens: ['located', 'energy', 'assignment', 'treasured', 'revealed']...) from 5 documents (total 5590 corpus positions)\n",
      "2019-10-29 00:39:32,511 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:32,515 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:32,518 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:32,523 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:32,526 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:32,742 : INFO : -8.230 per-word bound, 300.2 perplexity estimate based on a held-out corpus of 5 documents with 5590 words\n",
      "2019-10-29 00:39:32,744 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:32,752 : INFO : topic #8 (0.100): 0.031*\"student\" + 0.019*\"school\" + 0.016*\"reading\" + 0.015*\"digital\" + 0.014*\"text\" + 0.011*\"print\" + 0.009*\"caption\" + 0.008*\"world\" + 0.007*\"photo\" + 0.007*\"better\"\n",
      "2019-10-29 00:39:32,755 : INFO : topic #6 (0.100): 0.038*\"student\" + 0.016*\"digital\" + 0.014*\"school\" + 0.012*\"reading\" + 0.012*\"print\" + 0.011*\"text\" + 0.011*\"hide\" + 0.009*\"better\" + 0.008*\"photo\" + 0.008*\"classroom\"\n",
      "2019-10-29 00:39:32,757 : INFO : topic #4 (0.100): 0.030*\"student\" + 0.022*\"school\" + 0.013*\"reading\" + 0.013*\"text\" + 0.012*\"digital\" + 0.010*\"better\" + 0.010*\"print\" + 0.009*\"caption\" + 0.009*\"photo\" + 0.008*\"classroom\"\n",
      "2019-10-29 00:39:32,760 : INFO : topic #9 (0.100): 0.027*\"student\" + 0.018*\"school\" + 0.013*\"reading\" + 0.013*\"text\" + 0.013*\"digital\" + 0.012*\"print\" + 0.011*\"photo\" + 0.010*\"better\" + 0.010*\"classroom\" + 0.009*\"hide\"\n",
      "2019-10-29 00:39:32,762 : INFO : topic #1 (0.100): 0.030*\"student\" + 0.021*\"school\" + 0.014*\"print\" + 0.014*\"text\" + 0.013*\"caption\" + 0.012*\"reading\" + 0.011*\"hide\" + 0.011*\"classroom\" + 0.009*\"technology\" + 0.009*\"digital\"\n",
      "2019-10-29 00:39:32,764 : INFO : topic diff=0.895751, rho=1.000000\n",
      "2019-10-29 00:39:33,187 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:33,190 : INFO : built Dictionary(167 unique tokens: ['even', 'every', 'wherever', 'book', 'campaign']...) from 5 documents (total 1375 corpus positions)\n",
      "2019-10-29 00:39:33,192 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:33,194 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:33,195 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:33,198 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:33,201 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:33,263 : INFO : -7.095 per-word bound, 136.7 perplexity estimate based on a held-out corpus of 5 documents with 1375 words\n",
      "2019-10-29 00:39:33,265 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:33,271 : INFO : topic #0 (0.100): 0.056*\"trump\" + 0.029*\"said\" + 0.026*\"ivana\" + 0.021*\"new\" + 0.019*\"donald\" + 0.018*\"maple\" + 0.017*\"bye\" + 0.016*\"president\" + 0.015*\"want\" + 0.015*\"go\"\n",
      "2019-10-29 00:39:33,273 : INFO : topic #8 (0.100): 0.075*\"trump\" + 0.048*\"said\" + 0.039*\"ivana\" + 0.025*\"bye\" + 0.018*\"president\" + 0.017*\"donald\" + 0.016*\"want\" + 0.015*\"new\" + 0.013*\"maple\" + 0.012*\"child\"\n",
      "2019-10-29 00:39:33,275 : INFO : topic #5 (0.100): 0.081*\"trump\" + 0.039*\"ivana\" + 0.030*\"said\" + 0.024*\"president\" + 0.020*\"bye\" + 0.020*\"donald\" + 0.017*\"new\" + 0.015*\"want\" + 0.013*\"wife\" + 0.013*\"go\"\n",
      "2019-10-29 00:39:33,278 : INFO : topic #3 (0.100): 0.061*\"trump\" + 0.038*\"said\" + 0.037*\"ivana\" + 0.018*\"donald\" + 0.017*\"want\" + 0.017*\"go\" + 0.016*\"president\" + 0.016*\"new\" + 0.015*\"bye\" + 0.013*\"maple\"\n",
      "2019-10-29 00:39:33,281 : INFO : topic #7 (0.100): 0.048*\"trump\" + 0.033*\"ivana\" + 0.033*\"said\" + 0.023*\"donald\" + 0.019*\"bye\" + 0.018*\"want\" + 0.016*\"president\" + 0.015*\"new\" + 0.013*\"told\" + 0.013*\"maple\"\n",
      "2019-10-29 00:39:33,283 : INFO : topic diff=0.885941, rho=1.000000\n",
      "2019-10-29 00:39:33,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:33,684 : INFO : built Dictionary(118 unique tokens: ['muscle', 'story', 'small', 'golden', 'life']...) from 5 documents (total 820 corpus positions)\n",
      "2019-10-29 00:39:33,686 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:33,688 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:33,689 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:33,691 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:33,692 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:33,747 : INFO : -7.055 per-word bound, 133.0 perplexity estimate based on a held-out corpus of 5 documents with 820 words\n",
      "2019-10-29 00:39:33,751 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:33,772 : INFO : topic #5 (0.100): 0.036*\"polio\" + 0.025*\"del\" + 0.024*\"country\" + 0.021*\"estal\" + 0.020*\"last\" + 0.019*\"year\" + 0.018*\"photographer\" + 0.017*\"kumar\" + 0.016*\"india\" + 0.015*\"wonder\"\n",
      "2019-10-29 00:39:33,776 : INFO : topic #8 (0.100): 0.033*\"polio\" + 0.030*\"del\" + 0.025*\"estal\" + 0.021*\"year\" + 0.021*\"last\" + 0.021*\"india\" + 0.019*\"country\" + 0.017*\"elena\" + 0.015*\"photographer\" + 0.015*\"since\"\n",
      "2019-10-29 00:39:33,779 : INFO : topic #7 (0.100): 0.027*\"polio\" + 0.025*\"last\" + 0.024*\"estal\" + 0.022*\"elena\" + 0.019*\"del\" + 0.019*\"photographer\" + 0.017*\"country\" + 0.017*\"india\" + 0.016*\"kumar\" + 0.016*\"year\"\n",
      "2019-10-29 00:39:33,795 : INFO : topic #0 (0.100): 0.026*\"estal\" + 0.025*\"polio\" + 0.023*\"last\" + 0.023*\"year\" + 0.021*\"del\" + 0.019*\"elena\" + 0.018*\"photographer\" + 0.018*\"kumar\" + 0.017*\"delhi\" + 0.017*\"india\"\n",
      "2019-10-29 00:39:33,798 : INFO : topic #3 (0.100): 0.041*\"polio\" + 0.027*\"last\" + 0.024*\"india\" + 0.023*\"del\" + 0.022*\"year\" + 0.020*\"estal\" + 0.018*\"elena\" + 0.016*\"kumar\" + 0.016*\"new\" + 0.015*\"photographer\"\n",
      "2019-10-29 00:39:33,803 : INFO : topic diff=0.757041, rho=1.000000\n",
      "2019-10-29 00:39:34,237 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:34,239 : INFO : built Dictionary(146 unique tokens: ['front', 'story', 'security', 'tax', 'beat']...) from 5 documents (total 1020 corpus positions)\n",
      "2019-10-29 00:39:34,242 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:34,243 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:34,244 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:34,247 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:34,248 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:34,323 : INFO : -7.233 per-word bound, 150.4 perplexity estimate based on a held-out corpus of 5 documents with 1020 words\n",
      "2019-10-29 00:39:34,326 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:34,332 : INFO : topic #3 (0.100): 0.047*\"trump\" + 0.029*\"corker\" + 0.023*\"need\" + 0.021*\"president\" + 0.018*\"republican\" + 0.018*\"war\" + 0.015*\"establishment\" + 0.014*\"jennings\" + 0.012*\"two\" + 0.012*\"senate\"\n",
      "2019-10-29 00:39:34,335 : INFO : topic #8 (0.100): 0.055*\"trump\" + 0.035*\"corker\" + 0.025*\"president\" + 0.022*\"need\" + 0.020*\"republican\" + 0.019*\"war\" + 0.014*\"two\" + 0.013*\"jennings\" + 0.012*\"senate\" + 0.012*\"establishment\"\n",
      "2019-10-29 00:39:34,338 : INFO : topic #1 (0.100): 0.057*\"trump\" + 0.032*\"corker\" + 0.021*\"republican\" + 0.020*\"president\" + 0.020*\"need\" + 0.017*\"establishment\" + 0.015*\"jennings\" + 0.015*\"war\" + 0.014*\"senate\" + 0.012*\"cnn\"\n",
      "2019-10-29 00:39:34,341 : INFO : topic #5 (0.100): 0.048*\"trump\" + 0.031*\"corker\" + 0.023*\"need\" + 0.022*\"war\" + 0.021*\"president\" + 0.015*\"republican\" + 0.014*\"establishment\" + 0.014*\"two\" + 0.012*\"endangers\" + 0.012*\"agenda\"\n",
      "2019-10-29 00:39:34,344 : INFO : topic #4 (0.100): 0.042*\"trump\" + 0.034*\"corker\" + 0.028*\"need\" + 0.020*\"president\" + 0.018*\"senate\" + 0.015*\"war\" + 0.015*\"establishment\" + 0.015*\"two\" + 0.014*\"jennings\" + 0.014*\"republican\"\n",
      "2019-10-29 00:39:34,347 : INFO : topic diff=0.784198, rho=1.000000\n",
      "2019-10-29 00:39:34,736 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:34,738 : INFO : built Dictionary(111 unique tokens: ['deadly', 'french', 'speaker', 'watch', 'nation']...) from 5 documents (total 785 corpus positions)\n",
      "2019-10-29 00:39:34,740 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:34,742 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:34,743 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:34,746 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:34,747 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:34,798 : INFO : -6.970 per-word bound, 125.4 perplexity estimate based on a held-out corpus of 5 documents with 785 words\n",
      "2019-10-29 00:39:34,799 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:34,805 : INFO : topic #9 (0.100): 0.032*\"english\" + 0.029*\"protester\" + 0.025*\"cameroon\" + 0.024*\"region\" + 0.023*\"speaking\" + 0.022*\"force\" + 0.021*\"right\" + 0.019*\"government\" + 0.018*\"french\" + 0.017*\"death\"\n",
      "2019-10-29 00:39:34,809 : INFO : topic #6 (0.100): 0.033*\"cameroon\" + 0.030*\"right\" + 0.029*\"english\" + 0.026*\"protester\" + 0.024*\"speaking\" + 0.021*\"force\" + 0.020*\"demonstration\" + 0.019*\"region\" + 0.018*\"government\" + 0.016*\"french\"\n",
      "2019-10-29 00:39:34,813 : INFO : topic #5 (0.100): 0.030*\"cameroon\" + 0.029*\"protester\" + 0.027*\"english\" + 0.026*\"right\" + 0.024*\"force\" + 0.021*\"speaking\" + 0.020*\"region\" + 0.020*\"french\" + 0.017*\"death\" + 0.015*\"call\"\n",
      "2019-10-29 00:39:34,816 : INFO : topic #1 (0.100): 0.035*\"english\" + 0.025*\"right\" + 0.025*\"cameroon\" + 0.024*\"force\" + 0.023*\"protester\" + 0.021*\"french\" + 0.020*\"speaking\" + 0.017*\"death\" + 0.017*\"government\" + 0.017*\"commissioner\"\n",
      "2019-10-29 00:39:34,819 : INFO : topic #0 (0.100): 0.035*\"protester\" + 0.033*\"cameroon\" + 0.030*\"english\" + 0.024*\"region\" + 0.023*\"government\" + 0.022*\"speaking\" + 0.022*\"right\" + 0.021*\"death\" + 0.020*\"force\" + 0.019*\"demonstration\"\n",
      "2019-10-29 00:39:34,821 : INFO : topic diff=0.794568, rho=1.000000\n",
      "2019-10-29 00:39:35,316 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:35,323 : INFO : built Dictionary(419 unique tokens: ['although', 'previously', 'filed', 'median', 'francisco']...) from 5 documents (total 4965 corpus positions)\n",
      "2019-10-29 00:39:35,328 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:35,330 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:35,331 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:35,335 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:35,336 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:35,473 : INFO : -7.537 per-word bound, 185.7 perplexity estimate based on a held-out corpus of 5 documents with 4965 words\n",
      "2019-10-29 00:39:35,475 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:35,481 : INFO : topic #6 (0.100): 0.056*\"abortion\" + 0.031*\"woman\" + 0.023*\"state\" + 0.022*\"mile\" + 0.015*\"said\" + 0.014*\"distance\" + 0.014*\"access\" + 0.012*\"bearak\" + 0.010*\"clinic\" + 0.010*\"provider\"\n",
      "2019-10-29 00:39:35,483 : INFO : topic #7 (0.100): 0.040*\"abortion\" + 0.032*\"woman\" + 0.022*\"state\" + 0.020*\"said\" + 0.019*\"distance\" + 0.019*\"mile\" + 0.013*\"access\" + 0.012*\"clinic\" + 0.011*\"grossman\" + 0.011*\"health\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:35,486 : INFO : topic #5 (0.100): 0.037*\"woman\" + 0.034*\"abortion\" + 0.024*\"mile\" + 0.020*\"state\" + 0.016*\"access\" + 0.015*\"distance\" + 0.015*\"said\" + 0.015*\"provider\" + 0.010*\"grossman\" + 0.010*\"clinic\"\n",
      "2019-10-29 00:39:35,488 : INFO : topic #8 (0.100): 0.057*\"abortion\" + 0.031*\"woman\" + 0.019*\"state\" + 0.018*\"mile\" + 0.016*\"said\" + 0.014*\"access\" + 0.012*\"clinic\" + 0.012*\"distance\" + 0.011*\"provider\" + 0.011*\"travel\"\n",
      "2019-10-29 00:39:35,490 : INFO : topic #1 (0.100): 0.043*\"abortion\" + 0.029*\"woman\" + 0.026*\"state\" + 0.020*\"distance\" + 0.018*\"mile\" + 0.017*\"said\" + 0.016*\"access\" + 0.011*\"provider\" + 0.010*\"area\" + 0.010*\"doctor\"\n",
      "2019-10-29 00:39:35,493 : INFO : topic diff=1.023948, rho=1.000000\n",
      "2019-10-29 00:39:35,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:35,903 : INFO : built Dictionary(98 unique tokens: ['rage', 'degeneration', 'career', 'new', 'cognitive']...) from 5 documents (total 735 corpus positions)\n",
      "2019-10-29 00:39:35,906 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:35,907 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:35,908 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:35,913 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:35,916 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:35,978 : INFO : -6.764 per-word bound, 108.7 perplexity estimate based on a held-out corpus of 5 documents with 735 words\n",
      "2019-10-29 00:39:35,981 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:35,986 : INFO : topic #7 (0.100): 0.055*\"hernandez\" + 0.040*\"brain\" + 0.037*\"cte\" + 0.026*\"university\" + 0.026*\"result\" + 0.022*\"attorney\" + 0.020*\"test\" + 0.018*\"aaron\" + 0.017*\"center\" + 0.016*\"loss\"\n",
      "2019-10-29 00:39:35,989 : INFO : topic #2 (0.100): 0.053*\"hernandez\" + 0.048*\"cte\" + 0.039*\"brain\" + 0.022*\"aaron\" + 0.022*\"center\" + 0.018*\"result\" + 0.018*\"attorney\" + 0.017*\"disease\" + 0.016*\"university\" + 0.015*\"mckee\"\n",
      "2019-10-29 00:39:35,993 : INFO : topic #1 (0.100): 0.066*\"hernandez\" + 0.034*\"brain\" + 0.030*\"result\" + 0.027*\"cte\" + 0.025*\"university\" + 0.021*\"center\" + 0.020*\"aaron\" + 0.020*\"disease\" + 0.015*\"stage\" + 0.015*\"attorney\"\n",
      "2019-10-29 00:39:35,996 : INFO : topic #6 (0.100): 0.043*\"hernandez\" + 0.039*\"cte\" + 0.037*\"brain\" + 0.026*\"result\" + 0.021*\"attorney\" + 0.019*\"university\" + 0.018*\"center\" + 0.017*\"disease\" + 0.016*\"test\" + 0.016*\"boston\"\n",
      "2019-10-29 00:39:35,999 : INFO : topic #3 (0.100): 0.055*\"hernandez\" + 0.040*\"cte\" + 0.038*\"brain\" + 0.025*\"result\" + 0.024*\"center\" + 0.020*\"attorney\" + 0.019*\"aaron\" + 0.019*\"disease\" + 0.017*\"university\" + 0.016*\"examined\"\n",
      "2019-10-29 00:39:36,000 : INFO : topic diff=0.799671, rho=1.000000\n",
      "2019-10-29 00:39:36,396 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:36,398 : INFO : built Dictionary(86 unique tokens: ['franco', 'andrade', 'filed', 'florida', 'evacuate']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:39:36,401 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:36,402 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:36,404 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:36,406 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:36,410 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:36,458 : INFO : -6.664 per-word bound, 101.4 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:39:36,462 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:36,471 : INFO : topic #9 (0.100): 0.042*\"died\" + 0.032*\"home\" + 0.029*\"family\" + 0.025*\"resident\" + 0.025*\"nursing\" + 0.022*\"following\" + 0.022*\"year\" + 0.022*\"franco\" + 0.020*\"week\" + 0.019*\"florida\"\n",
      "2019-10-29 00:39:36,475 : INFO : topic #8 (0.100): 0.040*\"died\" + 0.032*\"franco\" + 0.029*\"nursing\" + 0.028*\"resident\" + 0.027*\"florida\" + 0.025*\"facility\" + 0.024*\"home\" + 0.023*\"old\" + 0.022*\"year\" + 0.022*\"week\"\n",
      "2019-10-29 00:39:36,481 : INFO : topic #5 (0.100): 0.045*\"died\" + 0.030*\"home\" + 0.027*\"nursing\" + 0.026*\"franco\" + 0.025*\"week\" + 0.024*\"florida\" + 0.024*\"year\" + 0.023*\"old\" + 0.023*\"facility\" + 0.023*\"resident\"\n",
      "2019-10-29 00:39:36,483 : INFO : topic #2 (0.100): 0.040*\"died\" + 0.035*\"nursing\" + 0.031*\"franco\" + 0.029*\"resident\" + 0.027*\"home\" + 0.026*\"family\" + 0.024*\"facility\" + 0.023*\"year\" + 0.020*\"following\" + 0.019*\"old\"\n",
      "2019-10-29 00:39:36,485 : INFO : topic #1 (0.100): 0.036*\"died\" + 0.036*\"franco\" + 0.029*\"home\" + 0.029*\"resident\" + 0.024*\"following\" + 0.024*\"week\" + 0.024*\"florida\" + 0.023*\"nursing\" + 0.023*\"facility\" + 0.021*\"monday\"\n",
      "2019-10-29 00:39:36,487 : INFO : topic diff=0.815028, rho=1.000000\n",
      "2019-10-29 00:39:36,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:36,900 : INFO : built Dictionary(116 unique tokens: ['soil', 'security', 'book', 'omar', 'involved']...) from 5 documents (total 935 corpus positions)\n",
      "2019-10-29 00:39:36,902 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:36,903 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:36,905 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:36,907 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:36,908 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:36,962 : INFO : -6.793 per-word bound, 110.9 perplexity estimate based on a held-out corpus of 5 documents with 935 words\n",
      "2019-10-29 00:39:36,966 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:36,974 : INFO : topic #3 (0.100): 0.042*\"terrorist\" + 0.034*\"state\" + 0.029*\"carried\" + 0.023*\"united\" + 0.021*\"citizen\" + 0.020*\"attack\" + 0.019*\"permanent\" + 0.018*\"american\" + 0.018*\"u\" + 0.016*\"new\"\n",
      "2019-10-29 00:39:36,977 : INFO : topic #7 (0.100): 0.035*\"state\" + 0.032*\"united\" + 0.032*\"carried\" + 0.027*\"terrorist\" + 0.025*\"citizen\" + 0.021*\"attack\" + 0.019*\"american\" + 0.017*\"permanent\" + 0.016*\"legal\" + 0.016*\"u\"\n",
      "2019-10-29 00:39:36,981 : INFO : topic #8 (0.100): 0.035*\"state\" + 0.034*\"terrorist\" + 0.026*\"united\" + 0.024*\"citizen\" + 0.022*\"carried\" + 0.020*\"since\" + 0.018*\"attack\" + 0.018*\"resident\" + 0.018*\"new\" + 0.017*\"permanent\"\n",
      "2019-10-29 00:39:36,986 : INFO : topic #2 (0.100): 0.039*\"state\" + 0.035*\"citizen\" + 0.031*\"united\" + 0.030*\"carried\" + 0.029*\"terrorist\" + 0.022*\"american\" + 0.020*\"resident\" + 0.020*\"legal\" + 0.020*\"homegrown\" + 0.018*\"attack\"\n",
      "2019-10-29 00:39:36,991 : INFO : topic #5 (0.100): 0.041*\"state\" + 0.034*\"united\" + 0.032*\"carried\" + 0.028*\"terrorist\" + 0.028*\"american\" + 0.021*\"citizen\" + 0.017*\"since\" + 0.017*\"attack\" + 0.016*\"u\" + 0.016*\"new\"\n",
      "2019-10-29 00:39:36,993 : INFO : topic diff=0.809860, rho=1.000000\n",
      "2019-10-29 00:39:37,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:37,438 : INFO : built Dictionary(441 unique tokens: ['rmit', 'fostering', 'energy', 'retreat', 'party']...) from 5 documents (total 3950 corpus positions)\n",
      "2019-10-29 00:39:37,444 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:37,448 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:37,451 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:37,456 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:37,459 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:37,641 : INFO : -7.898 per-word bound, 238.5 perplexity estimate based on a held-out corpus of 5 documents with 3950 words\n",
      "2019-10-29 00:39:37,643 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:37,654 : INFO : topic #8 (0.100): 0.023*\"iran\" + 0.022*\"said\" + 0.020*\"u\" + 0.018*\"deal\" + 0.017*\"agreement\" + 0.011*\"north\" + 0.011*\"state\" + 0.011*\"trump\" + 0.010*\"accord\" + 0.008*\"nuclear\"\n",
      "2019-10-29 00:39:37,656 : INFO : topic #5 (0.100): 0.023*\"iran\" + 0.022*\"u\" + 0.021*\"deal\" + 0.019*\"said\" + 0.017*\"agreement\" + 0.013*\"trump\" + 0.012*\"state\" + 0.012*\"north\" + 0.009*\"korea\" + 0.008*\"nuclear\"\n",
      "2019-10-29 00:39:37,659 : INFO : topic #0 (0.100): 0.023*\"iran\" + 0.019*\"said\" + 0.017*\"u\" + 0.015*\"deal\" + 0.014*\"trump\" + 0.014*\"agreement\" + 0.011*\"state\" + 0.010*\"north\" + 0.010*\"nuclear\" + 0.009*\"foreign\"\n",
      "2019-10-29 00:39:37,663 : INFO : topic #7 (0.100): 0.022*\"iran\" + 0.020*\"said\" + 0.017*\"agreement\" + 0.016*\"u\" + 0.015*\"deal\" + 0.012*\"trump\" + 0.010*\"foreign\" + 0.010*\"state\" + 0.010*\"north\" + 0.009*\"mogherini\"\n",
      "2019-10-29 00:39:37,667 : INFO : topic #9 (0.100): 0.022*\"u\" + 0.021*\"iran\" + 0.017*\"said\" + 0.016*\"north\" + 0.015*\"deal\" + 0.014*\"agreement\" + 0.012*\"trump\" + 0.011*\"would\" + 0.010*\"state\" + 0.009*\"nuclear\"\n",
      "2019-10-29 00:39:37,669 : INFO : topic diff=0.883360, rho=1.000000\n",
      "2019-10-29 00:39:38,208 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:38,215 : INFO : built Dictionary(305 unique tokens: ['concern', 'person', 'relation', 'tax', 'echoing']...) from 5 documents (total 2420 corpus positions)\n",
      "2019-10-29 00:39:38,220 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:38,222 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:38,224 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:38,227 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:38,229 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:38,365 : INFO : -7.710 per-word bound, 209.4 perplexity estimate based on a held-out corpus of 5 documents with 2420 words\n",
      "2019-10-29 00:39:38,367 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:38,375 : INFO : topic #2 (0.100): 0.051*\"corker\" + 0.046*\"trump\" + 0.018*\"tax\" + 0.015*\"republican\" + 0.014*\"senate\" + 0.010*\"one\" + 0.008*\"house\" + 0.008*\"agenda\" + 0.008*\"reform\" + 0.008*\"president\"\n",
      "2019-10-29 00:39:38,377 : INFO : topic #6 (0.100): 0.043*\"corker\" + 0.032*\"trump\" + 0.016*\"senate\" + 0.014*\"republican\" + 0.012*\"agenda\" + 0.011*\"tax\" + 0.011*\"reform\" + 0.010*\"president\" + 0.009*\"u\" + 0.009*\"new\"\n",
      "2019-10-29 00:39:38,379 : INFO : topic #1 (0.100): 0.058*\"corker\" + 0.037*\"trump\" + 0.023*\"senate\" + 0.012*\"tax\" + 0.012*\"republican\" + 0.010*\"house\" + 0.010*\"reform\" + 0.010*\"new\" + 0.009*\"president\" + 0.009*\"committee\"\n",
      "2019-10-29 00:39:38,380 : INFO : topic #0 (0.100): 0.049*\"corker\" + 0.037*\"trump\" + 0.017*\"senate\" + 0.016*\"republican\" + 0.012*\"president\" + 0.011*\"tax\" + 0.011*\"agenda\" + 0.010*\"one\" + 0.010*\"reform\" + 0.009*\"new\"\n",
      "2019-10-29 00:39:38,382 : INFO : topic #7 (0.100): 0.051*\"corker\" + 0.042*\"trump\" + 0.017*\"senate\" + 0.013*\"republican\" + 0.012*\"one\" + 0.011*\"tax\" + 0.010*\"president\" + 0.009*\"reform\" + 0.009*\"member\" + 0.009*\"said\"\n",
      "2019-10-29 00:39:38,384 : INFO : topic diff=0.837074, rho=1.000000\n",
      "2019-10-29 00:39:38,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:38,931 : INFO : built Dictionary(845 unique tokens: ['andriano', 'advantage', 'expert', 'used', 'christa']...) from 5 documents (total 10735 corpus positions)\n",
      "2019-10-29 00:39:38,941 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:38,945 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:38,948 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:38,954 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:38,957 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:39,207 : INFO : -8.163 per-word bound, 286.7 perplexity estimate based on a held-out corpus of 5 documents with 10735 words\n",
      "2019-10-29 00:39:39,209 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:39,220 : INFO : topic #9 (0.100): 0.049*\"death\" + 0.037*\"photo\" + 0.036*\"row\" + 0.033*\"hide\" + 0.032*\"caption\" + 0.030*\"woman\" + 0.026*\"sentenced\" + 0.025*\"year\" + 0.024*\"old\" + 0.023*\"murdered\"\n",
      "2019-10-29 00:39:39,222 : INFO : topic #5 (0.100): 0.040*\"death\" + 0.039*\"hide\" + 0.035*\"woman\" + 0.033*\"row\" + 0.031*\"photo\" + 0.028*\"caption\" + 0.027*\"sentenced\" + 0.024*\"old\" + 0.017*\"murdered\" + 0.017*\"year\"\n",
      "2019-10-29 00:39:39,224 : INFO : topic #3 (0.100): 0.052*\"death\" + 0.039*\"row\" + 0.038*\"woman\" + 0.034*\"caption\" + 0.032*\"hide\" + 0.030*\"photo\" + 0.027*\"sentenced\" + 0.024*\"murdered\" + 0.021*\"year\" + 0.020*\"old\"\n",
      "2019-10-29 00:39:39,227 : INFO : topic #8 (0.100): 0.035*\"death\" + 0.033*\"photo\" + 0.033*\"caption\" + 0.032*\"woman\" + 0.031*\"row\" + 0.030*\"murdered\" + 0.026*\"hide\" + 0.022*\"old\" + 0.019*\"year\" + 0.019*\"sentenced\"\n",
      "2019-10-29 00:39:39,229 : INFO : topic #0 (0.100): 0.043*\"woman\" + 0.037*\"death\" + 0.034*\"caption\" + 0.033*\"sentenced\" + 0.032*\"row\" + 0.028*\"photo\" + 0.028*\"hide\" + 0.025*\"year\" + 0.022*\"murdered\" + 0.019*\"old\"\n",
      "2019-10-29 00:39:39,231 : INFO : topic diff=1.181787, rho=1.000000\n",
      "2019-10-29 00:39:39,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:39,619 : INFO : built Dictionary(1 unique tokens: ['nan']) from 5 documents (total 5 corpus positions)\n",
      "2019-10-29 00:39:39,619 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:39,621 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:39,622 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:39,623 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:39,625 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:39,630 : INFO : -4.929 per-word bound, 30.5 perplexity estimate based on a held-out corpus of 5 documents with 5 words\n",
      "2019-10-29 00:39:39,631 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:39,635 : INFO : topic #9 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:39:39,637 : INFO : topic #0 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:39:39,638 : INFO : topic #6 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:39:39,640 : INFO : topic #4 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:39:39,641 : INFO : topic #8 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:39:39,650 : INFO : topic diff=0.000000, rho=1.000000\n",
      "2019-10-29 00:39:40,048 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:40,050 : INFO : built Dictionary(139 unique tokens: ['pure', 'launch', 'gained', 'something', 'trusted']...) from 5 documents (total 940 corpus positions)\n",
      "2019-10-29 00:39:40,053 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:40,054 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:40,056 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:40,058 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:40,060 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:40,132 : INFO : -7.247 per-word bound, 151.9 perplexity estimate based on a held-out corpus of 5 documents with 940 words\n",
      "2019-10-29 00:39:40,134 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:40,146 : INFO : topic #5 (0.100): 0.046*\"design\" + 0.032*\"year\" + 0.020*\"one\" + 0.018*\"designer\" + 0.018*\"sight\" + 0.017*\"offsite\" + 0.017*\"bit\" + 0.016*\"singer\" + 0.016*\"new\" + 0.015*\"york\"\n",
      "2019-10-29 00:39:40,148 : INFO : topic #6 (0.100): 0.041*\"design\" + 0.026*\"bit\" + 0.026*\"year\" + 0.020*\"one\" + 0.018*\"unseen\" + 0.018*\"offsite\" + 0.018*\"new\" + 0.016*\"khemsurov\" + 0.015*\"designer\" + 0.015*\"sight\"\n",
      "2019-10-29 00:39:40,151 : INFO : topic #9 (0.100): 0.027*\"year\" + 0.025*\"design\" + 0.021*\"bit\" + 0.021*\"new\" + 0.018*\"designer\" + 0.018*\"one\" + 0.017*\"offsite\" + 0.016*\"york\" + 0.016*\"sight\" + 0.016*\"khemsurov\"\n",
      "2019-10-29 00:39:40,155 : INFO : topic #3 (0.100): 0.033*\"design\" + 0.027*\"new\" + 0.027*\"year\" + 0.023*\"one\" + 0.021*\"designer\" + 0.017*\"bit\" + 0.016*\"york\" + 0.016*\"khemsurov\" + 0.015*\"offsite\" + 0.013*\"singer\"\n",
      "2019-10-29 00:39:40,158 : INFO : topic #0 (0.100): 0.043*\"design\" + 0.031*\"year\" + 0.021*\"bit\" + 0.020*\"new\" + 0.019*\"designer\" + 0.017*\"one\" + 0.016*\"offsite\" + 0.015*\"sight\" + 0.015*\"singer\" + 0.014*\"khemsurov\"\n",
      "2019-10-29 00:39:40,163 : INFO : topic diff=0.783460, rho=1.000000\n",
      "2019-10-29 00:39:40,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:40,589 : INFO : built Dictionary(126 unique tokens: ['type', 'colleague', 'relationship', 'learn', 'may']...) from 5 documents (total 1060 corpus positions)\n",
      "2019-10-29 00:39:40,591 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:40,592 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:40,593 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:40,595 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:40,597 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:40,654 : INFO : -6.805 per-word bound, 111.8 perplexity estimate based on a held-out corpus of 5 documents with 1060 words\n",
      "2019-10-29 00:39:40,658 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:40,666 : INFO : topic #7 (0.100): 0.067*\"sex\" + 0.047*\"parent\" + 0.037*\"parenting\" + 0.036*\"child\" + 0.035*\"study\" + 0.025*\"household\" + 0.019*\"said\" + 0.018*\"different\" + 0.018*\"health\" + 0.016*\"family\"\n",
      "2019-10-29 00:39:40,670 : INFO : topic #8 (0.100): 0.065*\"sex\" + 0.046*\"study\" + 0.042*\"child\" + 0.035*\"parenting\" + 0.034*\"parent\" + 0.021*\"household\" + 0.019*\"said\" + 0.015*\"different\" + 0.015*\"stress\" + 0.015*\"find\"\n",
      "2019-10-29 00:39:40,673 : INFO : topic #3 (0.100): 0.055*\"sex\" + 0.043*\"child\" + 0.037*\"parent\" + 0.036*\"study\" + 0.026*\"parenting\" + 0.025*\"health\" + 0.024*\"household\" + 0.019*\"said\" + 0.017*\"find\" + 0.017*\"different\"\n",
      "2019-10-29 00:39:40,677 : INFO : topic #1 (0.100): 0.065*\"sex\" + 0.056*\"study\" + 0.042*\"child\" + 0.039*\"parent\" + 0.031*\"parenting\" + 0.018*\"said\" + 0.017*\"household\" + 0.015*\"different\" + 0.015*\"health\" + 0.015*\"found\"\n",
      "2019-10-29 00:39:40,680 : INFO : topic #0 (0.100): 0.047*\"study\" + 0.042*\"sex\" + 0.041*\"parent\" + 0.038*\"parenting\" + 0.036*\"child\" + 0.026*\"household\" + 0.020*\"different\" + 0.016*\"said\" + 0.016*\"health\" + 0.015*\"family\"\n",
      "2019-10-29 00:39:40,682 : INFO : topic diff=0.909937, rho=1.000000\n",
      "2019-10-29 00:39:41,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:41,119 : INFO : built Dictionary(319 unique tokens: ['forward', 'let', 'energy', 'end', 'appreciation']...) from 5 documents (total 2970 corpus positions)\n",
      "2019-10-29 00:39:41,124 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:41,125 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:41,126 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:41,130 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:41,131 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:41,249 : INFO : -7.537 per-word bound, 185.7 perplexity estimate based on a held-out corpus of 5 documents with 2970 words\n",
      "2019-10-29 00:39:41,251 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:41,260 : INFO : topic #2 (0.100): 0.028*\"child\" + 0.027*\"kid\" + 0.025*\"said\" + 0.023*\"parent\" + 0.021*\"want\" + 0.018*\"spoiled\" + 0.011*\"lieber\" + 0.011*\"set\" + 0.011*\"limit\" + 0.010*\"please\"\n",
      "2019-10-29 00:39:41,263 : INFO : topic #4 (0.100): 0.034*\"kid\" + 0.028*\"parent\" + 0.026*\"child\" + 0.024*\"said\" + 0.020*\"spoiled\" + 0.019*\"want\" + 0.011*\"limit\" + 0.011*\"cnn\" + 0.011*\"ferrara\" + 0.010*\"year\"\n",
      "2019-10-29 00:39:41,266 : INFO : topic #1 (0.100): 0.029*\"kid\" + 0.028*\"parent\" + 0.026*\"want\" + 0.024*\"child\" + 0.020*\"said\" + 0.019*\"spoiled\" + 0.011*\"set\" + 0.010*\"limit\" + 0.010*\"please\" + 0.009*\"get\"\n",
      "2019-10-29 00:39:41,269 : INFO : topic #7 (0.100): 0.030*\"parent\" + 0.027*\"kid\" + 0.024*\"child\" + 0.020*\"said\" + 0.020*\"spoiled\" + 0.019*\"want\" + 0.012*\"limit\" + 0.010*\"ferrara\" + 0.010*\"lieber\" + 0.010*\"please\"\n",
      "2019-10-29 00:39:41,271 : INFO : topic #3 (0.100): 0.031*\"kid\" + 0.023*\"said\" + 0.023*\"spoiled\" + 0.022*\"parent\" + 0.022*\"child\" + 0.021*\"want\" + 0.011*\"give\" + 0.011*\"set\" + 0.011*\"lieber\" + 0.010*\"ferrara\"\n",
      "2019-10-29 00:39:41,274 : INFO : topic diff=0.929596, rho=1.000000\n",
      "2019-10-29 00:39:41,723 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:41,728 : INFO : built Dictionary(366 unique tokens: ['although', 'unsuccessful', 'laboratory', 'genetically', 'used']...) from 5 documents (total 3655 corpus positions)\n",
      "2019-10-29 00:39:41,733 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:41,734 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:41,735 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:41,739 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:41,740 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:41,861 : INFO : -7.580 per-word bound, 191.3 perplexity estimate based on a held-out corpus of 5 documents with 3655 words\n",
      "2019-10-29 00:39:41,863 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:41,872 : INFO : topic #0 (0.100): 0.048*\"base\" + 0.035*\"embryo\" + 0.034*\"editing\" + 0.022*\"study\" + 0.021*\"said\" + 0.017*\"human\" + 0.016*\"mutation\" + 0.013*\"thalassemia\" + 0.013*\"scientist\" + 0.012*\"beta\"\n",
      "2019-10-29 00:39:41,874 : INFO : topic #2 (0.100): 0.044*\"base\" + 0.036*\"embryo\" + 0.027*\"editing\" + 0.023*\"human\" + 0.022*\"study\" + 0.017*\"said\" + 0.016*\"scientist\" + 0.012*\"gene\" + 0.011*\"mutation\" + 0.010*\"beta\"\n",
      "2019-10-29 00:39:41,878 : INFO : topic #9 (0.100): 0.040*\"base\" + 0.035*\"embryo\" + 0.030*\"editing\" + 0.023*\"human\" + 0.022*\"study\" + 0.019*\"said\" + 0.015*\"mutation\" + 0.014*\"gene\" + 0.012*\"liu\" + 0.012*\"dna\"\n",
      "2019-10-29 00:39:41,881 : INFO : topic #7 (0.100): 0.045*\"base\" + 0.034*\"editing\" + 0.029*\"embryo\" + 0.025*\"human\" + 0.023*\"study\" + 0.017*\"said\" + 0.015*\"mutation\" + 0.014*\"scientist\" + 0.012*\"gene\" + 0.011*\"dna\"\n",
      "2019-10-29 00:39:41,884 : INFO : topic #8 (0.100): 0.037*\"editing\" + 0.036*\"base\" + 0.027*\"embryo\" + 0.024*\"said\" + 0.020*\"study\" + 0.015*\"gene\" + 0.014*\"human\" + 0.013*\"mutation\" + 0.013*\"scientist\" + 0.012*\"beta\"\n",
      "2019-10-29 00:39:41,889 : INFO : topic diff=0.964300, rho=1.000000\n",
      "2019-10-29 00:39:42,325 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:42,333 : INFO : built Dictionary(404 unique tokens: ['relative', 'daniel', 'cycle', 'one', 'self']...) from 5 documents (total 3095 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:42,337 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:42,338 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:42,340 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:42,344 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:42,345 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:42,478 : INFO : -8.029 per-word bound, 261.2 perplexity estimate based on a held-out corpus of 5 documents with 3095 words\n",
      "2019-10-29 00:39:42,481 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:42,490 : INFO : topic #2 (0.100): 0.032*\"stress\" + 0.011*\"u\" + 0.010*\"early\" + 0.010*\"class\" + 0.010*\"social\" + 0.010*\"inequality\" + 0.009*\"increasing\" + 0.009*\"control\" + 0.008*\"decade\" + 0.008*\"many\"\n",
      "2019-10-29 00:39:42,491 : INFO : topic #5 (0.100): 0.020*\"stress\" + 0.014*\"social\" + 0.012*\"increasing\" + 0.011*\"u\" + 0.011*\"inequality\" + 0.010*\"control\" + 0.009*\"many\" + 0.009*\"health\" + 0.008*\"mortality\" + 0.008*\"decade\"\n",
      "2019-10-29 00:39:42,493 : INFO : topic #6 (0.100): 0.025*\"stress\" + 0.014*\"also\" + 0.013*\"social\" + 0.012*\"u\" + 0.011*\"control\" + 0.010*\"class\" + 0.009*\"many\" + 0.009*\"increasing\" + 0.008*\"inequality\" + 0.008*\"decade\"\n",
      "2019-10-29 00:39:42,497 : INFO : topic #3 (0.100): 0.022*\"stress\" + 0.014*\"u\" + 0.011*\"social\" + 0.010*\"class\" + 0.010*\"also\" + 0.009*\"disease\" + 0.009*\"increasing\" + 0.009*\"early\" + 0.009*\"trend\" + 0.008*\"epidemic\"\n",
      "2019-10-29 00:39:42,500 : INFO : topic #4 (0.100): 0.025*\"stress\" + 0.012*\"increasing\" + 0.012*\"u\" + 0.011*\"social\" + 0.010*\"mortality\" + 0.009*\"disease\" + 0.009*\"also\" + 0.009*\"class\" + 0.008*\"inequality\" + 0.008*\"trend\"\n",
      "2019-10-29 00:39:42,502 : INFO : topic diff=0.824826, rho=1.000000\n",
      "2019-10-29 00:39:42,965 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:42,969 : INFO : built Dictionary(259 unique tokens: ['jazz', 'small', 'unbroken', 'dry', 'reluctant']...) from 5 documents (total 2070 corpus positions)\n",
      "2019-10-29 00:39:42,972 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:42,974 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:42,976 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:42,979 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:42,981 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:43,067 : INFO : -7.550 per-word bound, 187.5 perplexity estimate based on a held-out corpus of 5 documents with 2070 words\n",
      "2019-10-29 00:39:43,068 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:43,075 : INFO : topic #4 (0.100): 0.045*\"guitar\" + 0.042*\"gallagher\" + 0.020*\"watson\" + 0.017*\"year\" + 0.012*\"stephen\" + 0.012*\"w\" + 0.011*\"wait\" + 0.010*\"said\" + 0.009*\"j\" + 0.009*\"business\"\n",
      "2019-10-29 00:39:43,076 : INFO : topic #8 (0.100): 0.061*\"gallagher\" + 0.044*\"guitar\" + 0.017*\"watson\" + 0.017*\"year\" + 0.012*\"stephen\" + 0.012*\"j\" + 0.010*\"one\" + 0.009*\"said\" + 0.009*\"wait\" + 0.008*\"wood\"\n",
      "2019-10-29 00:39:43,078 : INFO : topic #0 (0.100): 0.063*\"guitar\" + 0.049*\"gallagher\" + 0.025*\"watson\" + 0.022*\"year\" + 0.012*\"j\" + 0.011*\"said\" + 0.010*\"wait\" + 0.009*\"stephen\" + 0.009*\"w\" + 0.009*\"company\"\n",
      "2019-10-29 00:39:43,080 : INFO : topic #1 (0.100): 0.076*\"guitar\" + 0.041*\"gallagher\" + 0.023*\"watson\" + 0.013*\"year\" + 0.012*\"stephen\" + 0.011*\"w\" + 0.009*\"wait\" + 0.009*\"j\" + 0.009*\"grandfather\" + 0.009*\"hand\"\n",
      "2019-10-29 00:39:43,082 : INFO : topic #3 (0.100): 0.055*\"guitar\" + 0.044*\"gallagher\" + 0.025*\"watson\" + 0.016*\"year\" + 0.013*\"j\" + 0.012*\"w\" + 0.011*\"stephen\" + 0.010*\"said\" + 0.009*\"buying\" + 0.008*\"work\"\n",
      "2019-10-29 00:39:43,084 : INFO : topic diff=0.836845, rho=1.000000\n",
      "2019-10-29 00:39:43,507 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:43,512 : INFO : built Dictionary(328 unique tokens: ['even', 'energy', 'small', 'duration', 'deep']...) from 5 documents (total 2365 corpus positions)\n",
      "2019-10-29 00:39:43,516 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:43,518 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:43,523 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:43,528 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:43,531 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:43,648 : INFO : -7.927 per-word bound, 243.3 perplexity estimate based on a held-out corpus of 5 documents with 2365 words\n",
      "2019-10-29 00:39:43,650 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:43,658 : INFO : topic #9 (0.100): 0.028*\"space\" + 0.016*\"time\" + 0.015*\"year\" + 0.013*\"earth\" + 0.012*\"mar\" + 0.010*\"first\" + 0.010*\"new\" + 0.009*\"america\" + 0.009*\"next\" + 0.008*\"company\"\n",
      "2019-10-29 00:39:43,660 : INFO : topic #4 (0.100): 0.030*\"space\" + 0.016*\"earth\" + 0.016*\"mar\" + 0.012*\"time\" + 0.011*\"new\" + 0.010*\"first\" + 0.010*\"one\" + 0.009*\"nasa\" + 0.009*\"next\" + 0.009*\"mission\"\n",
      "2019-10-29 00:39:43,662 : INFO : topic #1 (0.100): 0.042*\"space\" + 0.015*\"year\" + 0.015*\"earth\" + 0.014*\"mar\" + 0.010*\"u\" + 0.009*\"first\" + 0.008*\"one\" + 0.008*\"nasa\" + 0.008*\"time\" + 0.008*\"astronaut\"\n",
      "2019-10-29 00:39:43,665 : INFO : topic #3 (0.100): 0.025*\"space\" + 0.017*\"mar\" + 0.015*\"earth\" + 0.014*\"year\" + 0.010*\"time\" + 0.010*\"new\" + 0.010*\"first\" + 0.009*\"private\" + 0.009*\"astronaut\" + 0.009*\"america\"\n",
      "2019-10-29 00:39:43,668 : INFO : topic #6 (0.100): 0.029*\"space\" + 0.021*\"earth\" + 0.019*\"mar\" + 0.016*\"year\" + 0.014*\"time\" + 0.012*\"one\" + 0.009*\"u\" + 0.009*\"america\" + 0.009*\"new\" + 0.009*\"next\"\n",
      "2019-10-29 00:39:43,670 : INFO : topic diff=0.804564, rho=1.000000\n",
      "2019-10-29 00:39:44,104 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:44,111 : INFO : built Dictionary(245 unique tokens: ['previously', 'fox', 'story', 'described', 'relation']...) from 5 documents (total 2075 corpus positions)\n",
      "2019-10-29 00:39:44,114 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:44,116 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:44,117 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:44,121 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:44,122 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:44,205 : INFO : -7.410 per-word bound, 170.0 perplexity estimate based on a held-out corpus of 5 documents with 2075 words\n",
      "2019-10-29 00:39:44,206 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:44,212 : INFO : topic #3 (0.100): 0.057*\"hiv\" + 0.027*\"law\" + 0.024*\"bill\" + 0.019*\"california\" + 0.016*\"cnn\" + 0.015*\"people\" + 0.014*\"said\" + 0.013*\"infection\" + 0.013*\"state\" + 0.012*\"also\"\n",
      "2019-10-29 00:39:44,213 : INFO : topic #1 (0.100): 0.045*\"hiv\" + 0.029*\"bill\" + 0.025*\"law\" + 0.018*\"california\" + 0.018*\"cnn\" + 0.016*\"people\" + 0.014*\"also\" + 0.012*\"state\" + 0.012*\"infected\" + 0.011*\"said\"\n",
      "2019-10-29 00:39:44,215 : INFO : topic #8 (0.100): 0.044*\"hiv\" + 0.030*\"bill\" + 0.028*\"law\" + 0.019*\"people\" + 0.016*\"california\" + 0.015*\"stone\" + 0.015*\"cnn\" + 0.013*\"state\" + 0.012*\"also\" + 0.011*\"lower\"\n",
      "2019-10-29 00:39:44,217 : INFO : topic #7 (0.100): 0.036*\"hiv\" + 0.030*\"bill\" + 0.021*\"law\" + 0.020*\"people\" + 0.020*\"california\" + 0.016*\"cnn\" + 0.012*\"lower\" + 0.012*\"also\" + 0.012*\"stone\" + 0.012*\"state\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:44,219 : INFO : topic #5 (0.100): 0.046*\"hiv\" + 0.028*\"bill\" + 0.022*\"law\" + 0.021*\"people\" + 0.016*\"california\" + 0.013*\"cnn\" + 0.013*\"infection\" + 0.012*\"stone\" + 0.012*\"state\" + 0.011*\"lower\"\n",
      "2019-10-29 00:39:44,225 : INFO : topic diff=0.873126, rho=1.000000\n",
      "2019-10-29 00:39:44,689 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:44,696 : INFO : built Dictionary(384 unique tokens: ['although', 'real', 'francisco', 'coleman', 'brittany']...) from 5 documents (total 3190 corpus positions)\n",
      "2019-10-29 00:39:44,701 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:44,702 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:44,704 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:44,707 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:44,710 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:44,835 : INFO : -7.868 per-word bound, 233.6 perplexity estimate based on a held-out corpus of 5 documents with 3190 words\n",
      "2019-10-29 00:39:44,837 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:44,843 : INFO : topic #5 (0.100): 0.027*\"helton\" + 0.019*\"naloxone\" + 0.017*\"people\" + 0.017*\"coleman\" + 0.013*\"life\" + 0.012*\"drug\" + 0.012*\"year\" + 0.009*\"dos\" + 0.009*\"said\" + 0.009*\"heroin\"\n",
      "2019-10-29 00:39:44,846 : INFO : topic #6 (0.100): 0.018*\"life\" + 0.017*\"coleman\" + 0.016*\"drug\" + 0.014*\"naloxone\" + 0.013*\"people\" + 0.013*\"helton\" + 0.011*\"said\" + 0.011*\"dos\" + 0.010*\"told\" + 0.009*\"year\"\n",
      "2019-10-29 00:39:44,848 : INFO : topic #7 (0.100): 0.024*\"helton\" + 0.023*\"coleman\" + 0.019*\"people\" + 0.016*\"naloxone\" + 0.016*\"drug\" + 0.016*\"life\" + 0.011*\"year\" + 0.011*\"told\" + 0.010*\"said\" + 0.009*\"addiction\"\n",
      "2019-10-29 00:39:44,851 : INFO : topic #1 (0.100): 0.024*\"coleman\" + 0.024*\"helton\" + 0.017*\"life\" + 0.016*\"people\" + 0.015*\"drug\" + 0.012*\"said\" + 0.011*\"heroin\" + 0.011*\"naloxone\" + 0.011*\"addiction\" + 0.010*\"year\"\n",
      "2019-10-29 00:39:44,853 : INFO : topic #4 (0.100): 0.020*\"helton\" + 0.019*\"life\" + 0.018*\"coleman\" + 0.014*\"people\" + 0.014*\"naloxone\" + 0.013*\"drug\" + 0.010*\"said\" + 0.010*\"heroin\" + 0.010*\"year\" + 0.008*\"get\"\n",
      "2019-10-29 00:39:44,856 : INFO : topic diff=0.867970, rho=1.000000\n",
      "2019-10-29 00:39:45,307 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:45,314 : INFO : built Dictionary(410 unique tokens: ['banana', 'francisco', 'comb', 'partake', 'enjoy']...) from 5 documents (total 2770 corpus positions)\n",
      "2019-10-29 00:39:45,321 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:45,323 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:45,324 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:45,327 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:45,329 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:45,459 : INFO : -8.246 per-word bound, 303.6 perplexity estimate based on a held-out corpus of 5 documents with 2770 words\n",
      "2019-10-29 00:39:45,460 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:45,468 : INFO : topic #8 (0.100): 0.022*\"otawka\" + 0.016*\"island\" + 0.015*\"greyfield\" + 0.009*\"cumberland\" + 0.008*\"inn\" + 0.008*\"kitchen\" + 0.007*\"land\" + 0.006*\"restaurant\" + 0.006*\"program\" + 0.006*\"wild\"\n",
      "2019-10-29 00:39:45,471 : INFO : topic #6 (0.100): 0.023*\"otawka\" + 0.013*\"island\" + 0.011*\"greyfield\" + 0.011*\"kitchen\" + 0.011*\"inn\" + 0.008*\"program\" + 0.008*\"food\" + 0.008*\"cumberland\" + 0.007*\"chef\" + 0.006*\"year\"\n",
      "2019-10-29 00:39:45,473 : INFO : topic #0 (0.100): 0.022*\"otawka\" + 0.017*\"island\" + 0.012*\"inn\" + 0.010*\"greyfield\" + 0.010*\"kitchen\" + 0.008*\"program\" + 0.008*\"cumberland\" + 0.007*\"food\" + 0.007*\"chef\" + 0.007*\"table\"\n",
      "2019-10-29 00:39:45,476 : INFO : topic #7 (0.100): 0.022*\"otawka\" + 0.017*\"island\" + 0.010*\"greyfield\" + 0.010*\"kitchen\" + 0.009*\"program\" + 0.008*\"inn\" + 0.008*\"food\" + 0.007*\"cumberland\" + 0.006*\"water\" + 0.006*\"year\"\n",
      "2019-10-29 00:39:45,479 : INFO : topic #5 (0.100): 0.016*\"island\" + 0.014*\"otawka\" + 0.013*\"greyfield\" + 0.011*\"inn\" + 0.011*\"program\" + 0.010*\"kitchen\" + 0.008*\"cumberland\" + 0.007*\"food\" + 0.007*\"chef\" + 0.006*\"would\"\n",
      "2019-10-29 00:39:45,481 : INFO : topic diff=0.759509, rho=1.000000\n",
      "2019-10-29 00:39:45,936 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:45,943 : INFO : built Dictionary(604 unique tokens: ['although', 'offered', 'filed', 'revealed', 'party']...) from 5 documents (total 5015 corpus positions)\n",
      "2019-10-29 00:39:45,950 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:45,951 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:45,953 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:45,958 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:45,960 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:46,162 : INFO : -8.293 per-word bound, 313.7 perplexity estimate based on a held-out corpus of 5 documents with 5015 words\n",
      "2019-10-29 00:39:46,163 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:46,173 : INFO : topic #4 (0.100): 0.058*\"trump\" + 0.012*\"campaign\" + 0.011*\"outrageous\" + 0.011*\"caption\" + 0.010*\"quote\" + 0.010*\"hide\" + 0.009*\"photo\" + 0.008*\"character\" + 0.008*\"would\" + 0.008*\"time\"\n",
      "2019-10-29 00:39:46,175 : INFO : topic #7 (0.100): 0.066*\"trump\" + 0.015*\"campaign\" + 0.013*\"photo\" + 0.013*\"caption\" + 0.010*\"outrageous\" + 0.010*\"quote\" + 0.010*\"character\" + 0.008*\"hide\" + 0.007*\"would\" + 0.006*\"public\"\n",
      "2019-10-29 00:39:46,177 : INFO : topic #5 (0.100): 0.050*\"trump\" + 0.013*\"quote\" + 0.013*\"campaign\" + 0.012*\"hide\" + 0.012*\"outrageous\" + 0.011*\"photo\" + 0.009*\"would\" + 0.007*\"caption\" + 0.007*\"character\" + 0.006*\"rich\"\n",
      "2019-10-29 00:39:46,180 : INFO : topic #1 (0.100): 0.054*\"trump\" + 0.016*\"campaign\" + 0.012*\"quote\" + 0.012*\"caption\" + 0.011*\"outrageous\" + 0.009*\"photo\" + 0.009*\"hide\" + 0.008*\"character\" + 0.007*\"would\" + 0.007*\"public\"\n",
      "2019-10-29 00:39:46,182 : INFO : topic #8 (0.100): 0.071*\"trump\" + 0.012*\"outrageous\" + 0.011*\"campaign\" + 0.011*\"caption\" + 0.011*\"hide\" + 0.010*\"quote\" + 0.009*\"photo\" + 0.008*\"would\" + 0.008*\"character\" + 0.007*\"man\"\n",
      "2019-10-29 00:39:46,185 : INFO : topic diff=0.872475, rho=1.000000\n",
      "2019-10-29 00:39:46,592 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:46,597 : INFO : built Dictionary(392 unique tokens: ['rage', 'earned', 'deep', 'party', 'drive']...) from 5 documents (total 2900 corpus positions)\n",
      "2019-10-29 00:39:46,602 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:46,604 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:46,608 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:46,613 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:46,616 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:46,752 : INFO : -8.058 per-word bound, 266.4 perplexity estimate based on a held-out corpus of 5 documents with 2900 words\n",
      "2019-10-29 00:39:46,753 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:46,762 : INFO : topic #0 (0.100): 0.034*\"trump\" + 0.025*\"tax\" + 0.016*\"corker\" + 0.012*\"republican\" + 0.011*\"bob\" + 0.009*\"reform\" + 0.009*\"chance\" + 0.008*\"since\" + 0.008*\"may\" + 0.007*\"washington\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:46,764 : INFO : topic #4 (0.100): 0.040*\"trump\" + 0.020*\"tax\" + 0.018*\"republican\" + 0.012*\"reform\" + 0.012*\"corker\" + 0.010*\"bob\" + 0.009*\"chance\" + 0.009*\"could\" + 0.008*\"washington\" + 0.008*\"president\"\n",
      "2019-10-29 00:39:46,767 : INFO : topic #3 (0.100): 0.027*\"trump\" + 0.023*\"tax\" + 0.016*\"corker\" + 0.015*\"republican\" + 0.011*\"chance\" + 0.010*\"washington\" + 0.009*\"president\" + 0.009*\"bob\" + 0.008*\"reform\" + 0.007*\"bill\"\n",
      "2019-10-29 00:39:46,769 : INFO : topic #2 (0.100): 0.037*\"trump\" + 0.018*\"tax\" + 0.016*\"republican\" + 0.012*\"corker\" + 0.010*\"bob\" + 0.009*\"chance\" + 0.009*\"could\" + 0.008*\"reform\" + 0.008*\"plan\" + 0.007*\"may\"\n",
      "2019-10-29 00:39:46,772 : INFO : topic #6 (0.100): 0.025*\"trump\" + 0.023*\"tax\" + 0.018*\"republican\" + 0.012*\"corker\" + 0.011*\"chance\" + 0.009*\"reform\" + 0.009*\"bob\" + 0.008*\"since\" + 0.008*\"washington\" + 0.007*\"could\"\n",
      "2019-10-29 00:39:46,774 : INFO : topic diff=0.810605, rho=1.000000\n",
      "2019-10-29 00:39:47,208 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:47,215 : INFO : built Dictionary(451 unique tokens: ['although', 'cortex', 'energy', 'tremor', 'specie']...) from 5 documents (total 3720 corpus positions)\n",
      "2019-10-29 00:39:47,221 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:47,223 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:47,225 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:47,229 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:47,231 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:47,383 : INFO : -8.026 per-word bound, 260.6 perplexity estimate based on a held-out corpus of 5 documents with 3720 words\n",
      "2019-10-29 00:39:47,384 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:47,392 : INFO : topic #4 (0.100): 0.048*\"sugar\" + 0.014*\"also\" + 0.012*\"withdrawal\" + 0.012*\"food\" + 0.011*\"brain\" + 0.010*\"drug\" + 0.010*\"rat\" + 0.009*\"dopamine\" + 0.008*\"behaviour\" + 0.007*\"u\"\n",
      "2019-10-29 00:39:47,395 : INFO : topic #2 (0.100): 0.051*\"sugar\" + 0.015*\"food\" + 0.014*\"rat\" + 0.011*\"drug\" + 0.009*\"brain\" + 0.009*\"day\" + 0.009*\"also\" + 0.009*\"u\" + 0.009*\"withdrawal\" + 0.008*\"like\"\n",
      "2019-10-29 00:39:47,397 : INFO : topic #6 (0.100): 0.033*\"sugar\" + 0.014*\"food\" + 0.012*\"also\" + 0.011*\"drug\" + 0.011*\"brain\" + 0.011*\"day\" + 0.011*\"behaviour\" + 0.011*\"rat\" + 0.010*\"dopamine\" + 0.010*\"withdrawal\"\n",
      "2019-10-29 00:39:47,399 : INFO : topic #3 (0.100): 0.041*\"sugar\" + 0.016*\"food\" + 0.013*\"also\" + 0.011*\"brain\" + 0.011*\"drug\" + 0.010*\"dopamine\" + 0.009*\"day\" + 0.009*\"reward\" + 0.008*\"rat\" + 0.008*\"withdrawal\"\n",
      "2019-10-29 00:39:47,402 : INFO : topic #7 (0.100): 0.037*\"sugar\" + 0.013*\"food\" + 0.013*\"also\" + 0.012*\"withdrawal\" + 0.011*\"like\" + 0.011*\"reward\" + 0.011*\"brain\" + 0.010*\"sweet\" + 0.010*\"dopamine\" + 0.010*\"addiction\"\n",
      "2019-10-29 00:39:47,404 : INFO : topic diff=0.866338, rho=1.000000\n",
      "2019-10-29 00:39:47,838 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:47,842 : INFO : built Dictionary(272 unique tokens: ['josh', 'catholic', 'person', 'sticker', 'happy']...) from 5 documents (total 2190 corpus positions)\n",
      "2019-10-29 00:39:47,845 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:47,847 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:47,848 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:47,852 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:47,854 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:47,956 : INFO : -7.578 per-word bound, 191.1 perplexity estimate based on a held-out corpus of 5 documents with 2190 words\n",
      "2019-10-29 00:39:47,958 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:47,966 : INFO : topic #9 (0.100): 0.032*\"school\" + 0.025*\"indian\" + 0.021*\"letter\" + 0.020*\"native\" + 0.017*\"st\" + 0.016*\"joseph\" + 0.012*\"mailing\" + 0.012*\"american\" + 0.011*\"story\" + 0.011*\"child\"\n",
      "2019-10-29 00:39:47,968 : INFO : topic #4 (0.100): 0.031*\"school\" + 0.022*\"american\" + 0.021*\"joseph\" + 0.020*\"letter\" + 0.020*\"indian\" + 0.018*\"native\" + 0.014*\"st\" + 0.012*\"bear\" + 0.011*\"story\" + 0.011*\"child\"\n",
      "2019-10-29 00:39:47,969 : INFO : topic #8 (0.100): 0.027*\"school\" + 0.020*\"joseph\" + 0.020*\"st\" + 0.020*\"indian\" + 0.018*\"letter\" + 0.016*\"american\" + 0.015*\"native\" + 0.012*\"mailing\" + 0.011*\"exist\" + 0.010*\"year\"\n",
      "2019-10-29 00:39:47,970 : INFO : topic #5 (0.100): 0.033*\"school\" + 0.022*\"joseph\" + 0.019*\"indian\" + 0.019*\"native\" + 0.018*\"st\" + 0.017*\"letter\" + 0.016*\"american\" + 0.012*\"little\" + 0.012*\"child\" + 0.012*\"mailing\"\n",
      "2019-10-29 00:39:47,972 : INFO : topic #7 (0.100): 0.033*\"school\" + 0.020*\"indian\" + 0.018*\"st\" + 0.018*\"joseph\" + 0.018*\"american\" + 0.017*\"native\" + 0.016*\"letter\" + 0.012*\"child\" + 0.010*\"story\" + 0.010*\"mailing\"\n",
      "2019-10-29 00:39:47,974 : INFO : topic diff=0.850092, rho=1.000000\n",
      "2019-10-29 00:39:48,410 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:48,414 : INFO : built Dictionary(227 unique tokens: ['let', 'supposed', 'de', 'hero', 'come']...) from 5 documents (total 1835 corpus positions)\n",
      "2019-10-29 00:39:48,419 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:48,420 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:48,422 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:48,426 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:48,427 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:48,524 : INFO : -7.410 per-word bound, 170.1 perplexity estimate based on a held-out corpus of 5 documents with 1835 words\n",
      "2019-10-29 00:39:48,526 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:48,533 : INFO : topic #6 (0.100): 0.034*\"southerland\" + 0.023*\"said\" + 0.022*\"diabetes\" + 0.022*\"team\" + 0.017*\"race\" + 0.015*\"got\" + 0.014*\"kid\" + 0.012*\"bike\" + 0.012*\"type\" + 0.011*\"cyclist\"\n",
      "2019-10-29 00:39:48,536 : INFO : topic #0 (0.100): 0.026*\"southerland\" + 0.026*\"team\" + 0.022*\"race\" + 0.019*\"got\" + 0.019*\"diabetes\" + 0.016*\"said\" + 0.014*\"rwanda\" + 0.014*\"bike\" + 0.014*\"kid\" + 0.011*\"insulin\"\n",
      "2019-10-29 00:39:48,538 : INFO : topic #1 (0.100): 0.023*\"said\" + 0.022*\"southerland\" + 0.018*\"got\" + 0.018*\"diabetes\" + 0.015*\"team\" + 0.015*\"kid\" + 0.015*\"race\" + 0.014*\"news\" + 0.014*\"bike\" + 0.012*\"insulin\"\n",
      "2019-10-29 00:39:48,542 : INFO : topic #8 (0.100): 0.034*\"southerland\" + 0.025*\"said\" + 0.025*\"got\" + 0.023*\"team\" + 0.021*\"diabetes\" + 0.016*\"news\" + 0.016*\"race\" + 0.014*\"kid\" + 0.013*\"diabetic\" + 0.013*\"bike\"\n",
      "2019-10-29 00:39:48,544 : INFO : topic #7 (0.100): 0.028*\"team\" + 0.027*\"southerland\" + 0.024*\"race\" + 0.021*\"said\" + 0.020*\"diabetes\" + 0.018*\"got\" + 0.016*\"kid\" + 0.012*\"news\" + 0.012*\"cyclist\" + 0.011*\"type\"\n",
      "2019-10-29 00:39:48,548 : INFO : topic diff=0.849088, rho=1.000000\n",
      "2019-10-29 00:39:49,033 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:49,040 : INFO : built Dictionary(623 unique tokens: ['relation', 'wave', 'port', 'clientele', 'party']...) from 5 documents (total 4965 corpus positions)\n",
      "2019-10-29 00:39:49,046 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:49,047 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:49,048 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:49,053 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:49,055 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:49,266 : INFO : -8.389 per-word bound, 335.1 perplexity estimate based on a held-out corpus of 5 documents with 4965 words\n",
      "2019-10-29 00:39:49,268 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:49,277 : INFO : topic #9 (0.100): 0.039*\"tyre\" + 0.020*\"city\" + 0.013*\"lebanon\" + 0.013*\"hezbollah\" + 0.012*\"one\" + 0.010*\"beach\" + 0.010*\"lebanese\" + 0.009*\"party\" + 0.006*\"cnn\" + 0.005*\"site\"\n",
      "2019-10-29 00:39:49,278 : INFO : topic #6 (0.100): 0.031*\"tyre\" + 0.026*\"city\" + 0.016*\"lebanon\" + 0.011*\"beach\" + 0.011*\"lebanese\" + 0.010*\"one\" + 0.009*\"site\" + 0.008*\"hezbollah\" + 0.007*\"party\" + 0.007*\"tell\"\n",
      "2019-10-29 00:39:49,280 : INFO : topic #1 (0.100): 0.033*\"tyre\" + 0.021*\"city\" + 0.015*\"lebanon\" + 0.014*\"hezbollah\" + 0.012*\"beach\" + 0.010*\"lebanese\" + 0.009*\"one\" + 0.009*\"party\" + 0.006*\"tabet\" + 0.006*\"say\"\n",
      "2019-10-29 00:39:49,282 : INFO : topic #3 (0.100): 0.032*\"tyre\" + 0.023*\"city\" + 0.015*\"lebanon\" + 0.014*\"hezbollah\" + 0.009*\"site\" + 0.009*\"one\" + 0.008*\"beach\" + 0.008*\"lebanese\" + 0.006*\"cnn\" + 0.005*\"israel\"\n",
      "2019-10-29 00:39:49,283 : INFO : topic #2 (0.100): 0.031*\"tyre\" + 0.021*\"city\" + 0.013*\"one\" + 0.011*\"hezbollah\" + 0.010*\"lebanon\" + 0.008*\"say\" + 0.008*\"lebanese\" + 0.008*\"site\" + 0.008*\"cnn\" + 0.007*\"dar\"\n",
      "2019-10-29 00:39:49,286 : INFO : topic diff=0.841097, rho=1.000000\n",
      "2019-10-29 00:39:49,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:49,773 : INFO : built Dictionary(576 unique tokens: ['let', 'energy', 'pushed', 'size', 'entitled']...) from 5 documents (total 6380 corpus positions)\n",
      "2019-10-29 00:39:49,782 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:49,785 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:49,788 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:49,792 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:49,794 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:49,959 : INFO : -7.912 per-word bound, 240.8 perplexity estimate based on a held-out corpus of 5 documents with 6380 words\n",
      "2019-10-29 00:39:49,960 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:49,969 : INFO : topic #6 (0.100): 0.022*\"program\" + 0.020*\"state\" + 0.018*\"could\" + 0.016*\"federal\" + 0.015*\"medicaid\" + 0.014*\"child\" + 0.011*\"said\" + 0.010*\"grant\" + 0.010*\"cut\" + 0.010*\"block\"\n",
      "2019-10-29 00:39:49,971 : INFO : topic #8 (0.100): 0.024*\"program\" + 0.018*\"state\" + 0.016*\"cut\" + 0.015*\"could\" + 0.014*\"said\" + 0.013*\"medicaid\" + 0.013*\"grant\" + 0.013*\"block\" + 0.012*\"child\" + 0.010*\"health\"\n",
      "2019-10-29 00:39:49,972 : INFO : topic #5 (0.100): 0.027*\"program\" + 0.018*\"grant\" + 0.017*\"medicaid\" + 0.016*\"state\" + 0.014*\"block\" + 0.012*\"cut\" + 0.012*\"could\" + 0.012*\"health\" + 0.010*\"said\" + 0.010*\"federal\"\n",
      "2019-10-29 00:39:49,973 : INFO : topic #1 (0.100): 0.025*\"program\" + 0.021*\"state\" + 0.015*\"could\" + 0.014*\"medicaid\" + 0.014*\"child\" + 0.013*\"said\" + 0.012*\"grant\" + 0.012*\"cut\" + 0.011*\"people\" + 0.011*\"block\"\n",
      "2019-10-29 00:39:49,975 : INFO : topic #0 (0.100): 0.020*\"state\" + 0.020*\"program\" + 0.013*\"could\" + 0.013*\"medicaid\" + 0.012*\"said\" + 0.012*\"block\" + 0.012*\"cut\" + 0.012*\"grant\" + 0.012*\"family\" + 0.010*\"people\"\n",
      "2019-10-29 00:39:49,977 : INFO : topic diff=1.014051, rho=1.000000\n",
      "2019-10-29 00:39:50,379 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:50,381 : INFO : built Dictionary(98 unique tokens: ['let', 'floating', 'posed', 'come', 'life']...) from 5 documents (total 705 corpus positions)\n",
      "2019-10-29 00:39:50,383 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:50,384 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:50,386 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:50,389 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:50,390 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:50,438 : INFO : -6.834 per-word bound, 114.1 perplexity estimate based on a held-out corpus of 5 documents with 705 words\n",
      "2019-10-29 00:39:50,440 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:50,448 : INFO : topic #1 (0.100): 0.050*\"student\" + 0.027*\"say\" + 0.027*\"springfield\" + 0.026*\"picture\" + 0.024*\"confederate\" + 0.024*\"official\" + 0.023*\"outside\" + 0.022*\"school\" + 0.021*\"flag\" + 0.020*\"life\"\n",
      "2019-10-29 00:39:50,451 : INFO : topic #3 (0.100): 0.043*\"student\" + 0.035*\"say\" + 0.027*\"springfield\" + 0.026*\"outside\" + 0.024*\"geha\" + 0.023*\"school\" + 0.023*\"official\" + 0.023*\"confederate\" + 0.020*\"life\" + 0.019*\"flag\"\n",
      "2019-10-29 00:39:50,453 : INFO : topic #7 (0.100): 0.036*\"student\" + 0.032*\"springfield\" + 0.032*\"say\" + 0.029*\"outside\" + 0.025*\"school\" + 0.024*\"flag\" + 0.023*\"young\" + 0.023*\"life\" + 0.021*\"picture\" + 0.020*\"official\"\n",
      "2019-10-29 00:39:50,456 : INFO : topic #8 (0.100): 0.038*\"student\" + 0.034*\"springfield\" + 0.034*\"say\" + 0.027*\"outside\" + 0.025*\"school\" + 0.021*\"young\" + 0.021*\"flag\" + 0.019*\"confederate\" + 0.017*\"life\" + 0.016*\"district\"\n",
      "2019-10-29 00:39:50,458 : INFO : topic #5 (0.100): 0.040*\"springfield\" + 0.039*\"student\" + 0.038*\"say\" + 0.027*\"outside\" + 0.026*\"school\" + 0.021*\"official\" + 0.020*\"geha\" + 0.020*\"confederate\" + 0.020*\"life\" + 0.019*\"young\"\n",
      "2019-10-29 00:39:50,461 : INFO : topic diff=0.828083, rho=1.000000\n",
      "2019-10-29 00:39:50,938 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:50,943 : INFO : built Dictionary(420 unique tokens: ['let', 'mistreatment', 'weinstein', 'expense', 'party']...) from 5 documents (total 3205 corpus positions)\n",
      "2019-10-29 00:39:50,948 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:50,949 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:50,950 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:50,954 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:50,955 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:51,104 : INFO : -8.071 per-word bound, 268.8 perplexity estimate based on a held-out corpus of 5 documents with 3205 words\n",
      "2019-10-29 00:39:51,105 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:51,115 : INFO : topic #6 (0.100): 0.029*\"weinstein\" + 0.017*\"sexual\" + 0.015*\"woman\" + 0.014*\"new\" + 0.010*\"trump\" + 0.009*\"alleged\" + 0.008*\"money\" + 0.008*\"u\" + 0.007*\"men\" + 0.006*\"week\"\n",
      "2019-10-29 00:39:51,117 : INFO : topic #5 (0.100): 0.040*\"weinstein\" + 0.022*\"sexual\" + 0.014*\"woman\" + 0.011*\"new\" + 0.009*\"u\" + 0.009*\"predator\" + 0.009*\"trump\" + 0.008*\"alleged\" + 0.008*\"men\" + 0.007*\"jr\"\n",
      "2019-10-29 00:39:51,120 : INFO : topic #0 (0.100): 0.039*\"weinstein\" + 0.019*\"sexual\" + 0.014*\"trump\" + 0.011*\"woman\" + 0.009*\"new\" + 0.007*\"friend\" + 0.007*\"jr\" + 0.007*\"alleged\" + 0.007*\"u\" + 0.007*\"money\"\n",
      "2019-10-29 00:39:51,123 : INFO : topic #7 (0.100): 0.048*\"weinstein\" + 0.022*\"sexual\" + 0.015*\"trump\" + 0.012*\"woman\" + 0.011*\"u\" + 0.010*\"new\" + 0.007*\"jr\" + 0.007*\"accused\" + 0.007*\"also\" + 0.006*\"predator\"\n",
      "2019-10-29 00:39:51,126 : INFO : topic #9 (0.100): 0.032*\"weinstein\" + 0.020*\"sexual\" + 0.018*\"woman\" + 0.010*\"new\" + 0.009*\"trump\" + 0.008*\"alleged\" + 0.008*\"u\" + 0.008*\"predator\" + 0.006*\"friend\" + 0.006*\"jr\"\n",
      "2019-10-29 00:39:51,129 : INFO : topic diff=0.830472, rho=1.000000\n",
      "2019-10-29 00:39:51,548 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:51,553 : INFO : built Dictionary(281 unique tokens: ['scope', 'school', 'small', 'reach', 'happy']...) from 5 documents (total 2290 corpus positions)\n",
      "2019-10-29 00:39:51,557 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:51,558 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:51,559 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:51,562 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:51,563 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:51,676 : INFO : -7.594 per-word bound, 193.2 perplexity estimate based on a held-out corpus of 5 documents with 2290 words\n",
      "2019-10-29 00:39:51,677 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:51,684 : INFO : topic #2 (0.100): 0.029*\"child\" + 0.023*\"hillery\" + 0.020*\"food\" + 0.019*\"harlem\" + 0.015*\"healthy\" + 0.014*\"grown\" + 0.013*\"cnn\" + 0.013*\"school\" + 0.013*\"growing\" + 0.012*\"plant\"\n",
      "2019-10-29 00:39:51,687 : INFO : topic #4 (0.100): 0.028*\"hillery\" + 0.024*\"child\" + 0.023*\"harlem\" + 0.023*\"food\" + 0.015*\"healthy\" + 0.014*\"grown\" + 0.012*\"every\" + 0.012*\"school\" + 0.010*\"growing\" + 0.010*\"plant\"\n",
      "2019-10-29 00:39:51,690 : INFO : topic #3 (0.100): 0.032*\"child\" + 0.025*\"hillery\" + 0.020*\"harlem\" + 0.015*\"food\" + 0.014*\"cnn\" + 0.012*\"grown\" + 0.012*\"healthy\" + 0.012*\"plant\" + 0.011*\"school\" + 0.010*\"every\"\n",
      "2019-10-29 00:39:51,692 : INFO : topic #6 (0.100): 0.038*\"child\" + 0.026*\"hillery\" + 0.019*\"harlem\" + 0.018*\"food\" + 0.016*\"healthy\" + 0.015*\"cnn\" + 0.015*\"grown\" + 0.012*\"started\" + 0.011*\"every\" + 0.011*\"school\"\n",
      "2019-10-29 00:39:51,695 : INFO : topic #9 (0.100): 0.036*\"child\" + 0.022*\"hillery\" + 0.017*\"harlem\" + 0.015*\"food\" + 0.015*\"healthy\" + 0.014*\"grown\" + 0.012*\"cnn\" + 0.011*\"urban\" + 0.010*\"program\" + 0.010*\"started\"\n",
      "2019-10-29 00:39:51,699 : INFO : topic diff=0.877883, rho=1.000000\n",
      "2019-10-29 00:39:52,167 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:52,177 : INFO : built Dictionary(416 unique tokens: ['located', 'person', 'laboratory', 'refine', 'recommendation']...) from 5 documents (total 5350 corpus positions)\n",
      "2019-10-29 00:39:52,184 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:52,186 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:52,188 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:52,192 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:52,194 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:52,327 : INFO : -7.446 per-word bound, 174.3 perplexity estimate based on a held-out corpus of 5 documents with 5350 words\n",
      "2019-10-29 00:39:52,329 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:52,336 : INFO : topic #5 (0.100): 0.059*\"drone\" + 0.041*\"could\" + 0.022*\"save\" + 0.019*\"used\" + 0.019*\"life\" + 0.015*\"medical\" + 0.011*\"said\" + 0.011*\"photo\" + 0.010*\"emergency\" + 0.010*\"sample\"\n",
      "2019-10-29 00:39:52,337 : INFO : topic #3 (0.100): 0.062*\"drone\" + 0.034*\"could\" + 0.024*\"life\" + 0.021*\"save\" + 0.019*\"used\" + 0.015*\"medical\" + 0.011*\"emergency\" + 0.009*\"air\" + 0.008*\"said\" + 0.008*\"kit\"\n",
      "2019-10-29 00:39:52,338 : INFO : topic #1 (0.100): 0.068*\"drone\" + 0.045*\"could\" + 0.023*\"save\" + 0.022*\"used\" + 0.020*\"life\" + 0.017*\"medical\" + 0.011*\"said\" + 0.010*\"kit\" + 0.009*\"sample\" + 0.009*\"mississippi\"\n",
      "2019-10-29 00:39:52,340 : INFO : topic #2 (0.100): 0.069*\"drone\" + 0.040*\"could\" + 0.023*\"save\" + 0.020*\"life\" + 0.018*\"used\" + 0.016*\"medical\" + 0.011*\"photo\" + 0.011*\"said\" + 0.009*\"emergency\" + 0.008*\"sample\"\n",
      "2019-10-29 00:39:52,342 : INFO : topic #4 (0.100): 0.060*\"drone\" + 0.043*\"could\" + 0.021*\"save\" + 0.021*\"life\" + 0.018*\"used\" + 0.015*\"medical\" + 0.011*\"said\" + 0.010*\"emergency\" + 0.010*\"air\" + 0.009*\"sample\"\n",
      "2019-10-29 00:39:52,344 : INFO : topic diff=0.879364, rho=1.000000\n",
      "2019-10-29 00:39:52,766 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:52,771 : INFO : built Dictionary(297 unique tokens: ['offered', 'trying', 'single', 'gruosi', 'campaign']...) from 5 documents (total 2270 corpus positions)\n",
      "2019-10-29 00:39:52,776 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:52,780 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:52,783 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:52,787 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:52,790 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:52,918 : INFO : -7.738 per-word bound, 213.5 perplexity estimate based on a held-out corpus of 5 documents with 2270 words\n",
      "2019-10-29 00:39:52,919 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:52,927 : INFO : topic #3 (0.100): 0.046*\"diamond\" + 0.030*\"stone\" + 0.027*\"rough\" + 0.016*\"carat\" + 0.012*\"cut\" + 0.012*\"graff\" + 0.011*\"grisogono\" + 0.011*\"de\" + 0.011*\"mine\" + 0.010*\"house\"\n",
      "2019-10-29 00:39:52,929 : INFO : topic #4 (0.100): 0.048*\"diamond\" + 0.036*\"rough\" + 0.018*\"stone\" + 0.015*\"house\" + 0.014*\"carat\" + 0.014*\"graff\" + 0.012*\"mine\" + 0.012*\"grisogono\" + 0.011*\"jewelry\" + 0.011*\"de\"\n",
      "2019-10-29 00:39:52,931 : INFO : topic #1 (0.100): 0.035*\"diamond\" + 0.028*\"rough\" + 0.017*\"graff\" + 0.016*\"stone\" + 0.016*\"carat\" + 0.014*\"de\" + 0.012*\"company\" + 0.011*\"cut\" + 0.011*\"house\" + 0.010*\"jeweler\"\n",
      "2019-10-29 00:39:52,934 : INFO : topic #5 (0.100): 0.040*\"diamond\" + 0.038*\"rough\" + 0.020*\"stone\" + 0.016*\"graff\" + 0.013*\"carat\" + 0.011*\"cut\" + 0.011*\"mine\" + 0.010*\"jeweler\" + 0.010*\"de\" + 0.010*\"house\"\n",
      "2019-10-29 00:39:52,936 : INFO : topic #9 (0.100): 0.043*\"diamond\" + 0.024*\"stone\" + 0.024*\"rough\" + 0.013*\"de\" + 0.013*\"graff\" + 0.012*\"cut\" + 0.011*\"carat\" + 0.011*\"house\" + 0.011*\"high\" + 0.009*\"company\"\n",
      "2019-10-29 00:39:52,939 : INFO : topic diff=0.845634, rho=1.000000\n",
      "2019-10-29 00:39:53,403 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:53,410 : INFO : built Dictionary(442 unique tokens: ['let', 'sarajevan', 'spokesperson', 'bucket', 'perhaps']...) from 5 documents (total 3290 corpus positions)\n",
      "2019-10-29 00:39:53,416 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:53,418 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:53,420 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:53,425 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:53,428 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:53,593 : INFO : -8.158 per-word bound, 285.6 perplexity estimate based on a held-out corpus of 5 documents with 3290 words\n",
      "2019-10-29 00:39:53,595 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:53,605 : INFO : topic #6 (0.100): 0.032*\"hotel\" + 0.029*\"holiday\" + 0.020*\"inn\" + 0.014*\"sarajevo\" + 0.011*\"cnn\" + 0.009*\"war\" + 0.008*\"bosnian\" + 0.007*\"city\" + 0.007*\"travel\" + 0.007*\"room\"\n",
      "2019-10-29 00:39:53,607 : INFO : topic #5 (0.100): 0.043*\"hotel\" + 0.022*\"inn\" + 0.020*\"holiday\" + 0.014*\"cnn\" + 0.011*\"sarajevo\" + 0.008*\"guest\" + 0.008*\"old\" + 0.007*\"year\" + 0.007*\"room\" + 0.007*\"yellow\"\n",
      "2019-10-29 00:39:53,608 : INFO : topic #9 (0.100): 0.045*\"hotel\" + 0.020*\"holiday\" + 0.020*\"inn\" + 0.014*\"travel\" + 0.014*\"sarajevo\" + 0.012*\"cnn\" + 0.011*\"war\" + 0.008*\"international\" + 0.008*\"bosnian\" + 0.007*\"old\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:53,610 : INFO : topic #2 (0.100): 0.028*\"holiday\" + 0.028*\"hotel\" + 0.024*\"inn\" + 0.016*\"sarajevo\" + 0.010*\"cnn\" + 0.010*\"bosnian\" + 0.009*\"war\" + 0.009*\"travel\" + 0.008*\"tell\" + 0.007*\"old\"\n",
      "2019-10-29 00:39:53,612 : INFO : topic #1 (0.100): 0.032*\"hotel\" + 0.026*\"holiday\" + 0.021*\"inn\" + 0.014*\"sarajevo\" + 0.010*\"cnn\" + 0.009*\"bosnian\" + 0.009*\"war\" + 0.009*\"city\" + 0.008*\"travel\" + 0.007*\"yellow\"\n",
      "2019-10-29 00:39:53,613 : INFO : topic diff=0.821521, rho=1.000000\n",
      "2019-10-29 00:39:54,036 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:54,039 : INFO : built Dictionary(126 unique tokens: ['clink', 'french', 'special', 'window', 'joined']...) from 5 documents (total 900 corpus positions)\n",
      "2019-10-29 00:39:54,041 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:54,043 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:54,044 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:54,047 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:54,048 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:54,118 : INFO : -7.063 per-word bound, 133.7 perplexity estimate based on a held-out corpus of 5 documents with 900 words\n",
      "2019-10-29 00:39:54,119 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:54,126 : INFO : topic #1 (0.100): 0.039*\"side\" + 0.035*\"jr\" + 0.028*\"border\" + 0.024*\"eye\" + 0.020*\"artist\" + 0.017*\"u\" + 0.017*\"agent\" + 0.016*\"one\" + 0.015*\"mexico\" + 0.015*\"table\"\n",
      "2019-10-29 00:39:54,129 : INFO : topic #7 (0.100): 0.034*\"side\" + 0.031*\"jr\" + 0.022*\"border\" + 0.022*\"eye\" + 0.022*\"artist\" + 0.021*\"one\" + 0.019*\"picnic\" + 0.018*\"u\" + 0.017*\"mexico\" + 0.016*\"dreamer\"\n",
      "2019-10-29 00:39:54,132 : INFO : topic #3 (0.100): 0.031*\"jr\" + 0.026*\"border\" + 0.025*\"side\" + 0.022*\"u\" + 0.021*\"artist\" + 0.019*\"mexico\" + 0.018*\"table\" + 0.018*\"eye\" + 0.017*\"one\" + 0.016*\"picnic\"\n",
      "2019-10-29 00:39:54,136 : INFO : topic #0 (0.100): 0.032*\"side\" + 0.030*\"jr\" + 0.023*\"artist\" + 0.023*\"eye\" + 0.023*\"border\" + 0.020*\"one\" + 0.019*\"agent\" + 0.018*\"u\" + 0.016*\"picnic\" + 0.014*\"post\"\n",
      "2019-10-29 00:39:54,139 : INFO : topic #8 (0.100): 0.034*\"side\" + 0.034*\"jr\" + 0.026*\"border\" + 0.025*\"u\" + 0.021*\"one\" + 0.018*\"artist\" + 0.017*\"eye\" + 0.017*\"dreamer\" + 0.015*\"table\" + 0.014*\"agent\"\n",
      "2019-10-29 00:39:54,142 : INFO : topic diff=0.792001, rho=1.000000\n",
      "2019-10-29 00:39:54,551 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:54,554 : INFO : built Dictionary(72 unique tokens: ['pianist', 'lennon', 'renowned', 'provided', 'aisa']...) from 5 documents (total 435 corpus positions)\n",
      "2019-10-29 00:39:54,556 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:54,558 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:54,559 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:54,562 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:54,564 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:54,613 : INFO : -6.911 per-word bound, 120.3 perplexity estimate based on a held-out corpus of 5 documents with 435 words\n",
      "2019-10-29 00:39:54,616 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:54,626 : INFO : topic #6 (0.100): 0.062*\"piano\" + 0.046*\"world\" + 0.025*\"son\" + 0.025*\"revered\" + 0.024*\"steinway\" + 0.024*\"part\" + 0.023*\"pianist\" + 0.022*\"performing\" + 0.016*\"joel\" + 0.014*\"composed\"\n",
      "2019-10-29 00:39:54,629 : INFO : topic #7 (0.100): 0.045*\"world\" + 0.042*\"piano\" + 0.029*\"revered\" + 0.027*\"son\" + 0.026*\"pianist\" + 0.021*\"performing\" + 0.018*\"steinway\" + 0.017*\"part\" + 0.016*\"ijiri\" + 0.015*\"capture\"\n",
      "2019-10-29 00:39:54,635 : INFO : topic #3 (0.100): 0.064*\"world\" + 0.045*\"piano\" + 0.031*\"revered\" + 0.031*\"steinway\" + 0.027*\"son\" + 0.023*\"performing\" + 0.023*\"part\" + 0.016*\"pianist\" + 0.015*\"take\" + 0.014*\"assemble\"\n",
      "2019-10-29 00:39:54,639 : INFO : topic #2 (0.100): 0.052*\"piano\" + 0.041*\"world\" + 0.036*\"revered\" + 0.024*\"pianist\" + 0.024*\"performing\" + 0.022*\"part\" + 0.020*\"steinway\" + 0.019*\"son\" + 0.016*\"new\" + 0.015*\"series\"\n",
      "2019-10-29 00:39:54,641 : INFO : topic #9 (0.100): 0.052*\"world\" + 0.050*\"piano\" + 0.031*\"revered\" + 0.022*\"pianist\" + 0.022*\"part\" + 0.020*\"performing\" + 0.019*\"steinway\" + 0.019*\"son\" + 0.016*\"like\" + 0.015*\"ijiri\"\n",
      "2019-10-29 00:39:54,643 : INFO : topic diff=0.708775, rho=1.000000\n",
      "2019-10-29 00:39:55,053 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:55,056 : INFO : built Dictionary(201 unique tokens: ['although', 'earned', 'school', 'watch', 'provides']...) from 5 documents (total 1820 corpus positions)\n",
      "2019-10-29 00:39:55,059 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:55,061 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:55,063 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:55,065 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:55,067 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:55,142 : INFO : -7.143 per-word bound, 141.3 perplexity estimate based on a held-out corpus of 5 documents with 1820 words\n",
      "2019-10-29 00:39:55,143 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:55,149 : INFO : topic #9 (0.100): 0.056*\"transgender\" + 0.027*\"court\" + 0.027*\"person\" + 0.025*\"discrimination\" + 0.022*\"session\" + 0.021*\"protection\" + 0.020*\"law\" + 0.017*\"would\" + 0.015*\"sex\" + 0.013*\"gender\"\n",
      "2019-10-29 00:39:55,151 : INFO : topic #3 (0.100): 0.055*\"transgender\" + 0.031*\"person\" + 0.028*\"law\" + 0.022*\"court\" + 0.021*\"protection\" + 0.020*\"session\" + 0.020*\"sex\" + 0.019*\"discrimination\" + 0.018*\"would\" + 0.015*\"gender\"\n",
      "2019-10-29 00:39:55,153 : INFO : topic #5 (0.100): 0.071*\"transgender\" + 0.032*\"person\" + 0.029*\"discrimination\" + 0.027*\"court\" + 0.026*\"law\" + 0.020*\"session\" + 0.019*\"protection\" + 0.018*\"sex\" + 0.013*\"would\" + 0.012*\"federal\"\n",
      "2019-10-29 00:39:55,156 : INFO : topic #0 (0.100): 0.053*\"transgender\" + 0.031*\"person\" + 0.031*\"law\" + 0.030*\"discrimination\" + 0.029*\"court\" + 0.028*\"protection\" + 0.024*\"session\" + 0.017*\"would\" + 0.016*\"sex\" + 0.014*\"federal\"\n",
      "2019-10-29 00:39:55,158 : INFO : topic #8 (0.100): 0.048*\"transgender\" + 0.034*\"discrimination\" + 0.029*\"law\" + 0.023*\"person\" + 0.021*\"session\" + 0.021*\"court\" + 0.019*\"sex\" + 0.019*\"protection\" + 0.015*\"would\" + 0.014*\"federal\"\n",
      "2019-10-29 00:39:55,159 : INFO : topic diff=0.925626, rho=1.000000\n",
      "2019-10-29 00:39:55,566 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:55,570 : INFO : built Dictionary(235 unique tokens: ['several', 'filed', 'watch', 'conglomerate', 'stop']...) from 5 documents (total 1950 corpus positions)\n",
      "2019-10-29 00:39:55,573 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:55,574 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:55,576 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:55,578 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:55,579 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:55,695 : INFO : -7.401 per-word bound, 169.0 perplexity estimate based on a held-out corpus of 5 documents with 1950 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:55,698 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:55,706 : INFO : topic #8 (0.100): 0.042*\"sourceamerica\" + 0.029*\"cnn\" + 0.025*\"contract\" + 0.022*\"lopez\" + 0.020*\"company\" + 0.019*\"work\" + 0.018*\"bid\" + 0.014*\"recording\" + 0.013*\"robinson\" + 0.013*\"disabled\"\n",
      "2019-10-29 00:39:55,708 : INFO : topic #4 (0.100): 0.034*\"sourceamerica\" + 0.027*\"contract\" + 0.027*\"cnn\" + 0.024*\"lopez\" + 0.021*\"company\" + 0.016*\"work\" + 0.015*\"program\" + 0.015*\"abilityone\" + 0.014*\"recording\" + 0.014*\"robinson\"\n",
      "2019-10-29 00:39:55,710 : INFO : topic #5 (0.100): 0.031*\"contract\" + 0.028*\"sourceamerica\" + 0.023*\"company\" + 0.021*\"cnn\" + 0.020*\"program\" + 0.017*\"recording\" + 0.016*\"abilityone\" + 0.016*\"robinson\" + 0.014*\"work\" + 0.014*\"lopez\"\n",
      "2019-10-29 00:39:55,712 : INFO : topic #3 (0.100): 0.030*\"sourceamerica\" + 0.025*\"lopez\" + 0.021*\"contract\" + 0.021*\"company\" + 0.018*\"cnn\" + 0.016*\"robinson\" + 0.016*\"program\" + 0.013*\"disabled\" + 0.012*\"work\" + 0.011*\"people\"\n",
      "2019-10-29 00:39:55,714 : INFO : topic #0 (0.100): 0.029*\"contract\" + 0.024*\"sourceamerica\" + 0.021*\"cnn\" + 0.021*\"lopez\" + 0.021*\"company\" + 0.019*\"program\" + 0.017*\"recording\" + 0.014*\"abilityone\" + 0.012*\"disabled\" + 0.012*\"robinson\"\n",
      "2019-10-29 00:39:55,717 : INFO : topic diff=0.918343, rho=1.000000\n",
      "2019-10-29 00:39:56,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:56,135 : INFO : built Dictionary(112 unique tokens: ['prime', 'campaign', 'party', 'advantage', 'parliament']...) from 5 documents (total 690 corpus positions)\n",
      "2019-10-29 00:39:56,138 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:56,139 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:56,140 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:56,145 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:56,147 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:56,195 : INFO : -7.230 per-word bound, 150.1 perplexity estimate based on a held-out corpus of 5 documents with 690 words\n",
      "2019-10-29 00:39:56,196 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:56,203 : INFO : topic #5 (0.100): 0.025*\"election\" + 0.025*\"party\" + 0.023*\"japanese\" + 0.019*\"tokyo\" + 0.019*\"tuesday\" + 0.018*\"governor\" + 0.016*\"take\" + 0.015*\"minister\" + 0.015*\"koike\" + 0.014*\"former\"\n",
      "2019-10-29 00:39:56,207 : INFO : topic #7 (0.100): 0.028*\"party\" + 0.025*\"tuesday\" + 0.022*\"election\" + 0.022*\"japanese\" + 0.021*\"tokyo\" + 0.019*\"governor\" + 0.018*\"former\" + 0.017*\"seat\" + 0.015*\"campaign\" + 0.015*\"october\"\n",
      "2019-10-29 00:39:56,210 : INFO : topic #4 (0.100): 0.025*\"party\" + 0.024*\"election\" + 0.022*\"tuesday\" + 0.021*\"tokyo\" + 0.019*\"japanese\" + 0.019*\"abe\" + 0.016*\"begin\" + 0.015*\"take\" + 0.015*\"seat\" + 0.015*\"governor\"\n",
      "2019-10-29 00:39:56,213 : INFO : topic #9 (0.100): 0.028*\"election\" + 0.024*\"party\" + 0.021*\"japanese\" + 0.019*\"tokyo\" + 0.018*\"formed\" + 0.018*\"tuesday\" + 0.018*\"abe\" + 0.015*\"diet\" + 0.015*\"campaign\" + 0.014*\"snap\"\n",
      "2019-10-29 00:39:56,215 : INFO : topic #6 (0.100): 0.028*\"election\" + 0.028*\"party\" + 0.019*\"japanese\" + 0.018*\"japan\" + 0.018*\"tokyo\" + 0.017*\"former\" + 0.017*\"tuesday\" + 0.016*\"begin\" + 0.015*\"take\" + 0.015*\"seat\"\n",
      "2019-10-29 00:39:56,218 : INFO : topic diff=0.692902, rho=1.000000\n",
      "2019-10-29 00:39:56,621 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:56,625 : INFO : built Dictionary(154 unique tokens: ['chain', 'fan', 'end', 'cool', 'batch']...) from 5 documents (total 1260 corpus positions)\n",
      "2019-10-29 00:39:56,628 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:56,629 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:56,631 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:56,633 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:56,635 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:56,694 : INFO : -7.031 per-word bound, 130.7 perplexity estimate based on a held-out corpus of 5 documents with 1260 words\n",
      "2019-10-29 00:39:56,695 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:56,701 : INFO : topic #2 (0.100): 0.047*\"sauce\" + 0.040*\"morty\" + 0.036*\"mcdonald\" + 0.032*\"szechuan\" + 0.031*\"fan\" + 0.025*\"rick\" + 0.017*\"limited\" + 0.014*\"cartoon\" + 0.012*\"restaurant\" + 0.012*\"mcnugget\"\n",
      "2019-10-29 00:39:56,703 : INFO : topic #8 (0.100): 0.052*\"mcdonald\" + 0.047*\"sauce\" + 0.034*\"morty\" + 0.034*\"rick\" + 0.030*\"fan\" + 0.030*\"szechuan\" + 0.015*\"limited\" + 0.014*\"said\" + 0.014*\"restaurant\" + 0.013*\"one\"\n",
      "2019-10-29 00:39:56,706 : INFO : topic #4 (0.100): 0.045*\"sauce\" + 0.038*\"morty\" + 0.035*\"mcdonald\" + 0.030*\"rick\" + 0.030*\"szechuan\" + 0.023*\"fan\" + 0.016*\"limited\" + 0.014*\"mcnugget\" + 0.013*\"said\" + 0.013*\"cartoon\"\n",
      "2019-10-29 00:39:56,708 : INFO : topic #3 (0.100): 0.050*\"mcdonald\" + 0.047*\"sauce\" + 0.035*\"rick\" + 0.032*\"morty\" + 0.030*\"fan\" + 0.028*\"szechuan\" + 0.022*\"limited\" + 0.015*\"twitter\" + 0.012*\"say\" + 0.011*\"take\"\n",
      "2019-10-29 00:39:56,710 : INFO : topic #0 (0.100): 0.054*\"mcdonald\" + 0.048*\"sauce\" + 0.043*\"morty\" + 0.033*\"rick\" + 0.020*\"szechuan\" + 0.019*\"fan\" + 0.015*\"limited\" + 0.013*\"say\" + 0.013*\"mcnugget\" + 0.012*\"one\"\n",
      "2019-10-29 00:39:56,713 : INFO : topic diff=0.874963, rho=1.000000\n",
      "2019-10-29 00:39:57,160 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:57,164 : INFO : built Dictionary(197 unique tokens: ['located', 'product', 'book', 'grew', 'industry']...) from 5 documents (total 1405 corpus positions)\n",
      "2019-10-29 00:39:57,169 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:57,172 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:57,175 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:57,178 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:57,180 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:57,270 : INFO : -7.466 per-word bound, 176.8 perplexity estimate based on a held-out corpus of 5 documents with 1405 words\n",
      "2019-10-29 00:39:57,273 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:57,280 : INFO : topic #0 (0.100): 0.063*\"wine\" + 0.028*\"million\" + 0.024*\"zachariassen\" + 0.024*\"user\" + 0.016*\"app\" + 0.014*\"vivino\" + 0.013*\"year\" + 0.013*\"bottle\" + 0.011*\"said\" + 0.009*\"launched\"\n",
      "2019-10-29 00:39:57,282 : INFO : topic #5 (0.100): 0.075*\"wine\" + 0.031*\"million\" + 0.028*\"zachariassen\" + 0.018*\"app\" + 0.017*\"user\" + 0.016*\"vivino\" + 0.013*\"bottle\" + 0.012*\"said\" + 0.010*\"year\" + 0.008*\"like\"\n",
      "2019-10-29 00:39:57,285 : INFO : topic #4 (0.100): 0.068*\"wine\" + 0.028*\"million\" + 0.024*\"zachariassen\" + 0.019*\"user\" + 0.018*\"app\" + 0.015*\"vivino\" + 0.015*\"said\" + 0.014*\"bottle\" + 0.010*\"year\" + 0.009*\"rated\"\n",
      "2019-10-29 00:39:57,287 : INFO : topic #9 (0.100): 0.054*\"wine\" + 0.027*\"million\" + 0.026*\"zachariassen\" + 0.022*\"app\" + 0.020*\"vivino\" + 0.020*\"user\" + 0.015*\"bottle\" + 0.013*\"said\" + 0.009*\"sold\" + 0.009*\"year\"\n",
      "2019-10-29 00:39:57,288 : INFO : topic #3 (0.100): 0.073*\"wine\" + 0.028*\"million\" + 0.028*\"zachariassen\" + 0.021*\"user\" + 0.020*\"app\" + 0.015*\"vivino\" + 0.012*\"said\" + 0.010*\"bottle\" + 0.009*\"price\" + 0.009*\"restaurant\"\n",
      "2019-10-29 00:39:57,289 : INFO : topic diff=0.806628, rho=1.000000\n",
      "2019-10-29 00:39:57,702 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:57,705 : INFO : built Dictionary(178 unique tokens: ['dating', 'forward', 'sd', 'party', 'come']...) from 5 documents (total 1365 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:57,708 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:57,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:57,716 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:57,720 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:57,723 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:57,794 : INFO : -7.264 per-word bound, 153.7 perplexity estimate based on a held-out corpus of 5 documents with 1365 words\n",
      "2019-10-29 00:39:57,796 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:57,802 : INFO : topic #6 (0.100): 0.054*\"said\" + 0.029*\"airbnb\" + 0.027*\"starnes\" + 0.022*\"bourque\" + 0.022*\"natt\" + 0.014*\"police\" + 0.011*\"gave\" + 0.011*\"video\" + 0.011*\"key\" + 0.011*\"smoke\"\n",
      "2019-10-29 00:39:57,805 : INFO : topic #2 (0.100): 0.039*\"said\" + 0.022*\"starnes\" + 0.022*\"airbnb\" + 0.016*\"natt\" + 0.015*\"bourque\" + 0.013*\"detector\" + 0.013*\"smoke\" + 0.013*\"key\" + 0.012*\"police\" + 0.012*\"wife\"\n",
      "2019-10-29 00:39:57,808 : INFO : topic #8 (0.100): 0.039*\"said\" + 0.031*\"airbnb\" + 0.021*\"natt\" + 0.021*\"starnes\" + 0.017*\"police\" + 0.016*\"bourque\" + 0.013*\"hope\" + 0.012*\"smoke\" + 0.011*\"gave\" + 0.011*\"recording\"\n",
      "2019-10-29 00:39:57,810 : INFO : topic #0 (0.100): 0.043*\"said\" + 0.029*\"starnes\" + 0.025*\"airbnb\" + 0.021*\"natt\" + 0.018*\"bourque\" + 0.015*\"smoke\" + 0.014*\"recording\" + 0.013*\"detector\" + 0.013*\"police\" + 0.013*\"people\"\n",
      "2019-10-29 00:39:57,813 : INFO : topic #1 (0.100): 0.052*\"said\" + 0.028*\"starnes\" + 0.024*\"airbnb\" + 0.016*\"natt\" + 0.016*\"police\" + 0.015*\"bourque\" + 0.014*\"smoke\" + 0.012*\"rented\" + 0.011*\"wife\" + 0.011*\"longboat\"\n",
      "2019-10-29 00:39:57,815 : INFO : topic diff=0.808020, rho=1.000000\n",
      "2019-10-29 00:39:58,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:58,252 : INFO : built Dictionary(293 unique tokens: ['let', 'school', 'small', 'seal', 'take']...) from 5 documents (total 1865 corpus positions)\n",
      "2019-10-29 00:39:58,256 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:58,257 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:58,258 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:58,261 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:58,262 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:58,383 : INFO : -8.028 per-word bound, 261.0 perplexity estimate based on a held-out corpus of 5 documents with 1865 words\n",
      "2019-10-29 00:39:58,385 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:58,392 : INFO : topic #2 (0.100): 0.022*\"galapagos\" + 0.016*\"list\" + 0.015*\"wonder\" + 0.012*\"giant\" + 0.012*\"sea\" + 0.010*\"rock\" + 0.009*\"tortoise\" + 0.009*\"year\" + 0.009*\"endangered\" + 0.008*\"darwin\"\n",
      "2019-10-29 00:39:58,394 : INFO : topic #4 (0.100): 0.024*\"galapagos\" + 0.014*\"list\" + 0.012*\"sea\" + 0.011*\"island\" + 0.010*\"giant\" + 0.010*\"wonder\" + 0.009*\"darwin\" + 0.009*\"year\" + 0.008*\"endangered\" + 0.008*\"tortoise\"\n",
      "2019-10-29 00:39:58,396 : INFO : topic #8 (0.100): 0.025*\"galapagos\" + 0.014*\"list\" + 0.013*\"wonder\" + 0.010*\"darwin\" + 0.010*\"island\" + 0.010*\"giant\" + 0.009*\"people\" + 0.009*\"tortoise\" + 0.008*\"never\" + 0.008*\"world\"\n",
      "2019-10-29 00:39:58,399 : INFO : topic #7 (0.100): 0.023*\"galapagos\" + 0.018*\"list\" + 0.013*\"wonder\" + 0.012*\"tortoise\" + 0.011*\"sea\" + 0.010*\"giant\" + 0.010*\"darwin\" + 0.010*\"island\" + 0.009*\"rock\" + 0.009*\"earth\"\n",
      "2019-10-29 00:39:58,402 : INFO : topic #6 (0.100): 0.024*\"galapagos\" + 0.014*\"list\" + 0.011*\"tortoise\" + 0.011*\"wonder\" + 0.010*\"sea\" + 0.009*\"island\" + 0.009*\"darwin\" + 0.009*\"creature\" + 0.009*\"never\" + 0.008*\"giant\"\n",
      "2019-10-29 00:39:58,404 : INFO : topic diff=0.732289, rho=1.000000\n",
      "2019-10-29 00:39:58,809 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:58,812 : INFO : built Dictionary(174 unique tokens: ['previously', 'scope', 'campaign', 'inquiry', 'troll']...) from 5 documents (total 1420 corpus positions)\n",
      "2019-10-29 00:39:58,816 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:58,817 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:58,819 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:58,821 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:58,822 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:58,891 : INFO : -7.148 per-word bound, 141.8 perplexity estimate based on a held-out corpus of 5 documents with 1420 words\n",
      "2019-10-29 00:39:58,893 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:58,899 : INFO : topic #9 (0.100): 0.044*\"google\" + 0.034*\"ad\" + 0.028*\"company\" + 0.024*\"account\" + 0.017*\"said\" + 0.016*\"advertising\" + 0.016*\"twitter\" + 0.013*\"youtube\" + 0.013*\"source\" + 0.013*\"facebook\"\n",
      "2019-10-29 00:39:58,901 : INFO : topic #6 (0.100): 0.042*\"google\" + 0.030*\"company\" + 0.026*\"ad\" + 0.025*\"account\" + 0.021*\"advertising\" + 0.019*\"twitter\" + 0.017*\"said\" + 0.015*\"found\" + 0.014*\"facebook\" + 0.014*\"identified\"\n",
      "2019-10-29 00:39:58,903 : INFO : topic #0 (0.100): 0.048*\"google\" + 0.032*\"company\" + 0.032*\"ad\" + 0.031*\"account\" + 0.018*\"advertising\" + 0.017*\"said\" + 0.017*\"facebook\" + 0.016*\"cnn\" + 0.015*\"identified\" + 0.015*\"source\"\n",
      "2019-10-29 00:39:58,906 : INFO : topic #8 (0.100): 0.047*\"google\" + 0.031*\"company\" + 0.027*\"advertising\" + 0.026*\"ad\" + 0.025*\"account\" + 0.019*\"twitter\" + 0.016*\"russian\" + 0.016*\"facebook\" + 0.015*\"said\" + 0.015*\"source\"\n",
      "2019-10-29 00:39:58,909 : INFO : topic #2 (0.100): 0.047*\"google\" + 0.030*\"account\" + 0.029*\"ad\" + 0.020*\"company\" + 0.019*\"twitter\" + 0.018*\"advertising\" + 0.017*\"facebook\" + 0.017*\"said\" + 0.016*\"identified\" + 0.015*\"cnn\"\n",
      "2019-10-29 00:39:58,911 : INFO : topic diff=0.843305, rho=1.000000\n",
      "2019-10-29 00:39:59,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:39:59,444 : INFO : built Dictionary(489 unique tokens: ['rage', 'extensive', 'catholic', 'wanting', 'happy']...) from 5 documents (total 5455 corpus positions)\n",
      "2019-10-29 00:39:59,454 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:39:59,457 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:39:59,460 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:39:59,466 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:39:59,469 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:39:59,667 : INFO : -7.745 per-word bound, 214.5 perplexity estimate based on a held-out corpus of 5 documents with 5455 words\n",
      "2019-10-29 00:39:59,668 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:39:59,679 : INFO : topic #7 (0.100): 0.032*\"white\" + 0.026*\"working\" + 0.025*\"say\" + 0.021*\"class\" + 0.016*\"country\" + 0.015*\"immigrant\" + 0.013*\"job\" + 0.012*\"government\" + 0.012*\"poll\" + 0.011*\"cnn\"\n",
      "2019-10-29 00:39:59,682 : INFO : topic #4 (0.100): 0.033*\"white\" + 0.030*\"say\" + 0.026*\"class\" + 0.023*\"working\" + 0.015*\"country\" + 0.014*\"people\" + 0.013*\"photo\" + 0.012*\"government\" + 0.012*\"poll\" + 0.012*\"cnn\"\n",
      "2019-10-29 00:39:59,684 : INFO : topic #3 (0.100): 0.025*\"white\" + 0.022*\"working\" + 0.021*\"class\" + 0.021*\"say\" + 0.016*\"government\" + 0.015*\"immigrant\" + 0.012*\"people\" + 0.012*\"immigration\" + 0.012*\"country\" + 0.011*\"poll\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:39:59,687 : INFO : topic #8 (0.100): 0.028*\"working\" + 0.027*\"say\" + 0.023*\"class\" + 0.022*\"white\" + 0.016*\"country\" + 0.013*\"immigration\" + 0.012*\"kff\" + 0.012*\"government\" + 0.012*\"immigrant\" + 0.011*\"photo\"\n",
      "2019-10-29 00:39:59,690 : INFO : topic #5 (0.100): 0.030*\"say\" + 0.028*\"class\" + 0.023*\"white\" + 0.021*\"working\" + 0.017*\"country\" + 0.014*\"immigrant\" + 0.013*\"immigration\" + 0.013*\"poll\" + 0.012*\"people\" + 0.012*\"cnn\"\n",
      "2019-10-29 00:39:59,692 : INFO : topic diff=1.001033, rho=1.000000\n",
      "2019-10-29 00:40:00,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:00,114 : INFO : built Dictionary(298 unique tokens: ['staying', 'school', 'watch', 'hero', 'come']...) from 5 documents (total 2250 corpus positions)\n",
      "2019-10-29 00:40:00,119 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:00,120 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:00,122 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:00,125 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:00,127 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:00,258 : INFO : -7.764 per-word bound, 217.4 perplexity estimate based on a held-out corpus of 5 documents with 2250 words\n",
      "2019-10-29 00:40:00,261 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:00,268 : INFO : topic #9 (0.100): 0.039*\"patel\" + 0.032*\"amputee\" + 0.018*\"cnn\" + 0.015*\"help\" + 0.010*\"leg\" + 0.010*\"work\" + 0.009*\"support\" + 0.009*\"san\" + 0.009*\"antonio\" + 0.008*\"foot\"\n",
      "2019-10-29 00:40:00,271 : INFO : topic #2 (0.100): 0.035*\"patel\" + 0.031*\"amputee\" + 0.016*\"cnn\" + 0.012*\"help\" + 0.010*\"amputation\" + 0.010*\"san\" + 0.010*\"said\" + 0.009*\"mona\" + 0.009*\"leg\" + 0.009*\"going\"\n",
      "2019-10-29 00:40:00,274 : INFO : topic #5 (0.100): 0.034*\"amputee\" + 0.031*\"patel\" + 0.015*\"cnn\" + 0.015*\"help\" + 0.010*\"work\" + 0.010*\"group\" + 0.010*\"support\" + 0.009*\"leg\" + 0.009*\"foot\" + 0.009*\"going\"\n",
      "2019-10-29 00:40:00,276 : INFO : topic #4 (0.100): 0.040*\"patel\" + 0.030*\"amputee\" + 0.013*\"foot\" + 0.013*\"cnn\" + 0.013*\"help\" + 0.011*\"going\" + 0.009*\"work\" + 0.009*\"support\" + 0.009*\"san\" + 0.008*\"mona\"\n",
      "2019-10-29 00:40:00,279 : INFO : topic #1 (0.100): 0.034*\"amputee\" + 0.027*\"patel\" + 0.016*\"cnn\" + 0.014*\"help\" + 0.013*\"antonio\" + 0.010*\"year\" + 0.010*\"foot\" + 0.010*\"said\" + 0.010*\"going\" + 0.008*\"modification\"\n",
      "2019-10-29 00:40:00,282 : INFO : topic diff=0.814057, rho=1.000000\n",
      "2019-10-29 00:40:00,697 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:00,699 : INFO : built Dictionary(61 unique tokens: ['may', 'thoughtful', 'hijab', 'emoji', 'life']...) from 5 documents (total 380 corpus positions)\n",
      "2019-10-29 00:40:00,701 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:00,702 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:00,705 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:00,709 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:00,712 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:00,762 : INFO : -6.721 per-word bound, 105.5 perplexity estimate based on a held-out corpus of 5 documents with 380 words\n",
      "2019-10-29 00:40:00,764 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:00,770 : INFO : topic #3 (0.100): 0.047*\"emoji\" + 0.029*\"hijabi\" + 0.029*\"old\" + 0.027*\"teen\" + 0.026*\"woman\" + 0.026*\"represent\" + 0.025*\"rayouf\" + 0.025*\"cnn\" + 0.025*\"muslim\" + 0.024*\"headscarf\"\n",
      "2019-10-29 00:40:00,772 : INFO : topic #2 (0.100): 0.047*\"emoji\" + 0.033*\"woman\" + 0.031*\"muslim\" + 0.027*\"hijabi\" + 0.027*\"teen\" + 0.026*\"rayouf\" + 0.026*\"unicode\" + 0.026*\"cnn\" + 0.024*\"represent\" + 0.022*\"year\"\n",
      "2019-10-29 00:40:00,777 : INFO : topic #8 (0.100): 0.040*\"emoji\" + 0.036*\"woman\" + 0.034*\"teen\" + 0.030*\"year\" + 0.029*\"unicode\" + 0.028*\"old\" + 0.028*\"represent\" + 0.026*\"rayouf\" + 0.025*\"cnn\" + 0.024*\"headscarf\"\n",
      "2019-10-29 00:40:00,782 : INFO : topic #9 (0.100): 0.047*\"emoji\" + 0.041*\"woman\" + 0.030*\"year\" + 0.028*\"unicode\" + 0.026*\"rayouf\" + 0.026*\"headscarf\" + 0.025*\"muslim\" + 0.024*\"teen\" + 0.024*\"old\" + 0.023*\"hijabi\"\n",
      "2019-10-29 00:40:00,785 : INFO : topic #0 (0.100): 0.049*\"emoji\" + 0.040*\"woman\" + 0.032*\"hijabi\" + 0.029*\"muslim\" + 0.029*\"represent\" + 0.027*\"cnn\" + 0.027*\"unicode\" + 0.027*\"year\" + 0.023*\"old\" + 0.022*\"headscarf\"\n",
      "2019-10-29 00:40:00,788 : INFO : topic diff=0.685324, rho=1.000000\n",
      "2019-10-29 00:40:01,233 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:01,238 : INFO : built Dictionary(356 unique tokens: ['let', 'party', 'perhaps', 'mistake', 'rouhani']...) from 5 documents (total 2580 corpus positions)\n",
      "2019-10-29 00:40:01,244 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:01,245 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:01,246 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:01,250 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:01,252 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:01,408 : INFO : -7.993 per-word bound, 254.7 perplexity estimate based on a held-out corpus of 5 documents with 2580 words\n",
      "2019-10-29 00:40:01,410 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:01,418 : INFO : topic #5 (0.100): 0.044*\"iran\" + 0.017*\"deal\" + 0.016*\"oil\" + 0.015*\"nuclear\" + 0.010*\"could\" + 0.009*\"would\" + 0.009*\"secretary\" + 0.009*\"state\" + 0.009*\"trump\" + 0.008*\"president\"\n",
      "2019-10-29 00:40:01,420 : INFO : topic #2 (0.100): 0.043*\"iran\" + 0.017*\"oil\" + 0.015*\"nuclear\" + 0.013*\"state\" + 0.012*\"deal\" + 0.010*\"new\" + 0.009*\"would\" + 0.009*\"could\" + 0.008*\"trump\" + 0.008*\"secretary\"\n",
      "2019-10-29 00:40:01,422 : INFO : topic #0 (0.100): 0.050*\"iran\" + 0.013*\"deal\" + 0.013*\"nuclear\" + 0.013*\"oil\" + 0.010*\"new\" + 0.010*\"trump\" + 0.010*\"state\" + 0.009*\"american\" + 0.009*\"deeply\" + 0.008*\"secretary\"\n",
      "2019-10-29 00:40:01,424 : INFO : topic #9 (0.100): 0.040*\"iran\" + 0.015*\"nuclear\" + 0.014*\"state\" + 0.013*\"oil\" + 0.010*\"deal\" + 0.008*\"deeply\" + 0.008*\"new\" + 0.008*\"american\" + 0.008*\"could\" + 0.008*\"barrel\"\n",
      "2019-10-29 00:40:01,425 : INFO : topic #8 (0.100): 0.042*\"iran\" + 0.021*\"nuclear\" + 0.019*\"oil\" + 0.014*\"state\" + 0.011*\"deal\" + 0.009*\"trump\" + 0.009*\"new\" + 0.009*\"sanction\" + 0.007*\"would\" + 0.007*\"president\"\n",
      "2019-10-29 00:40:01,427 : INFO : topic diff=0.795915, rho=1.000000\n",
      "2019-10-29 00:40:01,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:01,913 : INFO : built Dictionary(378 unique tokens: ['previously', 'extensive', 'energy', 'retreat', 'located']...) from 5 documents (total 3240 corpus positions)\n",
      "2019-10-29 00:40:01,919 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:01,920 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:01,921 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:01,924 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:01,926 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:02,040 : INFO : -7.802 per-word bound, 223.2 perplexity estimate based on a held-out corpus of 5 documents with 3240 words\n",
      "2019-10-29 00:40:02,041 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:02,050 : INFO : topic #7 (0.100): 0.030*\"lodge\" + 0.029*\"mashpi\" + 0.019*\"forest\" + 0.016*\"ribadeneira\" + 0.013*\"site\" + 0.012*\"guest\" + 0.011*\"jungle\" + 0.009*\"ecuador\" + 0.008*\"year\" + 0.008*\"glass\"\n",
      "2019-10-29 00:40:02,053 : INFO : topic #3 (0.100): 0.029*\"lodge\" + 0.026*\"mashpi\" + 0.017*\"ribadeneira\" + 0.015*\"forest\" + 0.013*\"ecuador\" + 0.013*\"jungle\" + 0.011*\"guest\" + 0.010*\"site\" + 0.009*\"cnn\" + 0.008*\"property\"\n",
      "2019-10-29 00:40:02,056 : INFO : topic #9 (0.100): 0.030*\"lodge\" + 0.020*\"mashpi\" + 0.020*\"ribadeneira\" + 0.017*\"forest\" + 0.012*\"guest\" + 0.012*\"jungle\" + 0.012*\"year\" + 0.010*\"site\" + 0.009*\"ecuador\" + 0.009*\"building\"\n",
      "2019-10-29 00:40:02,060 : INFO : topic #4 (0.100): 0.031*\"mashpi\" + 0.025*\"lodge\" + 0.018*\"forest\" + 0.017*\"ribadeneira\" + 0.014*\"guest\" + 0.012*\"jungle\" + 0.011*\"hotel\" + 0.011*\"would\" + 0.009*\"ecuador\" + 0.009*\"site\"\n",
      "2019-10-29 00:40:02,063 : INFO : topic #1 (0.100): 0.026*\"mashpi\" + 0.021*\"lodge\" + 0.020*\"ribadeneira\" + 0.016*\"forest\" + 0.013*\"jungle\" + 0.012*\"guest\" + 0.011*\"ecuador\" + 0.010*\"hotel\" + 0.010*\"would\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:40:02,066 : INFO : topic diff=0.894247, rho=1.000000\n",
      "2019-10-29 00:40:02,539 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:02,543 : INFO : built Dictionary(99 unique tokens: ['happy', 'francisco', 'life', 'series', 'computer']...) from 5 documents (total 665 corpus positions)\n",
      "2019-10-29 00:40:02,546 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:02,548 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:02,549 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:02,552 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:02,553 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:02,600 : INFO : -6.961 per-word bound, 124.6 perplexity estimate based on a held-out corpus of 5 documents with 665 words\n",
      "2019-10-29 00:40:02,602 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:02,607 : INFO : topic #0 (0.100): 0.046*\"design\" + 0.034*\"behar\" + 0.030*\"new\" + 0.023*\"work\" + 0.023*\"york\" + 0.020*\"experience\" + 0.020*\"human\" + 0.016*\"urban\" + 0.016*\"people\" + 0.016*\"project\"\n",
      "2019-10-29 00:40:02,609 : INFO : topic #2 (0.100): 0.054*\"design\" + 0.034*\"new\" + 0.029*\"behar\" + 0.024*\"human\" + 0.022*\"york\" + 0.020*\"work\" + 0.020*\"experience\" + 0.019*\"designer\" + 0.018*\"city\" + 0.015*\"take\"\n",
      "2019-10-29 00:40:02,612 : INFO : topic #7 (0.100): 0.046*\"design\" + 0.038*\"behar\" + 0.025*\"new\" + 0.023*\"work\" + 0.020*\"human\" + 0.020*\"york\" + 0.018*\"walk\" + 0.017*\"tech\" + 0.017*\"experience\" + 0.017*\"take\"\n",
      "2019-10-29 00:40:02,614 : INFO : topic #5 (0.100): 0.044*\"design\" + 0.035*\"behar\" + 0.029*\"new\" + 0.023*\"experience\" + 0.022*\"york\" + 0.020*\"project\" + 0.020*\"work\" + 0.018*\"human\" + 0.017*\"architecture\" + 0.016*\"tech\"\n",
      "2019-10-29 00:40:02,615 : INFO : topic #1 (0.100): 0.041*\"design\" + 0.034*\"behar\" + 0.028*\"experience\" + 0.028*\"new\" + 0.022*\"york\" + 0.021*\"human\" + 0.019*\"work\" + 0.016*\"city\" + 0.016*\"important\" + 0.016*\"architecture\"\n",
      "2019-10-29 00:40:02,617 : INFO : topic diff=0.752436, rho=1.000000\n",
      "2019-10-29 00:40:03,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:03,107 : INFO : built Dictionary(346 unique tokens: ['reluctant', 'school', 'expert', 'label', 'new']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:40:03,113 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:03,117 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:03,121 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:03,126 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:03,129 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:03,266 : INFO : -7.566 per-word bound, 189.5 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:40:03,268 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:03,274 : INFO : topic #1 (0.100): 0.033*\"child\" + 0.032*\"said\" + 0.026*\"parent\" + 0.022*\"behavior\" + 0.021*\"kazdin\" + 0.018*\"get\" + 0.015*\"say\" + 0.010*\"put\" + 0.010*\"come\" + 0.009*\"praise\"\n",
      "2019-10-29 00:40:03,276 : INFO : topic #9 (0.100): 0.040*\"child\" + 0.032*\"said\" + 0.020*\"say\" + 0.020*\"get\" + 0.019*\"parent\" + 0.017*\"kazdin\" + 0.013*\"behavior\" + 0.011*\"defiant\" + 0.011*\"put\" + 0.010*\"praise\"\n",
      "2019-10-29 00:40:03,278 : INFO : topic #0 (0.100): 0.030*\"child\" + 0.030*\"said\" + 0.025*\"kazdin\" + 0.018*\"parent\" + 0.016*\"behavior\" + 0.016*\"say\" + 0.013*\"get\" + 0.012*\"defiant\" + 0.012*\"estes\" + 0.011*\"parenting\"\n",
      "2019-10-29 00:40:03,280 : INFO : topic #4 (0.100): 0.036*\"child\" + 0.029*\"said\" + 0.025*\"parent\" + 0.017*\"kazdin\" + 0.017*\"say\" + 0.017*\"get\" + 0.017*\"behavior\" + 0.013*\"praise\" + 0.011*\"parenting\" + 0.011*\"way\"\n",
      "2019-10-29 00:40:03,282 : INFO : topic #5 (0.100): 0.037*\"child\" + 0.025*\"said\" + 0.023*\"kazdin\" + 0.021*\"parent\" + 0.019*\"behavior\" + 0.017*\"say\" + 0.017*\"get\" + 0.012*\"defiant\" + 0.011*\"parenting\" + 0.010*\"choice\"\n",
      "2019-10-29 00:40:03,284 : INFO : topic diff=0.949439, rho=1.000000\n",
      "2019-10-29 00:40:03,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:03,761 : INFO : built Dictionary(41 unique tokens: ['night', 'whereabouts', 'white', 'pound', 'convicted']...) from 5 documents (total 235 corpus positions)\n",
      "2019-10-29 00:40:03,763 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:03,765 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:03,771 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:03,774 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:03,778 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:03,803 : INFO : -6.610 per-word bound, 97.7 perplexity estimate based on a held-out corpus of 5 documents with 235 words\n",
      "2019-10-29 00:40:03,812 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:03,818 : INFO : topic #6 (0.100): 0.059*\"nielsen\" + 0.049*\"release\" + 0.041*\"prisoner\" + 0.039*\"work\" + 0.037*\"iowa\" + 0.030*\"white\" + 0.026*\"dodge\" + 0.025*\"andrew\" + 0.024*\"facility\" + 0.024*\"contact\"\n",
      "2019-10-29 00:40:03,822 : INFO : topic #2 (0.100): 0.066*\"nielsen\" + 0.050*\"iowa\" + 0.037*\"work\" + 0.033*\"release\" + 0.033*\"prisoner\" + 0.027*\"old\" + 0.027*\"fort\" + 0.026*\"center\" + 0.024*\"person\" + 0.024*\"contact\"\n",
      "2019-10-29 00:40:03,828 : INFO : topic #0 (0.100): 0.063*\"nielsen\" + 0.046*\"iowa\" + 0.039*\"work\" + 0.037*\"prisoner\" + 0.027*\"release\" + 0.026*\"back\" + 0.025*\"dodge\" + 0.025*\"height\" + 0.024*\"year\" + 0.024*\"intent\"\n",
      "2019-10-29 00:40:03,832 : INFO : topic #7 (0.100): 0.051*\"iowa\" + 0.046*\"nielsen\" + 0.038*\"work\" + 0.036*\"prisoner\" + 0.035*\"release\" + 0.029*\"convicted\" + 0.028*\"report\" + 0.027*\"andrew\" + 0.027*\"height\" + 0.026*\"intent\"\n",
      "2019-10-29 00:40:03,837 : INFO : topic #1 (0.100): 0.050*\"nielsen\" + 0.047*\"release\" + 0.043*\"work\" + 0.036*\"prisoner\" + 0.033*\"iowa\" + 0.028*\"police\" + 0.027*\"escape\" + 0.027*\"james\" + 0.027*\"degree\" + 0.027*\"andrew\"\n",
      "2019-10-29 00:40:03,840 : INFO : topic diff=0.636607, rho=1.000000\n",
      "2019-10-29 00:40:04,388 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:04,404 : INFO : built Dictionary(747 unique tokens: ['happy', 'specie', 'advantage', 'recommendation', 'transport']...) from 5 documents (total 7090 corpus positions)\n",
      "2019-10-29 00:40:04,417 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:04,420 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:04,422 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:04,427 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:04,430 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:04,681 : INFO : -8.333 per-word bound, 322.5 perplexity estimate based on a held-out corpus of 5 documents with 7090 words\n",
      "2019-10-29 00:40:04,683 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:04,693 : INFO : topic #3 (0.100): 0.038*\"zika\" + 0.020*\"virus\" + 0.012*\"woman\" + 0.011*\"sexual\" + 0.011*\"state\" + 0.010*\"sexually\" + 0.009*\"disease\" + 0.008*\"among\" + 0.008*\"mosquito\" + 0.008*\"united\"\n",
      "2019-10-29 00:40:04,695 : INFO : topic #8 (0.100): 0.043*\"zika\" + 0.015*\"virus\" + 0.012*\"woman\" + 0.011*\"state\" + 0.009*\"mosquito\" + 0.009*\"among\" + 0.008*\"case\" + 0.008*\"disease\" + 0.008*\"baby\" + 0.007*\"sexually\"\n",
      "2019-10-29 00:40:04,696 : INFO : topic #1 (0.100): 0.034*\"zika\" + 0.014*\"woman\" + 0.011*\"state\" + 0.010*\"virus\" + 0.010*\"disease\" + 0.010*\"mosquito\" + 0.009*\"sexual\" + 0.009*\"among\" + 0.008*\"united\" + 0.007*\"transmission\"\n",
      "2019-10-29 00:40:04,697 : INFO : topic #5 (0.100): 0.035*\"zika\" + 0.018*\"woman\" + 0.012*\"virus\" + 0.011*\"state\" + 0.011*\"sexual\" + 0.009*\"disease\" + 0.008*\"sexually\" + 0.008*\"mosquito\" + 0.007*\"united\" + 0.007*\"among\"\n",
      "2019-10-29 00:40:04,699 : INFO : topic #4 (0.100): 0.049*\"zika\" + 0.016*\"virus\" + 0.015*\"woman\" + 0.011*\"state\" + 0.009*\"transmission\" + 0.008*\"baby\" + 0.008*\"sexual\" + 0.008*\"sexually\" + 0.008*\"disease\" + 0.007*\"among\"\n",
      "2019-10-29 00:40:04,701 : INFO : topic diff=0.949052, rho=1.000000\n",
      "2019-10-29 00:40:05,182 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:05,190 : INFO : built Dictionary(366 unique tokens: ['franco', 'previously', 'prime', 'deep', 'marched']...) from 5 documents (total 2995 corpus positions)\n",
      "2019-10-29 00:40:05,197 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:05,198 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:05,199 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:05,202 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:05,204 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:05,364 : INFO : -7.839 per-word bound, 229.0 perplexity estimate based on a held-out corpus of 5 documents with 2995 words\n",
      "2019-10-29 00:40:05,366 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:05,375 : INFO : topic #6 (0.100): 0.035*\"catalonia\" + 0.020*\"catalan\" + 0.016*\"madrid\" + 0.016*\"spain\" + 0.013*\"independence\" + 0.013*\"region\" + 0.013*\"puigdemont\" + 0.013*\"spanish\" + 0.012*\"would\" + 0.012*\"government\"\n",
      "2019-10-29 00:40:05,377 : INFO : topic #7 (0.100): 0.036*\"catalonia\" + 0.025*\"catalan\" + 0.017*\"spain\" + 0.016*\"madrid\" + 0.014*\"would\" + 0.013*\"puigdemont\" + 0.012*\"independence\" + 0.011*\"spanish\" + 0.011*\"country\" + 0.010*\"region\"\n",
      "2019-10-29 00:40:05,384 : INFO : topic #0 (0.100): 0.026*\"catalonia\" + 0.018*\"catalan\" + 0.017*\"spain\" + 0.016*\"madrid\" + 0.015*\"government\" + 0.013*\"spanish\" + 0.012*\"independence\" + 0.012*\"would\" + 0.012*\"country\" + 0.011*\"puigdemont\"\n",
      "2019-10-29 00:40:05,388 : INFO : topic #3 (0.100): 0.041*\"catalonia\" + 0.022*\"catalan\" + 0.015*\"madrid\" + 0.014*\"government\" + 0.013*\"country\" + 0.013*\"independence\" + 0.013*\"spain\" + 0.011*\"puigdemont\" + 0.011*\"would\" + 0.009*\"spanish\"\n",
      "2019-10-29 00:40:05,392 : INFO : topic #8 (0.100): 0.027*\"catalan\" + 0.023*\"catalonia\" + 0.017*\"spain\" + 0.014*\"puigdemont\" + 0.014*\"government\" + 0.014*\"independence\" + 0.013*\"would\" + 0.013*\"spanish\" + 0.012*\"region\" + 0.012*\"madrid\"\n",
      "2019-10-29 00:40:05,395 : INFO : topic diff=0.854761, rho=1.000000\n",
      "2019-10-29 00:40:05,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:05,814 : INFO : built Dictionary(87 unique tokens: ['offered', 'inquiry', 'open', 'detailed', 'adviser']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:40:05,816 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:05,817 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:05,818 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:05,820 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:05,821 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:05,872 : INFO : -6.826 per-word bound, 113.5 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:40:05,874 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:05,880 : INFO : topic #5 (0.100): 0.061*\"page\" + 0.027*\"intelligence\" + 0.027*\"senate\" + 0.026*\"carter\" + 0.020*\"obtained\" + 0.019*\"testify\" + 0.018*\"committee\" + 0.017*\"fifth\" + 0.016*\"trump\" + 0.016*\"adviser\"\n",
      "2019-10-29 00:40:05,883 : INFO : topic #1 (0.100): 0.067*\"page\" + 0.027*\"committee\" + 0.023*\"intelligence\" + 0.021*\"senate\" + 0.020*\"adviser\" + 0.020*\"publicly\" + 0.019*\"carter\" + 0.019*\"plead\" + 0.018*\"warrant\" + 0.018*\"government\"\n",
      "2019-10-29 00:40:05,886 : INFO : topic #4 (0.100): 0.071*\"page\" + 0.030*\"committee\" + 0.029*\"intelligence\" + 0.027*\"senate\" + 0.023*\"carter\" + 0.019*\"monitor\" + 0.018*\"communication\" + 0.018*\"fifth\" + 0.018*\"testify\" + 0.017*\"former\"\n",
      "2019-10-29 00:40:05,891 : INFO : topic #3 (0.100): 0.065*\"page\" + 0.025*\"carter\" + 0.024*\"intelligence\" + 0.022*\"senate\" + 0.020*\"committee\" + 0.020*\"monitor\" + 0.018*\"demanded\" + 0.018*\"former\" + 0.017*\"fbi\" + 0.017*\"adviser\"\n",
      "2019-10-29 00:40:05,894 : INFO : topic #6 (0.100): 0.060*\"page\" + 0.025*\"intelligence\" + 0.024*\"carter\" + 0.024*\"senate\" + 0.022*\"plead\" + 0.021*\"committee\" + 0.018*\"cnn\" + 0.018*\"request\" + 0.017*\"fbi\" + 0.017*\"government\"\n",
      "2019-10-29 00:40:05,897 : INFO : topic diff=0.730819, rho=1.000000\n",
      "2019-10-29 00:40:06,355 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:06,366 : INFO : built Dictionary(571 unique tokens: ['let', 'paradise', 'locked', 'ingesting', 'happy']...) from 5 documents (total 4920 corpus positions)\n",
      "2019-10-29 00:40:06,374 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:06,376 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:06,378 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:06,382 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:06,385 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:06,629 : INFO : -8.197 per-word bound, 293.5 perplexity estimate based on a held-out corpus of 5 documents with 4920 words\n",
      "2019-10-29 00:40:06,631 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:06,644 : INFO : topic #3 (0.100): 0.045*\"plastic\" + 0.014*\"ocean\" + 0.013*\"one\" + 0.012*\"piece\" + 0.010*\"midway\" + 0.009*\"made\" + 0.008*\"island\" + 0.008*\"u\" + 0.008*\"bird\" + 0.008*\"food\"\n",
      "2019-10-29 00:40:06,647 : INFO : topic #9 (0.100): 0.053*\"plastic\" + 0.011*\"ocean\" + 0.011*\"piece\" + 0.011*\"one\" + 0.009*\"bird\" + 0.009*\"fish\" + 0.009*\"could\" + 0.009*\"made\" + 0.008*\"year\" + 0.008*\"u\"\n",
      "2019-10-29 00:40:06,650 : INFO : topic #5 (0.100): 0.049*\"plastic\" + 0.014*\"ocean\" + 0.013*\"piece\" + 0.011*\"midway\" + 0.010*\"u\" + 0.010*\"one\" + 0.010*\"year\" + 0.009*\"human\" + 0.008*\"part\" + 0.008*\"fish\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:06,654 : INFO : topic #6 (0.100): 0.061*\"plastic\" + 0.010*\"ocean\" + 0.009*\"year\" + 0.009*\"u\" + 0.009*\"one\" + 0.009*\"piece\" + 0.008*\"midway\" + 0.008*\"island\" + 0.008*\"made\" + 0.007*\"much\"\n",
      "2019-10-29 00:40:06,657 : INFO : topic #0 (0.100): 0.057*\"plastic\" + 0.015*\"ocean\" + 0.012*\"one\" + 0.011*\"piece\" + 0.010*\"midway\" + 0.009*\"human\" + 0.009*\"bird\" + 0.009*\"food\" + 0.008*\"u\" + 0.008*\"fish\"\n",
      "2019-10-29 00:40:06,662 : INFO : topic diff=0.888591, rho=1.000000\n",
      "2019-10-29 00:40:07,084 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:07,088 : INFO : built Dictionary(320 unique tokens: ['freelance', 'let', 'trying', 'underneath', 'waning']...) from 5 documents (total 2460 corpus positions)\n",
      "2019-10-29 00:40:07,093 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:07,095 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:07,102 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:07,106 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:07,109 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:07,227 : INFO : -7.799 per-word bound, 222.7 perplexity estimate based on a held-out corpus of 5 documents with 2460 words\n",
      "2019-10-29 00:40:07,228 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:07,234 : INFO : topic #4 (0.100): 0.043*\"gun\" + 0.023*\"mental\" + 0.015*\"health\" + 0.013*\"illness\" + 0.011*\"disability\" + 0.011*\"people\" + 0.010*\"individual\" + 0.010*\"mass\" + 0.010*\"shooting\" + 0.009*\"condition\"\n",
      "2019-10-29 00:40:07,236 : INFO : topic #5 (0.100): 0.043*\"mental\" + 0.025*\"gun\" + 0.017*\"health\" + 0.015*\"illness\" + 0.013*\"people\" + 0.011*\"control\" + 0.011*\"disability\" + 0.010*\"violence\" + 0.010*\"ryan\" + 0.009*\"mass\"\n",
      "2019-10-29 00:40:07,239 : INFO : topic #6 (0.100): 0.031*\"gun\" + 0.028*\"mental\" + 0.019*\"health\" + 0.013*\"illness\" + 0.012*\"right\" + 0.011*\"disability\" + 0.011*\"control\" + 0.011*\"people\" + 0.010*\"mass\" + 0.009*\"violence\"\n",
      "2019-10-29 00:40:07,242 : INFO : topic #9 (0.100): 0.042*\"gun\" + 0.034*\"mental\" + 0.019*\"health\" + 0.014*\"control\" + 0.013*\"disability\" + 0.012*\"illness\" + 0.011*\"people\" + 0.010*\"mass\" + 0.009*\"violence\" + 0.009*\"ryan\"\n",
      "2019-10-29 00:40:07,244 : INFO : topic #2 (0.100): 0.032*\"gun\" + 0.032*\"mental\" + 0.017*\"health\" + 0.013*\"illness\" + 0.012*\"violence\" + 0.012*\"people\" + 0.010*\"disability\" + 0.010*\"ryan\" + 0.009*\"right\" + 0.008*\"control\"\n",
      "2019-10-29 00:40:07,247 : INFO : topic diff=0.831383, rho=1.000000\n",
      "2019-10-29 00:40:07,674 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:07,679 : INFO : built Dictionary(361 unique tokens: ['specie', 'refugee', 'jamie', 'focus', '2degrees']...) from 5 documents (total 2975 corpus positions)\n",
      "2019-10-29 00:40:07,683 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:07,685 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:07,686 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:07,691 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:07,692 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:07,814 : INFO : -7.816 per-word bound, 225.3 perplexity estimate based on a held-out corpus of 5 documents with 2975 words\n",
      "2019-10-29 00:40:07,815 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:07,824 : INFO : topic #7 (0.100): 0.028*\"climate\" + 0.027*\"degree\" + 0.014*\"change\" + 0.014*\"like\" + 0.013*\"world\" + 0.013*\"know\" + 0.011*\"one\" + 0.011*\"would\" + 0.011*\"said\" + 0.010*\"number\"\n",
      "2019-10-29 00:40:07,826 : INFO : topic #1 (0.100): 0.036*\"degree\" + 0.022*\"climate\" + 0.017*\"like\" + 0.017*\"would\" + 0.014*\"change\" + 0.013*\"one\" + 0.012*\"number\" + 0.012*\"know\" + 0.011*\"year\" + 0.010*\"said\"\n",
      "2019-10-29 00:40:07,828 : INFO : topic #0 (0.100): 0.036*\"degree\" + 0.024*\"climate\" + 0.017*\"change\" + 0.015*\"like\" + 0.014*\"one\" + 0.012*\"world\" + 0.011*\"number\" + 0.011*\"asked\" + 0.009*\"said\" + 0.009*\"would\"\n",
      "2019-10-29 00:40:07,830 : INFO : topic #8 (0.100): 0.030*\"degree\" + 0.021*\"climate\" + 0.018*\"change\" + 0.016*\"like\" + 0.015*\"world\" + 0.013*\"one\" + 0.012*\"number\" + 0.011*\"know\" + 0.010*\"would\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:40:07,832 : INFO : topic #5 (0.100): 0.037*\"degree\" + 0.024*\"climate\" + 0.018*\"like\" + 0.016*\"number\" + 0.014*\"change\" + 0.014*\"world\" + 0.014*\"one\" + 0.010*\"would\" + 0.010*\"know\" + 0.008*\"said\"\n",
      "2019-10-29 00:40:07,835 : INFO : topic diff=0.854821, rho=1.000000\n",
      "2019-10-29 00:40:08,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:08,253 : INFO : built Dictionary(264 unique tokens: ['although', 'incentivize', 'energy', 'swallow', 'end']...) from 5 documents (total 2205 corpus positions)\n",
      "2019-10-29 00:40:08,258 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:08,261 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:08,264 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:08,268 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:08,271 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:08,362 : INFO : -7.501 per-word bound, 181.1 perplexity estimate based on a held-out corpus of 5 documents with 2205 words\n",
      "2019-10-29 00:40:08,363 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:08,369 : INFO : topic #2 (0.100): 0.020*\"insurance\" + 0.016*\"could\" + 0.016*\"get\" + 0.015*\"said\" + 0.015*\"care\" + 0.015*\"daniel\" + 0.013*\"condition\" + 0.013*\"health\" + 0.012*\"coverage\" + 0.011*\"bill\"\n",
      "2019-10-29 00:40:08,372 : INFO : topic #8 (0.100): 0.019*\"said\" + 0.018*\"could\" + 0.018*\"daniel\" + 0.018*\"get\" + 0.018*\"insurance\" + 0.017*\"health\" + 0.015*\"care\" + 0.015*\"coverage\" + 0.013*\"bill\" + 0.013*\"family\"\n",
      "2019-10-29 00:40:08,375 : INFO : topic #5 (0.100): 0.024*\"insurance\" + 0.021*\"daniel\" + 0.019*\"could\" + 0.017*\"said\" + 0.016*\"care\" + 0.013*\"coverage\" + 0.012*\"bill\" + 0.012*\"family\" + 0.012*\"year\" + 0.011*\"chronic\"\n",
      "2019-10-29 00:40:08,377 : INFO : topic #7 (0.100): 0.020*\"get\" + 0.020*\"could\" + 0.020*\"insurance\" + 0.019*\"daniel\" + 0.019*\"said\" + 0.018*\"health\" + 0.016*\"care\" + 0.013*\"bill\" + 0.013*\"year\" + 0.012*\"going\"\n",
      "2019-10-29 00:40:08,380 : INFO : topic #6 (0.100): 0.018*\"insurance\" + 0.018*\"could\" + 0.018*\"daniel\" + 0.017*\"care\" + 0.017*\"bill\" + 0.017*\"health\" + 0.015*\"coverage\" + 0.015*\"said\" + 0.013*\"get\" + 0.012*\"condition\"\n",
      "2019-10-29 00:40:08,382 : INFO : topic diff=0.887138, rho=1.000000\n",
      "2019-10-29 00:40:08,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:08,794 : INFO : built Dictionary(76 unique tokens: ['story', 'party', 'victory', 'quits', 'trying']...) from 5 documents (total 540 corpus positions)\n",
      "2019-10-29 00:40:08,795 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:08,796 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:08,797 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:08,800 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:08,801 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:08,836 : INFO : -6.648 per-word bound, 100.3 perplexity estimate based on a held-out corpus of 5 documents with 540 words\n",
      "2019-10-29 00:40:08,840 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:08,848 : INFO : topic #0 (0.100): 0.043*\"election\" + 0.040*\"odinga\" + 0.039*\"kenya\" + 0.033*\"kenyatta\" + 0.028*\"vote\" + 0.028*\"rerun\" + 0.024*\"electoral\" + 0.021*\"leader\" + 0.021*\"said\" + 0.021*\"incumbent\"\n",
      "2019-10-29 00:40:08,852 : INFO : topic #7 (0.100): 0.051*\"odinga\" + 0.041*\"kenyatta\" + 0.038*\"election\" + 0.033*\"vote\" + 0.030*\"rerun\" + 0.022*\"court\" + 0.020*\"opposition\" + 0.020*\"kenya\" + 0.020*\"incumbent\" + 0.019*\"said\"\n",
      "2019-10-29 00:40:08,854 : INFO : topic #8 (0.100): 0.051*\"kenyatta\" + 0.047*\"odinga\" + 0.036*\"kenya\" + 0.036*\"election\" + 0.022*\"claimed\" + 0.021*\"vote\" + 0.021*\"president\" + 0.020*\"rerun\" + 0.020*\"uhuru\" + 0.020*\"announced\"\n",
      "2019-10-29 00:40:08,856 : INFO : topic #5 (0.100): 0.044*\"kenyatta\" + 0.042*\"odinga\" + 0.042*\"election\" + 0.031*\"kenya\" + 0.028*\"rerun\" + 0.026*\"vote\" + 0.020*\"said\" + 0.020*\"uhuru\" + 0.019*\"opposition\" + 0.019*\"incumbent\"\n",
      "2019-10-29 00:40:08,858 : INFO : topic #6 (0.100): 0.049*\"odinga\" + 0.046*\"election\" + 0.042*\"kenyatta\" + 0.025*\"vote\" + 0.024*\"kenya\" + 0.023*\"nairobi\" + 0.023*\"august\" + 0.021*\"rerun\" + 0.021*\"incumbent\" + 0.021*\"said\"\n",
      "2019-10-29 00:40:08,864 : INFO : topic diff=0.773309, rho=1.000000\n",
      "2019-10-29 00:40:09,300 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:09,313 : INFO : built Dictionary(427 unique tokens: ['although', 'portion', 'size', 'surprised', 'francisco']...) from 5 documents (total 3555 corpus positions)\n",
      "2019-10-29 00:40:09,320 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:09,321 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:09,325 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:09,331 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:09,335 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:09,478 : INFO : -7.961 per-word bound, 249.1 perplexity estimate based on a held-out corpus of 5 documents with 3555 words\n",
      "2019-10-29 00:40:09,479 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:09,487 : INFO : topic #1 (0.100): 0.037*\"diet\" + 0.016*\"study\" + 0.014*\"mind\" + 0.012*\"followed\" + 0.011*\"food\" + 0.011*\"risk\" + 0.010*\"said\" + 0.010*\"mediterranean\" + 0.009*\"brain\" + 0.009*\"cognitive\"\n",
      "2019-10-29 00:40:09,490 : INFO : topic #9 (0.100): 0.041*\"diet\" + 0.015*\"food\" + 0.012*\"study\" + 0.011*\"followed\" + 0.011*\"mediterranean\" + 0.010*\"mind\" + 0.010*\"cognitive\" + 0.009*\"said\" + 0.009*\"risk\" + 0.008*\"serving\"\n",
      "2019-10-29 00:40:09,492 : INFO : topic #5 (0.100): 0.031*\"diet\" + 0.016*\"mind\" + 0.016*\"food\" + 0.015*\"risk\" + 0.013*\"study\" + 0.011*\"said\" + 0.011*\"cognitive\" + 0.010*\"serving\" + 0.010*\"mediterranean\" + 0.009*\"brain\"\n",
      "2019-10-29 00:40:09,494 : INFO : topic #8 (0.100): 0.026*\"diet\" + 0.014*\"risk\" + 0.013*\"food\" + 0.012*\"mediterranean\" + 0.011*\"mind\" + 0.011*\"brain\" + 0.011*\"study\" + 0.010*\"serving\" + 0.010*\"cognitive\" + 0.009*\"mcevoy\"\n",
      "2019-10-29 00:40:09,495 : INFO : topic #0 (0.100): 0.033*\"diet\" + 0.016*\"study\" + 0.015*\"mediterranean\" + 0.013*\"said\" + 0.012*\"risk\" + 0.012*\"followed\" + 0.011*\"mind\" + 0.010*\"cognitive\" + 0.010*\"serving\" + 0.010*\"food\"\n",
      "2019-10-29 00:40:09,497 : INFO : topic diff=0.880130, rho=1.000000\n",
      "2019-10-29 00:40:09,999 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:10,002 : INFO : built Dictionary(167 unique tokens: ['bombshell', 'forward', 'story', 'shared', 'weinstein']...) from 5 documents (total 1405 corpus positions)\n",
      "2019-10-29 00:40:10,006 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:10,009 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:10,013 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:10,017 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:10,020 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:10,135 : INFO : -7.059 per-word bound, 133.4 perplexity estimate based on a held-out corpus of 5 documents with 1405 words\n",
      "2019-10-29 00:40:10,137 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:10,145 : INFO : topic #1 (0.100): 0.053*\"weinstein\" + 0.043*\"paltrow\" + 0.038*\"time\" + 0.025*\"woman\" + 0.024*\"told\" + 0.023*\"jolie\" + 0.020*\"cnn\" + 0.020*\"pitt\" + 0.017*\"new\" + 0.016*\"said\"\n",
      "2019-10-29 00:40:10,148 : INFO : topic #5 (0.100): 0.060*\"weinstein\" + 0.043*\"paltrow\" + 0.035*\"time\" + 0.024*\"told\" + 0.022*\"woman\" + 0.020*\"jolie\" + 0.017*\"cnn\" + 0.016*\"said\" + 0.015*\"allegation\" + 0.013*\"pitt\"\n",
      "2019-10-29 00:40:10,150 : INFO : topic #2 (0.100): 0.072*\"weinstein\" + 0.037*\"time\" + 0.033*\"paltrow\" + 0.027*\"told\" + 0.025*\"jolie\" + 0.023*\"woman\" + 0.022*\"cnn\" + 0.017*\"new\" + 0.017*\"said\" + 0.015*\"allegation\"\n",
      "2019-10-29 00:40:10,153 : INFO : topic #7 (0.100): 0.061*\"weinstein\" + 0.036*\"time\" + 0.032*\"paltrow\" + 0.026*\"jolie\" + 0.025*\"woman\" + 0.025*\"told\" + 0.021*\"cnn\" + 0.019*\"said\" + 0.018*\"new\" + 0.016*\"allegation\"\n",
      "2019-10-29 00:40:10,156 : INFO : topic #6 (0.100): 0.046*\"weinstein\" + 0.035*\"paltrow\" + 0.032*\"time\" + 0.030*\"told\" + 0.023*\"woman\" + 0.021*\"cnn\" + 0.020*\"said\" + 0.020*\"jolie\" + 0.017*\"york\" + 0.017*\"new\"\n",
      "2019-10-29 00:40:10,158 : INFO : topic diff=0.892871, rho=1.000000\n",
      "2019-10-29 00:40:10,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:10,732 : INFO : built Dictionary(628 unique tokens: ['although', 'anniversary', 'catholic', 'bone', 'happy']...) from 5 documents (total 5165 corpus positions)\n",
      "2019-10-29 00:40:10,742 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:10,745 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:10,748 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:10,752 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:10,755 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:11,019 : INFO : -8.351 per-word bound, 326.5 perplexity estimate based on a held-out corpus of 5 documents with 5165 words\n",
      "2019-10-29 00:40:11,021 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:11,030 : INFO : topic #4 (0.100): 0.018*\"jew\" + 0.010*\"warsaw\" + 0.009*\"one\" + 0.009*\"jewish\" + 0.008*\"ghetto\" + 0.008*\"polish\" + 0.008*\"nazi\" + 0.008*\"radom\" + 0.008*\"history\" + 0.008*\"father\"\n",
      "2019-10-29 00:40:11,032 : INFO : topic #6 (0.100): 0.015*\"jew\" + 0.012*\"u\" + 0.011*\"radom\" + 0.010*\"father\" + 0.009*\"auschwitz\" + 0.008*\"family\" + 0.008*\"ghetto\" + 0.008*\"warsaw\" + 0.008*\"jewish\" + 0.007*\"nazi\"\n",
      "2019-10-29 00:40:11,034 : INFO : topic #0 (0.100): 0.014*\"u\" + 0.012*\"jew\" + 0.010*\"radom\" + 0.009*\"warsaw\" + 0.009*\"jewish\" + 0.008*\"mother\" + 0.008*\"father\" + 0.008*\"family\" + 0.007*\"survivor\" + 0.007*\"ghetto\"\n",
      "2019-10-29 00:40:11,037 : INFO : topic #9 (0.100): 0.013*\"warsaw\" + 0.011*\"jew\" + 0.010*\"family\" + 0.009*\"jewish\" + 0.008*\"ghetto\" + 0.008*\"radom\" + 0.007*\"father\" + 0.007*\"many\" + 0.007*\"u\" + 0.007*\"polish\"\n",
      "2019-10-29 00:40:11,040 : INFO : topic #3 (0.100): 0.016*\"jew\" + 0.010*\"warsaw\" + 0.009*\"many\" + 0.009*\"family\" + 0.009*\"jewish\" + 0.008*\"father\" + 0.008*\"radom\" + 0.008*\"auschwitz\" + 0.007*\"history\" + 0.007*\"ghetto\"\n",
      "2019-10-29 00:40:11,042 : INFO : topic diff=0.861727, rho=1.000000\n",
      "2019-10-29 00:40:11,442 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:11,444 : INFO : built Dictionary(135 unique tokens: ['extensive', 'sorry', 'weinstein', 'consensual', 'interview']...) from 5 documents (total 1000 corpus positions)\n",
      "2019-10-29 00:40:11,446 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:11,450 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:11,453 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:11,456 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:11,460 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:11,520 : INFO : -7.067 per-word bound, 134.1 perplexity estimate based on a held-out corpus of 5 documents with 1000 words\n",
      "2019-10-29 00:40:11,522 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:11,528 : INFO : topic #3 (0.100): 0.049*\"weinstein\" + 0.036*\"damon\" + 0.025*\"cnn\" + 0.019*\"story\" + 0.019*\"allegation\" + 0.019*\"tuesday\" + 0.017*\"interview\" + 0.016*\"time\" + 0.015*\"new\" + 0.013*\"report\"\n",
      "2019-10-29 00:40:11,530 : INFO : topic #1 (0.100): 0.057*\"weinstein\" + 0.028*\"damon\" + 0.026*\"cnn\" + 0.021*\"allegation\" + 0.017*\"story\" + 0.016*\"tuesday\" + 0.015*\"interview\" + 0.014*\"harvey\" + 0.014*\"time\" + 0.014*\"woman\"\n",
      "2019-10-29 00:40:11,533 : INFO : topic #2 (0.100): 0.045*\"weinstein\" + 0.033*\"damon\" + 0.020*\"story\" + 0.020*\"allegation\" + 0.019*\"cnn\" + 0.018*\"interview\" + 0.017*\"tuesday\" + 0.014*\"time\" + 0.014*\"report\" + 0.014*\"harvey\"\n",
      "2019-10-29 00:40:11,535 : INFO : topic #6 (0.100): 0.038*\"weinstein\" + 0.032*\"damon\" + 0.025*\"cnn\" + 0.021*\"tuesday\" + 0.020*\"interview\" + 0.018*\"harvey\" + 0.017*\"story\" + 0.016*\"allegation\" + 0.015*\"report\" + 0.014*\"time\"\n",
      "2019-10-29 00:40:11,538 : INFO : topic #7 (0.100): 0.045*\"weinstein\" + 0.035*\"damon\" + 0.023*\"interview\" + 0.021*\"tuesday\" + 0.020*\"cnn\" + 0.018*\"story\" + 0.016*\"new\" + 0.016*\"report\" + 0.015*\"allegation\" + 0.015*\"woman\"\n",
      "2019-10-29 00:40:11,541 : INFO : topic diff=0.792145, rho=1.000000\n",
      "2019-10-29 00:40:11,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:11,947 : INFO : built Dictionary(76 unique tokens: ['started', 'may', 'bonath', 'night', 'checking']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:40:11,949 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:11,950 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:11,951 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:11,955 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:11,957 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:11,995 : INFO : -6.476 per-word bound, 89.0 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:40:11,999 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:12,004 : INFO : topic #2 (0.100): 0.064*\"officer\" + 0.052*\"texas\" + 0.040*\"police\" + 0.033*\"campus\" + 0.029*\"said\" + 0.029*\"east\" + 0.026*\"tech\" + 0.024*\"floyd\" + 0.022*\"shot\" + 0.022*\"jr\"\n",
      "2019-10-29 00:40:12,005 : INFO : topic #1 (0.100): 0.049*\"officer\" + 0.043*\"police\" + 0.033*\"campus\" + 0.032*\"texas\" + 0.031*\"said\" + 0.030*\"tech\" + 0.024*\"jr\" + 0.024*\"night\" + 0.023*\"east\" + 0.022*\"floyd\"\n",
      "2019-10-29 00:40:12,007 : INFO : topic #3 (0.100): 0.044*\"officer\" + 0.034*\"tech\" + 0.033*\"police\" + 0.031*\"east\" + 0.031*\"campus\" + 0.030*\"said\" + 0.026*\"night\" + 0.025*\"shot\" + 0.025*\"floyd\" + 0.023*\"jr\"\n",
      "2019-10-29 00:40:12,009 : INFO : topic #7 (0.100): 0.056*\"officer\" + 0.040*\"police\" + 0.038*\"east\" + 0.033*\"texas\" + 0.029*\"tech\" + 0.028*\"said\" + 0.027*\"shot\" + 0.026*\"campus\" + 0.024*\"floyd\" + 0.023*\"night\"\n",
      "2019-10-29 00:40:12,011 : INFO : topic #8 (0.100): 0.050*\"officer\" + 0.047*\"texas\" + 0.040*\"tech\" + 0.038*\"east\" + 0.034*\"police\" + 0.031*\"said\" + 0.025*\"shot\" + 0.025*\"floyd\" + 0.024*\"night\" + 0.022*\"jr\"\n",
      "2019-10-29 00:40:12,012 : INFO : topic diff=0.855576, rho=1.000000\n",
      "2019-10-29 00:40:12,434 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:12,440 : INFO : built Dictionary(332 unique tokens: ['although', 'concern', 'energy', 'small', 'catalonia']...) from 5 documents (total 2360 corpus positions)\n",
      "2019-10-29 00:40:12,444 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:12,445 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:12,447 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:12,450 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:12,451 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:12,571 : INFO : -7.956 per-word bound, 248.3 perplexity estimate based on a held-out corpus of 5 documents with 2360 words\n",
      "2019-10-29 00:40:12,572 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:12,580 : INFO : topic #3 (0.100): 0.014*\"weinstein\" + 0.013*\"election\" + 0.013*\"anthem\" + 0.012*\"independence\" + 0.009*\"replay\" + 0.009*\"said\" + 0.009*\"video\" + 0.009*\"owner\" + 0.009*\"watched\" + 0.008*\"talk\"\n",
      "2019-10-29 00:40:12,582 : INFO : topic #7 (0.100): 0.013*\"anthem\" + 0.012*\"people\" + 0.010*\"nfl\" + 0.010*\"must\" + 0.010*\"weinstein\" + 0.009*\"said\" + 0.009*\"owner\" + 0.009*\"independence\" + 0.008*\"election\" + 0.008*\"video\"\n",
      "2019-10-29 00:40:12,585 : INFO : topic #0 (0.100): 0.014*\"anthem\" + 0.013*\"election\" + 0.013*\"people\" + 0.012*\"weinstein\" + 0.011*\"nfl\" + 0.010*\"independence\" + 0.009*\"said\" + 0.008*\"must\" + 0.008*\"say\" + 0.008*\"video\"\n",
      "2019-10-29 00:40:12,587 : INFO : topic #5 (0.100): 0.013*\"weinstein\" + 0.013*\"anthem\" + 0.011*\"people\" + 0.010*\"election\" + 0.010*\"said\" + 0.009*\"nfl\" + 0.009*\"independence\" + 0.009*\"talk\" + 0.008*\"owner\" + 0.008*\"must\"\n",
      "2019-10-29 00:40:12,589 : INFO : topic #4 (0.100): 0.014*\"anthem\" + 0.013*\"nfl\" + 0.012*\"said\" + 0.010*\"weinstein\" + 0.010*\"independence\" + 0.010*\"watch\" + 0.009*\"election\" + 0.009*\"must\" + 0.009*\"watched\" + 0.008*\"owner\"\n",
      "2019-10-29 00:40:12,591 : INFO : topic diff=0.768501, rho=1.000000\n",
      "2019-10-29 00:40:13,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:13,150 : INFO : built Dictionary(1082 unique tokens: ['let', 'wave', 'wanting', 'florida', 'spot']...) from 5 documents (total 11960 corpus positions)\n",
      "2019-10-29 00:40:13,163 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:13,164 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:13,169 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:13,176 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:13,178 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:13,495 : INFO : -8.534 per-word bound, 370.7 perplexity estimate based on a held-out corpus of 5 documents with 11960 words\n",
      "2019-10-29 00:40:13,497 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:13,511 : INFO : topic #0 (0.100): 0.029*\"say\" + 0.012*\"county\" + 0.011*\"obamacare\" + 0.011*\"one\" + 0.009*\"people\" + 0.008*\"like\" + 0.007*\"year\" + 0.007*\"white\" + 0.007*\"grant\" + 0.006*\"care\"\n",
      "2019-10-29 00:40:13,512 : INFO : topic #5 (0.100): 0.019*\"say\" + 0.012*\"people\" + 0.010*\"one\" + 0.010*\"county\" + 0.009*\"grant\" + 0.009*\"hyannis\" + 0.007*\"obamacare\" + 0.007*\"care\" + 0.007*\"insurance\" + 0.006*\"could\"\n",
      "2019-10-29 00:40:13,514 : INFO : topic #6 (0.100): 0.019*\"say\" + 0.017*\"county\" + 0.013*\"people\" + 0.010*\"one\" + 0.008*\"grant\" + 0.008*\"obamacare\" + 0.008*\"hyannis\" + 0.007*\"like\" + 0.007*\"month\" + 0.006*\"care\"\n",
      "2019-10-29 00:40:13,515 : INFO : topic #8 (0.100): 0.019*\"say\" + 0.013*\"county\" + 0.010*\"one\" + 0.009*\"obamacare\" + 0.008*\"people\" + 0.007*\"like\" + 0.007*\"grant\" + 0.006*\"care\" + 0.006*\"hyannis\" + 0.006*\"year\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:13,517 : INFO : topic #7 (0.100): 0.018*\"say\" + 0.017*\"county\" + 0.013*\"people\" + 0.009*\"one\" + 0.009*\"obamacare\" + 0.008*\"hyannis\" + 0.008*\"year\" + 0.007*\"grant\" + 0.007*\"like\" + 0.007*\"care\"\n",
      "2019-10-29 00:40:13,519 : INFO : topic diff=0.959329, rho=1.000000\n",
      "2019-10-29 00:40:13,939 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:13,943 : INFO : built Dictionary(206 unique tokens: ['school', 'come', 'consensus', 'electronic', 'trying']...) from 5 documents (total 1825 corpus positions)\n",
      "2019-10-29 00:40:13,948 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:13,949 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:13,950 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:13,956 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:13,959 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:14,048 : INFO : -7.181 per-word bound, 145.1 perplexity estimate based on a held-out corpus of 5 documents with 1825 words\n",
      "2019-10-29 00:40:14,049 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:14,056 : INFO : topic #2 (0.100): 0.046*\"start\" + 0.036*\"school\" + 0.036*\"time\" + 0.032*\"said\" + 0.024*\"later\" + 0.019*\"parent\" + 0.015*\"get\" + 0.014*\"want\" + 0.014*\"san\" + 0.013*\"board\"\n",
      "2019-10-29 00:40:14,057 : INFO : topic #7 (0.100): 0.034*\"school\" + 0.030*\"time\" + 0.030*\"later\" + 0.029*\"start\" + 0.021*\"said\" + 0.019*\"diego\" + 0.017*\"parent\" + 0.016*\"sleep\" + 0.016*\"san\" + 0.014*\"kid\"\n",
      "2019-10-29 00:40:14,059 : INFO : topic #9 (0.100): 0.044*\"school\" + 0.039*\"start\" + 0.032*\"time\" + 0.025*\"said\" + 0.023*\"later\" + 0.016*\"get\" + 0.015*\"sleep\" + 0.014*\"parent\" + 0.014*\"kid\" + 0.011*\"middle\"\n",
      "2019-10-29 00:40:14,061 : INFO : topic #3 (0.100): 0.041*\"school\" + 0.041*\"start\" + 0.031*\"time\" + 0.030*\"said\" + 0.027*\"later\" + 0.015*\"get\" + 0.015*\"sleep\" + 0.014*\"parent\" + 0.013*\"kid\" + 0.013*\"san\"\n",
      "2019-10-29 00:40:14,062 : INFO : topic #4 (0.100): 0.050*\"start\" + 0.035*\"school\" + 0.025*\"time\" + 0.023*\"said\" + 0.023*\"later\" + 0.018*\"sleep\" + 0.016*\"parent\" + 0.014*\"night\" + 0.014*\"san\" + 0.011*\"student\"\n",
      "2019-10-29 00:40:14,064 : INFO : topic diff=0.918641, rho=1.000000\n",
      "2019-10-29 00:40:14,487 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:14,493 : INFO : built Dictionary(321 unique tokens: ['rage', 'let', 'school', 'method', 'caution']...) from 5 documents (total 2595 corpus positions)\n",
      "2019-10-29 00:40:14,497 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:14,498 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:14,504 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:14,508 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:14,511 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:14,631 : INFO : -7.734 per-word bound, 212.8 perplexity estimate based on a held-out corpus of 5 documents with 2595 words\n",
      "2019-10-29 00:40:14,632 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:14,640 : INFO : topic #6 (0.100): 0.046*\"game\" + 0.038*\"video\" + 0.031*\"violent\" + 0.016*\"violence\" + 0.012*\"behavior\" + 0.012*\"said\" + 0.012*\"child\" + 0.010*\"american\" + 0.010*\"study\" + 0.010*\"playing\"\n",
      "2019-10-29 00:40:14,643 : INFO : topic #7 (0.100): 0.046*\"game\" + 0.034*\"video\" + 0.026*\"violent\" + 0.018*\"violence\" + 0.011*\"behavior\" + 0.011*\"playing\" + 0.010*\"psychological\" + 0.009*\"said\" + 0.009*\"american\" + 0.009*\"may\"\n",
      "2019-10-29 00:40:14,645 : INFO : topic #4 (0.100): 0.042*\"game\" + 0.035*\"video\" + 0.023*\"violent\" + 0.015*\"playing\" + 0.014*\"violence\" + 0.012*\"american\" + 0.011*\"academy\" + 0.011*\"may\" + 0.010*\"said\" + 0.010*\"behavior\"\n",
      "2019-10-29 00:40:14,648 : INFO : topic #8 (0.100): 0.052*\"game\" + 0.027*\"video\" + 0.026*\"violent\" + 0.016*\"violence\" + 0.014*\"playing\" + 0.012*\"american\" + 0.010*\"said\" + 0.009*\"academy\" + 0.009*\"behavior\" + 0.009*\"psychological\"\n",
      "2019-10-29 00:40:14,650 : INFO : topic #1 (0.100): 0.043*\"video\" + 0.042*\"game\" + 0.033*\"violent\" + 0.015*\"violence\" + 0.013*\"playing\" + 0.012*\"said\" + 0.011*\"behavior\" + 0.010*\"american\" + 0.010*\"psychological\" + 0.009*\"study\"\n",
      "2019-10-29 00:40:14,652 : INFO : topic diff=0.847887, rho=1.000000\n",
      "2019-10-29 00:40:15,129 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:15,136 : INFO : built Dictionary(461 unique tokens: ['josh', 'energy', 'wave', 'deep', 'francisco']...) from 5 documents (total 4750 corpus positions)\n",
      "2019-10-29 00:40:15,143 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:15,144 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:15,146 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:15,150 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:15,151 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:15,289 : INFO : -7.755 per-word bound, 216.1 perplexity estimate based on a held-out corpus of 5 documents with 4750 words\n",
      "2019-10-29 00:40:15,291 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:15,298 : INFO : topic #1 (0.100): 0.065*\"photo\" + 0.037*\"caption\" + 0.031*\"amazing\" + 0.028*\"hide\" + 0.027*\"shot\" + 0.026*\"october\" + 0.025*\"sport\" + 0.014*\"sunday\" + 0.008*\"new\" + 0.008*\"game\"\n",
      "2019-10-29 00:40:15,301 : INFO : topic #7 (0.100): 0.071*\"photo\" + 0.041*\"amazing\" + 0.034*\"caption\" + 0.032*\"shot\" + 0.031*\"sport\" + 0.029*\"october\" + 0.024*\"hide\" + 0.012*\"sunday\" + 0.008*\"new\" + 0.008*\"yankee\"\n",
      "2019-10-29 00:40:15,303 : INFO : topic #0 (0.100): 0.078*\"photo\" + 0.040*\"amazing\" + 0.038*\"sport\" + 0.032*\"hide\" + 0.032*\"caption\" + 0.030*\"october\" + 0.028*\"shot\" + 0.014*\"sunday\" + 0.009*\"game\" + 0.009*\"saturday\"\n",
      "2019-10-29 00:40:15,305 : INFO : topic #9 (0.100): 0.058*\"photo\" + 0.048*\"shot\" + 0.044*\"hide\" + 0.035*\"sport\" + 0.035*\"october\" + 0.032*\"amazing\" + 0.027*\"caption\" + 0.012*\"sunday\" + 0.008*\"saturday\" + 0.008*\"yankee\"\n",
      "2019-10-29 00:40:15,308 : INFO : topic #2 (0.100): 0.081*\"photo\" + 0.042*\"sport\" + 0.039*\"caption\" + 0.032*\"hide\" + 0.032*\"october\" + 0.031*\"shot\" + 0.029*\"amazing\" + 0.010*\"sunday\" + 0.008*\"saturday\" + 0.008*\"series\"\n",
      "2019-10-29 00:40:15,310 : INFO : topic diff=1.031438, rho=1.000000\n",
      "2019-10-29 00:40:15,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:15,696 : INFO : built Dictionary(40 unique tokens: ['considered', 'myanmar', 'rakhine', 'nation', 'week']...) from 5 documents (total 220 corpus positions)\n",
      "2019-10-29 00:40:15,698 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:15,699 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:15,700 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:15,702 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:15,703 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:15,725 : INFO : -6.690 per-word bound, 103.3 perplexity estimate based on a held-out corpus of 5 documents with 220 words\n",
      "2019-10-29 00:40:15,726 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:15,734 : INFO : topic #5 (0.100): 0.059*\"rohingya\" + 0.049*\"bangladesh\" + 0.038*\"myanmar\" + 0.027*\"according\" + 0.026*\"son\" + 0.026*\"people\" + 0.026*\"photo\" + 0.026*\"government\" + 0.025*\"rakhine\" + 0.025*\"september\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:15,735 : INFO : topic #2 (0.100): 0.073*\"rohingya\" + 0.049*\"myanmar\" + 0.043*\"bangladesh\" + 0.029*\"muslim\" + 0.029*\"group\" + 0.027*\"refugee\" + 0.027*\"fleeing\" + 0.027*\"abdul\" + 0.026*\"august\" + 0.026*\"son\"\n",
      "2019-10-29 00:40:15,736 : INFO : topic #0 (0.100): 0.050*\"myanmar\" + 0.047*\"rohingya\" + 0.044*\"bangladesh\" + 0.030*\"photo\" + 0.028*\"masood\" + 0.028*\"state\" + 0.028*\"nation\" + 0.027*\"people\" + 0.027*\"united\" + 0.027*\"right\"\n",
      "2019-10-29 00:40:15,738 : INFO : topic #1 (0.100): 0.068*\"rohingya\" + 0.042*\"myanmar\" + 0.039*\"bangladesh\" + 0.029*\"fled\" + 0.029*\"united\" + 0.028*\"died\" + 0.028*\"recognized\" + 0.027*\"since\" + 0.026*\"world\" + 0.025*\"citizen\"\n",
      "2019-10-29 00:40:15,739 : INFO : topic #3 (0.100): 0.066*\"rohingya\" + 0.041*\"bangladesh\" + 0.039*\"myanmar\" + 0.028*\"rakhine\" + 0.028*\"wednesday\" + 0.027*\"boat\" + 0.026*\"human\" + 0.026*\"citizen\" + 0.026*\"live\" + 0.025*\"august\"\n",
      "2019-10-29 00:40:15,740 : INFO : topic diff=0.610699, rho=1.000000\n",
      "2019-10-29 00:40:16,187 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:16,192 : INFO : built Dictionary(183 unique tokens: ['forward', 'seriously', 'proud', 'eventful', 'salary']...) from 5 documents (total 1270 corpus positions)\n",
      "2019-10-29 00:40:16,194 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:16,196 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:16,198 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:16,201 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:16,203 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:16,296 : INFO : -7.447 per-word bound, 174.5 perplexity estimate based on a held-out corpus of 5 documents with 1270 words\n",
      "2019-10-29 00:40:16,297 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:16,306 : INFO : topic #4 (0.100): 0.036*\"bbc\" + 0.029*\"news\" + 0.026*\"harding\" + 0.015*\"said\" + 0.014*\"year\" + 0.014*\"memo\" + 0.013*\"world\" + 0.012*\"gap\" + 0.012*\"new\" + 0.011*\"current\"\n",
      "2019-10-29 00:40:16,309 : INFO : topic #6 (0.100): 0.055*\"bbc\" + 0.035*\"harding\" + 0.033*\"news\" + 0.016*\"gap\" + 0.013*\"current\" + 0.013*\"said\" + 0.013*\"year\" + 0.012*\"role\" + 0.011*\"time\" + 0.011*\"world\"\n",
      "2019-10-29 00:40:16,312 : INFO : topic #1 (0.100): 0.033*\"bbc\" + 0.026*\"news\" + 0.021*\"harding\" + 0.017*\"journalism\" + 0.016*\"gap\" + 0.014*\"year\" + 0.012*\"said\" + 0.012*\"job\" + 0.012*\"new\" + 0.012*\"memo\"\n",
      "2019-10-29 00:40:16,314 : INFO : topic #9 (0.100): 0.048*\"bbc\" + 0.029*\"harding\" + 0.025*\"news\" + 0.015*\"new\" + 0.014*\"gap\" + 0.014*\"said\" + 0.013*\"journalism\" + 0.012*\"current\" + 0.012*\"memo\" + 0.012*\"year\"\n",
      "2019-10-29 00:40:16,317 : INFO : topic #7 (0.100): 0.041*\"bbc\" + 0.023*\"news\" + 0.022*\"harding\" + 0.018*\"year\" + 0.017*\"said\" + 0.013*\"current\" + 0.011*\"role\" + 0.011*\"world\" + 0.011*\"time\" + 0.011*\"job\"\n",
      "2019-10-29 00:40:16,319 : INFO : topic diff=0.790230, rho=1.000000\n",
      "2019-10-29 00:40:16,767 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:16,772 : INFO : built Dictionary(340 unique tokens: ['energy', 'transition', 'end', 'industry', 'come']...) from 5 documents (total 2780 corpus positions)\n",
      "2019-10-29 00:40:16,776 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:16,777 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:16,779 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:16,784 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:16,786 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:16,903 : INFO : -7.768 per-word bound, 217.9 perplexity estimate based on a held-out corpus of 5 documents with 2780 words\n",
      "2019-10-29 00:40:16,905 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:16,912 : INFO : topic #8 (0.100): 0.044*\"energy\" + 0.026*\"morocco\" + 0.021*\"country\" + 0.016*\"percent\" + 0.015*\"billion\" + 0.014*\"world\" + 0.011*\"solar\" + 0.011*\"one\" + 0.009*\"climate\" + 0.009*\"change\"\n",
      "2019-10-29 00:40:16,914 : INFO : topic #4 (0.100): 0.034*\"energy\" + 0.028*\"country\" + 0.019*\"morocco\" + 0.019*\"percent\" + 0.012*\"billion\" + 0.012*\"world\" + 0.011*\"climate\" + 0.011*\"water\" + 0.010*\"efficiency\" + 0.009*\"solar\"\n",
      "2019-10-29 00:40:16,917 : INFO : topic #0 (0.100): 0.031*\"energy\" + 0.030*\"morocco\" + 0.024*\"country\" + 0.014*\"billion\" + 0.014*\"percent\" + 0.012*\"efficiency\" + 0.011*\"solar\" + 0.010*\"world\" + 0.010*\"according\" + 0.009*\"million\"\n",
      "2019-10-29 00:40:16,919 : INFO : topic #7 (0.100): 0.031*\"energy\" + 0.020*\"morocco\" + 0.018*\"country\" + 0.015*\"percent\" + 0.014*\"world\" + 0.013*\"solar\" + 0.011*\"efficiency\" + 0.010*\"water\" + 0.010*\"billion\" + 0.009*\"according\"\n",
      "2019-10-29 00:40:16,921 : INFO : topic #1 (0.100): 0.048*\"energy\" + 0.025*\"morocco\" + 0.021*\"country\" + 0.017*\"percent\" + 0.014*\"billion\" + 0.011*\"world\" + 0.010*\"solar\" + 0.010*\"said\" + 0.009*\"one\" + 0.009*\"according\"\n",
      "2019-10-29 00:40:16,923 : INFO : topic diff=0.860750, rho=1.000000\n",
      "2019-10-29 00:40:17,327 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:17,328 : INFO : built Dictionary(21 unique tokens: ['short', 'cancer', 'fill', 'please', 'minute']...) from 5 documents (total 110 corpus positions)\n",
      "2019-10-29 00:40:17,330 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:17,332 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:17,334 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:17,337 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:17,338 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:17,359 : INFO : -6.451 per-word bound, 87.5 perplexity estimate based on a held-out corpus of 5 documents with 110 words\n",
      "2019-10-29 00:40:17,362 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:17,368 : INFO : topic #1 (0.100): 0.084*\"survey\" + 0.059*\"minute\" + 0.053*\"anonymous\" + 0.052*\"short\" + 0.051*\"head\" + 0.050*\"opinion\" + 0.049*\"end\" + 0.048*\"fill\" + 0.048*\"appear\" + 0.047*\"visit\"\n",
      "2019-10-29 00:40:17,370 : INFO : topic #5 (0.100): 0.089*\"survey\" + 0.054*\"immunotherapy\" + 0.053*\"cancer\" + 0.053*\"end\" + 0.052*\"learning\" + 0.050*\"visit\" + 0.050*\"minute\" + 0.049*\"please\" + 0.048*\"personally\" + 0.048*\"linked\"\n",
      "2019-10-29 00:40:17,373 : INFO : topic #4 (0.100): 0.073*\"survey\" + 0.058*\"fill\" + 0.054*\"answer\" + 0.054*\"cancer\" + 0.052*\"linked\" + 0.051*\"neck\" + 0.049*\"matter\" + 0.049*\"immunotherapy\" + 0.046*\"learning\" + 0.046*\"opinion\"\n",
      "2019-10-29 00:40:17,376 : INFO : topic #6 (0.100): 0.092*\"survey\" + 0.056*\"learning\" + 0.054*\"short\" + 0.052*\"appear\" + 0.051*\"anonymous\" + 0.049*\"neck\" + 0.048*\"personally\" + 0.047*\"opinion\" + 0.047*\"fill\" + 0.047*\"answer\"\n",
      "2019-10-29 00:40:17,378 : INFO : topic #2 (0.100): 0.067*\"survey\" + 0.058*\"neck\" + 0.055*\"visit\" + 0.054*\"end\" + 0.053*\"cancer\" + 0.053*\"immunotherapy\" + 0.051*\"advance\" + 0.050*\"minute\" + 0.049*\"head\" + 0.048*\"short\"\n",
      "2019-10-29 00:40:17,381 : INFO : topic diff=0.552168, rho=1.000000\n",
      "2019-10-29 00:40:17,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:17,812 : INFO : built Dictionary(276 unique tokens: ['wave', 'party', 'come', 'democrat', 'caucus']...) from 5 documents (total 2380 corpus positions)\n",
      "2019-10-29 00:40:17,816 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:17,820 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:17,823 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:17,827 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:17,830 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:17,927 : INFO : -7.498 per-word bound, 180.8 perplexity estimate based on a held-out corpus of 5 documents with 2380 words\n",
      "2019-10-29 00:40:17,928 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:17,935 : INFO : topic #5 (0.100): 0.030*\"year\" + 0.027*\"democrat\" + 0.023*\"democratic\" + 0.022*\"old\" + 0.018*\"leader\" + 0.018*\"average\" + 0.016*\"party\" + 0.016*\"republican\" + 0.015*\"house\" + 0.011*\"think\"\n",
      "2019-10-29 00:40:17,938 : INFO : topic #0 (0.100): 0.034*\"democrat\" + 0.024*\"year\" + 0.023*\"democratic\" + 0.022*\"party\" + 0.021*\"old\" + 0.018*\"leader\" + 0.017*\"average\" + 0.015*\"house\" + 0.011*\"top\" + 0.010*\"voter\"\n",
      "2019-10-29 00:40:17,940 : INFO : topic #8 (0.100): 0.033*\"democrat\" + 0.028*\"old\" + 0.025*\"year\" + 0.022*\"average\" + 0.020*\"democratic\" + 0.020*\"party\" + 0.012*\"leader\" + 0.011*\"top\" + 0.011*\"republican\" + 0.011*\"house\"\n",
      "2019-10-29 00:40:17,942 : INFO : topic #1 (0.100): 0.035*\"year\" + 0.026*\"old\" + 0.025*\"democrat\" + 0.024*\"democratic\" + 0.018*\"average\" + 0.016*\"party\" + 0.013*\"leader\" + 0.013*\"house\" + 0.012*\"top\" + 0.011*\"republican\"\n",
      "2019-10-29 00:40:17,945 : INFO : topic #4 (0.100): 0.029*\"year\" + 0.025*\"democratic\" + 0.024*\"democrat\" + 0.023*\"old\" + 0.016*\"party\" + 0.016*\"leader\" + 0.013*\"average\" + 0.013*\"republican\" + 0.011*\"house\" + 0.010*\"think\"\n",
      "2019-10-29 00:40:17,948 : INFO : topic diff=0.872375, rho=1.000000\n",
      "2019-10-29 00:40:18,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:18,423 : INFO : built Dictionary(296 unique tokens: ['although', 'offered', 'significant', 'hijab', 'communicates']...) from 5 documents (total 2040 corpus positions)\n",
      "2019-10-29 00:40:18,428 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:18,430 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:18,434 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:18,438 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:18,440 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:18,576 : INFO : -7.902 per-word bound, 239.3 perplexity estimate based on a held-out corpus of 5 documents with 2040 words\n",
      "2019-10-29 00:40:18,578 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:18,587 : INFO : topic #3 (0.100): 0.021*\"item\" + 0.020*\"modern\" + 0.018*\"antonelli\" + 0.015*\"one\" + 0.014*\"garment\" + 0.014*\"exhibition\" + 0.013*\"fashion\" + 0.012*\"design\" + 0.008*\"museum\" + 0.008*\"dress\"\n",
      "2019-10-29 00:40:18,589 : INFO : topic #5 (0.100): 0.023*\"item\" + 0.018*\"fashion\" + 0.018*\"antonelli\" + 0.016*\"modern\" + 0.014*\"exhibition\" + 0.014*\"garment\" + 0.013*\"design\" + 0.013*\"one\" + 0.008*\"museum\" + 0.008*\"shirt\"\n",
      "2019-10-29 00:40:18,590 : INFO : topic #7 (0.100): 0.018*\"fashion\" + 0.017*\"item\" + 0.016*\"antonelli\" + 0.015*\"one\" + 0.014*\"modern\" + 0.014*\"exhibition\" + 0.012*\"garment\" + 0.010*\"design\" + 0.010*\"museum\" + 0.009*\"cap\"\n",
      "2019-10-29 00:40:18,594 : INFO : topic #6 (0.100): 0.020*\"one\" + 0.019*\"modern\" + 0.018*\"fashion\" + 0.018*\"antonelli\" + 0.017*\"item\" + 0.014*\"exhibition\" + 0.013*\"garment\" + 0.011*\"design\" + 0.011*\"museum\" + 0.008*\"black\"\n",
      "2019-10-29 00:40:18,597 : INFO : topic #9 (0.100): 0.022*\"item\" + 0.019*\"antonelli\" + 0.015*\"fashion\" + 0.014*\"one\" + 0.013*\"modern\" + 0.011*\"exhibition\" + 0.011*\"garment\" + 0.010*\"design\" + 0.009*\"example\" + 0.008*\"also\"\n",
      "2019-10-29 00:40:18,600 : INFO : topic diff=0.779720, rho=1.000000\n",
      "2019-10-29 00:40:19,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:19,093 : INFO : built Dictionary(312 unique tokens: ['product', 'campaign', 'maintenance', 'come', 'conjunction']...) from 5 documents (total 2880 corpus positions)\n",
      "2019-10-29 00:40:19,102 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:19,105 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:19,108 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:19,111 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:19,114 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:19,292 : INFO : -7.527 per-word bound, 184.5 perplexity estimate based on a held-out corpus of 5 documents with 2880 words\n",
      "2019-10-29 00:40:19,294 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:19,302 : INFO : topic #7 (0.100): 0.037*\"woman\" + 0.034*\"iud\" + 0.029*\"said\" + 0.027*\"method\" + 0.021*\"implant\" + 0.014*\"pregnancy\" + 0.013*\"effective\" + 0.013*\"birth\" + 0.013*\"care\" + 0.013*\"may\"\n",
      "2019-10-29 00:40:19,304 : INFO : topic #3 (0.100): 0.035*\"said\" + 0.033*\"iud\" + 0.032*\"woman\" + 0.027*\"method\" + 0.026*\"implant\" + 0.019*\"control\" + 0.013*\"may\" + 0.012*\"birth\" + 0.011*\"effective\" + 0.011*\"unplanned\"\n",
      "2019-10-29 00:40:19,306 : INFO : topic #9 (0.100): 0.043*\"said\" + 0.039*\"woman\" + 0.027*\"iud\" + 0.025*\"implant\" + 0.018*\"method\" + 0.013*\"effective\" + 0.013*\"control\" + 0.012*\"birth\" + 0.011*\"pregnancy\" + 0.011*\"health\"\n",
      "2019-10-29 00:40:19,309 : INFO : topic #5 (0.100): 0.039*\"woman\" + 0.032*\"iud\" + 0.024*\"said\" + 0.023*\"method\" + 0.017*\"implant\" + 0.015*\"pregnancy\" + 0.013*\"effective\" + 0.012*\"birth\" + 0.012*\"health\" + 0.011*\"control\"\n",
      "2019-10-29 00:40:19,312 : INFO : topic #8 (0.100): 0.042*\"woman\" + 0.029*\"implant\" + 0.024*\"iud\" + 0.021*\"said\" + 0.020*\"method\" + 0.014*\"pregnancy\" + 0.014*\"may\" + 0.012*\"birth\" + 0.011*\"ehrlich\" + 0.011*\"effective\"\n",
      "2019-10-29 00:40:19,315 : INFO : topic diff=0.944451, rho=1.000000\n",
      "2019-10-29 00:40:19,759 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:19,765 : INFO : built Dictionary(462 unique tokens: ['energy', 'deep', 'school', 'one', 'new']...) from 5 documents (total 3905 corpus positions)\n",
      "2019-10-29 00:40:19,771 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:19,773 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:19,774 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:19,778 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:19,779 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:19,913 : INFO : -8.020 per-word bound, 259.6 perplexity estimate based on a held-out corpus of 5 documents with 3905 words\n",
      "2019-10-29 00:40:19,914 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:19,923 : INFO : topic #3 (0.100): 0.021*\"kellogg\" + 0.017*\"child\" + 0.016*\"power\" + 0.016*\"said\" + 0.016*\"air\" + 0.012*\"asthma\" + 0.011*\"lung\" + 0.010*\"clean\" + 0.010*\"pollution\" + 0.010*\"health\"\n",
      "2019-10-29 00:40:19,925 : INFO : topic #5 (0.100): 0.020*\"power\" + 0.017*\"air\" + 0.017*\"child\" + 0.017*\"kellogg\" + 0.012*\"said\" + 0.012*\"clean\" + 0.012*\"health\" + 0.011*\"asthma\" + 0.011*\"year\" + 0.009*\"plan\"\n",
      "2019-10-29 00:40:19,927 : INFO : topic #1 (0.100): 0.025*\"air\" + 0.018*\"child\" + 0.018*\"kellogg\" + 0.015*\"power\" + 0.013*\"said\" + 0.012*\"health\" + 0.012*\"asthma\" + 0.011*\"pollution\" + 0.010*\"clean\" + 0.009*\"year\"\n",
      "2019-10-29 00:40:19,928 : INFO : topic #9 (0.100): 0.020*\"kellogg\" + 0.018*\"child\" + 0.016*\"power\" + 0.016*\"asthma\" + 0.015*\"health\" + 0.014*\"said\" + 0.012*\"air\" + 0.011*\"clean\" + 0.010*\"year\" + 0.009*\"quality\"\n",
      "2019-10-29 00:40:19,930 : INFO : topic #2 (0.100): 0.021*\"kellogg\" + 0.018*\"child\" + 0.015*\"said\" + 0.014*\"power\" + 0.014*\"asthma\" + 0.013*\"air\" + 0.012*\"clean\" + 0.011*\"health\" + 0.010*\"administration\" + 0.010*\"year\"\n",
      "2019-10-29 00:40:19,934 : INFO : topic diff=0.901651, rho=1.000000\n",
      "2019-10-29 00:40:20,336 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:20,339 : INFO : built Dictionary(153 unique tokens: ['approach', 'story', 'others', 'recruitment', 'failure']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:40:20,341 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:20,343 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:20,344 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:20,347 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:20,348 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:20,415 : INFO : -7.199 per-word bound, 146.9 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:40:20,418 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:20,426 : INFO : topic #4 (0.100): 0.043*\"trump\" + 0.031*\"terrorist\" + 0.028*\"internet\" + 0.020*\"recruitment\" + 0.018*\"militant\" + 0.015*\"group\" + 0.015*\"attack\" + 0.015*\"right\" + 0.014*\"london\" + 0.014*\"also\"\n",
      "2019-10-29 00:40:20,429 : INFO : topic #3 (0.100): 0.040*\"terrorist\" + 0.037*\"internet\" + 0.027*\"trump\" + 0.020*\"militant\" + 0.019*\"group\" + 0.018*\"right\" + 0.018*\"isi\" + 0.015*\"attack\" + 0.015*\"state\" + 0.014*\"united\"\n",
      "2019-10-29 00:40:20,432 : INFO : topic #2 (0.100): 0.041*\"trump\" + 0.033*\"terrorist\" + 0.022*\"internet\" + 0.021*\"militant\" + 0.018*\"isi\" + 0.017*\"america\" + 0.017*\"cut\" + 0.016*\"recruitment\" + 0.015*\"london\" + 0.015*\"right\"\n",
      "2019-10-29 00:40:20,435 : INFO : topic #6 (0.100): 0.038*\"terrorist\" + 0.029*\"trump\" + 0.025*\"internet\" + 0.021*\"militant\" + 0.019*\"group\" + 0.017*\"isi\" + 0.017*\"recruitment\" + 0.015*\"london\" + 0.014*\"right\" + 0.014*\"attack\"\n",
      "2019-10-29 00:40:20,439 : INFO : topic #0 (0.100): 0.037*\"terrorist\" + 0.030*\"trump\" + 0.029*\"internet\" + 0.022*\"militant\" + 0.020*\"right\" + 0.020*\"recruitment\" + 0.017*\"group\" + 0.017*\"state\" + 0.016*\"isi\" + 0.015*\"cut\"\n",
      "2019-10-29 00:40:20,442 : INFO : topic diff=0.834928, rho=1.000000\n",
      "2019-10-29 00:40:20,882 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:20,887 : INFO : built Dictionary(128 unique tokens: ['courtesy', 'fewer', 'end', 'come', 'greatest']...) from 5 documents (total 1070 corpus positions)\n",
      "2019-10-29 00:40:20,891 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:20,894 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:20,895 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:20,898 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:20,899 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:20,970 : INFO : -6.837 per-word bound, 114.3 perplexity estimate based on a held-out corpus of 5 documents with 1070 words\n",
      "2019-10-29 00:40:20,973 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:20,980 : INFO : topic #9 (0.100): 0.043*\"painting\" + 0.034*\"vinci\" + 0.030*\"salvator\" + 0.029*\"one\" + 0.026*\"mundi\" + 0.025*\"christie\" + 0.025*\"da\" + 0.017*\"auction\" + 0.017*\"leonardo\" + 0.015*\"york\"\n",
      "2019-10-29 00:40:20,982 : INFO : topic #5 (0.100): 0.042*\"painting\" + 0.041*\"one\" + 0.030*\"mundi\" + 0.029*\"da\" + 0.025*\"vinci\" + 0.023*\"auction\" + 0.023*\"salvator\" + 0.020*\"christie\" + 0.018*\"new\" + 0.015*\"ever\"\n",
      "2019-10-29 00:40:20,986 : INFO : topic #3 (0.100): 0.048*\"painting\" + 0.026*\"one\" + 0.025*\"auction\" + 0.025*\"da\" + 0.025*\"mundi\" + 0.024*\"salvator\" + 0.023*\"christie\" + 0.022*\"vinci\" + 0.016*\"new\" + 0.015*\"leonardo\"\n",
      "2019-10-29 00:40:20,990 : INFO : topic #2 (0.100): 0.044*\"painting\" + 0.035*\"salvator\" + 0.034*\"one\" + 0.028*\"mundi\" + 0.025*\"vinci\" + 0.024*\"auction\" + 0.023*\"christie\" + 0.018*\"da\" + 0.015*\"million\" + 0.014*\"york\"\n",
      "2019-10-29 00:40:20,993 : INFO : topic #1 (0.100): 0.055*\"painting\" + 0.033*\"one\" + 0.032*\"salvator\" + 0.030*\"mundi\" + 0.029*\"vinci\" + 0.028*\"auction\" + 0.028*\"da\" + 0.023*\"christie\" + 0.014*\"leonardo\" + 0.014*\"million\"\n",
      "2019-10-29 00:40:20,995 : INFO : topic diff=0.844256, rho=1.000000\n",
      "2019-10-29 00:40:21,498 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:21,504 : INFO : built Dictionary(534 unique tokens: ['reclaim', 'residency', 'translated', 'filed', 'reach']...) from 5 documents (total 4775 corpus positions)\n",
      "2019-10-29 00:40:21,511 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:21,512 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:21,513 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:21,518 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:21,520 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:21,673 : INFO : -8.085 per-word bound, 271.5 perplexity estimate based on a held-out corpus of 5 documents with 4775 words\n",
      "2019-10-29 00:40:21,674 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:21,682 : INFO : topic #0 (0.100): 0.030*\"allami\" + 0.030*\"hrebid\" + 0.017*\"say\" + 0.012*\"day\" + 0.009*\"two\" + 0.009*\"refugee\" + 0.009*\"one\" + 0.009*\"year\" + 0.009*\"would\" + 0.009*\"seattle\"\n",
      "2019-10-29 00:40:21,684 : INFO : topic #3 (0.100): 0.030*\"allami\" + 0.030*\"hrebid\" + 0.015*\"say\" + 0.010*\"new\" + 0.010*\"day\" + 0.010*\"year\" + 0.009*\"refugee\" + 0.009*\"u\" + 0.009*\"seattle\" + 0.008*\"would\"\n",
      "2019-10-29 00:40:21,686 : INFO : topic #7 (0.100): 0.031*\"hrebid\" + 0.023*\"allami\" + 0.012*\"night\" + 0.011*\"seattle\" + 0.011*\"day\" + 0.010*\"home\" + 0.010*\"love\" + 0.010*\"one\" + 0.009*\"would\" + 0.008*\"say\"\n",
      "2019-10-29 00:40:21,688 : INFO : topic #6 (0.100): 0.035*\"allami\" + 0.034*\"hrebid\" + 0.022*\"say\" + 0.015*\"day\" + 0.013*\"u\" + 0.012*\"new\" + 0.012*\"one\" + 0.011*\"refugee\" + 0.009*\"two\" + 0.008*\"love\"\n",
      "2019-10-29 00:40:21,689 : INFO : topic #4 (0.100): 0.030*\"hrebid\" + 0.025*\"allami\" + 0.012*\"say\" + 0.010*\"one\" + 0.010*\"night\" + 0.010*\"love\" + 0.009*\"u\" + 0.009*\"refugee\" + 0.009*\"two\" + 0.009*\"seattle\"\n",
      "2019-10-29 00:40:21,691 : INFO : topic diff=0.899678, rho=1.000000\n",
      "2019-10-29 00:40:22,077 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:22,079 : INFO : built Dictionary(83 unique tokens: ['considered', 'level', 'significant', 'reach', 'spread']...) from 5 documents (total 610 corpus positions)\n",
      "2019-10-29 00:40:22,081 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:22,083 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:22,084 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:22,087 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:22,099 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:22,159 : INFO : -6.652 per-word bound, 100.6 perplexity estimate based on a held-out corpus of 5 documents with 610 words\n",
      "2019-10-29 00:40:22,162 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:22,169 : INFO : topic #4 (0.100): 0.050*\"home\" + 0.032*\"risk\" + 0.031*\"say\" + 0.031*\"california\" + 0.027*\"wildfire\" + 0.027*\"fire\" + 0.025*\"billion\" + 0.024*\"corelogic\" + 0.024*\"damage\" + 0.021*\"could\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:22,173 : INFO : topic #6 (0.100): 0.042*\"home\" + 0.036*\"damage\" + 0.033*\"risk\" + 0.027*\"could\" + 0.024*\"fire\" + 0.024*\"billion\" + 0.024*\"say\" + 0.023*\"property\" + 0.023*\"california\" + 0.022*\"wildfire\"\n",
      "2019-10-29 00:40:22,180 : INFO : topic #9 (0.100): 0.043*\"home\" + 0.029*\"california\" + 0.028*\"billion\" + 0.027*\"risk\" + 0.024*\"property\" + 0.023*\"damage\" + 0.023*\"say\" + 0.023*\"fire\" + 0.022*\"wildfire\" + 0.021*\"could\"\n",
      "2019-10-29 00:40:22,184 : INFO : topic #8 (0.100): 0.038*\"home\" + 0.037*\"damage\" + 0.030*\"fire\" + 0.029*\"risk\" + 0.028*\"property\" + 0.026*\"california\" + 0.024*\"wildfire\" + 0.024*\"say\" + 0.023*\"corelogic\" + 0.021*\"billion\"\n",
      "2019-10-29 00:40:22,190 : INFO : topic #2 (0.100): 0.043*\"home\" + 0.036*\"fire\" + 0.036*\"damage\" + 0.031*\"california\" + 0.029*\"risk\" + 0.027*\"say\" + 0.023*\"corelogic\" + 0.023*\"wildfire\" + 0.023*\"billion\" + 0.022*\"property\"\n",
      "2019-10-29 00:40:22,193 : INFO : topic diff=0.807547, rho=1.000000\n",
      "2019-10-29 00:40:22,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:22,660 : INFO : built Dictionary(368 unique tokens: ['energy', 'nature', 'portion', 'advantage', 'asked']...) from 5 documents (total 3515 corpus positions)\n",
      "2019-10-29 00:40:22,666 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:22,668 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:22,670 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:22,674 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:22,675 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:22,833 : INFO : -7.639 per-word bound, 199.3 perplexity estimate based on a held-out corpus of 5 documents with 3515 words\n",
      "2019-10-29 00:40:22,835 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:22,844 : INFO : topic #5 (0.100): 0.032*\"meal\" + 0.026*\"eating\" + 0.024*\"calorie\" + 0.021*\"may\" + 0.021*\"three\" + 0.017*\"eat\" + 0.016*\"day\" + 0.014*\"said\" + 0.012*\"mckittrick\" + 0.012*\"people\"\n",
      "2019-10-29 00:40:22,846 : INFO : topic #6 (0.100): 0.042*\"eating\" + 0.034*\"meal\" + 0.021*\"calorie\" + 0.018*\"may\" + 0.014*\"said\" + 0.014*\"three\" + 0.014*\"day\" + 0.012*\"eat\" + 0.012*\"mckittrick\" + 0.011*\"go\"\n",
      "2019-10-29 00:40:22,848 : INFO : topic #8 (0.100): 0.040*\"meal\" + 0.033*\"eating\" + 0.024*\"calorie\" + 0.016*\"small\" + 0.015*\"day\" + 0.015*\"eat\" + 0.015*\"may\" + 0.015*\"said\" + 0.013*\"three\" + 0.012*\"mckittrick\"\n",
      "2019-10-29 00:40:22,851 : INFO : topic #4 (0.100): 0.040*\"meal\" + 0.035*\"eating\" + 0.023*\"calorie\" + 0.019*\"may\" + 0.019*\"said\" + 0.016*\"eat\" + 0.015*\"three\" + 0.015*\"day\" + 0.013*\"small\" + 0.011*\"people\"\n",
      "2019-10-29 00:40:22,854 : INFO : topic #1 (0.100): 0.033*\"eating\" + 0.030*\"meal\" + 0.020*\"calorie\" + 0.019*\"three\" + 0.017*\"said\" + 0.016*\"may\" + 0.015*\"eat\" + 0.013*\"mckittrick\" + 0.012*\"small\" + 0.012*\"day\"\n",
      "2019-10-29 00:40:22,857 : INFO : topic diff=0.939903, rho=1.000000\n",
      "2019-10-29 00:40:23,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:23,286 : INFO : built Dictionary(335 unique tokens: ['although', 'concern', 'caution', 'come', 'shut']...) from 5 documents (total 2875 corpus positions)\n",
      "2019-10-29 00:40:23,290 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:23,291 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:23,293 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:23,297 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:23,299 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:23,410 : INFO : -7.686 per-word bound, 206.0 perplexity estimate based on a held-out corpus of 5 documents with 2875 words\n",
      "2019-10-29 00:40:23,412 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:23,420 : INFO : topic #6 (0.100): 0.034*\"said\" + 0.026*\"rhabdomyolysis\" + 0.023*\"class\" + 0.016*\"muscle\" + 0.014*\"everett\" + 0.010*\"condition\" + 0.010*\"case\" + 0.010*\"medicine\" + 0.010*\"new\" + 0.010*\"kidney\"\n",
      "2019-10-29 00:40:23,423 : INFO : topic #4 (0.100): 0.037*\"said\" + 0.029*\"rhabdomyolysis\" + 0.014*\"class\" + 0.014*\"muscle\" + 0.013*\"kidney\" + 0.012*\"everett\" + 0.010*\"condition\" + 0.010*\"case\" + 0.008*\"medicine\" + 0.008*\"dialysis\"\n",
      "2019-10-29 00:40:23,426 : INFO : topic #2 (0.100): 0.032*\"said\" + 0.021*\"class\" + 0.021*\"rhabdomyolysis\" + 0.016*\"everett\" + 0.015*\"kidney\" + 0.013*\"muscle\" + 0.012*\"condition\" + 0.011*\"case\" + 0.010*\"study\" + 0.010*\"hospital\"\n",
      "2019-10-29 00:40:23,429 : INFO : topic #7 (0.100): 0.037*\"said\" + 0.019*\"rhabdomyolysis\" + 0.018*\"class\" + 0.016*\"muscle\" + 0.016*\"everett\" + 0.013*\"condition\" + 0.010*\"thigh\" + 0.010*\"hospital\" + 0.009*\"first\" + 0.009*\"kidney\"\n",
      "2019-10-29 00:40:23,433 : INFO : topic #0 (0.100): 0.033*\"said\" + 0.018*\"rhabdomyolysis\" + 0.016*\"class\" + 0.015*\"kidney\" + 0.014*\"condition\" + 0.014*\"everett\" + 0.011*\"spinning\" + 0.010*\"muscle\" + 0.010*\"study\" + 0.010*\"dialysis\"\n",
      "2019-10-29 00:40:23,436 : INFO : topic diff=0.876093, rho=1.000000\n",
      "2019-10-29 00:40:23,850 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:23,852 : INFO : built Dictionary(53 unique tokens: ['forward', 'help', 'contagious', 'collect', 'time']...) from 5 documents (total 405 corpus positions)\n",
      "2019-10-29 00:40:23,853 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:23,854 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:23,856 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:23,858 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:23,859 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:23,887 : INFO : -6.231 per-word bound, 75.1 perplexity estimate based on a held-out corpus of 5 documents with 405 words\n",
      "2019-10-29 00:40:23,889 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:23,895 : INFO : topic #7 (0.100): 0.061*\"windsor\" + 0.058*\"police\" + 0.055*\"east\" + 0.043*\"animal\" + 0.037*\"shelter\" + 0.032*\"birthday\" + 0.031*\"maggie\" + 0.027*\"used\" + 0.026*\"wfsb\" + 0.024*\"girl\"\n",
      "2019-10-29 00:40:23,897 : INFO : topic #3 (0.100): 0.062*\"windsor\" + 0.059*\"police\" + 0.056*\"east\" + 0.038*\"animal\" + 0.037*\"maggie\" + 0.031*\"birthday\" + 0.029*\"collect\" + 0.028*\"wfsb\" + 0.027*\"shelter\" + 0.025*\"girl\"\n",
      "2019-10-29 00:40:23,900 : INFO : topic #4 (0.100): 0.063*\"windsor\" + 0.062*\"police\" + 0.061*\"east\" + 0.044*\"maggie\" + 0.038*\"animal\" + 0.036*\"shelter\" + 0.032*\"birthday\" + 0.027*\"collect\" + 0.026*\"time\" + 0.025*\"used\"\n",
      "2019-10-29 00:40:23,904 : INFO : topic #5 (0.100): 0.054*\"windsor\" + 0.049*\"police\" + 0.048*\"east\" + 0.048*\"animal\" + 0.043*\"maggie\" + 0.038*\"shelter\" + 0.032*\"time\" + 0.032*\"birthday\" + 0.026*\"wfsb\" + 0.024*\"donation\"\n",
      "2019-10-29 00:40:23,907 : INFO : topic #2 (0.100): 0.078*\"police\" + 0.060*\"windsor\" + 0.053*\"animal\" + 0.046*\"east\" + 0.043*\"shelter\" + 0.031*\"maggie\" + 0.026*\"donation\" + 0.025*\"wfsb\" + 0.025*\"used\" + 0.025*\"time\"\n",
      "2019-10-29 00:40:23,910 : INFO : topic diff=0.844081, rho=1.000000\n",
      "2019-10-29 00:40:24,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:24,342 : INFO : built Dictionary(322 unique tokens: ['scope', 'specie', 'significant', 'universe', 'come']...) from 5 documents (total 2715 corpus positions)\n",
      "2019-10-29 00:40:24,347 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:24,348 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:24,349 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:24,353 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:24,354 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:24,451 : INFO : -7.676 per-word bound, 204.5 perplexity estimate based on a held-out corpus of 5 documents with 2715 words\n",
      "2019-10-29 00:40:24,452 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:24,460 : INFO : topic #5 (0.100): 0.021*\"specie\" + 0.018*\"year\" + 0.018*\"extinction\" + 0.012*\"said\" + 0.012*\"population\" + 0.012*\"number\" + 0.011*\"going\" + 0.010*\"planet\" + 0.010*\"time\" + 0.009*\"stop\"\n",
      "2019-10-29 00:40:24,462 : INFO : topic #6 (0.100): 0.030*\"specie\" + 0.017*\"extinction\" + 0.016*\"year\" + 0.011*\"told\" + 0.011*\"said\" + 0.011*\"population\" + 0.010*\"barnosky\" + 0.010*\"planet\" + 0.009*\"going\" + 0.009*\"time\"\n",
      "2019-10-29 00:40:24,464 : INFO : topic #3 (0.100): 0.020*\"specie\" + 0.017*\"extinction\" + 0.013*\"told\" + 0.013*\"year\" + 0.012*\"said\" + 0.012*\"number\" + 0.011*\"planet\" + 0.010*\"population\" + 0.010*\"time\" + 0.009*\"going\"\n",
      "2019-10-29 00:40:24,467 : INFO : topic #7 (0.100): 0.027*\"specie\" + 0.018*\"extinction\" + 0.018*\"year\" + 0.012*\"told\" + 0.011*\"number\" + 0.010*\"population\" + 0.010*\"going\" + 0.009*\"planet\" + 0.009*\"stop\" + 0.009*\"barnosky\"\n",
      "2019-10-29 00:40:24,468 : INFO : topic #2 (0.100): 0.030*\"specie\" + 0.024*\"year\" + 0.022*\"extinction\" + 0.013*\"said\" + 0.012*\"population\" + 0.010*\"going\" + 0.010*\"rate\" + 0.009*\"planet\" + 0.009*\"told\" + 0.009*\"sixth\"\n",
      "2019-10-29 00:40:24,470 : INFO : topic diff=0.837215, rho=1.000000\n",
      "2019-10-29 00:40:24,881 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:24,883 : INFO : built Dictionary(67 unique tokens: ['unforgivable', 'time', 'request', 'break', 'harassment']...) from 5 documents (total 415 corpus positions)\n",
      "2019-10-29 00:40:24,885 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:24,886 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:24,888 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:24,890 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:24,891 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:24,924 : INFO : -6.802 per-word bound, 111.6 perplexity estimate based on a held-out corpus of 5 documents with 415 words\n",
      "2019-10-29 00:40:24,927 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:24,935 : INFO : topic #4 (0.100): 0.036*\"weinstein\" + 0.026*\"read\" + 0.026*\"statement\" + 0.025*\"leaving\" + 0.025*\"woman\" + 0.024*\"cnn\" + 0.024*\"harvey\" + 0.023*\"new\" + 0.023*\"chapman\" + 0.022*\"young\"\n",
      "2019-10-29 00:40:24,937 : INFO : topic #0 (0.100): 0.061*\"weinstein\" + 0.027*\"statement\" + 0.027*\"wife\" + 0.026*\"child\" + 0.026*\"read\" + 0.026*\"leaving\" + 0.025*\"cnn\" + 0.025*\"magazine\" + 0.023*\"new\" + 0.022*\"chapman\"\n",
      "2019-10-29 00:40:24,938 : INFO : topic #3 (0.100): 0.045*\"weinstein\" + 0.034*\"read\" + 0.028*\"harvey\" + 0.024*\"woman\" + 0.023*\"wife\" + 0.023*\"chapman\" + 0.023*\"young\" + 0.022*\"allegation\" + 0.022*\"child\" + 0.022*\"leaving\"\n",
      "2019-10-29 00:40:24,939 : INFO : topic #6 (0.100): 0.048*\"weinstein\" + 0.029*\"cnn\" + 0.026*\"wife\" + 0.026*\"allegation\" + 0.025*\"new\" + 0.024*\"harvey\" + 0.024*\"magazine\" + 0.024*\"woman\" + 0.023*\"child\" + 0.021*\"chapman\"\n",
      "2019-10-29 00:40:24,943 : INFO : topic #8 (0.100): 0.035*\"weinstein\" + 0.031*\"woman\" + 0.030*\"magazine\" + 0.028*\"new\" + 0.027*\"cnn\" + 0.024*\"child\" + 0.024*\"young\" + 0.023*\"chapman\" + 0.023*\"wife\" + 0.022*\"read\"\n",
      "2019-10-29 00:40:24,947 : INFO : topic diff=0.664558, rho=1.000000\n",
      "2019-10-29 00:40:25,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:25,354 : INFO : built Dictionary(119 unique tokens: ['paris', 'commissioned', 'industry', 'home', 'get']...) from 5 documents (total 910 corpus positions)\n",
      "2019-10-29 00:40:25,356 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:25,358 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:25,362 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:25,366 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:25,370 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:25,438 : INFO : -6.899 per-word bound, 119.3 perplexity estimate based on a held-out corpus of 5 documents with 910 words\n",
      "2019-10-29 00:40:25,440 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:25,447 : INFO : topic #0 (0.100): 0.055*\"gold\" + 0.032*\"swiss\" + 0.027*\"waste\" + 0.025*\"water\" + 0.021*\"sewage\" + 0.021*\"silver\" + 0.021*\"found\" + 0.019*\"worth\" + 0.017*\"million\" + 0.017*\"flushed\"\n",
      "2019-10-29 00:40:25,450 : INFO : topic #4 (0.100): 0.045*\"gold\" + 0.037*\"swiss\" + 0.035*\"water\" + 0.027*\"waste\" + 0.024*\"sewage\" + 0.018*\"million\" + 0.018*\"year\" + 0.016*\"found\" + 0.016*\"worth\" + 0.016*\"researcher\"\n",
      "2019-10-29 00:40:25,452 : INFO : topic #8 (0.100): 0.048*\"gold\" + 0.037*\"swiss\" + 0.033*\"water\" + 0.025*\"waste\" + 0.019*\"flushed\" + 0.018*\"sewage\" + 0.016*\"scientist\" + 0.015*\"silver\" + 0.014*\"current\" + 0.014*\"researcher\"\n",
      "2019-10-29 00:40:25,455 : INFO : topic #5 (0.100): 0.060*\"gold\" + 0.038*\"swiss\" + 0.030*\"water\" + 0.024*\"waste\" + 0.022*\"sewage\" + 0.018*\"researcher\" + 0.017*\"flushed\" + 0.017*\"year\" + 0.016*\"found\" + 0.015*\"silver\"\n",
      "2019-10-29 00:40:25,458 : INFO : topic #2 (0.100): 0.046*\"gold\" + 0.036*\"swiss\" + 0.033*\"water\" + 0.028*\"sewage\" + 0.026*\"waste\" + 0.021*\"million\" + 0.018*\"flushed\" + 0.017*\"researcher\" + 0.017*\"worth\" + 0.017*\"found\"\n",
      "2019-10-29 00:40:25,460 : INFO : topic diff=0.809310, rho=1.000000\n",
      "2019-10-29 00:40:25,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:25,902 : INFO : built Dictionary(53 unique tokens: ['enrolled', 'extensive', 'school', 'anderson', 'watch']...) from 5 documents (total 420 corpus positions)\n",
      "2019-10-29 00:40:25,905 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:25,908 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:25,911 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:25,914 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:25,918 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:25,947 : INFO : -6.176 per-word bound, 72.3 perplexity estimate based on a held-out corpus of 5 documents with 420 words\n",
      "2019-10-29 00:40:25,949 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:25,955 : INFO : topic #3 (0.100): 0.093*\"white\" + 0.073*\"class\" + 0.070*\"working\" + 0.041*\"voter\" + 0.038*\"trump\" + 0.037*\"result\" + 0.026*\"cnn\" + 0.025*\"adult\" + 0.022*\"support\" + 0.022*\"among\"\n",
      "2019-10-29 00:40:25,958 : INFO : topic #7 (0.100): 0.087*\"white\" + 0.067*\"working\" + 0.060*\"class\" + 0.045*\"voter\" + 0.038*\"result\" + 0.032*\"trump\" + 0.030*\"cnn\" + 0.027*\"point\" + 0.023*\"poll\" + 0.023*\"support\"\n",
      "2019-10-29 00:40:25,962 : INFO : topic #8 (0.100): 0.086*\"white\" + 0.060*\"working\" + 0.053*\"class\" + 0.042*\"trump\" + 0.041*\"voter\" + 0.038*\"cnn\" + 0.033*\"result\" + 0.030*\"adult\" + 0.025*\"survey\" + 0.022*\"point\"\n",
      "2019-10-29 00:40:25,963 : INFO : topic #2 (0.100): 0.078*\"white\" + 0.072*\"class\" + 0.061*\"working\" + 0.045*\"cnn\" + 0.038*\"voter\" + 0.033*\"trump\" + 0.029*\"adult\" + 0.027*\"result\" + 0.026*\"poll\" + 0.024*\"point\"\n",
      "2019-10-29 00:40:25,965 : INFO : topic #9 (0.100): 0.078*\"working\" + 0.073*\"white\" + 0.064*\"class\" + 0.046*\"voter\" + 0.040*\"result\" + 0.037*\"cnn\" + 0.032*\"trump\" + 0.026*\"point\" + 0.026*\"poll\" + 0.024*\"survey\"\n",
      "2019-10-29 00:40:25,967 : INFO : topic diff=0.887114, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:26,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:26,376 : INFO : built Dictionary(103 unique tokens: ['fox', 'acceptable', 'retiring', 'trying', 'reserved']...) from 5 documents (total 675 corpus positions)\n",
      "2019-10-29 00:40:26,380 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:26,382 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:26,383 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:26,386 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:26,388 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:26,449 : INFO : -7.041 per-word bound, 131.7 perplexity estimate based on a held-out corpus of 5 documents with 675 words\n",
      "2019-10-29 00:40:26,450 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:26,456 : INFO : topic #1 (0.100): 0.037*\"deputy\" + 0.027*\"said\" + 0.025*\"nude\" + 0.024*\"email\" + 0.022*\"photo\" + 0.019*\"courthouse\" + 0.019*\"called\" + 0.018*\"fox\" + 0.018*\"would\" + 0.017*\"kptv\"\n",
      "2019-10-29 00:40:26,459 : INFO : topic #2 (0.100): 0.047*\"deputy\" + 0.038*\"nude\" + 0.021*\"email\" + 0.020*\"fox\" + 0.020*\"courthouse\" + 0.019*\"photo\" + 0.018*\"sept\" + 0.017*\"said\" + 0.016*\"told\" + 0.016*\"would\"\n",
      "2019-10-29 00:40:26,462 : INFO : topic #4 (0.100): 0.038*\"deputy\" + 0.030*\"courthouse\" + 0.029*\"would\" + 0.025*\"nude\" + 0.021*\"photo\" + 0.018*\"email\" + 0.018*\"sheriff\" + 0.017*\"shoot\" + 0.017*\"fox\" + 0.016*\"copy\"\n",
      "2019-10-29 00:40:26,466 : INFO : topic #3 (0.100): 0.038*\"deputy\" + 0.023*\"nude\" + 0.022*\"would\" + 0.021*\"fox\" + 0.021*\"courthouse\" + 0.019*\"email\" + 0.019*\"photo\" + 0.018*\"video\" + 0.016*\"sheriff\" + 0.015*\"copy\"\n",
      "2019-10-29 00:40:26,471 : INFO : topic #8 (0.100): 0.036*\"deputy\" + 0.027*\"said\" + 0.026*\"nude\" + 0.022*\"would\" + 0.020*\"fox\" + 0.019*\"photo\" + 0.018*\"email\" + 0.017*\"called\" + 0.017*\"courthouse\" + 0.017*\"calendar\"\n",
      "2019-10-29 00:40:26,475 : INFO : topic diff=0.739633, rho=1.000000\n",
      "2019-10-29 00:40:26,955 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:26,968 : INFO : built Dictionary(632 unique tokens: ['dating', 'havely', 'enterprise', 'person', 'bone']...) from 5 documents (total 6745 corpus positions)\n",
      "2019-10-29 00:40:26,980 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:26,983 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:26,987 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:26,993 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:27,002 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:27,240 : INFO : -8.040 per-word bound, 263.2 perplexity estimate based on a held-out corpus of 5 documents with 6745 words\n",
      "2019-10-29 00:40:27,242 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:27,251 : INFO : topic #0 (0.100): 0.028*\"said\" + 0.011*\"cnn\" + 0.011*\"mountain\" + 0.010*\"hotshot\" + 0.010*\"always\" + 0.010*\"told\" + 0.010*\"fire\" + 0.009*\"one\" + 0.009*\"family\" + 0.008*\"affiliate\"\n",
      "2019-10-29 00:40:27,254 : INFO : topic #6 (0.100): 0.025*\"said\" + 0.019*\"fire\" + 0.013*\"cnn\" + 0.012*\"hotshot\" + 0.011*\"friend\" + 0.011*\"told\" + 0.010*\"always\" + 0.009*\"mountain\" + 0.009*\"family\" + 0.008*\"one\"\n",
      "2019-10-29 00:40:27,256 : INFO : topic #1 (0.100): 0.026*\"said\" + 0.013*\"told\" + 0.011*\"friend\" + 0.011*\"hotshot\" + 0.011*\"cnn\" + 0.010*\"fire\" + 0.010*\"family\" + 0.010*\"mountain\" + 0.010*\"school\" + 0.008*\"always\"\n",
      "2019-10-29 00:40:27,261 : INFO : topic #2 (0.100): 0.017*\"fire\" + 0.016*\"said\" + 0.012*\"told\" + 0.012*\"hotshot\" + 0.010*\"granite\" + 0.009*\"one\" + 0.009*\"arizona\" + 0.008*\"family\" + 0.008*\"friend\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:40:27,264 : INFO : topic #8 (0.100): 0.025*\"said\" + 0.016*\"fire\" + 0.013*\"hotshot\" + 0.012*\"cnn\" + 0.011*\"told\" + 0.011*\"friend\" + 0.009*\"mountain\" + 0.008*\"family\" + 0.008*\"one\" + 0.008*\"child\"\n",
      "2019-10-29 00:40:27,266 : INFO : topic diff=0.950099, rho=1.000000\n",
      "2019-10-29 00:40:27,705 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:27,713 : INFO : built Dictionary(310 unique tokens: ['relation', 'acceptable', 'book', 'caution', 'nation']...) from 5 documents (total 2335 corpus positions)\n",
      "2019-10-29 00:40:27,718 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:27,720 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:27,722 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:27,727 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:27,731 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:27,838 : INFO : -7.804 per-word bound, 223.5 perplexity estimate based on a held-out corpus of 5 documents with 2335 words\n",
      "2019-10-29 00:40:27,840 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:27,847 : INFO : topic #0 (0.100): 0.021*\"post\" + 0.021*\"employee\" + 0.018*\"company\" + 0.016*\"staffer\" + 0.015*\"social\" + 0.011*\"employer\" + 0.010*\"fire\" + 0.010*\"public\" + 0.009*\"executive\" + 0.009*\"geftman\"\n",
      "2019-10-29 00:40:27,849 : INFO : topic #6 (0.100): 0.020*\"employee\" + 0.017*\"staffer\" + 0.017*\"post\" + 0.015*\"company\" + 0.013*\"medium\" + 0.011*\"social\" + 0.010*\"employer\" + 0.009*\"public\" + 0.009*\"facebook\" + 0.009*\"relation\"\n",
      "2019-10-29 00:40:27,852 : INFO : topic #7 (0.100): 0.019*\"employee\" + 0.017*\"staffer\" + 0.016*\"post\" + 0.016*\"company\" + 0.016*\"employer\" + 0.013*\"fire\" + 0.010*\"fired\" + 0.010*\"facebook\" + 0.009*\"social\" + 0.009*\"medium\"\n",
      "2019-10-29 00:40:27,854 : INFO : topic #3 (0.100): 0.024*\"employee\" + 0.020*\"staffer\" + 0.016*\"post\" + 0.016*\"employer\" + 0.014*\"medium\" + 0.013*\"company\" + 0.013*\"social\" + 0.011*\"fire\" + 0.010*\"fired\" + 0.010*\"geftman\"\n",
      "2019-10-29 00:40:27,856 : INFO : topic #8 (0.100): 0.023*\"post\" + 0.019*\"employee\" + 0.014*\"staffer\" + 0.014*\"social\" + 0.012*\"fire\" + 0.011*\"company\" + 0.011*\"medium\" + 0.011*\"employer\" + 0.010*\"public\" + 0.009*\"reason\"\n",
      "2019-10-29 00:40:27,857 : INFO : topic diff=0.815070, rho=1.000000\n",
      "2019-10-29 00:40:28,304 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:28,310 : INFO : built Dictionary(403 unique tokens: ['extensive', 'incremental', 'portion', 'francisco', 'blanket']...) from 5 documents (total 3470 corpus positions)\n",
      "2019-10-29 00:40:28,315 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:28,317 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:28,318 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:28,322 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:28,324 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:28,452 : INFO : -7.858 per-word bound, 232.0 perplexity estimate based on a held-out corpus of 5 documents with 3470 words\n",
      "2019-10-29 00:40:28,454 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:28,464 : INFO : topic #5 (0.100): 0.038*\"rail\" + 0.027*\"speed\" + 0.025*\"high\" + 0.018*\"train\" + 0.018*\"state\" + 0.012*\"service\" + 0.010*\"united\" + 0.009*\"corridor\" + 0.009*\"line\" + 0.009*\"fast\"\n",
      "2019-10-29 00:40:28,467 : INFO : topic #7 (0.100): 0.030*\"speed\" + 0.030*\"high\" + 0.027*\"rail\" + 0.023*\"train\" + 0.013*\"state\" + 0.013*\"united\" + 0.011*\"service\" + 0.010*\"line\" + 0.009*\"new\" + 0.008*\"fast\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:28,475 : INFO : topic #9 (0.100): 0.031*\"rail\" + 0.023*\"train\" + 0.023*\"high\" + 0.021*\"speed\" + 0.017*\"state\" + 0.011*\"line\" + 0.010*\"united\" + 0.010*\"service\" + 0.010*\"corridor\" + 0.009*\"fast\"\n",
      "2019-10-29 00:40:28,482 : INFO : topic #8 (0.100): 0.034*\"rail\" + 0.034*\"speed\" + 0.020*\"train\" + 0.020*\"high\" + 0.018*\"state\" + 0.010*\"united\" + 0.010*\"service\" + 0.009*\"corridor\" + 0.008*\"city\" + 0.008*\"york\"\n",
      "2019-10-29 00:40:28,485 : INFO : topic #4 (0.100): 0.040*\"rail\" + 0.028*\"high\" + 0.024*\"speed\" + 0.017*\"train\" + 0.014*\"state\" + 0.013*\"corridor\" + 0.012*\"united\" + 0.009*\"service\" + 0.009*\"line\" + 0.009*\"city\"\n",
      "2019-10-29 00:40:28,488 : INFO : topic diff=0.881733, rho=1.000000\n",
      "2019-10-29 00:40:28,913 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:28,916 : INFO : built Dictionary(77 unique tokens: ['thanked', 'deadly', 'performing', 'visit', 'time']...) from 5 documents (total 525 corpus positions)\n",
      "2019-10-29 00:40:28,920 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:28,922 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:28,924 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:28,927 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:28,930 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:28,977 : INFO : -6.727 per-word bound, 106.0 perplexity estimate based on a held-out corpus of 5 documents with 525 words\n",
      "2019-10-29 00:40:28,979 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:28,988 : INFO : topic #0 (0.100): 0.048*\"aldean\" + 0.038*\"jason\" + 0.037*\"visit\" + 0.029*\"shooting\" + 0.028*\"music\" + 0.026*\"la\" + 0.022*\"country\" + 0.022*\"vega\" + 0.020*\"sunday\" + 0.019*\"posted\"\n",
      "2019-10-29 00:40:28,992 : INFO : topic #7 (0.100): 0.053*\"aldean\" + 0.033*\"jason\" + 0.031*\"visit\" + 0.027*\"music\" + 0.027*\"vega\" + 0.025*\"shooting\" + 0.025*\"country\" + 0.024*\"la\" + 0.022*\"posted\" + 0.020*\"victim\"\n",
      "2019-10-29 00:40:28,995 : INFO : topic #5 (0.100): 0.050*\"aldean\" + 0.040*\"visit\" + 0.034*\"jason\" + 0.029*\"la\" + 0.027*\"vega\" + 0.026*\"country\" + 0.026*\"music\" + 0.023*\"shooting\" + 0.022*\"gratitude\" + 0.020*\"star\"\n",
      "2019-10-29 00:40:28,997 : INFO : topic #1 (0.100): 0.039*\"aldean\" + 0.032*\"visit\" + 0.032*\"jason\" + 0.032*\"vega\" + 0.031*\"la\" + 0.028*\"country\" + 0.027*\"shooting\" + 0.025*\"music\" + 0.023*\"posted\" + 0.019*\"sunday\"\n",
      "2019-10-29 00:40:29,000 : INFO : topic #9 (0.100): 0.055*\"aldean\" + 0.034*\"visit\" + 0.032*\"jason\" + 0.028*\"music\" + 0.028*\"shooting\" + 0.023*\"victim\" + 0.023*\"country\" + 0.022*\"la\" + 0.021*\"star\" + 0.021*\"vega\"\n",
      "2019-10-29 00:40:29,005 : INFO : topic diff=0.788071, rho=1.000000\n",
      "2019-10-29 00:40:29,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:29,451 : INFO : built Dictionary(121 unique tokens: ['school', 'campaign', 'leader', 'home', 'get']...) from 5 documents (total 920 corpus positions)\n",
      "2019-10-29 00:40:29,453 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:29,454 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:29,456 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:29,459 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:29,461 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:29,514 : INFO : -6.920 per-word bound, 121.1 perplexity estimate based on a held-out corpus of 5 documents with 920 words\n",
      "2019-10-29 00:40:29,515 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:29,523 : INFO : topic #6 (0.100): 0.054*\"girl\" + 0.026*\"world\" + 0.022*\"africa\" + 0.022*\"education\" + 0.019*\"get\" + 0.019*\"country\" + 0.018*\"day\" + 0.018*\"million\" + 0.017*\"year\" + 0.017*\"school\"\n",
      "2019-10-29 00:40:29,526 : INFO : topic #1 (0.100): 0.058*\"girl\" + 0.023*\"day\" + 0.020*\"country\" + 0.020*\"africa\" + 0.020*\"million\" + 0.020*\"get\" + 0.019*\"world\" + 0.018*\"education\" + 0.017*\"year\" + 0.016*\"smith\"\n",
      "2019-10-29 00:40:29,528 : INFO : topic #8 (0.100): 0.070*\"girl\" + 0.025*\"country\" + 0.024*\"day\" + 0.020*\"million\" + 0.020*\"africa\" + 0.019*\"education\" + 0.019*\"get\" + 0.017*\"long\" + 0.017*\"world\" + 0.016*\"school\"\n",
      "2019-10-29 00:40:29,531 : INFO : topic #3 (0.100): 0.069*\"girl\" + 0.025*\"africa\" + 0.025*\"world\" + 0.025*\"million\" + 0.023*\"get\" + 0.021*\"school\" + 0.018*\"education\" + 0.018*\"gayle\" + 0.018*\"day\" + 0.015*\"smith\"\n",
      "2019-10-29 00:40:29,533 : INFO : topic #2 (0.100): 0.080*\"girl\" + 0.024*\"get\" + 0.024*\"education\" + 0.021*\"day\" + 0.021*\"million\" + 0.019*\"africa\" + 0.018*\"country\" + 0.016*\"smith\" + 0.016*\"world\" + 0.015*\"gayle\"\n",
      "2019-10-29 00:40:29,536 : INFO : topic diff=0.812811, rho=1.000000\n",
      "2019-10-29 00:40:29,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:29,943 : INFO : built Dictionary(84 unique tokens: ['residency', 'help', 'school', 'finished', 'administrator']...) from 5 documents (total 545 corpus positions)\n",
      "2019-10-29 00:40:29,945 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:29,950 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:29,953 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:29,957 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:29,960 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:30,011 : INFO : -6.898 per-word bound, 119.3 perplexity estimate based on a held-out corpus of 5 documents with 545 words\n",
      "2019-10-29 00:40:30,013 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:30,019 : INFO : topic #6 (0.100): 0.054*\"school\" + 0.032*\"desilva\" + 0.028*\"homeless\" + 0.027*\"high\" + 0.023*\"kept\" + 0.020*\"going\" + 0.018*\"college\" + 0.017*\"first\" + 0.017*\"could\" + 0.016*\"document\"\n",
      "2019-10-29 00:40:30,023 : INFO : topic #5 (0.100): 0.043*\"desilva\" + 0.041*\"school\" + 0.027*\"homeless\" + 0.026*\"high\" + 0.023*\"trying\" + 0.023*\"kept\" + 0.020*\"houston\" + 0.020*\"liyjon\" + 0.017*\"could\" + 0.017*\"college\"\n",
      "2019-10-29 00:40:30,026 : INFO : topic #4 (0.100): 0.050*\"school\" + 0.048*\"desilva\" + 0.029*\"homeless\" + 0.029*\"kept\" + 0.024*\"high\" + 0.021*\"liyjon\" + 0.021*\"going\" + 0.020*\"could\" + 0.018*\"trying\" + 0.017*\"document\"\n",
      "2019-10-29 00:40:30,028 : INFO : topic #3 (0.100): 0.062*\"school\" + 0.044*\"desilva\" + 0.028*\"kept\" + 0.024*\"high\" + 0.022*\"homeless\" + 0.021*\"document\" + 0.021*\"going\" + 0.021*\"year\" + 0.017*\"liyjon\" + 0.017*\"college\"\n",
      "2019-10-29 00:40:30,031 : INFO : topic #1 (0.100): 0.064*\"school\" + 0.038*\"desilva\" + 0.025*\"kept\" + 0.025*\"high\" + 0.023*\"trying\" + 0.021*\"homeless\" + 0.019*\"year\" + 0.018*\"document\" + 0.018*\"going\" + 0.017*\"houston\"\n",
      "2019-10-29 00:40:30,033 : INFO : topic diff=0.749828, rho=1.000000\n",
      "2019-10-29 00:40:30,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:30,463 : INFO : built Dictionary(192 unique tokens: ['enterprise', 'embody', 'industry', 'focus', 'plastic']...) from 5 documents (total 1235 corpus positions)\n",
      "2019-10-29 00:40:30,466 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:30,467 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:30,469 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:30,472 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:30,473 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:30,559 : INFO : -7.620 per-word bound, 196.8 perplexity estimate based on a held-out corpus of 5 documents with 1235 words\n",
      "2019-10-29 00:40:30,560 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:30,567 : INFO : topic #3 (0.100): 0.038*\"semaan\" + 0.017*\"u\" + 0.015*\"collection\" + 0.015*\"travel\" + 0.014*\"fashion\" + 0.013*\"ban\" + 0.013*\"first\" + 0.013*\"slow\" + 0.010*\"year\" + 0.009*\"refugee\"\n",
      "2019-10-29 00:40:30,569 : INFO : topic #4 (0.100): 0.037*\"semaan\" + 0.016*\"ban\" + 0.016*\"travel\" + 0.015*\"collection\" + 0.013*\"fashion\" + 0.013*\"year\" + 0.013*\"u\" + 0.013*\"slow\" + 0.010*\"factory\" + 0.009*\"country\"\n",
      "2019-10-29 00:40:30,570 : INFO : topic #6 (0.100): 0.039*\"semaan\" + 0.020*\"collection\" + 0.018*\"travel\" + 0.015*\"slow\" + 0.014*\"u\" + 0.012*\"ban\" + 0.012*\"fashion\" + 0.011*\"trump\" + 0.010*\"constitution\" + 0.009*\"first\"\n",
      "2019-10-29 00:40:30,571 : INFO : topic #1 (0.100): 0.041*\"semaan\" + 0.018*\"slow\" + 0.018*\"collection\" + 0.016*\"u\" + 0.015*\"ban\" + 0.014*\"travel\" + 0.013*\"year\" + 0.013*\"fashion\" + 0.010*\"first\" + 0.010*\"trump\"\n",
      "2019-10-29 00:40:30,573 : INFO : topic #0 (0.100): 0.040*\"semaan\" + 0.018*\"ban\" + 0.017*\"fashion\" + 0.015*\"collection\" + 0.015*\"slow\" + 0.015*\"travel\" + 0.013*\"trump\" + 0.012*\"u\" + 0.011*\"year\" + 0.010*\"first\"\n",
      "2019-10-29 00:40:30,574 : INFO : topic diff=0.731628, rho=1.000000\n",
      "2019-10-29 00:40:30,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:30,992 : INFO : built Dictionary(83 unique tokens: ['gear', 'including', '32nd', 'special', 'two']...) from 5 documents (total 715 corpus positions)\n",
      "2019-10-29 00:40:30,994 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:30,996 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:30,997 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:31,000 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:31,002 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:31,046 : INFO : -6.409 per-word bound, 85.0 perplexity estimate based on a held-out corpus of 5 documents with 715 words\n",
      "2019-10-29 00:40:31,048 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:31,055 : INFO : topic #8 (0.100): 0.056*\"round\" + 0.051*\"tank\" + 0.042*\"incendiary\" + 0.034*\"fuel\" + 0.032*\"paddock\" + 0.028*\"source\" + 0.025*\"fired\" + 0.025*\"investigator\" + 0.023*\"struck\" + 0.021*\"said\"\n",
      "2019-10-29 00:40:31,062 : INFO : topic #9 (0.100): 0.058*\"round\" + 0.051*\"tank\" + 0.042*\"incendiary\" + 0.037*\"fuel\" + 0.035*\"source\" + 0.026*\"paddock\" + 0.023*\"say\" + 0.022*\"fired\" + 0.020*\"room\" + 0.019*\"recovered\"\n",
      "2019-10-29 00:40:31,066 : INFO : topic #1 (0.100): 0.056*\"tank\" + 0.054*\"round\" + 0.038*\"source\" + 0.030*\"incendiary\" + 0.025*\"paddock\" + 0.025*\"fired\" + 0.023*\"room\" + 0.023*\"fuel\" + 0.022*\"recovered\" + 0.020*\"say\"\n",
      "2019-10-29 00:40:31,069 : INFO : topic #2 (0.100): 0.071*\"tank\" + 0.054*\"round\" + 0.033*\"incendiary\" + 0.030*\"fuel\" + 0.028*\"source\" + 0.025*\"paddock\" + 0.025*\"said\" + 0.024*\"fired\" + 0.023*\"room\" + 0.022*\"say\"\n",
      "2019-10-29 00:40:31,078 : INFO : topic #7 (0.100): 0.059*\"round\" + 0.055*\"tank\" + 0.035*\"source\" + 0.034*\"fuel\" + 0.034*\"incendiary\" + 0.029*\"fired\" + 0.028*\"paddock\" + 0.027*\"near\" + 0.020*\"room\" + 0.019*\"struck\"\n",
      "2019-10-29 00:40:31,081 : INFO : topic diff=0.892145, rho=1.000000\n",
      "2019-10-29 00:40:31,516 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:31,525 : INFO : built Dictionary(365 unique tokens: ['let', 'method', 'real', 'offered', 'mistake']...) from 5 documents (total 3045 corpus positions)\n",
      "2019-10-29 00:40:31,535 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:31,538 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:31,541 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:31,546 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:31,549 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:31,706 : INFO : -7.810 per-word bound, 224.4 perplexity estimate based on a held-out corpus of 5 documents with 3045 words\n",
      "2019-10-29 00:40:31,707 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:31,717 : INFO : topic #0 (0.100): 0.025*\"food\" + 0.022*\"time\" + 0.020*\"cooking\" + 0.019*\"pollan\" + 0.013*\"make\" + 0.012*\"get\" + 0.010*\"cook\" + 0.010*\"cnn\" + 0.009*\"really\" + 0.008*\"want\"\n",
      "2019-10-29 00:40:31,720 : INFO : topic #5 (0.100): 0.030*\"time\" + 0.029*\"cooking\" + 0.024*\"food\" + 0.020*\"pollan\" + 0.012*\"cook\" + 0.012*\"cnn\" + 0.011*\"make\" + 0.008*\"meal\" + 0.008*\"get\" + 0.008*\"say\"\n",
      "2019-10-29 00:40:31,722 : INFO : topic #8 (0.100): 0.026*\"cooking\" + 0.023*\"food\" + 0.022*\"time\" + 0.017*\"pollan\" + 0.014*\"cook\" + 0.010*\"really\" + 0.010*\"say\" + 0.009*\"think\" + 0.009*\"series\" + 0.009*\"people\"\n",
      "2019-10-29 00:40:31,724 : INFO : topic #7 (0.100): 0.036*\"food\" + 0.025*\"time\" + 0.022*\"pollan\" + 0.019*\"cooking\" + 0.017*\"make\" + 0.014*\"cook\" + 0.009*\"meal\" + 0.009*\"cnn\" + 0.008*\"really\" + 0.008*\"think\"\n",
      "2019-10-29 00:40:31,726 : INFO : topic #6 (0.100): 0.032*\"food\" + 0.029*\"cooking\" + 0.024*\"pollan\" + 0.024*\"time\" + 0.014*\"get\" + 0.012*\"cook\" + 0.011*\"make\" + 0.009*\"really\" + 0.009*\"cnn\" + 0.008*\"meal\"\n",
      "2019-10-29 00:40:31,728 : INFO : topic diff=0.871921, rho=1.000000\n",
      "2019-10-29 00:40:32,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:32,239 : INFO : built Dictionary(354 unique tokens: ['acceptable', 'portion', 'doc', 'cycle', 'stop']...) from 5 documents (total 2925 corpus positions)\n",
      "2019-10-29 00:40:32,242 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:32,243 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:32,245 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:32,249 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:32,250 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:32,360 : INFO : -7.795 per-word bound, 222.1 perplexity estimate based on a held-out corpus of 5 documents with 2925 words\n",
      "2019-10-29 00:40:32,361 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:32,369 : INFO : topic #5 (0.100): 0.038*\"control\" + 0.024*\"birth\" + 0.019*\"woman\" + 0.015*\"said\" + 0.011*\"phipps\" + 0.010*\"ovary\" + 0.009*\"pill\" + 0.009*\"jarnagin\" + 0.009*\"davis\" + 0.009*\"health\"\n",
      "2019-10-29 00:40:32,371 : INFO : topic #3 (0.100): 0.029*\"control\" + 0.025*\"birth\" + 0.014*\"said\" + 0.014*\"woman\" + 0.011*\"phipps\" + 0.011*\"health\" + 0.010*\"condition\" + 0.009*\"davis\" + 0.009*\"endometriosis\" + 0.008*\"pill\"\n",
      "2019-10-29 00:40:32,373 : INFO : topic #4 (0.100): 0.030*\"birth\" + 0.027*\"control\" + 0.020*\"woman\" + 0.014*\"said\" + 0.013*\"phipps\" + 0.010*\"davis\" + 0.010*\"condition\" + 0.008*\"pill\" + 0.008*\"health\" + 0.008*\"endometriosis\"\n",
      "2019-10-29 00:40:32,376 : INFO : topic #0 (0.100): 0.034*\"control\" + 0.031*\"birth\" + 0.020*\"said\" + 0.013*\"woman\" + 0.011*\"phipps\" + 0.010*\"endometriosis\" + 0.010*\"condition\" + 0.009*\"davis\" + 0.009*\"health\" + 0.009*\"ovary\"\n",
      "2019-10-29 00:40:32,378 : INFO : topic #6 (0.100): 0.024*\"birth\" + 0.024*\"control\" + 0.013*\"said\" + 0.011*\"health\" + 0.011*\"woman\" + 0.010*\"davis\" + 0.008*\"endometriosis\" + 0.008*\"phipps\" + 0.008*\"jarnagin\" + 0.008*\"allison\"\n",
      "2019-10-29 00:40:32,380 : INFO : topic diff=0.840286, rho=1.000000\n",
      "2019-10-29 00:40:32,864 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:32,873 : INFO : built Dictionary(678 unique tokens: ['although', 'let', 'ammonia', 'portion', 'happy']...) from 5 documents (total 6740 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:32,883 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:32,886 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:32,889 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:32,896 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:32,899 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:33,116 : INFO : -8.185 per-word bound, 291.0 perplexity estimate based on a held-out corpus of 5 documents with 6740 words\n",
      "2019-10-29 00:40:33,117 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:33,127 : INFO : topic #1 (0.100): 0.035*\"vinegar\" + 0.018*\"say\" + 0.018*\"apple\" + 0.016*\"cider\" + 0.012*\"use\" + 0.011*\"study\" + 0.008*\"people\" + 0.007*\"natural\" + 0.007*\"might\" + 0.007*\"could\"\n",
      "2019-10-29 00:40:33,129 : INFO : topic #6 (0.100): 0.034*\"vinegar\" + 0.024*\"apple\" + 0.021*\"say\" + 0.017*\"cider\" + 0.011*\"study\" + 0.010*\"use\" + 0.008*\"also\" + 0.008*\"people\" + 0.007*\"natural\" + 0.006*\"might\"\n",
      "2019-10-29 00:40:33,130 : INFO : topic #2 (0.100): 0.036*\"vinegar\" + 0.020*\"cider\" + 0.014*\"apple\" + 0.013*\"say\" + 0.009*\"use\" + 0.008*\"could\" + 0.008*\"study\" + 0.008*\"diabetes\" + 0.007*\"might\" + 0.007*\"home\"\n",
      "2019-10-29 00:40:33,132 : INFO : topic #7 (0.100): 0.044*\"vinegar\" + 0.021*\"apple\" + 0.019*\"say\" + 0.018*\"cider\" + 0.014*\"study\" + 0.009*\"use\" + 0.008*\"people\" + 0.008*\"also\" + 0.007*\"could\" + 0.007*\"might\"\n",
      "2019-10-29 00:40:33,134 : INFO : topic #0 (0.100): 0.045*\"vinegar\" + 0.026*\"say\" + 0.023*\"apple\" + 0.014*\"cider\" + 0.011*\"use\" + 0.010*\"study\" + 0.008*\"could\" + 0.007*\"also\" + 0.007*\"help\" + 0.007*\"people\"\n",
      "2019-10-29 00:40:33,135 : INFO : topic diff=0.931431, rho=1.000000\n",
      "2019-10-29 00:40:33,541 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:33,543 : INFO : built Dictionary(112 unique tokens: ['afterward', 'de', 'undaunted', 'come', 'brazil']...) from 5 documents (total 650 corpus positions)\n",
      "2019-10-29 00:40:33,545 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:33,546 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:33,547 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:33,550 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:33,551 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:33,601 : INFO : -7.354 per-word bound, 163.6 perplexity estimate based on a held-out corpus of 5 documents with 650 words\n",
      "2019-10-29 00:40:33,603 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:33,616 : INFO : topic #6 (0.100): 0.042*\"alvim\" + 0.019*\"mma\" + 0.017*\"ticket\" + 0.016*\"cage\" + 0.016*\"event\" + 0.015*\"happened\" + 0.015*\"girlfriend\" + 0.015*\"change\" + 0.015*\"enough\" + 0.015*\"welterweight\"\n",
      "2019-10-29 00:40:33,624 : INFO : topic #5 (0.100): 0.050*\"alvim\" + 0.017*\"mma\" + 0.017*\"enough\" + 0.016*\"change\" + 0.016*\"fighting\" + 0.016*\"champion\" + 0.016*\"cage\" + 0.015*\"ticket\" + 0.015*\"happened\" + 0.013*\"welterweight\"\n",
      "2019-10-29 00:40:33,632 : INFO : topic #8 (0.100): 0.046*\"alvim\" + 0.018*\"mma\" + 0.017*\"event\" + 0.016*\"girlfriend\" + 0.016*\"enough\" + 0.015*\"welterweight\" + 0.015*\"happened\" + 0.015*\"fighting\" + 0.015*\"cage\" + 0.014*\"ticket\"\n",
      "2019-10-29 00:40:33,635 : INFO : topic #7 (0.100): 0.053*\"alvim\" + 0.021*\"mma\" + 0.018*\"cage\" + 0.016*\"ticket\" + 0.015*\"change\" + 0.015*\"fighting\" + 0.015*\"enough\" + 0.014*\"event\" + 0.014*\"champion\" + 0.013*\"welterweight\"\n",
      "2019-10-29 00:40:33,643 : INFO : topic #4 (0.100): 0.046*\"alvim\" + 0.022*\"mma\" + 0.016*\"ticket\" + 0.015*\"event\" + 0.015*\"change\" + 0.015*\"welterweight\" + 0.014*\"cage\" + 0.014*\"fighting\" + 0.014*\"girlfriend\" + 0.013*\"champion\"\n",
      "2019-10-29 00:40:33,650 : INFO : topic diff=0.658989, rho=1.000000\n",
      "2019-10-29 00:40:34,087 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:34,092 : INFO : built Dictionary(319 unique tokens: ['forward', 'let', 'energy', 'end', 'appreciation']...) from 5 documents (total 2970 corpus positions)\n",
      "2019-10-29 00:40:34,098 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:34,100 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:34,104 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:34,108 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:34,111 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:34,234 : INFO : -7.533 per-word bound, 185.2 perplexity estimate based on a held-out corpus of 5 documents with 2970 words\n",
      "2019-10-29 00:40:34,237 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:34,246 : INFO : topic #0 (0.100): 0.037*\"kid\" + 0.028*\"said\" + 0.027*\"parent\" + 0.027*\"want\" + 0.023*\"child\" + 0.016*\"spoiled\" + 0.012*\"set\" + 0.011*\"ferrara\" + 0.010*\"lieber\" + 0.009*\"please\"\n",
      "2019-10-29 00:40:34,249 : INFO : topic #6 (0.100): 0.026*\"kid\" + 0.024*\"parent\" + 0.024*\"child\" + 0.023*\"spoiled\" + 0.022*\"want\" + 0.018*\"said\" + 0.012*\"limit\" + 0.012*\"lieber\" + 0.011*\"say\" + 0.009*\"please\"\n",
      "2019-10-29 00:40:34,252 : INFO : topic #4 (0.100): 0.028*\"kid\" + 0.028*\"parent\" + 0.023*\"said\" + 0.023*\"child\" + 0.019*\"want\" + 0.018*\"spoiled\" + 0.014*\"set\" + 0.013*\"limit\" + 0.013*\"lieber\" + 0.011*\"ferrara\"\n",
      "2019-10-29 00:40:34,255 : INFO : topic #1 (0.100): 0.026*\"kid\" + 0.026*\"said\" + 0.024*\"want\" + 0.024*\"child\" + 0.023*\"parent\" + 0.018*\"spoiled\" + 0.013*\"limit\" + 0.013*\"lieber\" + 0.011*\"set\" + 0.009*\"ferrara\"\n",
      "2019-10-29 00:40:34,258 : INFO : topic #8 (0.100): 0.030*\"kid\" + 0.028*\"child\" + 0.024*\"said\" + 0.022*\"want\" + 0.022*\"spoiled\" + 0.018*\"parent\" + 0.013*\"set\" + 0.012*\"lieber\" + 0.012*\"limit\" + 0.010*\"please\"\n",
      "2019-10-29 00:40:34,261 : INFO : topic diff=0.930957, rho=1.000000\n",
      "2019-10-29 00:40:34,686 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:34,690 : INFO : built Dictionary(328 unique tokens: ['although', 'talking', 'product', 'method', 'de']...) from 5 documents (total 2985 corpus positions)\n",
      "2019-10-29 00:40:34,695 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:34,697 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:34,699 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:34,703 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:34,706 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:34,816 : INFO : -7.591 per-word bound, 192.8 perplexity estimate based on a held-out corpus of 5 documents with 2985 words\n",
      "2019-10-29 00:40:34,817 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:34,824 : INFO : topic #0 (0.100): 0.028*\"tony\" + 0.025*\"chocolate\" + 0.021*\"cocoa\" + 0.019*\"chocolonely\" + 0.017*\"product\" + 0.015*\"say\" + 0.013*\"labor\" + 0.013*\"company\" + 0.012*\"beltman\" + 0.012*\"hide\"\n",
      "2019-10-29 00:40:34,826 : INFO : topic #2 (0.100): 0.031*\"chocolate\" + 0.028*\"chocolonely\" + 0.027*\"tony\" + 0.017*\"say\" + 0.016*\"cocoa\" + 0.015*\"company\" + 0.014*\"slave\" + 0.014*\"product\" + 0.013*\"photo\" + 0.013*\"labor\"\n",
      "2019-10-29 00:40:34,827 : INFO : topic #7 (0.100): 0.035*\"chocolate\" + 0.026*\"tony\" + 0.022*\"cocoa\" + 0.021*\"chocolonely\" + 0.019*\"company\" + 0.015*\"product\" + 0.014*\"labor\" + 0.012*\"say\" + 0.011*\"slave\" + 0.011*\"industry\"\n",
      "2019-10-29 00:40:34,829 : INFO : topic #4 (0.100): 0.029*\"chocolate\" + 0.024*\"tony\" + 0.020*\"cocoa\" + 0.019*\"chocolonely\" + 0.015*\"company\" + 0.013*\"product\" + 0.012*\"slave\" + 0.012*\"hide\" + 0.011*\"labor\" + 0.011*\"caption\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:34,830 : INFO : topic #5 (0.100): 0.030*\"chocolate\" + 0.023*\"chocolonely\" + 0.022*\"tony\" + 0.018*\"cocoa\" + 0.015*\"company\" + 0.015*\"say\" + 0.015*\"product\" + 0.014*\"caption\" + 0.013*\"labor\" + 0.011*\"photo\"\n",
      "2019-10-29 00:40:34,832 : INFO : topic diff=0.937453, rho=1.000000\n",
      "2019-10-29 00:40:35,264 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:35,268 : INFO : built Dictionary(249 unique tokens: ['enterprise', 'book', 'campaign', 'party', 'come']...) from 5 documents (total 1985 corpus positions)\n",
      "2019-10-29 00:40:35,271 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:35,272 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:35,274 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:35,278 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:35,279 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:35,408 : INFO : -7.509 per-word bound, 182.1 perplexity estimate based on a held-out corpus of 5 documents with 1985 words\n",
      "2019-10-29 00:40:35,410 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:35,420 : INFO : topic #2 (0.100): 0.038*\"williams\" + 0.024*\"election\" + 0.022*\"medium\" + 0.019*\"say\" + 0.014*\"candidate\" + 0.014*\"ghana\" + 0.014*\"people\" + 0.014*\"nigeria\" + 0.013*\"young\" + 0.013*\"presidential\"\n",
      "2019-10-29 00:40:35,421 : INFO : topic #6 (0.100): 0.038*\"williams\" + 0.021*\"medium\" + 0.018*\"election\" + 0.017*\"ghana\" + 0.017*\"say\" + 0.014*\"people\" + 0.012*\"young\" + 0.012*\"statecraft\" + 0.012*\"jonathan\" + 0.012*\"leader\"\n",
      "2019-10-29 00:40:35,423 : INFO : topic #7 (0.100): 0.033*\"williams\" + 0.027*\"medium\" + 0.021*\"election\" + 0.018*\"candidate\" + 0.014*\"say\" + 0.014*\"buhari\" + 0.013*\"statecraft\" + 0.013*\"ghana\" + 0.012*\"people\" + 0.012*\"jonathan\"\n",
      "2019-10-29 00:40:35,425 : INFO : topic #3 (0.100): 0.035*\"williams\" + 0.022*\"medium\" + 0.017*\"ghana\" + 0.016*\"election\" + 0.016*\"people\" + 0.016*\"say\" + 0.015*\"young\" + 0.014*\"candidate\" + 0.013*\"jonathan\" + 0.012*\"presidential\"\n",
      "2019-10-29 00:40:35,427 : INFO : topic #8 (0.100): 0.024*\"williams\" + 0.020*\"medium\" + 0.018*\"election\" + 0.017*\"ghana\" + 0.016*\"candidate\" + 0.015*\"say\" + 0.014*\"people\" + 0.013*\"jonathan\" + 0.012*\"campaign\" + 0.010*\"leader\"\n",
      "2019-10-29 00:40:35,429 : INFO : topic diff=0.901389, rho=1.000000\n",
      "2019-10-29 00:40:35,898 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:35,903 : INFO : built Dictionary(314 unique tokens: ['recover', 'revitalize', 'de', 'prove', 'victory']...) from 5 documents (total 2600 corpus positions)\n",
      "2019-10-29 00:40:35,906 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:35,908 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:35,909 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:35,912 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:35,913 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:36,031 : INFO : -7.683 per-word bound, 205.5 perplexity estimate based on a held-out corpus of 5 documents with 2600 words\n",
      "2019-10-29 00:40:36,032 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:36,040 : INFO : topic #6 (0.100): 0.038*\"station\" + 0.034*\"canfranc\" + 0.018*\"say\" + 0.018*\"sánchez\" + 0.014*\"spain\" + 0.013*\"tourism\" + 0.013*\"morale\" + 0.012*\"nazi\" + 0.011*\"war\" + 0.011*\"gold\"\n",
      "2019-10-29 00:40:36,041 : INFO : topic #8 (0.100): 0.041*\"canfranc\" + 0.028*\"station\" + 0.018*\"say\" + 0.012*\"sánchez\" + 0.012*\"war\" + 0.011*\"morale\" + 0.011*\"tourism\" + 0.011*\"gold\" + 0.010*\"campo\" + 0.010*\"new\"\n",
      "2019-10-29 00:40:36,043 : INFO : topic #9 (0.100): 0.043*\"station\" + 0.030*\"canfranc\" + 0.019*\"morale\" + 0.016*\"say\" + 0.011*\"world\" + 0.011*\"gold\" + 0.011*\"war\" + 0.010*\"nazi\" + 0.010*\"fraile\" + 0.010*\"spain\"\n",
      "2019-10-29 00:40:36,044 : INFO : topic #2 (0.100): 0.040*\"canfranc\" + 0.040*\"station\" + 0.015*\"say\" + 0.013*\"morale\" + 0.013*\"war\" + 0.012*\"tourism\" + 0.011*\"gold\" + 0.011*\"spain\" + 0.011*\"nazi\" + 0.011*\"sánchez\"\n",
      "2019-10-29 00:40:36,046 : INFO : topic #5 (0.100): 0.041*\"canfranc\" + 0.035*\"station\" + 0.016*\"say\" + 0.016*\"spain\" + 0.014*\"sánchez\" + 0.013*\"gold\" + 0.012*\"tourism\" + 0.011*\"morale\" + 0.010*\"world\" + 0.010*\"war\"\n",
      "2019-10-29 00:40:36,047 : INFO : topic diff=0.862765, rho=1.000000\n",
      "2019-10-29 00:40:36,477 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:36,483 : INFO : built Dictionary(358 unique tokens: ['although', 'earned', 'paradise', 'wave', 'deep']...) from 5 documents (total 3705 corpus positions)\n",
      "2019-10-29 00:40:36,488 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:36,489 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:36,490 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:36,494 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:36,495 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:36,617 : INFO : -7.518 per-word bound, 183.3 perplexity estimate based on a held-out corpus of 5 documents with 3705 words\n",
      "2019-10-29 00:40:36,619 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:36,629 : INFO : topic #2 (0.100): 0.034*\"surf\" + 0.032*\"wave\" + 0.022*\"year\" + 0.017*\"dakar\" + 0.017*\"surfer\" + 0.016*\"swell\" + 0.015*\"spot\" + 0.015*\"surfing\" + 0.014*\"tourist\" + 0.013*\"camp\"\n",
      "2019-10-29 00:40:36,632 : INFO : topic #3 (0.100): 0.042*\"surf\" + 0.033*\"wave\" + 0.021*\"dakar\" + 0.020*\"surfing\" + 0.019*\"year\" + 0.018*\"surfer\" + 0.015*\"swell\" + 0.014*\"africa\" + 0.013*\"spot\" + 0.012*\"catching\"\n",
      "2019-10-29 00:40:36,635 : INFO : topic #8 (0.100): 0.039*\"surf\" + 0.027*\"wave\" + 0.019*\"year\" + 0.019*\"dakar\" + 0.018*\"surfer\" + 0.013*\"tourist\" + 0.013*\"foot\" + 0.013*\"surfing\" + 0.013*\"swell\" + 0.013*\"spot\"\n",
      "2019-10-29 00:40:36,639 : INFO : topic #1 (0.100): 0.037*\"surf\" + 0.028*\"wave\" + 0.020*\"year\" + 0.019*\"surfing\" + 0.019*\"dakar\" + 0.018*\"swell\" + 0.017*\"surfer\" + 0.014*\"tourist\" + 0.013*\"spot\" + 0.012*\"foot\"\n",
      "2019-10-29 00:40:36,642 : INFO : topic #7 (0.100): 0.049*\"surf\" + 0.035*\"wave\" + 0.030*\"dakar\" + 0.020*\"surfing\" + 0.018*\"year\" + 0.017*\"surfer\" + 0.016*\"spot\" + 0.015*\"swell\" + 0.013*\"local\" + 0.012*\"tourist\"\n",
      "2019-10-29 00:40:36,645 : INFO : topic diff=1.000877, rho=1.000000\n",
      "2019-10-29 00:40:37,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:37,118 : INFO : built Dictionary(258 unique tokens: ['concern', 'school', 'size', 'let', 'focus']...) from 5 documents (total 2100 corpus positions)\n",
      "2019-10-29 00:40:37,121 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:37,124 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:37,128 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:37,132 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:37,135 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:37,232 : INFO : -7.515 per-word bound, 182.9 perplexity estimate based on a held-out corpus of 5 documents with 2100 words\n",
      "2019-10-29 00:40:37,233 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:37,239 : INFO : topic #7 (0.100): 0.037*\"school\" + 0.034*\"learning\" + 0.024*\"space\" + 0.016*\"environment\" + 0.015*\"really\" + 0.014*\"way\" + 0.014*\"design\" + 0.013*\"child\" + 0.013*\"color\" + 0.012*\"designed\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:37,241 : INFO : topic #4 (0.100): 0.036*\"school\" + 0.027*\"learning\" + 0.024*\"space\" + 0.023*\"environment\" + 0.017*\"really\" + 0.016*\"way\" + 0.015*\"design\" + 0.012*\"create\" + 0.012*\"color\" + 0.011*\"one\"\n",
      "2019-10-29 00:40:37,243 : INFO : topic #0 (0.100): 0.041*\"school\" + 0.039*\"learning\" + 0.020*\"space\" + 0.018*\"design\" + 0.016*\"color\" + 0.015*\"really\" + 0.015*\"child\" + 0.015*\"way\" + 0.014*\"environment\" + 0.014*\"one\"\n",
      "2019-10-29 00:40:37,246 : INFO : topic #9 (0.100): 0.044*\"school\" + 0.026*\"space\" + 0.020*\"learning\" + 0.019*\"environment\" + 0.015*\"really\" + 0.015*\"way\" + 0.015*\"design\" + 0.014*\"color\" + 0.013*\"child\" + 0.012*\"one\"\n",
      "2019-10-29 00:40:37,248 : INFO : topic #2 (0.100): 0.052*\"school\" + 0.027*\"learning\" + 0.026*\"environment\" + 0.020*\"way\" + 0.018*\"space\" + 0.015*\"child\" + 0.015*\"really\" + 0.014*\"design\" + 0.013*\"designed\" + 0.012*\"color\"\n",
      "2019-10-29 00:40:37,251 : INFO : topic diff=0.870852, rho=1.000000\n",
      "2019-10-29 00:40:37,682 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:37,691 : INFO : built Dictionary(548 unique tokens: ['phase', 'grew', 'allergic', 'recommendation', 'orphan']...) from 5 documents (total 4910 corpus positions)\n",
      "2019-10-29 00:40:37,696 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:37,697 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:37,698 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:37,703 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:37,705 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:37,874 : INFO : -8.108 per-word bound, 276.0 perplexity estimate based on a held-out corpus of 5 documents with 4910 words\n",
      "2019-10-29 00:40:37,875 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:37,885 : INFO : topic #4 (0.100): 0.026*\"said\" + 0.022*\"gene\" + 0.014*\"therapy\" + 0.013*\"patient\" + 0.013*\"christian\" + 0.011*\"mahajan\" + 0.011*\"would\" + 0.010*\"cell\" + 0.009*\"virus\" + 0.009*\"treatment\"\n",
      "2019-10-29 00:40:37,887 : INFO : topic #5 (0.100): 0.021*\"said\" + 0.017*\"therapy\" + 0.016*\"christian\" + 0.016*\"gene\" + 0.011*\"would\" + 0.010*\"patient\" + 0.010*\"drug\" + 0.010*\"cell\" + 0.009*\"mahajan\" + 0.009*\"disease\"\n",
      "2019-10-29 00:40:37,888 : INFO : topic #2 (0.100): 0.033*\"said\" + 0.020*\"gene\" + 0.017*\"would\" + 0.016*\"therapy\" + 0.015*\"cell\" + 0.014*\"christian\" + 0.011*\"mahajan\" + 0.010*\"patient\" + 0.010*\"eye\" + 0.009*\"virus\"\n",
      "2019-10-29 00:40:37,892 : INFO : topic #8 (0.100): 0.030*\"said\" + 0.025*\"gene\" + 0.014*\"christian\" + 0.012*\"disease\" + 0.012*\"eye\" + 0.011*\"therapy\" + 0.011*\"would\" + 0.010*\"virus\" + 0.010*\"drug\" + 0.009*\"vision\"\n",
      "2019-10-29 00:40:37,895 : INFO : topic #7 (0.100): 0.022*\"said\" + 0.019*\"gene\" + 0.013*\"christian\" + 0.012*\"would\" + 0.011*\"patient\" + 0.011*\"virus\" + 0.011*\"cell\" + 0.010*\"therapy\" + 0.010*\"disease\" + 0.009*\"eye\"\n",
      "2019-10-29 00:40:37,898 : INFO : topic diff=0.908642, rho=1.000000\n",
      "2019-10-29 00:40:38,334 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:38,340 : INFO : built Dictionary(342 unique tokens: ['anniversary', 'attending', 'used', 'beijing', 'barman']...) from 5 documents (total 2515 corpus positions)\n",
      "2019-10-29 00:40:38,344 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:38,345 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:38,346 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:38,350 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:38,352 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:38,464 : INFO : -7.935 per-word bound, 244.7 perplexity estimate based on a held-out corpus of 5 documents with 2515 words\n",
      "2019-10-29 00:40:38,466 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:38,474 : INFO : topic #0 (0.100): 0.045*\"raffle\" + 0.024*\"singapore\" + 0.023*\"gin\" + 0.022*\"galsworthy\" + 0.016*\"sipsmith\" + 0.012*\"one\" + 0.012*\"say\" + 0.011*\"great\" + 0.010*\"sling\" + 0.010*\"hotel\"\n",
      "2019-10-29 00:40:38,477 : INFO : topic #6 (0.100): 0.035*\"raffle\" + 0.031*\"gin\" + 0.022*\"singapore\" + 0.020*\"sipsmith\" + 0.017*\"galsworthy\" + 0.012*\"sling\" + 0.012*\"great\" + 0.012*\"one\" + 0.010*\"ingredient\" + 0.009*\"hotel\"\n",
      "2019-10-29 00:40:38,480 : INFO : topic #8 (0.100): 0.035*\"raffle\" + 0.030*\"galsworthy\" + 0.027*\"gin\" + 0.021*\"sipsmith\" + 0.021*\"singapore\" + 0.011*\"one\" + 0.010*\"say\" + 0.010*\"great\" + 0.009*\"would\" + 0.009*\"sling\"\n",
      "2019-10-29 00:40:38,483 : INFO : topic #1 (0.100): 0.051*\"raffle\" + 0.030*\"gin\" + 0.021*\"singapore\" + 0.018*\"galsworthy\" + 0.016*\"sipsmith\" + 0.014*\"one\" + 0.011*\"great\" + 0.010*\"ingredient\" + 0.009*\"year\" + 0.008*\"sling\"\n",
      "2019-10-29 00:40:38,486 : INFO : topic #2 (0.100): 0.033*\"raffle\" + 0.030*\"singapore\" + 0.027*\"gin\" + 0.019*\"galsworthy\" + 0.013*\"sipsmith\" + 0.012*\"sling\" + 0.011*\"great\" + 0.010*\"say\" + 0.009*\"hotel\" + 0.009*\"one\"\n",
      "2019-10-29 00:40:38,490 : INFO : topic diff=0.863304, rho=1.000000\n",
      "2019-10-29 00:40:38,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:38,904 : INFO : built Dictionary(104 unique tokens: ['school', 'significant', 'special', 'severely', 'regulation']...) from 5 documents (total 740 corpus positions)\n",
      "2019-10-29 00:40:38,906 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:38,907 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:38,909 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:38,911 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:38,912 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:38,963 : INFO : -6.904 per-word bound, 119.8 perplexity estimate based on a held-out corpus of 5 documents with 740 words\n",
      "2019-10-29 00:40:38,965 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:38,974 : INFO : topic #6 (0.100): 0.045*\"heroin\" + 0.031*\"diacetylmorphine\" + 0.030*\"doctor\" + 0.030*\"regulation\" + 0.029*\"treatment\" + 0.027*\"access\" + 0.023*\"health\" + 0.019*\"canada\" + 0.017*\"addicted\" + 0.017*\"patient\"\n",
      "2019-10-29 00:40:38,978 : INFO : topic #3 (0.100): 0.037*\"heroin\" + 0.029*\"doctor\" + 0.025*\"access\" + 0.024*\"treatment\" + 0.024*\"diacetylmorphine\" + 0.024*\"health\" + 0.021*\"regulation\" + 0.020*\"addicted\" + 0.017*\"patient\" + 0.016*\"use\"\n",
      "2019-10-29 00:40:38,980 : INFO : topic #1 (0.100): 0.035*\"doctor\" + 0.031*\"heroin\" + 0.027*\"access\" + 0.025*\"regulation\" + 0.023*\"health\" + 0.023*\"treatment\" + 0.022*\"diacetylmorphine\" + 0.020*\"addicted\" + 0.016*\"canada\" + 0.016*\"allow\"\n",
      "2019-10-29 00:40:38,982 : INFO : topic #0 (0.100): 0.033*\"health\" + 0.032*\"doctor\" + 0.031*\"heroin\" + 0.027*\"regulation\" + 0.027*\"treatment\" + 0.026*\"canada\" + 0.024*\"access\" + 0.023*\"patient\" + 0.019*\"diacetylmorphine\" + 0.017*\"addicted\"\n",
      "2019-10-29 00:40:38,983 : INFO : topic #8 (0.100): 0.036*\"doctor\" + 0.034*\"heroin\" + 0.028*\"treatment\" + 0.027*\"diacetylmorphine\" + 0.025*\"access\" + 0.024*\"regulation\" + 0.024*\"patient\" + 0.023*\"health\" + 0.019*\"canada\" + 0.016*\"addicted\"\n",
      "2019-10-29 00:40:38,985 : INFO : topic diff=0.798452, rho=1.000000\n",
      "2019-10-29 00:40:39,411 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:39,413 : INFO : built Dictionary(72 unique tokens: ['blocked', 'fox', 'story', 'weinstein', 'prominent']...) from 5 documents (total 470 corpus positions)\n",
      "2019-10-29 00:40:39,415 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:39,416 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:39,417 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:39,420 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:39,421 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:39,454 : INFO : -6.760 per-word bound, 108.4 perplexity estimate based on a held-out corpus of 5 documents with 470 words\n",
      "2019-10-29 00:40:39,455 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:39,462 : INFO : topic #3 (0.100): 0.044*\"sivan\" + 0.037*\"said\" + 0.028*\"story\" + 0.025*\"anyone\" + 0.023*\"weinstein\" + 0.023*\"secret\" + 0.022*\"new\" + 0.022*\"accuser\" + 0.022*\"told\" + 0.021*\"camerota\"\n",
      "2019-10-29 00:40:39,465 : INFO : topic #2 (0.100): 0.063*\"sivan\" + 0.048*\"said\" + 0.029*\"story\" + 0.028*\"weinstein\" + 0.023*\"accuser\" + 0.022*\"harvey\" + 0.022*\"new\" + 0.021*\"brought\" + 0.020*\"camerota\" + 0.020*\"secret\"\n",
      "2019-10-29 00:40:39,469 : INFO : topic #7 (0.100): 0.046*\"sivan\" + 0.036*\"weinstein\" + 0.029*\"said\" + 0.026*\"story\" + 0.024*\"told\" + 0.023*\"new\" + 0.022*\"restaurant\" + 0.022*\"cnn\" + 0.021*\"anyone\" + 0.021*\"brought\"\n",
      "2019-10-29 00:40:39,473 : INFO : topic #0 (0.100): 0.042*\"sivan\" + 0.041*\"said\" + 0.034*\"story\" + 0.026*\"weinstein\" + 0.023*\"harvey\" + 0.022*\"many\" + 0.022*\"accuser\" + 0.022*\"secret\" + 0.021*\"camerota\" + 0.021*\"restaurant\"\n",
      "2019-10-29 00:40:39,478 : INFO : topic #5 (0.100): 0.053*\"said\" + 0.042*\"sivan\" + 0.028*\"story\" + 0.028*\"weinstein\" + 0.027*\"cnn\" + 0.026*\"many\" + 0.025*\"told\" + 0.024*\"restaurant\" + 0.021*\"harvey\" + 0.021*\"accuser\"\n",
      "2019-10-29 00:40:39,482 : INFO : topic diff=0.723976, rho=1.000000\n",
      "2019-10-29 00:40:39,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:39,908 : INFO : built Dictionary(345 unique tokens: ['previously', 'relation', 'memo', 'inquiry', 'blatant']...) from 5 documents (total 3105 corpus positions)\n",
      "2019-10-29 00:40:39,914 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:39,916 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:39,918 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:39,922 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:39,925 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:40,044 : INFO : -7.653 per-word bound, 201.2 perplexity estimate based on a held-out corpus of 5 documents with 3105 words\n",
      "2019-10-29 00:40:40,045 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:40,052 : INFO : topic #1 (0.100): 0.029*\"nunes\" + 0.025*\"committee\" + 0.025*\"said\" + 0.022*\"subpoena\" + 0.018*\"investigation\" + 0.013*\"conaway\" + 0.013*\"trump\" + 0.012*\"intelligence\" + 0.012*\"house\" + 0.010*\"source\"\n",
      "2019-10-29 00:40:40,054 : INFO : topic #6 (0.100): 0.027*\"nunes\" + 0.026*\"committee\" + 0.024*\"investigation\" + 0.024*\"said\" + 0.023*\"subpoena\" + 0.015*\"conaway\" + 0.015*\"source\" + 0.012*\"trump\" + 0.011*\"intelligence\" + 0.010*\"rep\"\n",
      "2019-10-29 00:40:40,058 : INFO : topic #0 (0.100): 0.044*\"nunes\" + 0.028*\"committee\" + 0.024*\"said\" + 0.024*\"subpoena\" + 0.024*\"investigation\" + 0.014*\"conaway\" + 0.012*\"russia\" + 0.011*\"cnn\" + 0.011*\"trump\" + 0.010*\"source\"\n",
      "2019-10-29 00:40:40,061 : INFO : topic #9 (0.100): 0.040*\"nunes\" + 0.036*\"subpoena\" + 0.027*\"investigation\" + 0.024*\"committee\" + 0.023*\"said\" + 0.013*\"trump\" + 0.011*\"cnn\" + 0.010*\"source\" + 0.010*\"intelligence\" + 0.009*\"conaway\"\n",
      "2019-10-29 00:40:40,064 : INFO : topic #3 (0.100): 0.038*\"nunes\" + 0.028*\"committee\" + 0.027*\"subpoena\" + 0.023*\"investigation\" + 0.017*\"said\" + 0.015*\"conaway\" + 0.013*\"russia\" + 0.012*\"trump\" + 0.011*\"cnn\" + 0.010*\"house\"\n",
      "2019-10-29 00:40:40,066 : INFO : topic diff=0.896416, rho=1.000000\n",
      "2019-10-29 00:40:40,482 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:40,484 : INFO : built Dictionary(93 unique tokens: ['book', 'end', 'omar', 'concacaf', 'home']...) from 5 documents (total 625 corpus positions)\n",
      "2019-10-29 00:40:40,486 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:40,488 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:40,489 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:40,492 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:40,494 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:40,532 : INFO : -6.913 per-word bound, 120.5 perplexity estimate based on a held-out corpus of 5 documents with 625 words\n",
      "2019-10-29 00:40:40,535 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:40,543 : INFO : topic #4 (0.100): 0.030*\"u\" + 0.028*\"usmnt\" + 0.027*\"tobago\" + 0.027*\"world\" + 0.022*\"cup\" + 0.022*\"trinidad\" + 0.021*\"place\" + 0.021*\"failed\" + 0.020*\"argentina\" + 0.019*\"team\"\n",
      "2019-10-29 00:40:40,546 : INFO : topic #6 (0.100): 0.036*\"u\" + 0.036*\"world\" + 0.030*\"cup\" + 0.029*\"team\" + 0.025*\"trinidad\" + 0.022*\"failed\" + 0.020*\"place\" + 0.018*\"defeat\" + 0.017*\"qualify\" + 0.017*\"christian\"\n",
      "2019-10-29 00:40:40,550 : INFO : topic #9 (0.100): 0.033*\"cup\" + 0.031*\"u\" + 0.026*\"world\" + 0.024*\"usmnt\" + 0.022*\"place\" + 0.020*\"team\" + 0.020*\"tobago\" + 0.019*\"failed\" + 0.018*\"trinidad\" + 0.018*\"goal\"\n",
      "2019-10-29 00:40:40,553 : INFO : topic #2 (0.100): 0.036*\"cup\" + 0.030*\"world\" + 0.022*\"team\" + 0.021*\"usmnt\" + 0.020*\"trinidad\" + 0.020*\"tobago\" + 0.020*\"u\" + 0.020*\"failed\" + 0.018*\"argentina\" + 0.018*\"pulisic\"\n",
      "2019-10-29 00:40:40,557 : INFO : topic #8 (0.100): 0.030*\"u\" + 0.030*\"trinidad\" + 0.026*\"world\" + 0.024*\"cup\" + 0.023*\"tobago\" + 0.023*\"place\" + 0.022*\"failed\" + 0.021*\"team\" + 0.020*\"usmnt\" + 0.019*\"pulisic\"\n",
      "2019-10-29 00:40:40,560 : INFO : topic diff=0.760997, rho=1.000000\n",
      "2019-10-29 00:40:41,076 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:41,094 : INFO : built Dictionary(1121 unique tokens: ['although', 'let', 'paradise', 'fide', 'repeat']...) from 5 documents (total 10230 corpus positions)\n",
      "2019-10-29 00:40:41,106 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:41,108 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:41,109 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:41,115 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:41,118 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:41,511 : INFO : -8.782 per-word bound, 440.3 perplexity estimate based on a held-out corpus of 5 documents with 10230 words\n",
      "2019-10-29 00:40:41,513 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:41,527 : INFO : topic #5 (0.100): 0.016*\"food\" + 0.009*\"dish\" + 0.008*\"best\" + 0.008*\"one\" + 0.008*\"sauce\" + 0.008*\"butter\" + 0.007*\"rice\" + 0.007*\"chicken\" + 0.006*\"delicious\" + 0.005*\"tomato\"\n",
      "2019-10-29 00:40:41,530 : INFO : topic #4 (0.100): 0.012*\"dish\" + 0.011*\"food\" + 0.007*\"sauce\" + 0.007*\"chicken\" + 0.006*\"best\" + 0.006*\"one\" + 0.006*\"butter\" + 0.006*\"delicious\" + 0.006*\"rice\" + 0.006*\"taste\"\n",
      "2019-10-29 00:40:41,533 : INFO : topic #2 (0.100): 0.012*\"best\" + 0.011*\"food\" + 0.009*\"dish\" + 0.008*\"butter\" + 0.008*\"chicken\" + 0.007*\"delicious\" + 0.007*\"taste\" + 0.006*\"sauce\" + 0.006*\"tomato\" + 0.006*\"rice\"\n",
      "2019-10-29 00:40:41,536 : INFO : topic #9 (0.100): 0.011*\"food\" + 0.010*\"best\" + 0.009*\"chicken\" + 0.008*\"one\" + 0.008*\"dish\" + 0.008*\"butter\" + 0.008*\"rice\" + 0.006*\"world\" + 0.006*\"taste\" + 0.006*\"sauce\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:41,540 : INFO : topic #3 (0.100): 0.011*\"best\" + 0.011*\"food\" + 0.010*\"dish\" + 0.009*\"butter\" + 0.007*\"sauce\" + 0.007*\"taste\" + 0.007*\"one\" + 0.007*\"chicken\" + 0.007*\"delicious\" + 0.006*\"rice\"\n",
      "2019-10-29 00:40:41,543 : INFO : topic diff=0.895004, rho=1.000000\n",
      "2019-10-29 00:40:41,980 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:41,983 : INFO : built Dictionary(213 unique tokens: ['trying', 'watch', 'bos', 'despite', 'staff']...) from 5 documents (total 1770 corpus positions)\n",
      "2019-10-29 00:40:41,986 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:41,988 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:41,989 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:41,992 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:41,993 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:42,081 : INFO : -7.301 per-word bound, 157.7 perplexity estimate based on a held-out corpus of 5 documents with 1770 words\n",
      "2019-10-29 00:40:42,082 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:42,089 : INFO : topic #8 (0.100): 0.044*\"tillerson\" + 0.042*\"trump\" + 0.022*\"said\" + 0.019*\"comment\" + 0.016*\"secretary\" + 0.016*\"state\" + 0.015*\"iq\" + 0.014*\"president\" + 0.012*\"added\" + 0.012*\"cnn\"\n",
      "2019-10-29 00:40:42,092 : INFO : topic #7 (0.100): 0.046*\"trump\" + 0.039*\"tillerson\" + 0.020*\"secretary\" + 0.020*\"president\" + 0.016*\"comment\" + 0.014*\"iq\" + 0.014*\"state\" + 0.014*\"said\" + 0.012*\"made\" + 0.012*\"relationship\"\n",
      "2019-10-29 00:40:42,095 : INFO : topic #4 (0.100): 0.048*\"trump\" + 0.033*\"tillerson\" + 0.021*\"said\" + 0.020*\"secretary\" + 0.019*\"president\" + 0.017*\"comment\" + 0.016*\"iq\" + 0.014*\"state\" + 0.013*\"relationship\" + 0.011*\"added\"\n",
      "2019-10-29 00:40:42,098 : INFO : topic #1 (0.100): 0.044*\"trump\" + 0.038*\"tillerson\" + 0.020*\"comment\" + 0.020*\"president\" + 0.019*\"secretary\" + 0.019*\"said\" + 0.018*\"state\" + 0.012*\"iq\" + 0.012*\"made\" + 0.011*\"told\"\n",
      "2019-10-29 00:40:42,101 : INFO : topic #2 (0.100): 0.049*\"trump\" + 0.028*\"tillerson\" + 0.027*\"said\" + 0.022*\"secretary\" + 0.018*\"president\" + 0.016*\"comment\" + 0.014*\"iq\" + 0.014*\"state\" + 0.011*\"added\" + 0.010*\"relationship\"\n",
      "2019-10-29 00:40:42,105 : INFO : topic diff=0.861329, rho=1.000000\n",
      "2019-10-29 00:40:42,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:42,539 : INFO : built Dictionary(354 unique tokens: ['wanting', 'focus', 'enjoy', 'interpret', 'actually']...) from 5 documents (total 3175 corpus positions)\n",
      "2019-10-29 00:40:42,545 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:42,547 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:42,551 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:42,555 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:42,558 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:42,704 : INFO : -7.683 per-word bound, 205.4 perplexity estimate based on a held-out corpus of 5 documents with 3175 words\n",
      "2019-10-29 00:40:42,706 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:42,714 : INFO : topic #1 (0.100): 0.038*\"sex\" + 0.027*\"said\" + 0.022*\"men\" + 0.021*\"heart\" + 0.019*\"health\" + 0.016*\"older\" + 0.016*\"sexual\" + 0.015*\"risk\" + 0.014*\"cardiovascular\" + 0.013*\"woman\"\n",
      "2019-10-29 00:40:42,717 : INFO : topic #5 (0.100): 0.042*\"sex\" + 0.031*\"said\" + 0.021*\"men\" + 0.019*\"health\" + 0.019*\"older\" + 0.019*\"sexual\" + 0.017*\"heart\" + 0.017*\"cardiovascular\" + 0.014*\"risk\" + 0.012*\"woman\"\n",
      "2019-10-29 00:40:42,720 : INFO : topic #9 (0.100): 0.035*\"said\" + 0.025*\"heart\" + 0.022*\"sex\" + 0.021*\"men\" + 0.020*\"older\" + 0.018*\"health\" + 0.017*\"sexual\" + 0.015*\"risk\" + 0.013*\"woman\" + 0.012*\"may\"\n",
      "2019-10-29 00:40:42,724 : INFO : topic #6 (0.100): 0.028*\"said\" + 0.026*\"sex\" + 0.025*\"heart\" + 0.019*\"health\" + 0.017*\"men\" + 0.016*\"sexual\" + 0.016*\"older\" + 0.015*\"cardiovascular\" + 0.015*\"woman\" + 0.014*\"risk\"\n",
      "2019-10-29 00:40:42,727 : INFO : topic #2 (0.100): 0.028*\"sex\" + 0.025*\"heart\" + 0.022*\"said\" + 0.021*\"older\" + 0.020*\"health\" + 0.018*\"men\" + 0.016*\"sexual\" + 0.015*\"woman\" + 0.012*\"risk\" + 0.011*\"may\"\n",
      "2019-10-29 00:40:42,730 : INFO : topic diff=0.889939, rho=1.000000\n",
      "2019-10-29 00:40:43,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:43,462 : INFO : built Dictionary(1323 unique tokens: ['let', 'filed', 'taxpayer', 'happy', 'pediatrician']...) from 5 documents (total 22960 corpus positions)\n",
      "2019-10-29 00:40:43,493 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:43,496 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:43,502 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:43,511 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:43,516 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:43,882 : INFO : -8.360 per-word bound, 328.6 perplexity estimate based on a held-out corpus of 5 documents with 22960 words\n",
      "2019-10-29 00:40:43,884 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:43,897 : INFO : topic #1 (0.100): 0.042*\"child\" + 0.025*\"florida\" + 0.021*\"health\" + 0.021*\"said\" + 0.016*\"state\" + 0.014*\"cm\" + 0.014*\"department\" + 0.010*\"care\" + 0.009*\"plan\" + 0.008*\"medical\"\n",
      "2019-10-29 00:40:43,899 : INFO : topic #4 (0.100): 0.034*\"child\" + 0.032*\"florida\" + 0.025*\"health\" + 0.023*\"said\" + 0.014*\"cm\" + 0.014*\"care\" + 0.013*\"department\" + 0.013*\"state\" + 0.009*\"plan\" + 0.009*\"pediatrician\"\n",
      "2019-10-29 00:40:43,900 : INFO : topic #0 (0.100): 0.035*\"florida\" + 0.034*\"child\" + 0.028*\"said\" + 0.027*\"health\" + 0.016*\"state\" + 0.014*\"cm\" + 0.013*\"department\" + 0.012*\"care\" + 0.009*\"medical\" + 0.009*\"plan\"\n",
      "2019-10-29 00:40:43,901 : INFO : topic #6 (0.100): 0.035*\"child\" + 0.029*\"florida\" + 0.022*\"said\" + 0.021*\"health\" + 0.016*\"department\" + 0.014*\"cm\" + 0.013*\"state\" + 0.009*\"care\" + 0.009*\"plan\" + 0.008*\"pediatrician\"\n",
      "2019-10-29 00:40:43,903 : INFO : topic #9 (0.100): 0.030*\"child\" + 0.028*\"florida\" + 0.023*\"health\" + 0.021*\"said\" + 0.015*\"care\" + 0.015*\"state\" + 0.012*\"plan\" + 0.012*\"cm\" + 0.011*\"department\" + 0.009*\"insurance\"\n",
      "2019-10-29 00:40:43,905 : INFO : topic diff=1.230580, rho=1.000000\n",
      "2019-10-29 00:40:44,353 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:44,360 : INFO : built Dictionary(428 unique tokens: ['shower', 'extent', 'expert', 'stop', 'beijing']...) from 5 documents (total 3795 corpus positions)\n",
      "2019-10-29 00:40:44,365 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:44,366 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:44,368 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:44,372 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:44,373 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:44,534 : INFO : -7.882 per-word bound, 236.0 perplexity estimate based on a held-out corpus of 5 documents with 3795 words\n",
      "2019-10-29 00:40:44,536 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:44,546 : INFO : topic #3 (0.100): 0.023*\"air\" + 0.017*\"said\" + 0.014*\"level\" + 0.013*\"particle\" + 0.013*\"pollution\" + 0.011*\"use\" + 0.011*\"pollutant\" + 0.010*\"people\" + 0.009*\"exposure\" + 0.009*\"khatri\"\n",
      "2019-10-29 00:40:44,549 : INFO : topic #7 (0.100): 0.033*\"air\" + 0.023*\"said\" + 0.013*\"exposure\" + 0.013*\"pollution\" + 0.013*\"particle\" + 0.011*\"people\" + 0.011*\"khatri\" + 0.010*\"reduce\" + 0.010*\"level\" + 0.009*\"clean\"\n",
      "2019-10-29 00:40:44,550 : INFO : topic #9 (0.100): 0.029*\"air\" + 0.017*\"said\" + 0.016*\"pollution\" + 0.012*\"level\" + 0.012*\"khatri\" + 0.010*\"particle\" + 0.010*\"people\" + 0.010*\"use\" + 0.009*\"score\" + 0.009*\"health\"\n",
      "2019-10-29 00:40:44,552 : INFO : topic #8 (0.100): 0.027*\"air\" + 0.026*\"said\" + 0.016*\"pollution\" + 0.013*\"level\" + 0.012*\"khatri\" + 0.012*\"people\" + 0.011*\"reduce\" + 0.011*\"particle\" + 0.009*\"exposure\" + 0.008*\"pollutant\"\n",
      "2019-10-29 00:40:44,554 : INFO : topic #4 (0.100): 0.036*\"air\" + 0.020*\"said\" + 0.017*\"pollution\" + 0.013*\"khatri\" + 0.013*\"people\" + 0.012*\"particle\" + 0.011*\"level\" + 0.010*\"reduce\" + 0.009*\"clean\" + 0.009*\"pollutant\"\n",
      "2019-10-29 00:40:44,556 : INFO : topic diff=0.878790, rho=1.000000\n",
      "2019-10-29 00:40:44,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:44,982 : INFO : built Dictionary(371 unique tokens: ['energy', 'person', 'happy', 'party', 'timber']...) from 5 documents (total 2515 corpus positions)\n",
      "2019-10-29 00:40:44,988 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:44,990 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:44,991 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:44,996 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:44,999 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:45,141 : INFO : -8.144 per-word bound, 282.9 perplexity estimate based on a held-out corpus of 5 documents with 2515 words\n",
      "2019-10-29 00:40:45,143 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:45,152 : INFO : topic #8 (0.100): 0.029*\"design\" + 0.024*\"luxury\" + 0.010*\"modern\" + 0.010*\"studio\" + 0.009*\"year\" + 0.009*\"u\" + 0.009*\"new\" + 0.009*\"art\" + 0.008*\"luggage\" + 0.008*\"brand\"\n",
      "2019-10-29 00:40:45,156 : INFO : topic #3 (0.100): 0.021*\"luxury\" + 0.020*\"design\" + 0.011*\"new\" + 0.010*\"art\" + 0.009*\"year\" + 0.009*\"u\" + 0.009*\"luggage\" + 0.008*\"studio\" + 0.008*\"week\" + 0.007*\"modern\"\n",
      "2019-10-29 00:40:45,159 : INFO : topic #1 (0.100): 0.025*\"design\" + 0.025*\"luxury\" + 0.009*\"art\" + 0.009*\"u\" + 0.009*\"new\" + 0.008*\"year\" + 0.007*\"week\" + 0.007*\"luggage\" + 0.007*\"blend\" + 0.007*\"modern\"\n",
      "2019-10-29 00:40:45,168 : INFO : topic #2 (0.100): 0.033*\"design\" + 0.020*\"luxury\" + 0.016*\"new\" + 0.011*\"year\" + 0.008*\"u\" + 0.008*\"studio\" + 0.008*\"said\" + 0.007*\"week\" + 0.007*\"art\" + 0.007*\"brand\"\n",
      "2019-10-29 00:40:45,171 : INFO : topic #0 (0.100): 0.030*\"design\" + 0.020*\"luxury\" + 0.012*\"studio\" + 0.011*\"new\" + 0.009*\"u\" + 0.009*\"art\" + 0.009*\"year\" + 0.008*\"brand\" + 0.008*\"modern\" + 0.007*\"milan\"\n",
      "2019-10-29 00:40:45,174 : INFO : topic diff=0.765584, rho=1.000000\n",
      "2019-10-29 00:40:45,604 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:45,611 : INFO : built Dictionary(400 unique tokens: ['extensive', 'pushed', 'hong', 'extent', 'one']...) from 5 documents (total 3155 corpus positions)\n",
      "2019-10-29 00:40:45,614 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:45,616 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:45,618 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:45,625 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:45,628 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:45,761 : INFO : -7.975 per-word bound, 251.7 perplexity estimate based on a held-out corpus of 5 documents with 3155 words\n",
      "2019-10-29 00:40:45,763 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:45,769 : INFO : topic #3 (0.100): 0.030*\"dubai\" + 0.029*\"tower\" + 0.023*\"building\" + 0.019*\"world\" + 0.013*\"tall\" + 0.012*\"burj\" + 0.012*\"tallest\" + 0.008*\"saudi\" + 0.008*\"skyscraper\" + 0.007*\"cnn\"\n",
      "2019-10-29 00:40:45,771 : INFO : topic #8 (0.100): 0.043*\"tower\" + 0.021*\"dubai\" + 0.021*\"building\" + 0.014*\"world\" + 0.012*\"tall\" + 0.012*\"tallest\" + 0.011*\"burj\" + 0.008*\"skyscraper\" + 0.008*\"construction\" + 0.007*\"arab\"\n",
      "2019-10-29 00:40:45,773 : INFO : topic #2 (0.100): 0.044*\"tower\" + 0.037*\"dubai\" + 0.022*\"world\" + 0.019*\"building\" + 0.014*\"tallest\" + 0.011*\"tall\" + 0.010*\"burj\" + 0.008*\"saudi\" + 0.007*\"height\" + 0.007*\"middle\"\n",
      "2019-10-29 00:40:45,775 : INFO : topic #4 (0.100): 0.048*\"tower\" + 0.039*\"dubai\" + 0.020*\"world\" + 0.019*\"building\" + 0.013*\"tall\" + 0.011*\"burj\" + 0.010*\"tallest\" + 0.009*\"skyscraper\" + 0.009*\"construction\" + 0.009*\"cnn\"\n",
      "2019-10-29 00:40:45,776 : INFO : topic #9 (0.100): 0.036*\"tower\" + 0.031*\"dubai\" + 0.023*\"building\" + 0.017*\"world\" + 0.013*\"tall\" + 0.011*\"burj\" + 0.011*\"tallest\" + 0.010*\"skyscraper\" + 0.008*\"saudi\" + 0.008*\"also\"\n",
      "2019-10-29 00:40:45,778 : INFO : topic diff=0.865347, rho=1.000000\n",
      "2019-10-29 00:40:46,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:46,280 : INFO : built Dictionary(790 unique tokens: ['although', 'let', 'grew', 'appreciation', 'focus']...) from 5 documents (total 8250 corpus positions)\n",
      "2019-10-29 00:40:46,290 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:46,292 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:46,294 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:46,298 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:46,301 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:46,559 : INFO : -8.281 per-word bound, 311.0 perplexity estimate based on a held-out corpus of 5 documents with 8250 words\n",
      "2019-10-29 00:40:46,560 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:46,573 : INFO : topic #9 (0.100): 0.046*\"muslim\" + 0.026*\"say\" + 0.015*\"american\" + 0.012*\"like\" + 0.010*\"khan\" + 0.010*\"kid\" + 0.007*\"want\" + 0.007*\"one\" + 0.007*\"school\" + 0.006*\"name\"\n",
      "2019-10-29 00:40:46,575 : INFO : topic #1 (0.100): 0.033*\"muslim\" + 0.019*\"say\" + 0.015*\"like\" + 0.013*\"american\" + 0.010*\"school\" + 0.009*\"islam\" + 0.009*\"u\" + 0.008*\"khan\" + 0.008*\"want\" + 0.007*\"said\"\n",
      "2019-10-29 00:40:46,578 : INFO : topic #5 (0.100): 0.034*\"muslim\" + 0.028*\"say\" + 0.016*\"like\" + 0.011*\"american\" + 0.011*\"khan\" + 0.010*\"want\" + 0.009*\"one\" + 0.008*\"islam\" + 0.008*\"kid\" + 0.008*\"school\"\n",
      "2019-10-29 00:40:46,582 : INFO : topic #8 (0.100): 0.040*\"muslim\" + 0.023*\"say\" + 0.019*\"american\" + 0.011*\"like\" + 0.010*\"want\" + 0.010*\"islam\" + 0.009*\"faith\" + 0.009*\"school\" + 0.009*\"khan\" + 0.008*\"one\"\n",
      "2019-10-29 00:40:46,585 : INFO : topic #2 (0.100): 0.035*\"muslim\" + 0.028*\"say\" + 0.014*\"like\" + 0.013*\"american\" + 0.012*\"khan\" + 0.008*\"want\" + 0.008*\"islam\" + 0.008*\"kid\" + 0.007*\"said\" + 0.007*\"one\"\n",
      "2019-10-29 00:40:46,588 : INFO : topic diff=0.959457, rho=1.000000\n",
      "2019-10-29 00:40:46,987 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:46,989 : INFO : built Dictionary(75 unique tokens: ['story', 'road', 'tourist', 'armed', 'according']...) from 5 documents (total 575 corpus positions)\n",
      "2019-10-29 00:40:46,991 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:46,992 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:46,994 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:46,996 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:46,997 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:47,036 : INFO : -6.503 per-word bound, 90.7 perplexity estimate based on a held-out corpus of 5 documents with 575 words\n",
      "2019-10-29 00:40:47,037 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:47,045 : INFO : topic #2 (0.100): 0.044*\"police\" + 0.043*\"london\" + 0.028*\"man\" + 0.028*\"people\" + 0.027*\"injured\" + 0.027*\"car\" + 0.026*\"museum\" + 0.026*\"natural\" + 0.022*\"injury\" + 0.021*\"history\"\n",
      "2019-10-29 00:40:47,048 : INFO : topic #3 (0.100): 0.054*\"london\" + 0.035*\"police\" + 0.031*\"car\" + 0.026*\"man\" + 0.024*\"people\" + 0.023*\"natural\" + 0.023*\"museum\" + 0.023*\"history\" + 0.022*\"said\" + 0.020*\"injured\"\n",
      "2019-10-29 00:40:47,051 : INFO : topic #8 (0.100): 0.041*\"london\" + 0.040*\"police\" + 0.031*\"man\" + 0.029*\"natural\" + 0.028*\"injured\" + 0.027*\"said\" + 0.027*\"people\" + 0.025*\"car\" + 0.025*\"history\" + 0.022*\"scene\"\n",
      "2019-10-29 00:40:47,054 : INFO : topic #5 (0.100): 0.047*\"london\" + 0.043*\"police\" + 0.032*\"people\" + 0.029*\"said\" + 0.027*\"history\" + 0.026*\"car\" + 0.025*\"museum\" + 0.025*\"injured\" + 0.022*\"man\" + 0.021*\"natural\"\n",
      "2019-10-29 00:40:47,057 : INFO : topic #6 (0.100): 0.042*\"london\" + 0.039*\"police\" + 0.031*\"history\" + 0.029*\"injured\" + 0.025*\"museum\" + 0.024*\"said\" + 0.023*\"natural\" + 0.022*\"saturday\" + 0.021*\"according\" + 0.021*\"related\"\n",
      "2019-10-29 00:40:47,060 : INFO : topic diff=0.770851, rho=1.000000\n",
      "2019-10-29 00:40:47,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:47,521 : INFO : built Dictionary(344 unique tokens: ['although', 'earned', 'selection', 'party', 'fox']...) from 5 documents (total 2455 corpus positions)\n",
      "2019-10-29 00:40:47,526 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:47,528 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:47,530 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:47,533 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:47,534 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:47,703 : INFO : -7.984 per-word bound, 253.1 perplexity estimate based on a held-out corpus of 5 documents with 2455 words\n",
      "2019-10-29 00:40:47,705 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:47,715 : INFO : topic #2 (0.100): 0.018*\"candidate\" + 0.013*\"primary\" + 0.011*\"party\" + 0.010*\"running\" + 0.009*\"first\" + 0.009*\"like\" + 0.008*\"future\" + 0.008*\"president\" + 0.008*\"debate\" + 0.007*\"sander\"\n",
      "2019-10-29 00:40:47,718 : INFO : topic #4 (0.100): 0.022*\"candidate\" + 0.013*\"primary\" + 0.012*\"party\" + 0.009*\"first\" + 0.009*\"president\" + 0.008*\"new\" + 0.008*\"campaign\" + 0.008*\"debate\" + 0.008*\"future\" + 0.008*\"running\"\n",
      "2019-10-29 00:40:47,720 : INFO : topic #1 (0.100): 0.018*\"candidate\" + 0.011*\"party\" + 0.011*\"primary\" + 0.010*\"first\" + 0.010*\"running\" + 0.008*\"future\" + 0.008*\"debate\" + 0.008*\"national\" + 0.007*\"medium\" + 0.007*\"president\"\n",
      "2019-10-29 00:40:47,722 : INFO : topic #9 (0.100): 0.018*\"candidate\" + 0.012*\"party\" + 0.011*\"primary\" + 0.010*\"running\" + 0.009*\"debate\" + 0.008*\"campaign\" + 0.007*\"medium\" + 0.007*\"nomination\" + 0.007*\"republican\" + 0.007*\"even\"\n",
      "2019-10-29 00:40:47,724 : INFO : topic #3 (0.100): 0.027*\"candidate\" + 0.016*\"primary\" + 0.010*\"party\" + 0.009*\"running\" + 0.008*\"medium\" + 0.008*\"like\" + 0.008*\"president\" + 0.007*\"reagan\" + 0.006*\"make\" + 0.006*\"new\"\n",
      "2019-10-29 00:40:47,726 : INFO : topic diff=0.762213, rho=1.000000\n",
      "2019-10-29 00:40:48,211 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:48,218 : INFO : built Dictionary(444 unique tokens: ['hayes', 'grew', 'surprised', 'game', 'fumble']...) from 5 documents (total 4125 corpus positions)\n",
      "2019-10-29 00:40:48,224 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:48,226 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:48,228 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:48,235 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:48,238 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:48,379 : INFO : -7.854 per-word bound, 231.4 perplexity estimate based on a held-out corpus of 5 documents with 4125 words\n",
      "2019-10-29 00:40:48,380 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:48,389 : INFO : topic #2 (0.100): 0.030*\"lanning\" + 0.016*\"iowa\" + 0.015*\"state\" + 0.014*\"campbell\" + 0.013*\"say\" + 0.011*\"football\" + 0.011*\"season\" + 0.010*\"player\" + 0.010*\"play\" + 0.010*\"year\"\n",
      "2019-10-29 00:40:48,391 : INFO : topic #9 (0.100): 0.034*\"lanning\" + 0.019*\"iowa\" + 0.014*\"campbell\" + 0.013*\"state\" + 0.013*\"one\" + 0.013*\"play\" + 0.011*\"say\" + 0.010*\"quarterback\" + 0.009*\"linebacker\" + 0.009*\"player\"\n",
      "2019-10-29 00:40:48,393 : INFO : topic #6 (0.100): 0.040*\"lanning\" + 0.019*\"iowa\" + 0.013*\"state\" + 0.011*\"campbell\" + 0.011*\"play\" + 0.010*\"say\" + 0.009*\"linebacker\" + 0.009*\"player\" + 0.008*\"year\" + 0.008*\"wrestling\"\n",
      "2019-10-29 00:40:48,394 : INFO : topic #1 (0.100): 0.038*\"lanning\" + 0.016*\"state\" + 0.014*\"quarterback\" + 0.013*\"say\" + 0.012*\"campbell\" + 0.012*\"play\" + 0.011*\"iowa\" + 0.010*\"one\" + 0.010*\"year\" + 0.009*\"player\"\n",
      "2019-10-29 00:40:48,396 : INFO : topic #5 (0.100): 0.041*\"lanning\" + 0.014*\"play\" + 0.013*\"iowa\" + 0.011*\"campbell\" + 0.011*\"season\" + 0.011*\"player\" + 0.010*\"state\" + 0.010*\"one\" + 0.009*\"wrestling\" + 0.009*\"guy\"\n",
      "2019-10-29 00:40:48,398 : INFO : topic diff=0.903096, rho=1.000000\n",
      "2019-10-29 00:40:48,846 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:48,855 : INFO : built Dictionary(458 unique tokens: ['regular', 'unsuccessful', 'filed', 'potentially', 'recommendation']...) from 5 documents (total 4945 corpus positions)\n",
      "2019-10-29 00:40:48,861 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:48,863 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:48,864 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:48,868 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:48,870 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:49,011 : INFO : -7.718 per-word bound, 210.6 perplexity estimate based on a held-out corpus of 5 documents with 4945 words\n",
      "2019-10-29 00:40:49,012 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:49,022 : INFO : topic #3 (0.100): 0.026*\"abilityone\" + 0.026*\"cnn\" + 0.020*\"source\" + 0.020*\"contract\" + 0.019*\"disabled\" + 0.014*\"program\" + 0.013*\"people\" + 0.012*\"severely\" + 0.012*\"work\" + 0.012*\"company\"\n",
      "2019-10-29 00:40:49,024 : INFO : topic #9 (0.100): 0.040*\"contract\" + 0.026*\"abilityone\" + 0.024*\"source\" + 0.022*\"disabled\" + 0.019*\"cnn\" + 0.017*\"severely\" + 0.016*\"sourceamerica\" + 0.013*\"program\" + 0.012*\"work\" + 0.011*\"company\"\n",
      "2019-10-29 00:40:49,026 : INFO : topic #7 (0.100): 0.035*\"abilityone\" + 0.026*\"contract\" + 0.024*\"disabled\" + 0.023*\"cnn\" + 0.023*\"source\" + 0.016*\"sourceamerica\" + 0.013*\"severely\" + 0.012*\"program\" + 0.011*\"work\" + 0.010*\"company\"\n",
      "2019-10-29 00:40:49,029 : INFO : topic #4 (0.100): 0.030*\"contract\" + 0.023*\"abilityone\" + 0.022*\"source\" + 0.022*\"disabled\" + 0.020*\"cnn\" + 0.016*\"severely\" + 0.014*\"sourceamerica\" + 0.013*\"program\" + 0.012*\"company\" + 0.010*\"work\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:49,031 : INFO : topic #6 (0.100): 0.028*\"source\" + 0.027*\"abilityone\" + 0.027*\"contract\" + 0.022*\"disabled\" + 0.017*\"cnn\" + 0.015*\"sourceamerica\" + 0.014*\"work\" + 0.013*\"program\" + 0.013*\"severely\" + 0.009*\"said\"\n",
      "2019-10-29 00:40:49,034 : INFO : topic diff=0.993669, rho=1.000000\n",
      "2019-10-29 00:40:49,456 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:49,460 : INFO : built Dictionary(246 unique tokens: ['product', 'significant', 'portion', 'campaign', 'nation']...) from 5 documents (total 1915 corpus positions)\n",
      "2019-10-29 00:40:49,462 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:49,465 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:49,466 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:49,468 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:49,470 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:49,558 : INFO : -7.534 per-word bound, 185.4 perplexity estimate based on a held-out corpus of 5 documents with 1915 words\n",
      "2019-10-29 00:40:49,560 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:49,566 : INFO : topic #7 (0.100): 0.031*\"trade\" + 0.024*\"u\" + 0.020*\"trump\" + 0.017*\"rule\" + 0.013*\"canada\" + 0.012*\"north\" + 0.011*\"part\" + 0.011*\"nafta\" + 0.010*\"america\" + 0.010*\"car\"\n",
      "2019-10-29 00:40:49,568 : INFO : topic #4 (0.100): 0.027*\"trade\" + 0.021*\"trump\" + 0.019*\"nafta\" + 0.017*\"u\" + 0.015*\"rule\" + 0.014*\"america\" + 0.014*\"car\" + 0.013*\"canada\" + 0.012*\"north\" + 0.011*\"talk\"\n",
      "2019-10-29 00:40:49,569 : INFO : topic #2 (0.100): 0.032*\"trade\" + 0.021*\"america\" + 0.019*\"u\" + 0.015*\"trump\" + 0.014*\"rule\" + 0.014*\"north\" + 0.012*\"car\" + 0.012*\"nafta\" + 0.012*\"mexico\" + 0.011*\"one\"\n",
      "2019-10-29 00:40:49,571 : INFO : topic #5 (0.100): 0.035*\"trade\" + 0.026*\"trump\" + 0.018*\"nafta\" + 0.017*\"u\" + 0.016*\"rule\" + 0.015*\"north\" + 0.014*\"canada\" + 0.013*\"car\" + 0.012*\"one\" + 0.011*\"talk\"\n",
      "2019-10-29 00:40:49,573 : INFO : topic #0 (0.100): 0.033*\"trade\" + 0.020*\"rule\" + 0.017*\"north\" + 0.016*\"america\" + 0.016*\"trump\" + 0.014*\"u\" + 0.013*\"nafta\" + 0.012*\"canada\" + 0.011*\"mexico\" + 0.011*\"car\"\n",
      "2019-10-29 00:40:49,574 : INFO : topic diff=0.814789, rho=1.000000\n",
      "2019-10-29 00:40:50,013 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:50,016 : INFO : built Dictionary(266 unique tokens: ['anniversary', 'person', 'nation', 'wise', 'verge']...) from 5 documents (total 2125 corpus positions)\n",
      "2019-10-29 00:40:50,020 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:50,022 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:50,023 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:50,027 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:50,028 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:50,120 : INFO : -7.572 per-word bound, 190.3 perplexity estimate based on a held-out corpus of 5 documents with 2125 words\n",
      "2019-10-29 00:40:50,122 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:50,131 : INFO : topic #4 (0.100): 0.020*\"year\" + 0.018*\"child\" + 0.018*\"optimism\" + 0.017*\"warren\" + 0.016*\"better\" + 0.011*\"thing\" + 0.010*\"letter\" + 0.010*\"good\" + 0.010*\"people\" + 0.009*\"u\"\n",
      "2019-10-29 00:40:50,133 : INFO : topic #6 (0.100): 0.022*\"child\" + 0.020*\"warren\" + 0.018*\"optimism\" + 0.017*\"year\" + 0.016*\"better\" + 0.014*\"letter\" + 0.011*\"people\" + 0.011*\"thing\" + 0.010*\"u\" + 0.009*\"last\"\n",
      "2019-10-29 00:40:50,136 : INFO : topic #5 (0.100): 0.021*\"child\" + 0.021*\"year\" + 0.020*\"optimism\" + 0.018*\"warren\" + 0.017*\"better\" + 0.011*\"last\" + 0.010*\"people\" + 0.010*\"good\" + 0.010*\"right\" + 0.010*\"letter\"\n",
      "2019-10-29 00:40:50,138 : INFO : topic #2 (0.100): 0.022*\"child\" + 0.019*\"warren\" + 0.014*\"year\" + 0.013*\"good\" + 0.013*\"optimism\" + 0.012*\"better\" + 0.011*\"people\" + 0.011*\"thing\" + 0.011*\"poverty\" + 0.011*\"letter\"\n",
      "2019-10-29 00:40:50,139 : INFO : topic #8 (0.100): 0.024*\"warren\" + 0.017*\"year\" + 0.017*\"better\" + 0.015*\"optimism\" + 0.015*\"child\" + 0.013*\"thing\" + 0.011*\"good\" + 0.011*\"gate\" + 0.010*\"gain\" + 0.010*\"letter\"\n",
      "2019-10-29 00:40:50,142 : INFO : topic diff=0.842800, rho=1.000000\n",
      "2019-10-29 00:40:50,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:50,549 : INFO : built Dictionary(211 unique tokens: ['although', 'forward', 'diaz', 'nowhere', 'ponce']...) from 5 documents (total 1445 corpus positions)\n",
      "2019-10-29 00:40:50,552 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:50,554 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:50,555 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:50,558 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:50,559 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:50,632 : INFO : -7.603 per-word bound, 194.4 perplexity estimate based on a held-out corpus of 5 documents with 1445 words\n",
      "2019-10-29 00:40:50,633 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:50,641 : INFO : topic #4 (0.100): 0.022*\"rico\" + 0.021*\"home\" + 0.018*\"puerto\" + 0.016*\"pabon\" + 0.016*\"house\" + 0.013*\"diaz\" + 0.012*\"tree\" + 0.012*\"water\" + 0.010*\"room\" + 0.010*\"service\"\n",
      "2019-10-29 00:40:50,642 : INFO : topic #9 (0.100): 0.025*\"home\" + 0.023*\"rico\" + 0.020*\"puerto\" + 0.018*\"pabon\" + 0.015*\"diaz\" + 0.012*\"water\" + 0.012*\"house\" + 0.011*\"help\" + 0.010*\"hurricane\" + 0.010*\"lydia\"\n",
      "2019-10-29 00:40:50,643 : INFO : topic #1 (0.100): 0.025*\"puerto\" + 0.022*\"rico\" + 0.018*\"pabon\" + 0.017*\"home\" + 0.015*\"diaz\" + 0.014*\"maria\" + 0.013*\"lydia\" + 0.013*\"house\" + 0.011*\"service\" + 0.011*\"tree\"\n",
      "2019-10-29 00:40:50,644 : INFO : topic #3 (0.100): 0.024*\"home\" + 0.018*\"puerto\" + 0.017*\"rico\" + 0.013*\"pabon\" + 0.012*\"water\" + 0.012*\"room\" + 0.012*\"help\" + 0.012*\"house\" + 0.011*\"diaz\" + 0.011*\"thing\"\n",
      "2019-10-29 00:40:50,646 : INFO : topic #2 (0.100): 0.022*\"home\" + 0.021*\"rico\" + 0.020*\"puerto\" + 0.017*\"house\" + 0.016*\"pabon\" + 0.012*\"water\" + 0.012*\"help\" + 0.011*\"year\" + 0.011*\"island\" + 0.010*\"service\"\n",
      "2019-10-29 00:40:50,648 : INFO : topic diff=0.779024, rho=1.000000\n",
      "2019-10-29 00:40:51,097 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:51,102 : INFO : built Dictionary(324 unique tokens: ['although', 'dating', 'school', 'transition', '1990s']...) from 5 documents (total 2605 corpus positions)\n",
      "2019-10-29 00:40:51,107 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:51,108 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:51,109 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:51,119 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:51,122 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:51,226 : INFO : -7.745 per-word bound, 214.5 perplexity estimate based on a held-out corpus of 5 documents with 2605 words\n",
      "2019-10-29 00:40:51,228 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:51,238 : INFO : topic #8 (0.100): 0.036*\"teen\" + 0.013*\"adult\" + 0.012*\"alcohol\" + 0.012*\"time\" + 0.012*\"might\" + 0.011*\"adulthood\" + 0.011*\"trend\" + 0.011*\"life\" + 0.011*\"child\" + 0.010*\"taking\"\n",
      "2019-10-29 00:40:51,241 : INFO : topic #9 (0.100): 0.033*\"teen\" + 0.015*\"le\" + 0.013*\"might\" + 0.013*\"drinking\" + 0.012*\"longer\" + 0.011*\"life\" + 0.011*\"good\" + 0.010*\"time\" + 0.010*\"sex\" + 0.010*\"child\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:51,244 : INFO : topic #3 (0.100): 0.031*\"teen\" + 0.015*\"adulthood\" + 0.013*\"alcohol\" + 0.012*\"le\" + 0.012*\"child\" + 0.012*\"adult\" + 0.011*\"life\" + 0.011*\"sex\" + 0.010*\"time\" + 0.009*\"might\"\n",
      "2019-10-29 00:40:51,248 : INFO : topic #6 (0.100): 0.042*\"teen\" + 0.014*\"child\" + 0.014*\"adulthood\" + 0.013*\"le\" + 0.011*\"life\" + 0.011*\"might\" + 0.011*\"adult\" + 0.011*\"parent\" + 0.011*\"time\" + 0.010*\"alcohol\"\n",
      "2019-10-29 00:40:51,251 : INFO : topic #5 (0.100): 0.034*\"teen\" + 0.013*\"le\" + 0.011*\"adulthood\" + 0.011*\"child\" + 0.010*\"alcohol\" + 0.010*\"adult\" + 0.010*\"might\" + 0.010*\"time\" + 0.009*\"parent\" + 0.009*\"kid\"\n",
      "2019-10-29 00:40:51,254 : INFO : topic diff=0.889476, rho=1.000000\n",
      "2019-10-29 00:40:51,701 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:51,705 : INFO : built Dictionary(307 unique tokens: ['darkest', 'energy', 'kidding', 'campaign', 'focus']...) from 5 documents (total 2195 corpus positions)\n",
      "2019-10-29 00:40:51,709 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:51,710 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:51,711 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:51,714 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:51,716 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:51,814 : INFO : -7.873 per-word bound, 234.5 perplexity estimate based on a held-out corpus of 5 documents with 2195 words\n",
      "2019-10-29 00:40:51,816 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:51,822 : INFO : topic #8 (0.100): 0.041*\"trump\" + 0.015*\"corker\" + 0.014*\"bully\" + 0.013*\"like\" + 0.012*\"president\" + 0.010*\"caller\" + 0.010*\"people\" + 0.010*\"said\" + 0.010*\"name\" + 0.009*\"republican\"\n",
      "2019-10-29 00:40:51,824 : INFO : topic #9 (0.100): 0.045*\"trump\" + 0.014*\"president\" + 0.014*\"like\" + 0.012*\"people\" + 0.012*\"bully\" + 0.011*\"corker\" + 0.010*\"change\" + 0.009*\"campaign\" + 0.009*\"name\" + 0.007*\"said\"\n",
      "2019-10-29 00:40:51,827 : INFO : topic #7 (0.100): 0.053*\"trump\" + 0.017*\"like\" + 0.016*\"bully\" + 0.015*\"corker\" + 0.014*\"people\" + 0.013*\"name\" + 0.009*\"change\" + 0.009*\"republican\" + 0.008*\"president\" + 0.008*\"make\"\n",
      "2019-10-29 00:40:51,830 : INFO : topic #2 (0.100): 0.036*\"trump\" + 0.016*\"corker\" + 0.014*\"like\" + 0.013*\"change\" + 0.012*\"bully\" + 0.011*\"people\" + 0.011*\"president\" + 0.010*\"campaign\" + 0.009*\"tennessee\" + 0.008*\"name\"\n",
      "2019-10-29 00:40:51,833 : INFO : topic #4 (0.100): 0.037*\"trump\" + 0.015*\"bully\" + 0.013*\"people\" + 0.013*\"like\" + 0.013*\"change\" + 0.013*\"corker\" + 0.012*\"president\" + 0.011*\"name\" + 0.010*\"republican\" + 0.008*\"said\"\n",
      "2019-10-29 00:40:51,835 : INFO : topic diff=0.787086, rho=1.000000\n",
      "2019-10-29 00:40:52,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:52,242 : INFO : built Dictionary(78 unique tokens: ['civilian', 'help', 'school', 'food', 'aleppo']...) from 5 documents (total 505 corpus positions)\n",
      "2019-10-29 00:40:52,244 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:52,246 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:52,248 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:52,250 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:52,251 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:52,287 : INFO : -6.837 per-word bound, 114.4 perplexity estimate based on a held-out corpus of 5 documents with 505 words\n",
      "2019-10-29 00:40:52,290 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:52,299 : INFO : topic #1 (0.100): 0.035*\"aleppo\" + 0.029*\"help\" + 0.029*\"food\" + 0.028*\"syrian\" + 0.024*\"people\" + 0.021*\"thousand\" + 0.020*\"aid\" + 0.020*\"could\" + 0.020*\"need\" + 0.020*\"medical\"\n",
      "2019-10-29 00:40:52,302 : INFO : topic #0 (0.100): 0.033*\"aleppo\" + 0.030*\"people\" + 0.027*\"help\" + 0.027*\"food\" + 0.027*\"syrian\" + 0.024*\"thousand\" + 0.022*\"live\" + 0.021*\"survive\" + 0.021*\"parent\" + 0.020*\"shelter\"\n",
      "2019-10-29 00:40:52,304 : INFO : topic #4 (0.100): 0.040*\"aleppo\" + 0.031*\"syrian\" + 0.026*\"help\" + 0.024*\"people\" + 0.023*\"child\" + 0.021*\"medical\" + 0.021*\"could\" + 0.021*\"aid\" + 0.020*\"longer\" + 0.020*\"city\"\n",
      "2019-10-29 00:40:52,306 : INFO : topic #9 (0.100): 0.032*\"aleppo\" + 0.031*\"help\" + 0.030*\"people\" + 0.029*\"food\" + 0.028*\"syrian\" + 0.023*\"city\" + 0.022*\"live\" + 0.020*\"could\" + 0.020*\"need\" + 0.018*\"medical\"\n",
      "2019-10-29 00:40:52,307 : INFO : topic #6 (0.100): 0.033*\"aleppo\" + 0.030*\"food\" + 0.029*\"syrian\" + 0.023*\"people\" + 0.023*\"help\" + 0.022*\"need\" + 0.022*\"medical\" + 0.021*\"survive\" + 0.021*\"live\" + 0.021*\"child\"\n",
      "2019-10-29 00:40:52,308 : INFO : topic diff=0.719743, rho=1.000000\n",
      "2019-10-29 00:40:52,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:52,725 : INFO : built Dictionary(239 unique tokens: ['school', 'bet', 'book', 'end', 'maintenance']...) from 5 documents (total 1670 corpus positions)\n",
      "2019-10-29 00:40:52,733 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:52,735 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:52,740 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:52,743 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:52,746 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:52,857 : INFO : -7.680 per-word bound, 205.0 perplexity estimate based on a held-out corpus of 5 documents with 1670 words\n",
      "2019-10-29 00:40:52,859 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:52,866 : INFO : topic #5 (0.100): 0.022*\"london\" + 0.020*\"walk\" + 0.019*\"ticket\" + 0.016*\"eye\" + 0.012*\"river\" + 0.012*\"hall\" + 0.011*\"hour\" + 0.010*\"wheel\" + 0.010*\"minute\" + 0.010*\"line\"\n",
      "2019-10-29 00:40:52,869 : INFO : topic #0 (0.100): 0.024*\"london\" + 0.022*\"ticket\" + 0.021*\"walk\" + 0.015*\"eye\" + 0.013*\"hour\" + 0.012*\"line\" + 0.011*\"capsule\" + 0.011*\"westminster\" + 0.011*\"one\" + 0.010*\"river\"\n",
      "2019-10-29 00:40:52,871 : INFO : topic #2 (0.100): 0.025*\"london\" + 0.021*\"walk\" + 0.018*\"ticket\" + 0.016*\"hour\" + 0.014*\"eye\" + 0.012*\"one\" + 0.012*\"uk\" + 0.011*\"line\" + 0.010*\"capsule\" + 0.010*\"river\"\n",
      "2019-10-29 00:40:52,874 : INFO : topic #9 (0.100): 0.030*\"london\" + 0.018*\"walk\" + 0.016*\"ticket\" + 0.015*\"eye\" + 0.012*\"one\" + 0.012*\"hour\" + 0.012*\"westminster\" + 0.012*\"capsule\" + 0.011*\"book\" + 0.011*\"line\"\n",
      "2019-10-29 00:40:52,876 : INFO : topic #8 (0.100): 0.023*\"london\" + 0.017*\"ticket\" + 0.015*\"one\" + 0.013*\"track\" + 0.012*\"hour\" + 0.012*\"walk\" + 0.012*\"eye\" + 0.012*\"capsule\" + 0.012*\"westminster\" + 0.011*\"fast\"\n",
      "2019-10-29 00:40:52,878 : INFO : topic diff=0.788914, rho=1.000000\n",
      "2019-10-29 00:40:53,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:53,295 : INFO : built Dictionary(123 unique tokens: ['rumor', 'shot', 'security', 'concertgoers', 'life']...) from 5 documents (total 905 corpus positions)\n",
      "2019-10-29 00:40:53,299 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:53,302 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:53,304 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:53,307 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:53,310 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:53,384 : INFO : -6.992 per-word bound, 127.3 perplexity estimate based on a held-out corpus of 5 documents with 905 words\n",
      "2019-10-29 00:40:53,388 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:53,395 : INFO : topic #1 (0.100): 0.043*\"lombardo\" + 0.041*\"paddock\" + 0.037*\"sheriff\" + 0.023*\"said\" + 0.018*\"briefing\" + 0.018*\"vega\" + 0.017*\"prior\" + 0.016*\"mass\" + 0.016*\"la\" + 0.016*\"kvvu\"\n",
      "2019-10-29 00:40:53,398 : INFO : topic #9 (0.100): 0.049*\"lombardo\" + 0.028*\"paddock\" + 0.028*\"sheriff\" + 0.021*\"vega\" + 0.021*\"said\" + 0.019*\"shooting\" + 0.018*\"la\" + 0.016*\"prior\" + 0.015*\"investigator\" + 0.015*\"timeline\"\n",
      "2019-10-29 00:40:53,401 : INFO : topic #5 (0.100): 0.039*\"lombardo\" + 0.032*\"sheriff\" + 0.028*\"paddock\" + 0.027*\"vega\" + 0.023*\"shooting\" + 0.020*\"said\" + 0.019*\"la\" + 0.018*\"kvvu\" + 0.018*\"mass\" + 0.015*\"prior\"\n",
      "2019-10-29 00:40:53,404 : INFO : topic #4 (0.100): 0.048*\"sheriff\" + 0.044*\"paddock\" + 0.043*\"lombardo\" + 0.021*\"shooting\" + 0.021*\"said\" + 0.019*\"vega\" + 0.017*\"timeline\" + 0.017*\"investigator\" + 0.016*\"briefing\" + 0.015*\"kvvu\"\n",
      "2019-10-29 00:40:53,407 : INFO : topic #3 (0.100): 0.045*\"lombardo\" + 0.039*\"sheriff\" + 0.037*\"paddock\" + 0.026*\"shooting\" + 0.022*\"said\" + 0.018*\"vega\" + 0.016*\"briefing\" + 0.016*\"mass\" + 0.014*\"la\" + 0.014*\"timeline\"\n",
      "2019-10-29 00:40:53,410 : INFO : topic diff=0.822706, rho=1.000000\n",
      "2019-10-29 00:40:53,885 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:53,890 : INFO : built Dictionary(197 unique tokens: ['dating', 'forward', 'incremental', 'single', 'part']...) from 5 documents (total 1905 corpus positions)\n",
      "2019-10-29 00:40:53,894 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:53,896 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:53,898 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:53,900 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:53,902 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:54,008 : INFO : -7.035 per-word bound, 131.1 perplexity estimate based on a held-out corpus of 5 documents with 1905 words\n",
      "2019-10-29 00:40:54,010 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:54,018 : INFO : topic #1 (0.100): 0.033*\"said\" + 0.030*\"okcupid\" + 0.026*\"relationship\" + 0.024*\"non\" + 0.024*\"user\" + 0.022*\"site\" + 0.021*\"monogamous\" + 0.020*\"people\" + 0.019*\"polyamorous\" + 0.018*\"open\"\n",
      "2019-10-29 00:40:54,021 : INFO : topic #5 (0.100): 0.038*\"relationship\" + 0.028*\"monogamous\" + 0.025*\"people\" + 0.024*\"okcupid\" + 0.023*\"said\" + 0.023*\"couple\" + 0.019*\"feature\" + 0.019*\"site\" + 0.019*\"user\" + 0.018*\"dating\"\n",
      "2019-10-29 00:40:54,024 : INFO : topic #8 (0.100): 0.045*\"relationship\" + 0.032*\"okcupid\" + 0.027*\"said\" + 0.025*\"user\" + 0.021*\"non\" + 0.021*\"people\" + 0.021*\"monogamous\" + 0.019*\"polyamorous\" + 0.017*\"open\" + 0.016*\"feature\"\n",
      "2019-10-29 00:40:54,027 : INFO : topic #3 (0.100): 0.044*\"relationship\" + 0.041*\"said\" + 0.029*\"user\" + 0.027*\"people\" + 0.023*\"non\" + 0.023*\"okcupid\" + 0.022*\"monogamous\" + 0.021*\"polyamorous\" + 0.020*\"feature\" + 0.019*\"open\"\n",
      "2019-10-29 00:40:54,031 : INFO : topic #2 (0.100): 0.035*\"people\" + 0.035*\"relationship\" + 0.032*\"monogamous\" + 0.027*\"non\" + 0.025*\"okcupid\" + 0.023*\"said\" + 0.019*\"site\" + 0.019*\"feature\" + 0.019*\"open\" + 0.017*\"user\"\n",
      "2019-10-29 00:40:54,034 : INFO : topic diff=0.961118, rho=1.000000\n",
      "2019-10-29 00:40:54,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:54,486 : INFO : built Dictionary(134 unique tokens: ['offered', 'paris', 'let', 'get', 'really']...) from 5 documents (total 845 corpus positions)\n",
      "2019-10-29 00:40:54,488 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:54,489 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:54,490 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:54,492 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:54,494 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:54,555 : INFO : -7.343 per-word bound, 162.4 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:40:54,558 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:54,565 : INFO : topic #6 (0.100): 0.031*\"model\" + 0.023*\"male\" + 0.021*\"owen\" + 0.019*\"penis\" + 0.018*\"shock\" + 0.018*\"runway\" + 0.016*\"nudity\" + 0.015*\"year\" + 0.014*\"affleck\" + 0.014*\"clothes\"\n",
      "2019-10-29 00:40:54,567 : INFO : topic #3 (0.100): 0.031*\"male\" + 0.022*\"owen\" + 0.022*\"model\" + 0.017*\"nudity\" + 0.016*\"runway\" + 0.014*\"show\" + 0.014*\"penis\" + 0.014*\"going\" + 0.014*\"shock\" + 0.014*\"clothes\"\n",
      "2019-10-29 00:40:54,569 : INFO : topic #0 (0.100): 0.024*\"model\" + 0.019*\"runway\" + 0.018*\"owen\" + 0.017*\"penis\" + 0.016*\"shock\" + 0.015*\"film\" + 0.014*\"male\" + 0.014*\"nudity\" + 0.014*\"lower\" + 0.013*\"full\"\n",
      "2019-10-29 00:40:54,570 : INFO : topic #4 (0.100): 0.023*\"model\" + 0.017*\"male\" + 0.017*\"shock\" + 0.014*\"owen\" + 0.014*\"runway\" + 0.014*\"lower\" + 0.013*\"penis\" + 0.013*\"drexler\" + 0.013*\"course\" + 0.013*\"nudity\"\n",
      "2019-10-29 00:40:54,571 : INFO : topic #7 (0.100): 0.034*\"model\" + 0.021*\"penis\" + 0.020*\"male\" + 0.019*\"nudity\" + 0.018*\"runway\" + 0.017*\"shock\" + 0.015*\"owen\" + 0.014*\"rick\" + 0.014*\"ben\" + 0.013*\"father\"\n",
      "2019-10-29 00:40:54,572 : INFO : topic diff=0.709476, rho=1.000000\n",
      "2019-10-29 00:40:55,000 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:55,002 : INFO : built Dictionary(146 unique tokens: ['book', 'something', 'shockingly', 'clearly', 'relationship']...) from 5 documents (total 1110 corpus positions)\n",
      "2019-10-29 00:40:55,004 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:55,006 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:55,007 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:55,008 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:55,009 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:55,065 : INFO : -7.092 per-word bound, 136.4 perplexity estimate based on a held-out corpus of 5 documents with 1110 words\n",
      "2019-10-29 00:40:55,066 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:55,071 : INFO : topic #9 (0.100): 0.028*\"melania\" + 0.028*\"reagan\" + 0.025*\"first\" + 0.024*\"trump\" + 0.020*\"nancy\" + 0.020*\"lady\" + 0.017*\"divorced\" + 0.015*\"statement\" + 0.015*\"child\" + 0.015*\"wife\"\n",
      "2019-10-29 00:40:55,072 : INFO : topic #2 (0.100): 0.030*\"melania\" + 0.029*\"first\" + 0.028*\"trump\" + 0.026*\"nancy\" + 0.022*\"reagan\" + 0.019*\"child\" + 0.016*\"page\" + 0.016*\"divorced\" + 0.014*\"president\" + 0.014*\"ivana\"\n",
      "2019-10-29 00:40:55,073 : INFO : topic #4 (0.100): 0.040*\"first\" + 0.035*\"melania\" + 0.031*\"trump\" + 0.026*\"reagan\" + 0.023*\"nancy\" + 0.018*\"lady\" + 0.015*\"brower\" + 0.015*\"take\" + 0.015*\"kate\" + 0.014*\"statement\"\n",
      "2019-10-29 00:40:55,074 : INFO : topic #7 (0.100): 0.031*\"first\" + 0.030*\"melania\" + 0.028*\"reagan\" + 0.027*\"trump\" + 0.025*\"nancy\" + 0.020*\"brower\" + 0.017*\"said\" + 0.017*\"divorced\" + 0.015*\"lady\" + 0.014*\"child\"\n",
      "2019-10-29 00:40:55,075 : INFO : topic #1 (0.100): 0.033*\"first\" + 0.031*\"trump\" + 0.028*\"melania\" + 0.026*\"nancy\" + 0.022*\"child\" + 0.021*\"reagan\" + 0.020*\"divorced\" + 0.017*\"lady\" + 0.016*\"brower\" + 0.015*\"three\"\n",
      "2019-10-29 00:40:55,076 : INFO : topic diff=0.850972, rho=1.000000\n",
      "2019-10-29 00:40:55,558 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:55,560 : INFO : built Dictionary(178 unique tokens: ['consent', 'watch', 'let', 'mayor', 'job']...) from 5 documents (total 1500 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:55,563 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:55,565 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:55,566 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:55,569 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:55,570 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:55,660 : INFO : -7.115 per-word bound, 138.6 perplexity estimate based on a held-out corpus of 5 documents with 1500 words\n",
      "2019-10-29 00:40:55,661 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:55,673 : INFO : topic #1 (0.100): 0.042*\"police\" + 0.030*\"payne\" + 0.026*\"officer\" + 0.023*\"said\" + 0.022*\"nurse\" + 0.021*\"blood\" + 0.014*\"city\" + 0.013*\"wubbels\" + 0.012*\"department\" + 0.011*\"body\"\n",
      "2019-10-29 00:40:55,675 : INFO : topic #2 (0.100): 0.050*\"police\" + 0.034*\"officer\" + 0.026*\"said\" + 0.024*\"payne\" + 0.023*\"blood\" + 0.018*\"wubbels\" + 0.017*\"hospital\" + 0.014*\"nurse\" + 0.013*\"city\" + 0.013*\"patient\"\n",
      "2019-10-29 00:40:55,677 : INFO : topic #0 (0.100): 0.042*\"police\" + 0.032*\"officer\" + 0.025*\"payne\" + 0.022*\"said\" + 0.019*\"blood\" + 0.018*\"nurse\" + 0.018*\"wubbels\" + 0.014*\"policy\" + 0.012*\"city\" + 0.012*\"hospital\"\n",
      "2019-10-29 00:40:55,684 : INFO : topic #7 (0.100): 0.036*\"police\" + 0.026*\"payne\" + 0.026*\"officer\" + 0.025*\"nurse\" + 0.023*\"said\" + 0.021*\"blood\" + 0.017*\"wubbels\" + 0.013*\"patient\" + 0.013*\"policy\" + 0.012*\"hospital\"\n",
      "2019-10-29 00:40:55,688 : INFO : topic #3 (0.100): 0.041*\"police\" + 0.026*\"officer\" + 0.023*\"payne\" + 0.021*\"said\" + 0.019*\"wubbels\" + 0.018*\"blood\" + 0.016*\"nurse\" + 0.015*\"hospital\" + 0.013*\"policy\" + 0.013*\"salt\"\n",
      "2019-10-29 00:40:55,691 : INFO : topic diff=0.840491, rho=1.000000\n",
      "2019-10-29 00:40:56,121 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:56,127 : INFO : built Dictionary(274 unique tokens: ['violence', 'prime', 'aspiration', 'embody', 'nation']...) from 5 documents (total 2135 corpus positions)\n",
      "2019-10-29 00:40:56,130 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:56,132 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:56,133 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:56,136 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:56,138 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:56,240 : INFO : -7.638 per-word bound, 199.1 perplexity estimate based on a held-out corpus of 5 documents with 2135 words\n",
      "2019-10-29 00:40:56,242 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:56,249 : INFO : topic #9 (0.100): 0.038*\"happiness\" + 0.029*\"country\" + 0.026*\"people\" + 0.017*\"world\" + 0.014*\"life\" + 0.013*\"report\" + 0.012*\"said\" + 0.010*\"social\" + 0.010*\"well\" + 0.009*\"according\"\n",
      "2019-10-29 00:40:56,252 : INFO : topic #8 (0.100): 0.033*\"happiness\" + 0.018*\"world\" + 0.018*\"country\" + 0.017*\"report\" + 0.017*\"people\" + 0.015*\"said\" + 0.012*\"place\" + 0.012*\"life\" + 0.011*\"inequality\" + 0.011*\"social\"\n",
      "2019-10-29 00:40:56,256 : INFO : topic #4 (0.100): 0.035*\"happiness\" + 0.021*\"country\" + 0.021*\"report\" + 0.016*\"world\" + 0.016*\"people\" + 0.015*\"well\" + 0.013*\"life\" + 0.012*\"economic\" + 0.011*\"said\" + 0.011*\"social\"\n",
      "2019-10-29 00:40:56,258 : INFO : topic #2 (0.100): 0.036*\"happiness\" + 0.018*\"people\" + 0.018*\"country\" + 0.016*\"well\" + 0.015*\"report\" + 0.014*\"said\" + 0.013*\"inequality\" + 0.011*\"place\" + 0.011*\"world\" + 0.011*\"according\"\n",
      "2019-10-29 00:40:56,261 : INFO : topic #6 (0.100): 0.037*\"happiness\" + 0.024*\"country\" + 0.019*\"report\" + 0.017*\"people\" + 0.015*\"life\" + 0.013*\"said\" + 0.012*\"well\" + 0.012*\"inequality\" + 0.011*\"social\" + 0.011*\"place\"\n",
      "2019-10-29 00:40:56,263 : INFO : topic diff=0.842791, rho=1.000000\n",
      "2019-10-29 00:40:56,683 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:56,689 : INFO : built Dictionary(310 unique tokens: ['several', 'relation', 'school', 'book', 'attending']...) from 5 documents (total 2655 corpus positions)\n",
      "2019-10-29 00:40:56,693 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:56,695 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:56,697 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:56,700 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:56,701 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:56,808 : INFO : -7.616 per-word bound, 196.1 perplexity estimate based on a held-out corpus of 5 documents with 2655 words\n",
      "2019-10-29 00:40:56,809 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:56,817 : INFO : topic #1 (0.100): 0.036*\"turkey\" + 0.026*\"u\" + 0.017*\"said\" + 0.016*\"gulen\" + 0.013*\"washington\" + 0.013*\"arrested\" + 0.012*\"brunson\" + 0.012*\"detained\" + 0.011*\"turkish\" + 0.010*\"year\"\n",
      "2019-10-29 00:40:56,818 : INFO : topic #0 (0.100): 0.034*\"u\" + 0.024*\"turkey\" + 0.022*\"gulen\" + 0.017*\"detained\" + 0.014*\"turkish\" + 0.012*\"said\" + 0.012*\"brunson\" + 0.012*\"arrested\" + 0.010*\"year\" + 0.010*\"link\"\n",
      "2019-10-29 00:40:56,819 : INFO : topic #2 (0.100): 0.034*\"u\" + 0.024*\"turkey\" + 0.017*\"gulen\" + 0.017*\"said\" + 0.016*\"detained\" + 0.014*\"american\" + 0.014*\"turkish\" + 0.012*\"brunson\" + 0.012*\"arrested\" + 0.012*\"year\"\n",
      "2019-10-29 00:40:56,821 : INFO : topic #5 (0.100): 0.032*\"u\" + 0.028*\"turkey\" + 0.023*\"gulen\" + 0.019*\"detained\" + 0.017*\"brunson\" + 0.015*\"said\" + 0.012*\"turkish\" + 0.012*\"american\" + 0.011*\"arrested\" + 0.011*\"year\"\n",
      "2019-10-29 00:40:56,822 : INFO : topic #7 (0.100): 0.035*\"u\" + 0.028*\"turkey\" + 0.016*\"arrested\" + 0.015*\"detained\" + 0.015*\"said\" + 0.015*\"gulen\" + 0.014*\"brunson\" + 0.012*\"year\" + 0.011*\"turkish\" + 0.010*\"american\"\n",
      "2019-10-29 00:40:56,824 : INFO : topic diff=0.898063, rho=1.000000\n",
      "2019-10-29 00:40:57,233 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:57,235 : INFO : built Dictionary(88 unique tokens: ['unsuccessful', 'count', 'filed', 'refugee', 'causing']...) from 5 documents (total 575 corpus positions)\n",
      "2019-10-29 00:40:57,238 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:57,239 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:57,241 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:57,244 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:57,246 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:57,302 : INFO : -6.914 per-word bound, 120.6 perplexity estimate based on a held-out corpus of 5 documents with 575 words\n",
      "2019-10-29 00:40:57,307 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:57,313 : INFO : topic #2 (0.100): 0.047*\"sharif\" + 0.030*\"edmonton\" + 0.029*\"five\" + 0.027*\"police\" + 0.021*\"charge\" + 0.020*\"incident\" + 0.019*\"terrorism\" + 0.019*\"time\" + 0.019*\"back\" + 0.018*\"said\"\n",
      "2019-10-29 00:40:57,316 : INFO : topic #8 (0.100): 0.029*\"sharif\" + 0.029*\"five\" + 0.027*\"police\" + 0.024*\"charge\" + 0.022*\"injured\" + 0.022*\"terrorism\" + 0.021*\"suspect\" + 0.020*\"edmonton\" + 0.018*\"back\" + 0.018*\"cnn\"\n",
      "2019-10-29 00:40:57,319 : INFO : topic #9 (0.100): 0.045*\"sharif\" + 0.037*\"police\" + 0.026*\"edmonton\" + 0.023*\"five\" + 0.021*\"charge\" + 0.021*\"terrorism\" + 0.019*\"charged\" + 0.018*\"back\" + 0.017*\"time\" + 0.017*\"abdulahi\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:57,330 : INFO : topic #6 (0.100): 0.050*\"sharif\" + 0.028*\"police\" + 0.025*\"terrorism\" + 0.022*\"five\" + 0.022*\"charge\" + 0.021*\"edmonton\" + 0.020*\"hasan\" + 0.018*\"suspect\" + 0.018*\"talbot\" + 0.018*\"said\"\n",
      "2019-10-29 00:40:57,334 : INFO : topic #7 (0.100): 0.044*\"sharif\" + 0.029*\"police\" + 0.026*\"terrorism\" + 0.026*\"charge\" + 0.024*\"edmonton\" + 0.020*\"five\" + 0.020*\"injured\" + 0.019*\"incident\" + 0.019*\"cnn\" + 0.018*\"dangerous\"\n",
      "2019-10-29 00:40:57,337 : INFO : topic diff=0.724627, rho=1.000000\n",
      "2019-10-29 00:40:57,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:57,803 : INFO : built Dictionary(403 unique tokens: ['valley', 'forecast', 'wave', 'deep', 'hazardous']...) from 5 documents (total 3015 corpus positions)\n",
      "2019-10-29 00:40:57,808 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:57,809 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:57,811 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:57,816 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:57,819 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:57,964 : INFO : -8.061 per-word bound, 267.1 perplexity estimate based on a held-out corpus of 5 documents with 3015 words\n",
      "2019-10-29 00:40:57,965 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:57,973 : INFO : topic #6 (0.100): 0.022*\"valley\" + 0.014*\"volcano\" + 0.012*\"mauna\" + 0.012*\"summit\" + 0.011*\"mile\" + 0.011*\"lava\" + 0.009*\"volcanic\" + 0.009*\"hawaiian\" + 0.009*\"island\" + 0.009*\"flow\"\n",
      "2019-10-29 00:40:57,975 : INFO : topic #7 (0.100): 0.026*\"valley\" + 0.014*\"volcano\" + 0.014*\"flow\" + 0.013*\"mauna\" + 0.013*\"lava\" + 0.012*\"mile\" + 0.010*\"summit\" + 0.010*\"hawaiian\" + 0.009*\"island\" + 0.009*\"hawaii\"\n",
      "2019-10-29 00:40:57,976 : INFO : topic #9 (0.100): 0.018*\"valley\" + 0.014*\"volcano\" + 0.013*\"lava\" + 0.013*\"mauna\" + 0.012*\"flow\" + 0.011*\"summit\" + 0.011*\"hawaiian\" + 0.010*\"mile\" + 0.008*\"volcanic\" + 0.008*\"island\"\n",
      "2019-10-29 00:40:57,978 : INFO : topic #3 (0.100): 0.018*\"valley\" + 0.013*\"volcano\" + 0.013*\"mile\" + 0.012*\"lava\" + 0.011*\"park\" + 0.011*\"flow\" + 0.010*\"mauna\" + 0.009*\"volcanic\" + 0.009*\"hawaiian\" + 0.009*\"island\"\n",
      "2019-10-29 00:40:57,980 : INFO : topic #2 (0.100): 0.022*\"valley\" + 0.014*\"volcano\" + 0.011*\"mile\" + 0.011*\"mauna\" + 0.010*\"summit\" + 0.010*\"park\" + 0.010*\"lava\" + 0.010*\"island\" + 0.010*\"flow\" + 0.009*\"hawaii\"\n",
      "2019-10-29 00:40:57,981 : INFO : topic diff=0.835831, rho=1.000000\n",
      "2019-10-29 00:40:58,432 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:58,438 : INFO : built Dictionary(341 unique tokens: ['forward', 'danley', 'phase', 'review', 'maintenance']...) from 5 documents (total 3200 corpus positions)\n",
      "2019-10-29 00:40:58,443 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:58,445 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:58,447 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:58,451 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:58,453 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:58,577 : INFO : -7.588 per-word bound, 192.4 perplexity estimate based on a held-out corpus of 5 documents with 3200 words\n",
      "2019-10-29 00:40:58,579 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:58,586 : INFO : topic #2 (0.100): 0.042*\"said\" + 0.025*\"paddock\" + 0.020*\"lombardo\" + 0.018*\"shot\" + 0.014*\"gunman\" + 0.013*\"shooting\" + 0.011*\"security\" + 0.011*\"campos\" + 0.011*\"room\" + 0.011*\"timeline\"\n",
      "2019-10-29 00:40:58,589 : INFO : topic #5 (0.100): 0.043*\"said\" + 0.025*\"paddock\" + 0.018*\"shot\" + 0.018*\"shooting\" + 0.016*\"lombardo\" + 0.011*\"campos\" + 0.011*\"suspect\" + 0.010*\"security\" + 0.010*\"danley\" + 0.009*\"gunman\"\n",
      "2019-10-29 00:40:58,591 : INFO : topic #7 (0.100): 0.046*\"said\" + 0.032*\"paddock\" + 0.023*\"lombardo\" + 0.014*\"shooting\" + 0.013*\"shot\" + 0.013*\"campos\" + 0.012*\"gunman\" + 0.012*\"danley\" + 0.010*\"room\" + 0.009*\"timeline\"\n",
      "2019-10-29 00:40:58,593 : INFO : topic #4 (0.100): 0.040*\"said\" + 0.023*\"lombardo\" + 0.021*\"paddock\" + 0.014*\"shooting\" + 0.013*\"gunman\" + 0.012*\"shot\" + 0.012*\"campos\" + 0.011*\"room\" + 0.011*\"guard\" + 0.011*\"know\"\n",
      "2019-10-29 00:40:58,594 : INFO : topic #0 (0.100): 0.036*\"said\" + 0.027*\"paddock\" + 0.027*\"lombardo\" + 0.013*\"shot\" + 0.013*\"shooting\" + 0.012*\"room\" + 0.012*\"gunman\" + 0.012*\"security\" + 0.009*\"guard\" + 0.009*\"floor\"\n",
      "2019-10-29 00:40:58,596 : INFO : topic diff=0.911170, rho=1.000000\n",
      "2019-10-29 00:40:58,989 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:58,990 : INFO : built Dictionary(67 unique tokens: ['story', 'chandigarh', 'forensic', 'working', 'victim']...) from 5 documents (total 550 corpus positions)\n",
      "2019-10-29 00:40:58,992 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:58,994 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:58,995 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:58,997 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:58,999 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:59,030 : INFO : -6.302 per-word bound, 78.9 perplexity estimate based on a held-out corpus of 5 documents with 550 words\n",
      "2019-10-29 00:40:59,032 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:59,042 : INFO : topic #2 (0.100): 0.069*\"uncle\" + 0.047*\"police\" + 0.045*\"dna\" + 0.037*\"second\" + 0.035*\"girl\" + 0.031*\"rape\" + 0.030*\"show\" + 0.030*\"indian\" + 0.029*\"test\" + 0.022*\"baby\"\n",
      "2019-10-29 00:40:59,044 : INFO : topic #7 (0.100): 0.075*\"uncle\" + 0.049*\"police\" + 0.041*\"second\" + 0.036*\"dna\" + 0.033*\"test\" + 0.028*\"show\" + 0.025*\"indian\" + 0.025*\"rape\" + 0.023*\"taken\" + 0.021*\"charge\"\n",
      "2019-10-29 00:40:59,048 : INFO : topic #9 (0.100): 0.061*\"second\" + 0.055*\"uncle\" + 0.051*\"police\" + 0.029*\"test\" + 0.027*\"show\" + 0.027*\"girl\" + 0.026*\"dna\" + 0.026*\"indian\" + 0.022*\"charge\" + 0.022*\"rape\"\n",
      "2019-10-29 00:40:59,051 : INFO : topic #5 (0.100): 0.059*\"uncle\" + 0.045*\"second\" + 0.041*\"police\" + 0.036*\"dna\" + 0.029*\"girl\" + 0.029*\"test\" + 0.027*\"indian\" + 0.025*\"show\" + 0.022*\"charge\" + 0.021*\"two\"\n",
      "2019-10-29 00:40:59,055 : INFO : topic #3 (0.100): 0.080*\"uncle\" + 0.055*\"second\" + 0.047*\"police\" + 0.028*\"girl\" + 0.028*\"indian\" + 0.028*\"dna\" + 0.027*\"show\" + 0.027*\"test\" + 0.023*\"rape\" + 0.021*\"chandigarh\"\n",
      "2019-10-29 00:40:59,058 : INFO : topic diff=0.828004, rho=1.000000\n",
      "2019-10-29 00:40:59,478 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:59,480 : INFO : built Dictionary(85 unique tokens: ['considered', 'retrospective', 'may', 'stieglitz', 'life']...) from 5 documents (total 535 corpus positions)\n",
      "2019-10-29 00:40:59,483 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:40:59,487 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:40:59,490 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:40:59,494 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:40:59,497 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:40:59,550 : INFO : -6.960 per-word bound, 124.5 perplexity estimate based on a held-out corpus of 5 documents with 535 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:40:59,553 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:40:59,562 : INFO : topic #2 (0.100): 0.060*\"keeffe\" + 0.027*\"year\" + 0.026*\"work\" + 0.022*\"artist\" + 0.021*\"modern\" + 0.020*\"one\" + 0.020*\"collection\" + 0.019*\"modernism\" + 0.018*\"american\" + 0.017*\"painting\"\n",
      "2019-10-29 00:40:59,566 : INFO : topic #5 (0.100): 0.043*\"keeffe\" + 0.035*\"american\" + 0.031*\"year\" + 0.020*\"flower\" + 0.019*\"work\" + 0.019*\"artist\" + 0.018*\"georgia\" + 0.017*\"modern\" + 0.017*\"painting\" + 0.017*\"exhibition\"\n",
      "2019-10-29 00:40:59,569 : INFO : topic #3 (0.100): 0.047*\"keeffe\" + 0.029*\"year\" + 0.029*\"american\" + 0.027*\"work\" + 0.026*\"artist\" + 0.023*\"flower\" + 0.019*\"exhibition\" + 0.017*\"modernism\" + 0.017*\"one\" + 0.016*\"collection\"\n",
      "2019-10-29 00:40:59,572 : INFO : topic #1 (0.100): 0.050*\"keeffe\" + 0.025*\"american\" + 0.024*\"work\" + 0.023*\"georgia\" + 0.022*\"year\" + 0.021*\"modernism\" + 0.021*\"female\" + 0.020*\"collection\" + 0.019*\"modern\" + 0.018*\"painting\"\n",
      "2019-10-29 00:40:59,575 : INFO : topic #6 (0.100): 0.039*\"keeffe\" + 0.030*\"work\" + 0.023*\"american\" + 0.023*\"year\" + 0.022*\"tate\" + 0.021*\"female\" + 0.021*\"exhibition\" + 0.020*\"georgia\" + 0.020*\"modernism\" + 0.019*\"artist\"\n",
      "2019-10-29 00:40:59,578 : INFO : topic diff=0.701500, rho=1.000000\n",
      "2019-10-29 00:40:59,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:40:59,997 : INFO : built Dictionary(216 unique tokens: ['although', 'let', 'architecture', 'located', 'painting']...) from 5 documents (total 1565 corpus positions)\n",
      "2019-10-29 00:41:00,000 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:00,002 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:00,004 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:00,015 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:00,018 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:00,111 : INFO : -7.529 per-word bound, 184.7 perplexity estimate based on a held-out corpus of 5 documents with 1565 words\n",
      "2019-10-29 00:41:00,112 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:00,117 : INFO : topic #3 (0.100): 0.043*\"city\" + 0.024*\"china\" + 0.016*\"architect\" + 0.014*\"nature\" + 0.012*\"mountain\" + 0.012*\"shanshui\" + 0.012*\"mad\" + 0.012*\"high\" + 0.012*\"architecture\" + 0.011*\"people\"\n",
      "2019-10-29 00:41:00,120 : INFO : topic #1 (0.100): 0.028*\"city\" + 0.019*\"china\" + 0.018*\"mountain\" + 0.015*\"nature\" + 0.013*\"architect\" + 0.013*\"chinese\" + 0.013*\"mad\" + 0.013*\"beijing\" + 0.013*\"people\" + 0.012*\"high\"\n",
      "2019-10-29 00:41:00,122 : INFO : topic #6 (0.100): 0.033*\"city\" + 0.022*\"architect\" + 0.020*\"china\" + 0.016*\"mountain\" + 0.015*\"beijing\" + 0.013*\"nature\" + 0.012*\"people\" + 0.012*\"high\" + 0.012*\"chinese\" + 0.011*\"mad\"\n",
      "2019-10-29 00:41:00,124 : INFO : topic #2 (0.100): 0.034*\"city\" + 0.020*\"mountain\" + 0.018*\"architect\" + 0.016*\"china\" + 0.013*\"mad\" + 0.013*\"high\" + 0.012*\"people\" + 0.012*\"say\" + 0.011*\"chinese\" + 0.011*\"beijing\"\n",
      "2019-10-29 00:41:00,126 : INFO : topic #7 (0.100): 0.025*\"city\" + 0.021*\"china\" + 0.018*\"mountain\" + 0.017*\"architect\" + 0.012*\"nature\" + 0.012*\"mad\" + 0.011*\"say\" + 0.011*\"chinese\" + 0.011*\"huangshan\" + 0.010*\"urban\"\n",
      "2019-10-29 00:41:00,128 : INFO : topic diff=0.805636, rho=1.000000\n",
      "2019-10-29 00:41:00,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:00,583 : INFO : built Dictionary(319 unique tokens: ['relation', 'perhaps', 'single', 'book', '1990s']...) from 5 documents (total 2410 corpus positions)\n",
      "2019-10-29 00:41:00,588 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:00,590 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:00,592 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:00,595 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:00,597 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:00,748 : INFO : -7.825 per-word bound, 226.7 perplexity estimate based on a held-out corpus of 5 documents with 2410 words\n",
      "2019-10-29 00:41:00,750 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:00,760 : INFO : topic #4 (0.100): 0.033*\"map\" + 0.025*\"qiu\" + 0.019*\"art\" + 0.018*\"china\" + 0.013*\"chinese\" + 0.012*\"world\" + 0.009*\"relationship\" + 0.009*\"said\" + 0.009*\"one\" + 0.008*\"zhijie\"\n",
      "2019-10-29 00:41:00,763 : INFO : topic #6 (0.100): 0.025*\"qiu\" + 0.025*\"art\" + 0.024*\"map\" + 0.021*\"china\" + 0.015*\"world\" + 0.013*\"chinese\" + 0.009*\"relationship\" + 0.009*\"exhibition\" + 0.008*\"zhijie\" + 0.008*\"story\"\n",
      "2019-10-29 00:41:00,767 : INFO : topic #1 (0.100): 0.035*\"map\" + 0.027*\"qiu\" + 0.021*\"art\" + 0.019*\"china\" + 0.014*\"chinese\" + 0.012*\"world\" + 0.010*\"one\" + 0.010*\"zhijie\" + 0.009*\"exhibition\" + 0.008*\"said\"\n",
      "2019-10-29 00:41:00,780 : INFO : topic #3 (0.100): 0.033*\"qiu\" + 0.029*\"map\" + 0.025*\"art\" + 0.020*\"china\" + 0.017*\"world\" + 0.013*\"chinese\" + 0.011*\"zhijie\" + 0.009*\"artist\" + 0.009*\"beijing\" + 0.008*\"said\"\n",
      "2019-10-29 00:41:00,783 : INFO : topic #7 (0.100): 0.025*\"qiu\" + 0.023*\"map\" + 0.022*\"china\" + 0.016*\"art\" + 0.012*\"world\" + 0.012*\"chinese\" + 0.011*\"zhijie\" + 0.009*\"exhibition\" + 0.007*\"one\" + 0.007*\"beijing\"\n",
      "2019-10-29 00:41:00,786 : INFO : topic diff=0.816508, rho=1.000000\n",
      "2019-10-29 00:41:01,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:01,235 : INFO : built Dictionary(339 unique tokens: ['anniversary', 'gettysburg', 'enterprise', 'campaign', 'retiring']...) from 5 documents (total 3680 corpus positions)\n",
      "2019-10-29 00:41:01,240 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:01,241 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:01,242 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:01,246 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:01,248 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:01,355 : INFO : -7.428 per-word bound, 172.2 perplexity estimate based on a held-out corpus of 5 documents with 3680 words\n",
      "2019-10-29 00:41:01,356 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:01,365 : INFO : topic #2 (0.100): 0.061*\"justice\" + 0.058*\"photo\" + 0.054*\"scalia\" + 0.033*\"antonin\" + 0.031*\"caption\" + 0.031*\"life\" + 0.029*\"hide\" + 0.018*\"court\" + 0.013*\"supreme\" + 0.013*\"washington\"\n",
      "2019-10-29 00:41:01,366 : INFO : topic #1 (0.100): 0.096*\"scalia\" + 0.052*\"photo\" + 0.050*\"justice\" + 0.035*\"antonin\" + 0.032*\"life\" + 0.024*\"caption\" + 0.022*\"hide\" + 0.017*\"court\" + 0.013*\"washington\" + 0.013*\"u\"\n",
      "2019-10-29 00:41:01,368 : INFO : topic #8 (0.100): 0.066*\"scalia\" + 0.060*\"justice\" + 0.045*\"photo\" + 0.037*\"antonin\" + 0.033*\"caption\" + 0.023*\"hide\" + 0.023*\"life\" + 0.020*\"court\" + 0.015*\"u\" + 0.012*\"president\"\n",
      "2019-10-29 00:41:01,370 : INFO : topic #4 (0.100): 0.071*\"scalia\" + 0.069*\"justice\" + 0.047*\"photo\" + 0.036*\"hide\" + 0.029*\"antonin\" + 0.026*\"caption\" + 0.022*\"life\" + 0.016*\"president\" + 0.013*\"u\" + 0.011*\"supreme\"\n",
      "2019-10-29 00:41:01,371 : INFO : topic #5 (0.100): 0.070*\"scalia\" + 0.064*\"photo\" + 0.059*\"justice\" + 0.036*\"antonin\" + 0.031*\"life\" + 0.025*\"caption\" + 0.022*\"hide\" + 0.018*\"u\" + 0.016*\"court\" + 0.012*\"washington\"\n",
      "2019-10-29 00:41:01,373 : INFO : topic diff=1.071237, rho=1.000000\n",
      "2019-10-29 00:41:01,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:01,806 : INFO : built Dictionary(354 unique tokens: ['although', 'cortex', 'nature', 'notice', 'focus']...) from 5 documents (total 2495 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:01,810 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:01,812 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:01,813 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:01,817 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:01,818 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:01,971 : INFO : -8.036 per-word bound, 262.5 perplexity estimate based on a held-out corpus of 5 documents with 2495 words\n",
      "2019-10-29 00:41:01,974 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:01,982 : INFO : topic #4 (0.100): 0.027*\"paddock\" + 0.017*\"brain\" + 0.011*\"behavior\" + 0.011*\"brother\" + 0.010*\"psychopathy\" + 0.010*\"people\" + 0.010*\"psychopath\" + 0.008*\"tumor\" + 0.007*\"u\" + 0.007*\"finally\"\n",
      "2019-10-29 00:41:01,984 : INFO : topic #2 (0.100): 0.033*\"paddock\" + 0.017*\"brain\" + 0.012*\"brother\" + 0.011*\"people\" + 0.009*\"behavior\" + 0.009*\"psychopathy\" + 0.008*\"tumor\" + 0.007*\"ftd\" + 0.007*\"could\" + 0.006*\"finally\"\n",
      "2019-10-29 00:41:01,986 : INFO : topic #6 (0.100): 0.020*\"brain\" + 0.017*\"paddock\" + 0.014*\"people\" + 0.013*\"brother\" + 0.011*\"psychopathy\" + 0.010*\"behavior\" + 0.007*\"finally\" + 0.007*\"disorder\" + 0.007*\"person\" + 0.007*\"psychopath\"\n",
      "2019-10-29 00:41:01,988 : INFO : topic #7 (0.100): 0.025*\"paddock\" + 0.018*\"brain\" + 0.014*\"people\" + 0.010*\"brother\" + 0.009*\"psychopathy\" + 0.007*\"important\" + 0.007*\"change\" + 0.007*\"behavior\" + 0.007*\"psychopath\" + 0.007*\"could\"\n",
      "2019-10-29 00:41:01,990 : INFO : topic #0 (0.100): 0.035*\"paddock\" + 0.020*\"brain\" + 0.012*\"brother\" + 0.010*\"people\" + 0.009*\"behavior\" + 0.008*\"psychopath\" + 0.007*\"psychopathy\" + 0.007*\"schizophrenia\" + 0.006*\"could\" + 0.006*\"u\"\n",
      "2019-10-29 00:41:01,992 : INFO : topic diff=0.772673, rho=1.000000\n",
      "2019-10-29 00:41:02,382 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:02,383 : INFO : built Dictionary(14 unique tokens: ['happening', 'unfolds', 'facebook', 'messenger', 'found']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:41:02,384 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:02,387 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:02,391 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:02,395 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:02,398 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:02,410 : INFO : -6.438 per-word bound, 86.7 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:41:02,413 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:02,419 : INFO : topic #6 (0.100): 0.092*\"messenger\" + 0.089*\"world\" + 0.079*\"chat\" + 0.079*\"unfolds\" + 0.075*\"round\" + 0.075*\"ammo\" + 0.074*\"found\" + 0.074*\"room\" + 0.068*\"happening\" + 0.068*\"tracer\"\n",
      "2019-10-29 00:41:02,421 : INFO : topic #0 (0.100): 0.091*\"ammo\" + 0.082*\"chat\" + 0.079*\"happening\" + 0.078*\"u\" + 0.074*\"facebook\" + 0.073*\"shooter\" + 0.072*\"unfolds\" + 0.070*\"round\" + 0.069*\"tracer\" + 0.068*\"world\"\n",
      "2019-10-29 00:41:02,424 : INFO : topic #7 (0.100): 0.085*\"find\" + 0.078*\"chat\" + 0.077*\"round\" + 0.076*\"ammo\" + 0.075*\"unfolds\" + 0.075*\"messenger\" + 0.074*\"found\" + 0.071*\"shooter\" + 0.069*\"tracer\" + 0.067*\"u\"\n",
      "2019-10-29 00:41:02,436 : INFO : topic #9 (0.100): 0.095*\"found\" + 0.086*\"room\" + 0.081*\"shooter\" + 0.080*\"facebook\" + 0.078*\"ammo\" + 0.071*\"find\" + 0.070*\"chat\" + 0.069*\"messenger\" + 0.067*\"unfolds\" + 0.066*\"u\"\n",
      "2019-10-29 00:41:02,439 : INFO : topic #5 (0.100): 0.086*\"round\" + 0.081*\"u\" + 0.080*\"found\" + 0.078*\"messenger\" + 0.077*\"world\" + 0.076*\"tracer\" + 0.075*\"room\" + 0.070*\"unfolds\" + 0.068*\"happening\" + 0.068*\"find\"\n",
      "2019-10-29 00:41:02,443 : INFO : topic diff=0.517147, rho=1.000000\n",
      "2019-10-29 00:41:02,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:02,880 : INFO : built Dictionary(355 unique tokens: ['although', 'let', 'treasured', 'deep', 'party']...) from 5 documents (total 3010 corpus positions)\n",
      "2019-10-29 00:41:02,884 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:02,885 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:02,887 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:02,890 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:02,892 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:03,010 : INFO : -7.760 per-word bound, 216.7 perplexity estimate based on a held-out corpus of 5 documents with 3010 words\n",
      "2019-10-29 00:41:03,012 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:03,021 : INFO : topic #5 (0.100): 0.019*\"recipe\" + 0.019*\"adam\" + 0.015*\"goodman\" + 0.014*\"conversation\" + 0.013*\"end\" + 0.013*\"family\" + 0.013*\"life\" + 0.012*\"said\" + 0.012*\"chef\" + 0.011*\"loved\"\n",
      "2019-10-29 00:41:03,024 : INFO : topic #8 (0.100): 0.018*\"family\" + 0.016*\"death\" + 0.016*\"recipe\" + 0.015*\"conversation\" + 0.015*\"hebb\" + 0.013*\"life\" + 0.012*\"goodman\" + 0.012*\"said\" + 0.011*\"end\" + 0.011*\"adam\"\n",
      "2019-10-29 00:41:03,027 : INFO : topic #1 (0.100): 0.017*\"recipe\" + 0.016*\"hebb\" + 0.015*\"adam\" + 0.014*\"dinner\" + 0.014*\"people\" + 0.014*\"goodman\" + 0.013*\"family\" + 0.013*\"end\" + 0.012*\"life\" + 0.012*\"conversation\"\n",
      "2019-10-29 00:41:03,029 : INFO : topic #7 (0.100): 0.015*\"goodman\" + 0.015*\"end\" + 0.014*\"conversation\" + 0.014*\"death\" + 0.013*\"recipe\" + 0.013*\"hebb\" + 0.013*\"family\" + 0.012*\"said\" + 0.012*\"adam\" + 0.011*\"father\"\n",
      "2019-10-29 00:41:03,032 : INFO : topic #3 (0.100): 0.021*\"recipe\" + 0.020*\"family\" + 0.014*\"death\" + 0.013*\"adam\" + 0.012*\"said\" + 0.012*\"life\" + 0.012*\"goodman\" + 0.011*\"hebb\" + 0.011*\"chef\" + 0.010*\"conversation\"\n",
      "2019-10-29 00:41:03,035 : INFO : topic diff=0.908510, rho=1.000000\n",
      "2019-10-29 00:41:03,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:03,468 : INFO : built Dictionary(343 unique tokens: ['let', 'catholic', 'filed', 'involved', 'focus']...) from 5 documents (total 3010 corpus positions)\n",
      "2019-10-29 00:41:03,474 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:03,476 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:03,477 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:03,481 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:03,483 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:03,622 : INFO : -7.683 per-word bound, 205.5 perplexity estimate based on a held-out corpus of 5 documents with 3010 words\n",
      "2019-10-29 00:41:03,624 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:03,633 : INFO : topic #6 (0.100): 0.030*\"woman\" + 0.021*\"religious\" + 0.020*\"birth\" + 0.017*\"control\" + 0.016*\"health\" + 0.016*\"rule\" + 0.015*\"said\" + 0.013*\"coverage\" + 0.011*\"could\" + 0.010*\"new\"\n",
      "2019-10-29 00:41:03,637 : INFO : topic #1 (0.100): 0.027*\"woman\" + 0.020*\"control\" + 0.019*\"birth\" + 0.019*\"said\" + 0.017*\"health\" + 0.016*\"rule\" + 0.016*\"religious\" + 0.013*\"coverage\" + 0.011*\"contraceptive\" + 0.010*\"could\"\n",
      "2019-10-29 00:41:03,637 : INFO : topic #3 (0.100): 0.025*\"woman\" + 0.017*\"said\" + 0.017*\"birth\" + 0.016*\"health\" + 0.016*\"religious\" + 0.015*\"rule\" + 0.015*\"coverage\" + 0.014*\"control\" + 0.013*\"could\" + 0.009*\"law\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:03,639 : INFO : topic #9 (0.100): 0.024*\"woman\" + 0.019*\"said\" + 0.017*\"health\" + 0.016*\"birth\" + 0.015*\"control\" + 0.014*\"rule\" + 0.013*\"could\" + 0.012*\"religious\" + 0.012*\"contraceptive\" + 0.010*\"coverage\"\n",
      "2019-10-29 00:41:03,641 : INFO : topic #7 (0.100): 0.028*\"woman\" + 0.019*\"said\" + 0.016*\"control\" + 0.016*\"religious\" + 0.015*\"birth\" + 0.014*\"health\" + 0.012*\"coverage\" + 0.011*\"contraceptive\" + 0.011*\"could\" + 0.009*\"would\"\n",
      "2019-10-29 00:41:03,643 : INFO : topic diff=0.900569, rho=1.000000\n",
      "2019-10-29 00:41:04,061 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:04,064 : INFO : built Dictionary(205 unique tokens: ['extremely', 'perhaps', 'single', 'chilly', 'wade']...) from 5 documents (total 1460 corpus positions)\n",
      "2019-10-29 00:41:04,067 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:04,069 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:04,070 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:04,078 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:04,080 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:04,169 : INFO : -7.506 per-word bound, 181.8 perplexity estimate based on a held-out corpus of 5 documents with 1460 words\n",
      "2019-10-29 00:41:04,170 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:04,178 : INFO : topic #4 (0.100): 0.027*\"license\" + 0.024*\"station\" + 0.023*\"nbc\" + 0.023*\"fcc\" + 0.019*\"trump\" + 0.018*\"political\" + 0.014*\"president\" + 0.013*\"local\" + 0.012*\"said\" + 0.011*\"nixon\"\n",
      "2019-10-29 00:41:04,183 : INFO : topic #5 (0.100): 0.029*\"trump\" + 0.029*\"license\" + 0.024*\"fcc\" + 0.023*\"station\" + 0.022*\"nbc\" + 0.017*\"political\" + 0.015*\"said\" + 0.015*\"president\" + 0.014*\"local\" + 0.014*\"law\"\n",
      "2019-10-29 00:41:04,186 : INFO : topic #0 (0.100): 0.031*\"nbc\" + 0.026*\"license\" + 0.021*\"trump\" + 0.020*\"fcc\" + 0.017*\"president\" + 0.013*\"law\" + 0.013*\"political\" + 0.013*\"news\" + 0.013*\"station\" + 0.012*\"said\"\n",
      "2019-10-29 00:41:04,189 : INFO : topic #7 (0.100): 0.033*\"license\" + 0.023*\"station\" + 0.023*\"trump\" + 0.022*\"nbc\" + 0.017*\"political\" + 0.016*\"law\" + 0.014*\"local\" + 0.014*\"president\" + 0.014*\"fcc\" + 0.013*\"would\"\n",
      "2019-10-29 00:41:04,192 : INFO : topic #6 (0.100): 0.033*\"license\" + 0.026*\"nbc\" + 0.021*\"trump\" + 0.020*\"fcc\" + 0.017*\"station\" + 0.016*\"president\" + 0.015*\"would\" + 0.014*\"law\" + 0.013*\"political\" + 0.013*\"said\"\n",
      "2019-10-29 00:41:04,195 : INFO : topic diff=0.808087, rho=1.000000\n",
      "2019-10-29 00:41:04,698 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:04,706 : INFO : built Dictionary(441 unique tokens: ['rmit', 'fostering', 'energy', 'retreat', 'party']...) from 5 documents (total 3950 corpus positions)\n",
      "2019-10-29 00:41:04,713 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:04,714 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:04,718 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:04,723 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:04,726 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:04,894 : INFO : -7.899 per-word bound, 238.7 perplexity estimate based on a held-out corpus of 5 documents with 3950 words\n",
      "2019-10-29 00:41:04,895 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:04,904 : INFO : topic #1 (0.100): 0.023*\"u\" + 0.021*\"iran\" + 0.018*\"agreement\" + 0.014*\"deal\" + 0.013*\"trump\" + 0.012*\"state\" + 0.011*\"said\" + 0.009*\"nuclear\" + 0.009*\"policy\" + 0.009*\"foreign\"\n",
      "2019-10-29 00:41:04,906 : INFO : topic #6 (0.100): 0.029*\"u\" + 0.018*\"agreement\" + 0.017*\"iran\" + 0.017*\"deal\" + 0.016*\"north\" + 0.013*\"said\" + 0.011*\"state\" + 0.010*\"trump\" + 0.010*\"foreign\" + 0.009*\"korea\"\n",
      "2019-10-29 00:41:04,907 : INFO : topic #7 (0.100): 0.025*\"iran\" + 0.019*\"said\" + 0.019*\"deal\" + 0.019*\"agreement\" + 0.016*\"u\" + 0.013*\"trump\" + 0.011*\"north\" + 0.010*\"state\" + 0.009*\"foreign\" + 0.009*\"accord\"\n",
      "2019-10-29 00:41:04,909 : INFO : topic #2 (0.100): 0.024*\"iran\" + 0.018*\"said\" + 0.018*\"deal\" + 0.017*\"u\" + 0.016*\"trump\" + 0.014*\"north\" + 0.013*\"agreement\" + 0.010*\"foreign\" + 0.010*\"state\" + 0.009*\"nuclear\"\n",
      "2019-10-29 00:41:04,910 : INFO : topic #5 (0.100): 0.021*\"said\" + 0.020*\"u\" + 0.020*\"iran\" + 0.015*\"deal\" + 0.013*\"agreement\" + 0.012*\"state\" + 0.011*\"trump\" + 0.010*\"north\" + 0.010*\"mogherini\" + 0.010*\"korea\"\n",
      "2019-10-29 00:41:04,912 : INFO : topic diff=0.883169, rho=1.000000\n",
      "2019-10-29 00:41:05,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:05,314 : INFO : built Dictionary(57 unique tokens: ['dry', 'catholic', 'nonna', 'end', 'something']...) from 5 documents (total 340 corpus positions)\n",
      "2019-10-29 00:41:05,316 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:05,317 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:05,319 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:05,322 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:05,323 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:05,357 : INFO : -6.757 per-word bound, 108.2 perplexity estimate based on a held-out corpus of 5 documents with 340 words\n",
      "2019-10-29 00:41:05,359 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:05,367 : INFO : topic #9 (0.100): 0.052*\"rich\" + 0.043*\"lazarus\" + 0.040*\"read\" + 0.037*\"father\" + 0.032*\"man\" + 0.026*\"cousin\" + 0.023*\"story\" + 0.019*\"cnn\" + 0.018*\"even\" + 0.018*\"would\"\n",
      "2019-10-29 00:41:05,371 : INFO : topic #3 (0.100): 0.050*\"lazarus\" + 0.044*\"read\" + 0.037*\"rich\" + 0.036*\"man\" + 0.033*\"story\" + 0.029*\"cousin\" + 0.023*\"father\" + 0.019*\"approved\" + 0.019*\"nameless\" + 0.018*\"wealth\"\n",
      "2019-10-29 00:41:05,374 : INFO : topic #7 (0.100): 0.048*\"read\" + 0.045*\"man\" + 0.045*\"rich\" + 0.038*\"lazarus\" + 0.030*\"father\" + 0.027*\"story\" + 0.021*\"cousin\" + 0.019*\"humor\" + 0.018*\"chicken\" + 0.017*\"rotisserie\"\n",
      "2019-10-29 00:41:05,376 : INFO : topic #6 (0.100): 0.049*\"man\" + 0.041*\"read\" + 0.040*\"rich\" + 0.038*\"lazarus\" + 0.035*\"cousin\" + 0.029*\"father\" + 0.027*\"story\" + 0.019*\"rotisserie\" + 0.019*\"grave\" + 0.019*\"heaven\"\n",
      "2019-10-29 00:41:05,379 : INFO : topic #8 (0.100): 0.058*\"man\" + 0.035*\"read\" + 0.035*\"lazarus\" + 0.033*\"rich\" + 0.032*\"cousin\" + 0.031*\"story\" + 0.026*\"father\" + 0.019*\"head\" + 0.019*\"spinning\" + 0.019*\"approved\"\n",
      "2019-10-29 00:41:05,381 : INFO : topic diff=0.689167, rho=1.000000\n",
      "2019-10-29 00:41:05,825 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:05,832 : INFO : built Dictionary(256 unique tokens: ['number', 'concern', 'paradise', 'significant', 'end']...) from 5 documents (total 1850 corpus positions)\n",
      "2019-10-29 00:41:05,837 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:05,840 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:05,842 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:05,845 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:05,848 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:05,938 : INFO : -7.693 per-word bound, 206.9 perplexity estimate based on a held-out corpus of 5 documents with 1850 words\n",
      "2019-10-29 00:41:05,940 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:05,946 : INFO : topic #3 (0.100): 0.029*\"said\" + 0.020*\"winery\" + 0.019*\"wine\" + 0.015*\"krause\" + 0.014*\"grape\" + 0.013*\"vineyard\" + 0.012*\"going\" + 0.012*\"property\" + 0.011*\"smoke\" + 0.011*\"california\"\n",
      "2019-10-29 00:41:05,948 : INFO : topic #6 (0.100): 0.022*\"said\" + 0.017*\"california\" + 0.016*\"wine\" + 0.015*\"grape\" + 0.014*\"winery\" + 0.014*\"going\" + 0.012*\"people\" + 0.012*\"smoke\" + 0.011*\"fire\" + 0.010*\"property\"\n",
      "2019-10-29 00:41:05,950 : INFO : topic #5 (0.100): 0.021*\"said\" + 0.018*\"wine\" + 0.018*\"california\" + 0.015*\"grape\" + 0.015*\"already\" + 0.014*\"smoke\" + 0.012*\"fire\" + 0.012*\"going\" + 0.012*\"krause\" + 0.012*\"people\"\n",
      "2019-10-29 00:41:05,952 : INFO : topic #2 (0.100): 0.025*\"said\" + 0.015*\"krause\" + 0.015*\"people\" + 0.014*\"winery\" + 0.014*\"grape\" + 0.014*\"wine\" + 0.012*\"california\" + 0.012*\"smoke\" + 0.011*\"property\" + 0.011*\"fire\"\n",
      "2019-10-29 00:41:05,955 : INFO : topic #8 (0.100): 0.021*\"said\" + 0.017*\"grape\" + 0.016*\"winery\" + 0.015*\"california\" + 0.015*\"wine\" + 0.014*\"smoke\" + 0.012*\"krause\" + 0.011*\"vineyard\" + 0.011*\"fire\" + 0.010*\"people\"\n",
      "2019-10-29 00:41:05,957 : INFO : topic diff=0.802314, rho=1.000000\n",
      "2019-10-29 00:41:06,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:06,399 : INFO : built Dictionary(248 unique tokens: ['concern', 'school', 'small', 'reach', 'camp']...) from 5 documents (total 1910 corpus positions)\n",
      "2019-10-29 00:41:06,403 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:06,404 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:06,406 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:06,409 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:06,411 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:06,528 : INFO : -7.558 per-word bound, 188.4 perplexity estimate based on a held-out corpus of 5 documents with 1910 words\n",
      "2019-10-29 00:41:06,530 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:06,536 : INFO : topic #0 (0.100): 0.036*\"said\" + 0.027*\"kid\" + 0.022*\"school\" + 0.021*\"student\" + 0.018*\"soccer\" + 0.017*\"mufleh\" + 0.014*\"refugee\" + 0.013*\"come\" + 0.013*\"fugees\" + 0.012*\"apartment\"\n",
      "2019-10-29 00:41:06,538 : INFO : topic #1 (0.100): 0.038*\"said\" + 0.033*\"kid\" + 0.021*\"mufleh\" + 0.019*\"school\" + 0.019*\"student\" + 0.015*\"soccer\" + 0.014*\"refugee\" + 0.013*\"fugees\" + 0.012*\"first\" + 0.012*\"goal\"\n",
      "2019-10-29 00:41:06,539 : INFO : topic #9 (0.100): 0.032*\"said\" + 0.023*\"mufleh\" + 0.021*\"kid\" + 0.019*\"soccer\" + 0.018*\"school\" + 0.016*\"student\" + 0.016*\"come\" + 0.014*\"refugee\" + 0.013*\"first\" + 0.012*\"fugees\"\n",
      "2019-10-29 00:41:06,541 : INFO : topic #7 (0.100): 0.030*\"said\" + 0.025*\"kid\" + 0.024*\"student\" + 0.024*\"school\" + 0.021*\"soccer\" + 0.017*\"mufleh\" + 0.014*\"refugee\" + 0.013*\"come\" + 0.012*\"fugees\" + 0.010*\"first\"\n",
      "2019-10-29 00:41:06,543 : INFO : topic #4 (0.100): 0.037*\"said\" + 0.023*\"school\" + 0.020*\"kid\" + 0.020*\"refugee\" + 0.020*\"student\" + 0.019*\"mufleh\" + 0.017*\"soccer\" + 0.012*\"come\" + 0.011*\"fugees\" + 0.011*\"academy\"\n",
      "2019-10-29 00:41:06,544 : INFO : topic diff=0.855841, rho=1.000000\n",
      "2019-10-29 00:41:07,041 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:07,043 : INFO : built Dictionary(86 unique tokens: ['residency', 'affected', 'financial', 'night', 'shooting']...) from 5 documents (total 645 corpus positions)\n",
      "2019-10-29 00:41:07,045 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:07,047 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:07,053 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:07,056 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:07,059 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:07,131 : INFO : -6.652 per-word bound, 100.6 perplexity estimate based on a held-out corpus of 5 documents with 645 words\n",
      "2019-10-29 00:41:07,134 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:07,143 : INFO : topic #1 (0.100): 0.035*\"show\" + 0.034*\"night\" + 0.030*\"dion\" + 0.029*\"go\" + 0.027*\"two\" + 0.025*\"still\" + 0.025*\"celine\" + 0.024*\"sunday\" + 0.023*\"said\" + 0.022*\"day\"\n",
      "2019-10-29 00:41:07,146 : INFO : topic #7 (0.100): 0.036*\"still\" + 0.036*\"two\" + 0.031*\"show\" + 0.027*\"night\" + 0.026*\"dion\" + 0.025*\"celine\" + 0.023*\"vega\" + 0.023*\"day\" + 0.022*\"go\" + 0.021*\"shooting\"\n",
      "2019-10-29 00:41:07,151 : INFO : topic #3 (0.100): 0.042*\"show\" + 0.034*\"night\" + 0.030*\"two\" + 0.030*\"still\" + 0.028*\"dion\" + 0.023*\"vega\" + 0.022*\"said\" + 0.022*\"day\" + 0.021*\"celine\" + 0.021*\"shooting\"\n",
      "2019-10-29 00:41:07,154 : INFO : topic #2 (0.100): 0.037*\"show\" + 0.036*\"dion\" + 0.035*\"sunday\" + 0.034*\"two\" + 0.030*\"night\" + 0.027*\"celine\" + 0.026*\"vega\" + 0.025*\"still\" + 0.023*\"day\" + 0.021*\"shooting\"\n",
      "2019-10-29 00:41:07,157 : INFO : topic #8 (0.100): 0.041*\"show\" + 0.040*\"dion\" + 0.030*\"two\" + 0.029*\"still\" + 0.027*\"night\" + 0.023*\"day\" + 0.022*\"vega\" + 0.022*\"shooting\" + 0.021*\"said\" + 0.020*\"sunday\"\n",
      "2019-10-29 00:41:07,168 : INFO : topic diff=0.796733, rho=1.000000\n",
      "2019-10-29 00:41:07,627 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:07,629 : INFO : built Dictionary(82 unique tokens: ['saddened', 'weinstein', 'manipulate', 'time', 'know']...) from 5 documents (total 490 corpus positions)\n",
      "2019-10-29 00:41:07,630 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:07,632 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:07,633 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:07,636 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:07,637 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:07,679 : INFO : -7.033 per-word bound, 130.9 perplexity estimate based on a held-out corpus of 5 documents with 490 words\n",
      "2019-10-29 00:41:07,681 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:07,690 : INFO : topic #4 (0.100): 0.031*\"harvey\" + 0.030*\"affleck\" + 0.030*\"weinstein\" + 0.025*\"produced\" + 0.020*\"worked\" + 0.020*\"film\" + 0.017*\"decade\" + 0.016*\"read\" + 0.016*\"ben\" + 0.015*\"lawrence\"\n",
      "2019-10-29 00:41:07,693 : INFO : topic #0 (0.100): 0.052*\"weinstein\" + 0.032*\"affleck\" + 0.026*\"harvey\" + 0.024*\"worked\" + 0.022*\"produced\" + 0.021*\"lawrence\" + 0.020*\"decade\" + 0.019*\"film\" + 0.018*\"harassment\" + 0.016*\"ben\"\n",
      "2019-10-29 00:41:07,697 : INFO : topic #3 (0.100): 0.047*\"weinstein\" + 0.034*\"affleck\" + 0.026*\"harvey\" + 0.024*\"ben\" + 0.022*\"worked\" + 0.021*\"decade\" + 0.021*\"harassment\" + 0.020*\"read\" + 0.019*\"lawrence\" + 0.018*\"film\"\n",
      "2019-10-29 00:41:07,702 : INFO : topic #5 (0.100): 0.043*\"weinstein\" + 0.032*\"harvey\" + 0.030*\"affleck\" + 0.025*\"read\" + 0.022*\"lawrence\" + 0.021*\"produced\" + 0.020*\"decade\" + 0.020*\"ben\" + 0.020*\"harassment\" + 0.016*\"worked\"\n",
      "2019-10-29 00:41:07,705 : INFO : topic #9 (0.100): 0.045*\"weinstein\" + 0.026*\"affleck\" + 0.024*\"harvey\" + 0.023*\"read\" + 0.020*\"decade\" + 0.019*\"produced\" + 0.019*\"film\" + 0.017*\"ben\" + 0.016*\"worked\" + 0.016*\"lawrence\"\n",
      "2019-10-29 00:41:07,707 : INFO : topic diff=0.677097, rho=1.000000\n",
      "2019-10-29 00:41:08,179 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:08,186 : INFO : built Dictionary(240 unique tokens: ['relation', 'let', 'energy', 'come', 'focus']...) from 5 documents (total 2045 corpus positions)\n",
      "2019-10-29 00:41:08,190 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:08,191 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:08,193 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:08,196 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:08,198 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:08,294 : INFO : -7.382 per-word bound, 166.8 perplexity estimate based on a held-out corpus of 5 documents with 2045 words\n",
      "2019-10-29 00:41:08,296 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:08,303 : INFO : topic #6 (0.100): 0.034*\"parent\" + 0.026*\"said\" + 0.019*\"child\" + 0.018*\"wrong\" + 0.017*\"say\" + 0.014*\"gold\" + 0.014*\"family\" + 0.013*\"daughter\" + 0.013*\"think\" + 0.012*\"right\"\n",
      "2019-10-29 00:41:08,305 : INFO : topic #1 (0.100): 0.030*\"parent\" + 0.026*\"said\" + 0.019*\"wrong\" + 0.018*\"child\" + 0.018*\"say\" + 0.017*\"simms\" + 0.015*\"family\" + 0.013*\"think\" + 0.013*\"may\" + 0.013*\"time\"\n",
      "2019-10-29 00:41:08,307 : INFO : topic #5 (0.100): 0.038*\"parent\" + 0.018*\"family\" + 0.017*\"say\" + 0.015*\"simms\" + 0.015*\"think\" + 0.015*\"kid\" + 0.014*\"said\" + 0.014*\"right\" + 0.013*\"daughter\" + 0.013*\"may\"\n",
      "2019-10-29 00:41:08,310 : INFO : topic #3 (0.100): 0.028*\"said\" + 0.025*\"say\" + 0.024*\"parent\" + 0.015*\"simms\" + 0.014*\"think\" + 0.014*\"child\" + 0.014*\"family\" + 0.014*\"right\" + 0.014*\"wrong\" + 0.014*\"act\"\n",
      "2019-10-29 00:41:08,312 : INFO : topic #0 (0.100): 0.031*\"said\" + 0.027*\"parent\" + 0.017*\"family\" + 0.016*\"child\" + 0.015*\"right\" + 0.015*\"say\" + 0.014*\"think\" + 0.013*\"wrong\" + 0.013*\"time\" + 0.013*\"everything\"\n",
      "2019-10-29 00:41:08,314 : INFO : topic diff=0.899703, rho=1.000000\n",
      "2019-10-29 00:41:08,777 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:08,780 : INFO : built Dictionary(188 unique tokens: ['trying', 'notice', 'come', 'asked', 'game']...) from 5 documents (total 1270 corpus positions)\n",
      "2019-10-29 00:41:08,783 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:08,784 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:08,786 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:08,788 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:08,793 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:08,864 : INFO : -7.519 per-word bound, 183.4 perplexity estimate based on a held-out corpus of 5 documents with 1270 words\n",
      "2019-10-29 00:41:08,866 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:08,874 : INFO : topic #0 (0.100): 0.025*\"female\" + 0.022*\"nudity\" + 0.018*\"male\" + 0.016*\"actress\" + 0.015*\"davis\" + 0.013*\"film\" + 0.013*\"trip\" + 0.012*\"naked\" + 0.012*\"woman\" + 0.010*\"body\"\n",
      "2019-10-29 00:41:08,876 : INFO : topic #5 (0.100): 0.026*\"female\" + 0.025*\"nudity\" + 0.017*\"actress\" + 0.014*\"film\" + 0.014*\"insecure\" + 0.013*\"male\" + 0.011*\"girl\" + 0.011*\"davis\" + 0.011*\"naked\" + 0.010*\"body\"\n",
      "2019-10-29 00:41:08,879 : INFO : topic #6 (0.100): 0.029*\"nudity\" + 0.025*\"female\" + 0.019*\"davis\" + 0.015*\"film\" + 0.014*\"raval\" + 0.014*\"male\" + 0.014*\"actress\" + 0.013*\"naked\" + 0.012*\"trip\" + 0.012*\"woman\"\n",
      "2019-10-29 00:41:08,882 : INFO : topic #8 (0.100): 0.031*\"female\" + 0.025*\"nudity\" + 0.015*\"actress\" + 0.014*\"male\" + 0.014*\"davis\" + 0.013*\"body\" + 0.013*\"film\" + 0.011*\"naked\" + 0.010*\"insecure\" + 0.010*\"barrier\"\n",
      "2019-10-29 00:41:08,884 : INFO : topic #9 (0.100): 0.024*\"nudity\" + 0.022*\"female\" + 0.019*\"actress\" + 0.016*\"film\" + 0.015*\"davis\" + 0.014*\"male\" + 0.013*\"insecure\" + 0.011*\"raval\" + 0.011*\"naked\" + 0.011*\"body\"\n",
      "2019-10-29 00:41:08,887 : INFO : topic diff=0.755706, rho=1.000000\n",
      "2019-10-29 00:41:09,418 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:09,427 : INFO : built Dictionary(517 unique tokens: ['previously', 'energy', 'nature', 'earthy', 'golden']...) from 5 documents (total 4300 corpus positions)\n",
      "2019-10-29 00:41:09,435 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:09,438 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:09,439 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:09,443 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:09,445 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:09,649 : INFO : -8.147 per-word bound, 283.4 perplexity estimate based on a held-out corpus of 5 documents with 4300 words\n",
      "2019-10-29 00:41:09,651 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:09,660 : INFO : topic #5 (0.100): 0.043*\"truffle\" + 0.024*\"white\" + 0.012*\"massimo\" + 0.012*\"san\" + 0.011*\"dog\" + 0.010*\"miniato\" + 0.009*\"taste\" + 0.008*\"oil\" + 0.008*\"eat\" + 0.007*\"italian\"\n",
      "2019-10-29 00:41:09,662 : INFO : topic #1 (0.100): 0.068*\"truffle\" + 0.017*\"white\" + 0.015*\"san\" + 0.014*\"miniato\" + 0.011*\"massimo\" + 0.011*\"taste\" + 0.009*\"dog\" + 0.008*\"italian\" + 0.008*\"pepe\" + 0.006*\"oil\"\n",
      "2019-10-29 00:41:09,664 : INFO : topic #4 (0.100): 0.065*\"truffle\" + 0.020*\"white\" + 0.014*\"massimo\" + 0.014*\"san\" + 0.013*\"miniato\" + 0.012*\"taste\" + 0.009*\"dog\" + 0.009*\"oil\" + 0.009*\"eat\" + 0.008*\"italian\"\n",
      "2019-10-29 00:41:09,666 : INFO : topic #6 (0.100): 0.072*\"truffle\" + 0.018*\"white\" + 0.014*\"miniato\" + 0.013*\"massimo\" + 0.010*\"san\" + 0.010*\"oil\" + 0.009*\"taste\" + 0.009*\"italian\" + 0.009*\"eat\" + 0.008*\"first\"\n",
      "2019-10-29 00:41:09,669 : INFO : topic #3 (0.100): 0.056*\"truffle\" + 0.016*\"white\" + 0.014*\"san\" + 0.014*\"massimo\" + 0.014*\"miniato\" + 0.010*\"italian\" + 0.010*\"oil\" + 0.007*\"taste\" + 0.007*\"eat\" + 0.006*\"first\"\n",
      "2019-10-29 00:41:09,672 : INFO : topic diff=0.868035, rho=1.000000\n",
      "2019-10-29 00:41:10,139 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:10,142 : INFO : built Dictionary(219 unique tokens: ['let', 'school', 'de', 'pediatrician', 'cool']...) from 5 documents (total 1740 corpus positions)\n",
      "2019-10-29 00:41:10,145 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:10,149 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:10,153 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:10,157 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:10,160 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:10,272 : INFO : -7.402 per-word bound, 169.1 perplexity estimate based on a held-out corpus of 5 documents with 1740 words\n",
      "2019-10-29 00:41:10,274 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:10,282 : INFO : topic #5 (0.100): 0.047*\"said\" + 0.030*\"mom\" + 0.028*\"brittany\" + 0.024*\"tennis\" + 0.012*\"first\" + 0.012*\"would\" + 0.011*\"able\" + 0.011*\"go\" + 0.011*\"like\" + 0.010*\"also\"\n",
      "2019-10-29 00:41:10,285 : INFO : topic #0 (0.100): 0.049*\"said\" + 0.032*\"mom\" + 0.024*\"tennis\" + 0.024*\"brittany\" + 0.015*\"like\" + 0.012*\"go\" + 0.012*\"would\" + 0.010*\"able\" + 0.009*\"court\" + 0.009*\"first\"\n",
      "2019-10-29 00:41:10,288 : INFO : topic #3 (0.100): 0.049*\"said\" + 0.035*\"mom\" + 0.028*\"tennis\" + 0.021*\"brittany\" + 0.014*\"go\" + 0.014*\"like\" + 0.012*\"court\" + 0.010*\"able\" + 0.010*\"first\" + 0.009*\"year\"\n",
      "2019-10-29 00:41:10,290 : INFO : topic #6 (0.100): 0.028*\"said\" + 0.026*\"tennis\" + 0.025*\"brittany\" + 0.024*\"mom\" + 0.014*\"would\" + 0.013*\"like\" + 0.012*\"go\" + 0.012*\"able\" + 0.010*\"baby\" + 0.010*\"court\"\n",
      "2019-10-29 00:41:10,293 : INFO : topic #8 (0.100): 0.047*\"said\" + 0.036*\"tennis\" + 0.031*\"mom\" + 0.020*\"brittany\" + 0.015*\"go\" + 0.013*\"like\" + 0.012*\"first\" + 0.011*\"court\" + 0.011*\"would\" + 0.010*\"also\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:10,296 : INFO : topic diff=0.817584, rho=1.000000\n",
      "2019-10-29 00:41:10,763 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:10,771 : INFO : built Dictionary(354 unique tokens: ['located', 'selection', 'bet', 'journey', 'sadly']...) from 5 documents (total 2755 corpus positions)\n",
      "2019-10-29 00:41:10,778 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:10,779 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:10,780 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:10,784 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:10,787 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:10,911 : INFO : -7.882 per-word bound, 235.9 perplexity estimate based on a held-out corpus of 5 documents with 2755 words\n",
      "2019-10-29 00:41:10,912 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:10,919 : INFO : topic #9 (0.100): 0.023*\"bus\" + 0.023*\"kawagoe\" + 0.017*\"street\" + 0.011*\"take\" + 0.011*\"right\" + 0.011*\"japanese\" + 0.010*\"japan\" + 0.009*\"stop\" + 0.009*\"station\" + 0.009*\"kitain\"\n",
      "2019-10-29 00:41:10,921 : INFO : topic #4 (0.100): 0.028*\"kawagoe\" + 0.021*\"bus\" + 0.013*\"street\" + 0.011*\"get\" + 0.011*\"right\" + 0.010*\"take\" + 0.010*\"side\" + 0.010*\"kitain\" + 0.009*\"japanese\" + 0.009*\"time\"\n",
      "2019-10-29 00:41:10,922 : INFO : topic #1 (0.100): 0.033*\"kawagoe\" + 0.021*\"bus\" + 0.018*\"street\" + 0.012*\"right\" + 0.011*\"time\" + 0.009*\"kitain\" + 0.009*\"japanese\" + 0.009*\"take\" + 0.009*\"stop\" + 0.009*\"japan\"\n",
      "2019-10-29 00:41:10,924 : INFO : topic #8 (0.100): 0.035*\"bus\" + 0.024*\"kawagoe\" + 0.015*\"right\" + 0.014*\"street\" + 0.012*\"japanese\" + 0.011*\"stop\" + 0.011*\"kitain\" + 0.010*\"time\" + 0.009*\"around\" + 0.008*\"take\"\n",
      "2019-10-29 00:41:10,926 : INFO : topic #7 (0.100): 0.028*\"kawagoe\" + 0.024*\"bus\" + 0.017*\"street\" + 0.012*\"take\" + 0.011*\"japanese\" + 0.010*\"right\" + 0.010*\"station\" + 0.010*\"kitain\" + 0.009*\"get\" + 0.009*\"store\"\n",
      "2019-10-29 00:41:10,928 : INFO : topic diff=0.858954, rho=1.000000\n",
      "2019-10-29 00:41:11,360 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:11,363 : INFO : built Dictionary(287 unique tokens: ['spender', 'relation', 'energy', 'fawaz', 'end']...) from 5 documents (total 2220 corpus positions)\n",
      "2019-10-29 00:41:11,368 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:11,369 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:11,370 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:11,374 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:11,375 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:11,481 : INFO : -7.686 per-word bound, 205.9 perplexity estimate based on a held-out corpus of 5 documents with 2220 words\n",
      "2019-10-29 00:41:11,483 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:11,494 : INFO : topic #4 (0.100): 0.039*\"saudi\" + 0.026*\"arabia\" + 0.025*\"russia\" + 0.023*\"oil\" + 0.023*\"russian\" + 0.010*\"ta\" + 0.010*\"energy\" + 0.010*\"king\" + 0.010*\"market\" + 0.010*\"billion\"\n",
      "2019-10-29 00:41:11,497 : INFO : topic #8 (0.100): 0.039*\"saudi\" + 0.026*\"oil\" + 0.026*\"arabia\" + 0.023*\"russia\" + 0.019*\"russian\" + 0.015*\"billion\" + 0.013*\"king\" + 0.011*\"talk\" + 0.010*\"energy\" + 0.009*\"visit\"\n",
      "2019-10-29 00:41:11,500 : INFO : topic #6 (0.100): 0.051*\"saudi\" + 0.030*\"oil\" + 0.023*\"arabia\" + 0.021*\"russia\" + 0.012*\"energy\" + 0.012*\"king\" + 0.011*\"russian\" + 0.010*\"market\" + 0.010*\"ta\" + 0.010*\"billion\"\n",
      "2019-10-29 00:41:11,504 : INFO : topic #3 (0.100): 0.037*\"saudi\" + 0.031*\"arabia\" + 0.022*\"oil\" + 0.022*\"russia\" + 0.016*\"russian\" + 0.014*\"energy\" + 0.012*\"king\" + 0.011*\"billion\" + 0.010*\"visit\" + 0.010*\"year\"\n",
      "2019-10-29 00:41:11,507 : INFO : topic #1 (0.100): 0.048*\"saudi\" + 0.028*\"arabia\" + 0.023*\"russia\" + 0.017*\"oil\" + 0.015*\"russian\" + 0.014*\"king\" + 0.012*\"energy\" + 0.010*\"billion\" + 0.010*\"market\" + 0.009*\"ta\"\n",
      "2019-10-29 00:41:11,510 : INFO : topic diff=0.858369, rho=1.000000\n",
      "2019-10-29 00:41:11,942 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:11,944 : INFO : built Dictionary(105 unique tokens: ['tribe', 'come', 'series', 'cite', 'semi']...) from 5 documents (total 655 corpus positions)\n",
      "2019-10-29 00:41:11,947 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:11,948 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:11,949 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:11,952 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:11,954 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:12,007 : INFO : -7.155 per-word bound, 142.5 perplexity estimate based on a held-out corpus of 5 documents with 655 words\n",
      "2019-10-29 00:41:12,010 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:12,016 : INFO : topic #6 (0.100): 0.036*\"njeri\" + 0.033*\"maasai\" + 0.030*\"space\" + 0.020*\"word\" + 0.020*\"herder\" + 0.018*\"artist\" + 0.016*\"spaceship\" + 0.016*\"member\" + 0.015*\"take\" + 0.015*\"project\"\n",
      "2019-10-29 00:41:12,019 : INFO : topic #2 (0.100): 0.044*\"njeri\" + 0.029*\"maasai\" + 0.029*\"space\" + 0.023*\"artist\" + 0.019*\"word\" + 0.017*\"herder\" + 0.017*\"idea\" + 0.017*\"elder\" + 0.016*\"around\" + 0.016*\"maasci\"\n",
      "2019-10-29 00:41:12,022 : INFO : topic #7 (0.100): 0.043*\"njeri\" + 0.023*\"maasai\" + 0.022*\"space\" + 0.021*\"word\" + 0.021*\"herder\" + 0.019*\"artist\" + 0.017*\"take\" + 0.016*\"elder\" + 0.016*\"inspired\" + 0.016*\"idea\"\n",
      "2019-10-29 00:41:12,025 : INFO : topic #3 (0.100): 0.041*\"njeri\" + 0.030*\"space\" + 0.028*\"maasai\" + 0.025*\"artist\" + 0.023*\"herder\" + 0.023*\"word\" + 0.018*\"maasci\" + 0.018*\"spaceship\" + 0.015*\"elder\" + 0.014*\"project\"\n",
      "2019-10-29 00:41:12,027 : INFO : topic #1 (0.100): 0.035*\"njeri\" + 0.032*\"space\" + 0.026*\"maasai\" + 0.024*\"herder\" + 0.022*\"word\" + 0.021*\"artist\" + 0.017*\"take\" + 0.016*\"inspired\" + 0.016*\"around\" + 0.016*\"project\"\n",
      "2019-10-29 00:41:12,030 : INFO : topic diff=0.722230, rho=1.000000\n",
      "2019-10-29 00:41:12,433 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:12,437 : INFO : built Dictionary(240 unique tokens: ['relation', 'let', 'energy', 'come', 'focus']...) from 5 documents (total 2045 corpus positions)\n",
      "2019-10-29 00:41:12,440 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:12,441 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:12,443 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:12,446 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:12,447 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:12,527 : INFO : -7.382 per-word bound, 166.7 perplexity estimate based on a held-out corpus of 5 documents with 2045 words\n",
      "2019-10-29 00:41:12,528 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:12,536 : INFO : topic #4 (0.100): 0.036*\"said\" + 0.027*\"parent\" + 0.018*\"family\" + 0.017*\"child\" + 0.016*\"say\" + 0.015*\"think\" + 0.014*\"ferrara\" + 0.012*\"right\" + 0.011*\"cnn\" + 0.011*\"gold\"\n",
      "2019-10-29 00:41:12,538 : INFO : topic #9 (0.100): 0.036*\"parent\" + 0.026*\"said\" + 0.019*\"wrong\" + 0.017*\"say\" + 0.016*\"child\" + 0.016*\"think\" + 0.015*\"family\" + 0.013*\"simms\" + 0.013*\"cnn\" + 0.012*\"daughter\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:12,539 : INFO : topic #5 (0.100): 0.029*\"parent\" + 0.024*\"said\" + 0.021*\"say\" + 0.017*\"wrong\" + 0.017*\"simms\" + 0.016*\"child\" + 0.015*\"family\" + 0.014*\"daughter\" + 0.013*\"may\" + 0.013*\"ferrara\"\n",
      "2019-10-29 00:41:12,542 : INFO : topic #7 (0.100): 0.033*\"said\" + 0.031*\"parent\" + 0.020*\"child\" + 0.017*\"right\" + 0.016*\"wrong\" + 0.015*\"say\" + 0.014*\"think\" + 0.014*\"family\" + 0.012*\"may\" + 0.012*\"ferrara\"\n",
      "2019-10-29 00:41:12,544 : INFO : topic #1 (0.100): 0.026*\"parent\" + 0.022*\"said\" + 0.021*\"say\" + 0.018*\"family\" + 0.016*\"simms\" + 0.015*\"child\" + 0.015*\"wrong\" + 0.013*\"think\" + 0.013*\"daughter\" + 0.013*\"time\"\n",
      "2019-10-29 00:41:12,545 : INFO : topic diff=0.899314, rho=1.000000\n",
      "2019-10-29 00:41:12,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:12,988 : INFO : built Dictionary(306 unique tokens: ['relation', 'duration', 'size', 'oversupply', 'expansion']...) from 5 documents (total 2505 corpus positions)\n",
      "2019-10-29 00:41:12,991 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:12,993 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:12,998 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:13,002 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:13,005 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:13,134 : INFO : -7.672 per-word bound, 204.0 perplexity estimate based on a held-out corpus of 5 documents with 2505 words\n",
      "2019-10-29 00:41:13,136 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:13,145 : INFO : topic #7 (0.100): 0.024*\"opioid\" + 0.021*\"patient\" + 0.021*\"prescription\" + 0.020*\"cv\" + 0.018*\"said\" + 0.012*\"opioids\" + 0.011*\"pharmacy\" + 0.010*\"drug\" + 0.010*\"medication\" + 0.009*\"american\"\n",
      "2019-10-29 00:41:13,148 : INFO : topic #6 (0.100): 0.025*\"cv\" + 0.021*\"opioid\" + 0.019*\"prescription\" + 0.017*\"patient\" + 0.016*\"said\" + 0.014*\"opioids\" + 0.012*\"health\" + 0.011*\"pain\" + 0.011*\"medication\" + 0.010*\"overdoses\"\n",
      "2019-10-29 00:41:13,152 : INFO : topic #4 (0.100): 0.026*\"opioid\" + 0.019*\"cv\" + 0.019*\"prescription\" + 0.016*\"said\" + 0.014*\"patient\" + 0.011*\"pain\" + 0.011*\"opioids\" + 0.010*\"physician\" + 0.010*\"use\" + 0.010*\"pharmacy\"\n",
      "2019-10-29 00:41:13,155 : INFO : topic #8 (0.100): 0.029*\"cv\" + 0.021*\"prescription\" + 0.020*\"opioid\" + 0.018*\"said\" + 0.016*\"patient\" + 0.013*\"limit\" + 0.012*\"opioids\" + 0.012*\"medication\" + 0.010*\"drug\" + 0.010*\"health\"\n",
      "2019-10-29 00:41:13,158 : INFO : topic #9 (0.100): 0.024*\"opioid\" + 0.021*\"patient\" + 0.020*\"said\" + 0.019*\"cv\" + 0.019*\"prescription\" + 0.013*\"opioids\" + 0.012*\"medication\" + 0.012*\"pain\" + 0.010*\"also\" + 0.010*\"limit\"\n",
      "2019-10-29 00:41:13,161 : INFO : topic diff=0.877248, rho=1.000000\n",
      "2019-10-29 00:41:13,573 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:13,575 : INFO : built Dictionary(111 unique tokens: ['prime', 'catalonia', 'interview', 'ago', 'needed']...) from 5 documents (total 740 corpus positions)\n",
      "2019-10-29 00:41:13,577 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:13,578 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:13,579 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:13,581 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:13,582 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:13,635 : INFO : -7.071 per-word bound, 134.5 perplexity estimate based on a held-out corpus of 5 documents with 740 words\n",
      "2019-10-29 00:41:13,636 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:13,643 : INFO : topic #7 (0.100): 0.046*\"independence\" + 0.031*\"catalonia\" + 0.029*\"rajoy\" + 0.029*\"spanish\" + 0.020*\"region\" + 0.020*\"spain\" + 0.016*\"leader\" + 0.015*\"autonomous\" + 0.015*\"held\" + 0.015*\"suspending\"\n",
      "2019-10-29 00:41:13,646 : INFO : topic #2 (0.100): 0.041*\"catalonia\" + 0.036*\"independence\" + 0.030*\"rajoy\" + 0.026*\"spanish\" + 0.021*\"region\" + 0.017*\"leader\" + 0.016*\"ago\" + 0.014*\"spain\" + 0.013*\"law\" + 0.013*\"prime\"\n",
      "2019-10-29 00:41:13,649 : INFO : topic #9 (0.100): 0.037*\"rajoy\" + 0.035*\"catalonia\" + 0.035*\"independence\" + 0.023*\"spanish\" + 0.020*\"region\" + 0.019*\"spain\" + 0.018*\"leader\" + 0.015*\"autonomous\" + 0.015*\"autonomy\" + 0.014*\"referendum\"\n",
      "2019-10-29 00:41:13,652 : INFO : topic #5 (0.100): 0.041*\"rajoy\" + 0.041*\"independence\" + 0.031*\"catalonia\" + 0.024*\"spanish\" + 0.018*\"region\" + 0.016*\"spain\" + 0.016*\"leader\" + 0.015*\"mariano\" + 0.015*\"minister\" + 0.015*\"week\"\n",
      "2019-10-29 00:41:13,655 : INFO : topic #0 (0.100): 0.036*\"independence\" + 0.035*\"rajoy\" + 0.034*\"catalonia\" + 0.029*\"spanish\" + 0.019*\"spain\" + 0.018*\"leader\" + 0.018*\"region\" + 0.017*\"suspending\" + 0.016*\"would\" + 0.016*\"prime\"\n",
      "2019-10-29 00:41:13,658 : INFO : topic diff=0.761732, rho=1.000000\n",
      "2019-10-29 00:41:14,082 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:14,087 : INFO : built Dictionary(133 unique tokens: ['ensuring', 'ensure', 'incubate', 'may', 'salad']...) from 5 documents (total 925 corpus positions)\n",
      "2019-10-29 00:41:14,092 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:14,095 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:14,098 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:14,101 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:14,104 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:14,164 : INFO : -7.161 per-word bound, 143.1 perplexity estimate based on a held-out corpus of 5 documents with 925 words\n",
      "2019-10-29 00:41:14,166 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:14,171 : INFO : topic #5 (0.100): 0.035*\"hawaii\" + 0.024*\"island\" + 0.021*\"disease\" + 0.020*\"vegetable\" + 0.019*\"infected\" + 0.019*\"infant\" + 0.019*\"snail\" + 0.019*\"week\" + 0.017*\"slug\" + 0.015*\"lungworm\"\n",
      "2019-10-29 00:41:14,173 : INFO : topic #3 (0.100): 0.030*\"hawaii\" + 0.029*\"disease\" + 0.021*\"slug\" + 0.020*\"snail\" + 0.019*\"infant\" + 0.017*\"health\" + 0.016*\"infected\" + 0.016*\"island\" + 0.015*\"week\" + 0.015*\"vegetable\"\n",
      "2019-10-29 00:41:14,176 : INFO : topic #7 (0.100): 0.030*\"hawaii\" + 0.026*\"disease\" + 0.022*\"island\" + 0.019*\"slug\" + 0.019*\"health\" + 0.018*\"lungworm\" + 0.016*\"snail\" + 0.016*\"infant\" + 0.016*\"hospitalized\" + 0.015*\"vegetable\"\n",
      "2019-10-29 00:41:14,178 : INFO : topic #1 (0.100): 0.034*\"disease\" + 0.030*\"hawaii\" + 0.026*\"snail\" + 0.025*\"island\" + 0.024*\"slug\" + 0.018*\"lungworm\" + 0.018*\"rat\" + 0.017*\"infected\" + 0.016*\"vegetable\" + 0.014*\"health\"\n",
      "2019-10-29 00:41:14,180 : INFO : topic #6 (0.100): 0.027*\"disease\" + 0.023*\"hawaii\" + 0.023*\"infant\" + 0.021*\"snail\" + 0.021*\"slug\" + 0.018*\"island\" + 0.016*\"according\" + 0.015*\"infected\" + 0.015*\"hospitalized\" + 0.014*\"vegetable\"\n",
      "2019-10-29 00:41:14,182 : INFO : topic diff=0.794864, rho=1.000000\n",
      "2019-10-29 00:41:14,584 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:14,588 : INFO : built Dictionary(245 unique tokens: ['previously', 'fox', 'story', 'described', 'relation']...) from 5 documents (total 2075 corpus positions)\n",
      "2019-10-29 00:41:14,593 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:14,594 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:14,600 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:14,606 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:14,609 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:14,705 : INFO : -7.409 per-word bound, 170.0 perplexity estimate based on a held-out corpus of 5 documents with 2075 words\n",
      "2019-10-29 00:41:14,707 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:14,714 : INFO : topic #0 (0.100): 0.055*\"hiv\" + 0.025*\"bill\" + 0.023*\"law\" + 0.019*\"cnn\" + 0.017*\"california\" + 0.016*\"people\" + 0.014*\"said\" + 0.013*\"stone\" + 0.013*\"told\" + 0.011*\"state\"\n",
      "2019-10-29 00:41:14,716 : INFO : topic #5 (0.100): 0.041*\"hiv\" + 0.030*\"bill\" + 0.028*\"law\" + 0.023*\"people\" + 0.018*\"california\" + 0.015*\"state\" + 0.014*\"cnn\" + 0.013*\"stone\" + 0.012*\"infection\" + 0.012*\"lower\"\n",
      "2019-10-29 00:41:14,718 : INFO : topic #1 (0.100): 0.052*\"hiv\" + 0.027*\"bill\" + 0.018*\"people\" + 0.018*\"california\" + 0.018*\"law\" + 0.012*\"cnn\" + 0.012*\"infection\" + 0.012*\"said\" + 0.011*\"stone\" + 0.011*\"new\"\n",
      "2019-10-29 00:41:14,720 : INFO : topic #2 (0.100): 0.048*\"hiv\" + 0.030*\"law\" + 0.028*\"people\" + 0.023*\"bill\" + 0.020*\"california\" + 0.014*\"cnn\" + 0.012*\"said\" + 0.011*\"also\" + 0.011*\"lower\" + 0.011*\"infection\"\n",
      "2019-10-29 00:41:14,722 : INFO : topic #3 (0.100): 0.045*\"hiv\" + 0.030*\"bill\" + 0.023*\"law\" + 0.021*\"people\" + 0.017*\"cnn\" + 0.013*\"california\" + 0.012*\"said\" + 0.012*\"stone\" + 0.011*\"infection\" + 0.011*\"lower\"\n",
      "2019-10-29 00:41:14,725 : INFO : topic diff=0.878153, rho=1.000000\n",
      "2019-10-29 00:41:15,224 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:15,236 : INFO : built Dictionary(641 unique tokens: ['pattern', 'bone', 'take', 'past', 'yard']...) from 5 documents (total 5405 corpus positions)\n",
      "2019-10-29 00:41:15,246 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:15,248 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:15,251 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:15,256 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:15,259 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:15,506 : INFO : -8.337 per-word bound, 323.4 perplexity estimate based on a held-out corpus of 5 documents with 5405 words\n",
      "2019-10-29 00:41:15,508 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:15,519 : INFO : topic #3 (0.100): 0.022*\"player\" + 0.016*\"newton\" + 0.010*\"week\" + 0.009*\"like\" + 0.009*\"say\" + 0.008*\"brown\" + 0.008*\"said\" + 0.007*\"get\" + 0.007*\"one\" + 0.007*\"nfl\"\n",
      "2019-10-29 00:41:15,522 : INFO : topic #1 (0.100): 0.023*\"newton\" + 0.019*\"player\" + 0.012*\"like\" + 0.010*\"one\" + 0.009*\"said\" + 0.008*\"week\" + 0.008*\"people\" + 0.006*\"football\" + 0.006*\"nfl\" + 0.006*\"say\"\n",
      "2019-10-29 00:41:15,523 : INFO : topic #8 (0.100): 0.021*\"player\" + 0.019*\"newton\" + 0.014*\"one\" + 0.009*\"like\" + 0.008*\"week\" + 0.007*\"people\" + 0.007*\"said\" + 0.007*\"brown\" + 0.007*\"nfl\" + 0.007*\"football\"\n",
      "2019-10-29 00:41:15,526 : INFO : topic #7 (0.100): 0.020*\"player\" + 0.018*\"newton\" + 0.011*\"one\" + 0.009*\"like\" + 0.009*\"nfl\" + 0.008*\"said\" + 0.007*\"week\" + 0.006*\"j\" + 0.006*\"brown\" + 0.006*\"football\"\n",
      "2019-10-29 00:41:15,528 : INFO : topic #6 (0.100): 0.021*\"newton\" + 0.019*\"player\" + 0.011*\"like\" + 0.011*\"nfl\" + 0.010*\"one\" + 0.009*\"said\" + 0.008*\"say\" + 0.007*\"get\" + 0.007*\"brown\" + 0.007*\"football\"\n",
      "2019-10-29 00:41:15,529 : INFO : topic diff=0.867944, rho=1.000000\n",
      "2019-10-29 00:41:15,952 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:15,955 : INFO : built Dictionary(217 unique tokens: ['previously', 'trying', 'including', 'end', 'timing']...) from 5 documents (total 1975 corpus positions)\n",
      "2019-10-29 00:41:15,959 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:15,961 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:15,966 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:15,970 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:15,973 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:16,049 : INFO : -7.199 per-word bound, 146.9 perplexity estimate based on a held-out corpus of 5 documents with 1975 words\n",
      "2019-10-29 00:41:16,051 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:16,059 : INFO : topic #3 (0.100): 0.053*\"immunotherapy\" + 0.049*\"cancer\" + 0.027*\"treatment\" + 0.027*\"neck\" + 0.027*\"people\" + 0.024*\"head\" + 0.014*\"right\" + 0.013*\"use\" + 0.013*\"doctor\" + 0.012*\"study\"\n",
      "2019-10-29 00:41:16,061 : INFO : topic #0 (0.100): 0.052*\"immunotherapy\" + 0.048*\"cancer\" + 0.037*\"treatment\" + 0.033*\"neck\" + 0.023*\"head\" + 0.022*\"people\" + 0.015*\"may\" + 0.012*\"doctor\" + 0.011*\"study\" + 0.011*\"fact\"\n",
      "2019-10-29 00:41:16,064 : INFO : topic #6 (0.100): 0.050*\"immunotherapy\" + 0.035*\"cancer\" + 0.033*\"treatment\" + 0.026*\"neck\" + 0.026*\"head\" + 0.021*\"people\" + 0.015*\"use\" + 0.012*\"inhibitor\" + 0.011*\"study\" + 0.011*\"doctor\"\n",
      "2019-10-29 00:41:16,066 : INFO : topic #9 (0.100): 0.047*\"immunotherapy\" + 0.045*\"cancer\" + 0.038*\"treatment\" + 0.037*\"neck\" + 0.032*\"head\" + 0.027*\"people\" + 0.013*\"doctor\" + 0.012*\"inhibitor\" + 0.010*\"fact\" + 0.010*\"study\"\n",
      "2019-10-29 00:41:16,068 : INFO : topic #7 (0.100): 0.051*\"immunotherapy\" + 0.045*\"cancer\" + 0.037*\"treatment\" + 0.029*\"head\" + 0.021*\"neck\" + 0.018*\"people\" + 0.013*\"use\" + 0.012*\"help\" + 0.011*\"chemotherapy\" + 0.011*\"may\"\n",
      "2019-10-29 00:41:16,069 : INFO : topic diff=0.945077, rho=1.000000\n",
      "2019-10-29 00:41:16,484 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:16,486 : INFO : built Dictionary(94 unique tokens: ['jazz', 'motorcycle', 'special', 'come', 'grounded']...) from 5 documents (total 575 corpus positions)\n",
      "2019-10-29 00:41:16,488 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:16,490 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:16,491 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:16,494 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:16,495 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:16,538 : INFO : -7.099 per-word bound, 137.1 perplexity estimate based on a held-out corpus of 5 documents with 575 words\n",
      "2019-10-29 00:41:16,540 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:16,549 : INFO : topic #5 (0.100): 0.042*\"bottura\" + 0.033*\"car\" + 0.024*\"modena\" + 0.023*\"massimo\" + 0.020*\"along\" + 0.018*\"like\" + 0.018*\"one\" + 0.018*\"listening\" + 0.015*\"pleasure\" + 0.014*\"secret\"\n",
      "2019-10-29 00:41:16,551 : INFO : topic #0 (0.100): 0.049*\"bottura\" + 0.042*\"car\" + 0.024*\"pleasure\" + 0.020*\"modena\" + 0.020*\"massimo\" + 0.019*\"like\" + 0.017*\"one\" + 0.017*\"along\" + 0.016*\"listening\" + 0.015*\"ride\"\n",
      "2019-10-29 00:41:16,553 : INFO : topic #1 (0.100): 0.044*\"bottura\" + 0.039*\"car\" + 0.022*\"modena\" + 0.022*\"massimo\" + 0.020*\"like\" + 0.020*\"listening\" + 0.017*\"one\" + 0.017*\"pleasure\" + 0.016*\"secret\" + 0.016*\"said\"\n",
      "2019-10-29 00:41:16,555 : INFO : topic #7 (0.100): 0.066*\"bottura\" + 0.042*\"car\" + 0.023*\"massimo\" + 0.019*\"modena\" + 0.018*\"ride\" + 0.017*\"secret\" + 0.016*\"like\" + 0.015*\"pleasure\" + 0.015*\"listening\" + 0.014*\"along\"\n",
      "2019-10-29 00:41:16,557 : INFO : topic #3 (0.100): 0.047*\"bottura\" + 0.029*\"modena\" + 0.025*\"car\" + 0.024*\"massimo\" + 0.020*\"like\" + 0.020*\"ride\" + 0.019*\"said\" + 0.018*\"secret\" + 0.017*\"one\" + 0.016*\"along\"\n",
      "2019-10-29 00:41:16,559 : INFO : topic diff=0.707406, rho=1.000000\n",
      "2019-10-29 00:41:16,980 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:16,982 : INFO : built Dictionary(152 unique tokens: ['star', 'online', 'shared', 'disney', 'come']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:41:16,985 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:16,987 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:16,988 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:16,991 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:16,993 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:17,057 : INFO : -7.184 per-word bound, 145.4 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:41:17,058 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:17,069 : INFO : topic #2 (0.100): 0.029*\"love\" + 0.028*\"husband\" + 0.024*\"thornton\" + 0.022*\"chris\" + 0.019*\"first\" + 0.018*\"new\" + 0.017*\"life\" + 0.015*\"two\" + 0.015*\"tiffany\" + 0.014*\"said\"\n",
      "2019-10-29 00:41:17,072 : INFO : topic #4 (0.100): 0.039*\"love\" + 0.034*\"thornton\" + 0.029*\"life\" + 0.025*\"husband\" + 0.024*\"chris\" + 0.019*\"new\" + 0.018*\"first\" + 0.014*\"back\" + 0.013*\"way\" + 0.012*\"day\"\n",
      "2019-10-29 00:41:17,074 : INFO : topic #3 (0.100): 0.038*\"thornton\" + 0.034*\"love\" + 0.024*\"husband\" + 0.023*\"life\" + 0.019*\"chris\" + 0.015*\"day\" + 0.015*\"back\" + 0.015*\"said\" + 0.014*\"first\" + 0.014*\"two\"\n",
      "2019-10-29 00:41:17,076 : INFO : topic #1 (0.100): 0.031*\"husband\" + 0.030*\"love\" + 0.030*\"thornton\" + 0.022*\"life\" + 0.019*\"first\" + 0.018*\"new\" + 0.017*\"chris\" + 0.016*\"instagram\" + 0.014*\"said\" + 0.013*\"capaci\"\n",
      "2019-10-29 00:41:17,081 : INFO : topic #8 (0.100): 0.031*\"husband\" + 0.029*\"love\" + 0.028*\"thornton\" + 0.022*\"chris\" + 0.020*\"first\" + 0.019*\"life\" + 0.017*\"new\" + 0.015*\"capaci\" + 0.015*\"tiffany\" + 0.015*\"instagram\"\n",
      "2019-10-29 00:41:17,084 : INFO : topic diff=0.808866, rho=1.000000\n",
      "2019-10-29 00:41:17,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:17,541 : INFO : built Dictionary(405 unique tokens: ['mirrored', 'pushed', 'portion', 'blowback', 'focus']...) from 5 documents (total 3645 corpus positions)\n",
      "2019-10-29 00:41:17,546 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:17,548 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:17,549 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:17,553 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:17,557 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:17,721 : INFO : -7.811 per-word bound, 224.5 perplexity estimate based on a held-out corpus of 5 documents with 3645 words\n",
      "2019-10-29 00:41:17,723 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:17,733 : INFO : topic #2 (0.100): 0.015*\"older\" + 0.015*\"said\" + 0.014*\"woman\" + 0.014*\"child\" + 0.014*\"father\" + 0.013*\"study\" + 0.013*\"age\" + 0.012*\"birth\" + 0.012*\"risk\" + 0.011*\"parent\"\n",
      "2019-10-29 00:41:17,737 : INFO : topic #7 (0.100): 0.021*\"age\" + 0.019*\"said\" + 0.016*\"risk\" + 0.015*\"woman\" + 0.014*\"child\" + 0.014*\"older\" + 0.012*\"parent\" + 0.011*\"birth\" + 0.010*\"old\" + 0.010*\"father\"\n",
      "2019-10-29 00:41:17,740 : INFO : topic #9 (0.100): 0.019*\"age\" + 0.017*\"older\" + 0.017*\"risk\" + 0.015*\"said\" + 0.012*\"lerman\" + 0.012*\"birth\" + 0.012*\"study\" + 0.011*\"child\" + 0.011*\"parent\" + 0.010*\"father\"\n",
      "2019-10-29 00:41:17,742 : INFO : topic #0 (0.100): 0.021*\"older\" + 0.020*\"age\" + 0.019*\"said\" + 0.014*\"woman\" + 0.014*\"old\" + 0.012*\"risk\" + 0.011*\"parent\" + 0.011*\"father\" + 0.011*\"birth\" + 0.011*\"child\"\n",
      "2019-10-29 00:41:17,745 : INFO : topic #4 (0.100): 0.023*\"age\" + 0.015*\"woman\" + 0.014*\"said\" + 0.014*\"father\" + 0.013*\"risk\" + 0.013*\"child\" + 0.011*\"birth\" + 0.011*\"older\" + 0.011*\"study\" + 0.011*\"parent\"\n",
      "2019-10-29 00:41:17,747 : INFO : topic diff=0.913017, rho=1.000000\n",
      "2019-10-29 00:41:18,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:18,181 : INFO : built Dictionary(372 unique tokens: ['let', 'filed', 'deep', 'party', 'francisco']...) from 5 documents (total 3060 corpus positions)\n",
      "2019-10-29 00:41:18,186 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:18,187 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:18,188 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:18,192 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:18,193 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:18,326 : INFO : -7.847 per-word bound, 230.2 perplexity estimate based on a held-out corpus of 5 documents with 3060 words\n",
      "2019-10-29 00:41:18,327 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:18,336 : INFO : topic #3 (0.100): 0.027*\"feinstein\" + 0.016*\"california\" + 0.012*\"race\" + 0.008*\"would\" + 0.008*\"term\" + 0.008*\"democrat\" + 0.008*\"run\" + 0.007*\"senate\" + 0.007*\"trump\" + 0.007*\"primary\"\n",
      "2019-10-29 00:41:18,337 : INFO : topic #5 (0.100): 0.024*\"feinstein\" + 0.014*\"california\" + 0.010*\"run\" + 0.008*\"challenge\" + 0.008*\"democratic\" + 0.008*\"term\" + 0.008*\"race\" + 0.008*\"senate\" + 0.007*\"senator\" + 0.007*\"democrat\"\n",
      "2019-10-29 00:41:18,340 : INFO : topic #4 (0.100): 0.033*\"feinstein\" + 0.017*\"california\" + 0.010*\"term\" + 0.008*\"run\" + 0.008*\"liberal\" + 0.008*\"race\" + 0.008*\"senate\" + 0.008*\"long\" + 0.008*\"would\" + 0.007*\"challenge\"\n",
      "2019-10-29 00:41:18,342 : INFO : topic #7 (0.100): 0.028*\"feinstein\" + 0.013*\"california\" + 0.009*\"challenge\" + 0.009*\"term\" + 0.009*\"race\" + 0.008*\"one\" + 0.008*\"would\" + 0.007*\"liberal\" + 0.007*\"senate\" + 0.007*\"state\"\n",
      "2019-10-29 00:41:18,344 : INFO : topic #0 (0.100): 0.031*\"feinstein\" + 0.016*\"california\" + 0.009*\"run\" + 0.009*\"race\" + 0.008*\"senate\" + 0.008*\"term\" + 0.008*\"challenge\" + 0.008*\"would\" + 0.007*\"democrat\" + 0.007*\"primary\"\n",
      "2019-10-29 00:41:18,346 : INFO : topic diff=0.821522, rho=1.000000\n",
      "2019-10-29 00:41:18,792 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:18,799 : INFO : built Dictionary(368 unique tokens: ['although', 'happy', 'trying', 'stop', 'self']...) from 5 documents (total 4070 corpus positions)\n",
      "2019-10-29 00:41:18,804 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:18,805 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:18,806 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:18,810 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:18,811 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:18,932 : INFO : -7.471 per-word bound, 177.4 perplexity estimate based on a held-out corpus of 5 documents with 4070 words\n",
      "2019-10-29 00:41:18,934 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:18,942 : INFO : topic #6 (0.100): 0.045*\"girl\" + 0.025*\"school\" + 0.023*\"zimbabwe\" + 0.020*\"say\" + 0.019*\"plan\" + 0.017*\"child\" + 0.016*\"according\" + 0.016*\"home\" + 0.015*\"young\" + 0.014*\"caption\"\n",
      "2019-10-29 00:41:18,945 : INFO : topic #1 (0.100): 0.046*\"girl\" + 0.028*\"school\" + 0.023*\"zimbabwe\" + 0.019*\"plan\" + 0.017*\"stay\" + 0.016*\"albrectsen\" + 0.015*\"according\" + 0.015*\"young\" + 0.014*\"child\" + 0.013*\"caption\"\n",
      "2019-10-29 00:41:18,949 : INFO : topic #0 (0.100): 0.038*\"girl\" + 0.027*\"zimbabwe\" + 0.022*\"plan\" + 0.022*\"school\" + 0.018*\"according\" + 0.016*\"child\" + 0.015*\"say\" + 0.014*\"stay\" + 0.014*\"hide\" + 0.013*\"daughter\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:18,952 : INFO : topic #9 (0.100): 0.033*\"girl\" + 0.027*\"school\" + 0.023*\"zimbabwe\" + 0.018*\"plan\" + 0.016*\"data\" + 0.015*\"say\" + 0.014*\"stay\" + 0.014*\"according\" + 0.014*\"home\" + 0.013*\"hide\"\n",
      "2019-10-29 00:41:18,956 : INFO : topic #4 (0.100): 0.036*\"girl\" + 0.030*\"zimbabwe\" + 0.024*\"plan\" + 0.020*\"according\" + 0.018*\"school\" + 0.016*\"stay\" + 0.016*\"home\" + 0.016*\"child\" + 0.014*\"young\" + 0.013*\"hide\"\n",
      "2019-10-29 00:41:18,959 : INFO : topic diff=1.023381, rho=1.000000\n",
      "2019-10-29 00:41:19,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:19,374 : INFO : built Dictionary(209 unique tokens: ['freelance', 'violence', 'school', 'danish', 'accompanied']...) from 5 documents (total 1745 corpus positions)\n",
      "2019-10-29 00:41:19,377 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:19,379 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:19,381 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:19,384 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:19,386 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:19,494 : INFO : -7.283 per-word bound, 155.7 perplexity estimate based on a held-out corpus of 5 documents with 1745 words\n",
      "2019-10-29 00:41:19,496 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:19,504 : INFO : topic #7 (0.100): 0.046*\"wall\" + 0.031*\"madsen\" + 0.017*\"august\" + 0.017*\"found\" + 0.016*\"kim\" + 0.016*\"submarine\" + 0.015*\"piece\" + 0.015*\"said\" + 0.014*\"journalist\" + 0.014*\"police\"\n",
      "2019-10-29 00:41:19,507 : INFO : topic #4 (0.100): 0.051*\"wall\" + 0.026*\"madsen\" + 0.020*\"journalist\" + 0.020*\"found\" + 0.019*\"police\" + 0.018*\"said\" + 0.016*\"august\" + 0.015*\"submarine\" + 0.014*\"copenhagen\" + 0.013*\"moeller\"\n",
      "2019-10-29 00:41:19,510 : INFO : topic #6 (0.100): 0.052*\"wall\" + 0.033*\"madsen\" + 0.021*\"police\" + 0.020*\"found\" + 0.020*\"august\" + 0.019*\"submarine\" + 0.018*\"copenhagen\" + 0.017*\"said\" + 0.017*\"journalist\" + 0.015*\"head\"\n",
      "2019-10-29 00:41:19,513 : INFO : topic #5 (0.100): 0.062*\"wall\" + 0.028*\"madsen\" + 0.024*\"found\" + 0.019*\"august\" + 0.019*\"missing\" + 0.018*\"police\" + 0.017*\"said\" + 0.016*\"submarine\" + 0.015*\"copenhagen\" + 0.014*\"journalist\"\n",
      "2019-10-29 00:41:19,516 : INFO : topic #9 (0.100): 0.049*\"wall\" + 0.024*\"said\" + 0.024*\"madsen\" + 0.022*\"august\" + 0.020*\"police\" + 0.018*\"found\" + 0.016*\"submarine\" + 0.014*\"head\" + 0.014*\"kim\" + 0.013*\"missing\"\n",
      "2019-10-29 00:41:19,519 : INFO : topic diff=0.891323, rho=1.000000\n",
      "2019-10-29 00:41:19,989 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:19,992 : INFO : built Dictionary(182 unique tokens: ['nation', 'francisco', 'player', 'game', 'vice']...) from 5 documents (total 1355 corpus positions)\n",
      "2019-10-29 00:41:19,996 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:19,999 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:20,002 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:20,005 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:20,008 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:20,104 : INFO : -7.326 per-word bound, 160.4 perplexity estimate based on a held-out corpus of 5 documents with 1355 words\n",
      "2019-10-29 00:41:20,106 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:20,113 : INFO : topic #3 (0.100): 0.049*\"penny\" + 0.019*\"outrage\" + 0.016*\"protest\" + 0.014*\"even\" + 0.014*\"game\" + 0.013*\"president\" + 0.013*\"colt\" + 0.012*\"49ers\" + 0.011*\"former\" + 0.011*\"player\"\n",
      "2019-10-29 00:41:20,116 : INFO : topic #0 (0.100): 0.064*\"penny\" + 0.017*\"protest\" + 0.016*\"game\" + 0.015*\"national\" + 0.015*\"even\" + 0.013*\"outrage\" + 0.013*\"president\" + 0.012*\"jemar\" + 0.012*\"49ers\" + 0.012*\"walkout\"\n",
      "2019-10-29 00:41:20,119 : INFO : topic #2 (0.100): 0.053*\"penny\" + 0.019*\"protest\" + 0.017*\"national\" + 0.016*\"game\" + 0.016*\"president\" + 0.014*\"49ers\" + 0.013*\"jemar\" + 0.013*\"player\" + 0.013*\"even\" + 0.012*\"outrage\"\n",
      "2019-10-29 00:41:20,122 : INFO : topic #8 (0.100): 0.059*\"penny\" + 0.018*\"game\" + 0.018*\"protest\" + 0.015*\"even\" + 0.014*\"president\" + 0.014*\"49ers\" + 0.014*\"action\" + 0.013*\"national\" + 0.013*\"colt\" + 0.012*\"mike\"\n",
      "2019-10-29 00:41:20,125 : INFO : topic #1 (0.100): 0.041*\"penny\" + 0.018*\"outrage\" + 0.017*\"national\" + 0.016*\"even\" + 0.014*\"protest\" + 0.014*\"49ers\" + 0.014*\"player\" + 0.014*\"game\" + 0.013*\"walkout\" + 0.012*\"president\"\n",
      "2019-10-29 00:41:20,128 : INFO : topic diff=0.800991, rho=1.000000\n",
      "2019-10-29 00:41:20,580 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:20,590 : INFO : built Dictionary(608 unique tokens: ['previously', 'rental', 'review', 'profit', 'esmond']...) from 5 documents (total 5640 corpus positions)\n",
      "2019-10-29 00:41:20,599 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:20,602 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:20,606 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:20,611 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:20,614 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:20,801 : INFO : -8.161 per-word bound, 286.3 perplexity estimate based on a held-out corpus of 5 documents with 5640 words\n",
      "2019-10-29 00:41:20,803 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:20,813 : INFO : topic #6 (0.100): 0.023*\"bromide\" + 0.022*\"methyl\" + 0.021*\"said\" + 0.015*\"epa\" + 0.013*\"terminix\" + 0.013*\"cnn\" + 0.013*\"family\" + 0.009*\"island\" + 0.009*\"use\" + 0.008*\"pesticide\"\n",
      "2019-10-29 00:41:20,815 : INFO : topic #4 (0.100): 0.022*\"epa\" + 0.020*\"methyl\" + 0.019*\"said\" + 0.015*\"bromide\" + 0.015*\"terminix\" + 0.015*\"family\" + 0.012*\"pesticide\" + 0.009*\"island\" + 0.009*\"cnn\" + 0.008*\"use\"\n",
      "2019-10-29 00:41:20,817 : INFO : topic #0 (0.100): 0.024*\"bromide\" + 0.023*\"methyl\" + 0.020*\"said\" + 0.018*\"epa\" + 0.014*\"terminix\" + 0.012*\"family\" + 0.011*\"cnn\" + 0.008*\"island\" + 0.008*\"pesticide\" + 0.008*\"use\"\n",
      "2019-10-29 00:41:20,820 : INFO : topic #7 (0.100): 0.028*\"methyl\" + 0.020*\"said\" + 0.019*\"epa\" + 0.019*\"bromide\" + 0.016*\"terminix\" + 0.010*\"family\" + 0.010*\"use\" + 0.009*\"dpnr\" + 0.009*\"pesticide\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:41:20,823 : INFO : topic #2 (0.100): 0.027*\"bromide\" + 0.019*\"methyl\" + 0.019*\"said\" + 0.017*\"epa\" + 0.015*\"terminix\" + 0.015*\"family\" + 0.012*\"cnn\" + 0.010*\"use\" + 0.009*\"pesticide\" + 0.007*\"dpnr\"\n",
      "2019-10-29 00:41:20,826 : INFO : topic diff=0.933580, rho=1.000000\n",
      "2019-10-29 00:41:21,297 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:21,308 : INFO : built Dictionary(868 unique tokens: ['rage', 'pediatrician', 'wave', 'darvena', 'staten']...) from 5 documents (total 7910 corpus positions)\n",
      "2019-10-29 00:41:21,319 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:21,320 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:21,322 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:21,327 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:21,329 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:21,594 : INFO : -8.529 per-word bound, 369.3 perplexity estimate based on a held-out corpus of 5 documents with 7910 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:21,595 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:21,606 : INFO : topic #4 (0.100): 0.021*\"kim\" + 0.020*\"rubella\" + 0.019*\"family\" + 0.009*\"cooper\" + 0.008*\"baby\" + 0.008*\"time\" + 0.008*\"home\" + 0.008*\"child\" + 0.008*\"florence\" + 0.007*\"congenital\"\n",
      "2019-10-29 00:41:21,607 : INFO : topic #5 (0.100): 0.031*\"kim\" + 0.015*\"family\" + 0.015*\"rubella\" + 0.010*\"home\" + 0.009*\"child\" + 0.009*\"like\" + 0.008*\"say\" + 0.008*\"cooper\" + 0.007*\"time\" + 0.007*\"congenital\"\n",
      "2019-10-29 00:41:21,609 : INFO : topic #6 (0.100): 0.030*\"kim\" + 0.017*\"rubella\" + 0.016*\"family\" + 0.010*\"say\" + 0.009*\"cooper\" + 0.009*\"home\" + 0.009*\"child\" + 0.008*\"baby\" + 0.008*\"florence\" + 0.007*\"like\"\n",
      "2019-10-29 00:41:21,610 : INFO : topic #1 (0.100): 0.026*\"kim\" + 0.016*\"rubella\" + 0.013*\"family\" + 0.010*\"child\" + 0.009*\"need\" + 0.009*\"home\" + 0.008*\"baby\" + 0.008*\"say\" + 0.008*\"florence\" + 0.007*\"time\"\n",
      "2019-10-29 00:41:21,611 : INFO : topic #0 (0.100): 0.029*\"kim\" + 0.018*\"rubella\" + 0.013*\"family\" + 0.011*\"baby\" + 0.009*\"home\" + 0.009*\"say\" + 0.009*\"child\" + 0.008*\"cooper\" + 0.008*\"need\" + 0.008*\"time\"\n",
      "2019-10-29 00:41:21,613 : INFO : topic diff=0.920858, rho=1.000000\n",
      "2019-10-29 00:41:22,022 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:22,023 : INFO : built Dictionary(65 unique tokens: ['deadly', 'reach', 'dad', 'relative', 'know']...) from 5 documents (total 440 corpus positions)\n",
      "2019-10-29 00:41:22,025 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:22,027 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:22,028 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:22,030 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:22,031 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:22,066 : INFO : -6.607 per-word bound, 97.5 perplexity estimate based on a held-out corpus of 5 documents with 440 words\n",
      "2019-10-29 00:41:22,068 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:22,084 : INFO : topic #1 (0.100): 0.046*\"christina\" + 0.042*\"hanson\" + 0.036*\"family\" + 0.032*\"one\" + 0.028*\"california\" + 0.027*\"father\" + 0.024*\"told\" + 0.024*\"missing\" + 0.023*\"called\" + 0.021*\"flame\"\n",
      "2019-10-29 00:41:22,086 : INFO : topic #8 (0.100): 0.057*\"christina\" + 0.050*\"hanson\" + 0.032*\"family\" + 0.030*\"michael\" + 0.028*\"santa\" + 0.024*\"one\" + 0.023*\"california\" + 0.023*\"called\" + 0.023*\"flame\" + 0.023*\"missing\"\n",
      "2019-10-29 00:41:22,089 : INFO : topic #2 (0.100): 0.052*\"christina\" + 0.047*\"family\" + 0.036*\"hanson\" + 0.030*\"one\" + 0.030*\"riordan\" + 0.027*\"father\" + 0.026*\"told\" + 0.025*\"california\" + 0.024*\"missing\" + 0.022*\"called\"\n",
      "2019-10-29 00:41:22,099 : INFO : topic #9 (0.100): 0.047*\"family\" + 0.046*\"christina\" + 0.046*\"hanson\" + 0.031*\"one\" + 0.025*\"flame\" + 0.024*\"rosa\" + 0.023*\"santa\" + 0.021*\"michael\" + 0.021*\"riordan\" + 0.021*\"father\"\n",
      "2019-10-29 00:41:22,105 : INFO : topic #3 (0.100): 0.043*\"christina\" + 0.042*\"family\" + 0.041*\"hanson\" + 0.031*\"one\" + 0.026*\"missing\" + 0.026*\"told\" + 0.025*\"riordan\" + 0.025*\"said\" + 0.024*\"flame\" + 0.023*\"michael\"\n",
      "2019-10-29 00:41:22,108 : INFO : topic diff=0.744633, rho=1.000000\n",
      "2019-10-29 00:41:22,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:22,585 : INFO : built Dictionary(568 unique tokens: ['racial', 'let', 'happy', 'window', 'offered']...) from 5 documents (total 4550 corpus positions)\n",
      "2019-10-29 00:41:22,592 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:22,593 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:22,595 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:22,600 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:22,602 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:22,814 : INFO : -8.291 per-word bound, 313.1 perplexity estimate based on a held-out corpus of 5 documents with 4550 words\n",
      "2019-10-29 00:41:22,815 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:22,824 : INFO : topic #8 (0.100): 0.020*\"mcdermott\" + 0.017*\"mental\" + 0.012*\"say\" + 0.012*\"illness\" + 0.010*\"said\" + 0.010*\"bird\" + 0.008*\"zack\" + 0.008*\"health\" + 0.007*\"son\" + 0.007*\"mcgilvrey\"\n",
      "2019-10-29 00:41:22,826 : INFO : topic #9 (0.100): 0.020*\"mcdermott\" + 0.019*\"mental\" + 0.012*\"illness\" + 0.012*\"bird\" + 0.012*\"say\" + 0.010*\"said\" + 0.010*\"mcgilvrey\" + 0.008*\"zack\" + 0.008*\"one\" + 0.006*\"bipolar\"\n",
      "2019-10-29 00:41:22,828 : INFO : topic #1 (0.100): 0.019*\"mcdermott\" + 0.013*\"said\" + 0.013*\"mental\" + 0.012*\"say\" + 0.012*\"illness\" + 0.009*\"mcgilvrey\" + 0.009*\"zack\" + 0.009*\"health\" + 0.008*\"one\" + 0.008*\"bird\"\n",
      "2019-10-29 00:41:22,830 : INFO : topic #4 (0.100): 0.016*\"mcdermott\" + 0.013*\"say\" + 0.012*\"mental\" + 0.011*\"illness\" + 0.009*\"zack\" + 0.009*\"bird\" + 0.009*\"said\" + 0.009*\"health\" + 0.009*\"time\" + 0.007*\"episode\"\n",
      "2019-10-29 00:41:22,832 : INFO : topic #3 (0.100): 0.025*\"mental\" + 0.016*\"mcdermott\" + 0.015*\"illness\" + 0.011*\"said\" + 0.011*\"say\" + 0.010*\"bird\" + 0.008*\"mcgilvrey\" + 0.008*\"zack\" + 0.007*\"time\" + 0.007*\"son\"\n",
      "2019-10-29 00:41:22,834 : INFO : topic diff=0.822985, rho=1.000000\n",
      "2019-10-29 00:41:23,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:23,228 : INFO : built Dictionary(125 unique tokens: ['amid', 'weinstein', 'campaign', 'military', 'mounting']...) from 5 documents (total 835 corpus positions)\n",
      "2019-10-29 00:41:23,230 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:23,232 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:23,234 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:23,236 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:23,238 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:23,299 : INFO : -7.172 per-word bound, 144.2 perplexity estimate based on a held-out corpus of 5 documents with 835 words\n",
      "2019-10-29 00:41:23,300 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:23,308 : INFO : topic #5 (0.100): 0.039*\"trump\" + 0.031*\"colbert\" + 0.026*\"president\" + 0.024*\"stewart\" + 0.024*\"storm\" + 0.020*\"night\" + 0.018*\"tv\" + 0.018*\"show\" + 0.018*\"time\" + 0.016*\"late\"\n",
      "2019-10-29 00:41:23,315 : INFO : topic #3 (0.100): 0.036*\"trump\" + 0.031*\"colbert\" + 0.029*\"stewart\" + 0.023*\"president\" + 0.022*\"storm\" + 0.019*\"show\" + 0.019*\"time\" + 0.017*\"tv\" + 0.015*\"provide\" + 0.014*\"balance\"\n",
      "2019-10-29 00:41:23,322 : INFO : topic #6 (0.100): 0.036*\"trump\" + 0.034*\"colbert\" + 0.030*\"stewart\" + 0.021*\"president\" + 0.020*\"time\" + 0.018*\"late\" + 0.018*\"storm\" + 0.016*\"tv\" + 0.014*\"jon\" + 0.013*\"show\"\n",
      "2019-10-29 00:41:23,325 : INFO : topic #9 (0.100): 0.034*\"trump\" + 0.030*\"stewart\" + 0.028*\"storm\" + 0.026*\"colbert\" + 0.025*\"president\" + 0.019*\"night\" + 0.017*\"tv\" + 0.016*\"late\" + 0.015*\"show\" + 0.015*\"time\"\n",
      "2019-10-29 00:41:23,329 : INFO : topic #7 (0.100): 0.041*\"trump\" + 0.036*\"colbert\" + 0.030*\"president\" + 0.025*\"stewart\" + 0.022*\"storm\" + 0.017*\"show\" + 0.017*\"tv\" + 0.017*\"late\" + 0.016*\"time\" + 0.014*\"night\"\n",
      "2019-10-29 00:41:23,332 : INFO : topic diff=0.783689, rho=1.000000\n",
      "2019-10-29 00:41:23,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:23,791 : INFO : built Dictionary(370 unique tokens: ['enterprise', 'kidding', 'happy', 'party', 'advantage']...) from 5 documents (total 2905 corpus positions)\n",
      "2019-10-29 00:41:23,796 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:23,797 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:23,798 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:23,802 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:23,803 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:23,928 : INFO : -7.909 per-word bound, 240.4 perplexity estimate based on a held-out corpus of 5 documents with 2905 words\n",
      "2019-10-29 00:41:23,929 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:23,936 : INFO : topic #4 (0.100): 0.034*\"marriage\" + 0.016*\"love\" + 0.014*\"year\" + 0.014*\"would\" + 0.013*\"married\" + 0.011*\"child\" + 0.010*\"think\" + 0.009*\"get\" + 0.009*\"sweden\" + 0.008*\"also\"\n",
      "2019-10-29 00:41:23,938 : INFO : topic #1 (0.100): 0.029*\"marriage\" + 0.014*\"married\" + 0.014*\"child\" + 0.013*\"would\" + 0.012*\"love\" + 0.012*\"get\" + 0.011*\"year\" + 0.010*\"told\" + 0.009*\"well\" + 0.008*\"people\"\n",
      "2019-10-29 00:41:23,939 : INFO : topic #0 (0.100): 0.037*\"marriage\" + 0.013*\"love\" + 0.011*\"child\" + 0.011*\"married\" + 0.010*\"would\" + 0.010*\"want\" + 0.010*\"year\" + 0.010*\"well\" + 0.009*\"get\" + 0.009*\"single\"\n",
      "2019-10-29 00:41:23,940 : INFO : topic #6 (0.100): 0.030*\"marriage\" + 0.016*\"love\" + 0.013*\"child\" + 0.012*\"would\" + 0.012*\"year\" + 0.011*\"married\" + 0.010*\"get\" + 0.009*\"people\" + 0.008*\"told\" + 0.008*\"well\"\n",
      "2019-10-29 00:41:23,942 : INFO : topic #7 (0.100): 0.031*\"marriage\" + 0.013*\"would\" + 0.012*\"love\" + 0.010*\"get\" + 0.009*\"told\" + 0.009*\"want\" + 0.009*\"people\" + 0.009*\"child\" + 0.009*\"year\" + 0.009*\"well\"\n",
      "2019-10-29 00:41:23,943 : INFO : topic diff=0.829399, rho=1.000000\n",
      "2019-10-29 00:41:24,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:24,355 : INFO : built Dictionary(215 unique tokens: ['selection', 'walkability', 'de', 'party', 'come']...) from 5 documents (total 1670 corpus positions)\n",
      "2019-10-29 00:41:24,358 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:24,360 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:24,361 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:24,364 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:24,366 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:24,455 : INFO : -7.412 per-word bound, 170.3 perplexity estimate based on a held-out corpus of 5 documents with 1670 words\n",
      "2019-10-29 00:41:24,456 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:24,463 : INFO : topic #1 (0.100): 0.042*\"city\" + 0.033*\"weekend\" + 0.019*\"best\" + 0.019*\"destination\" + 0.014*\"bar\" + 0.014*\"break\" + 0.014*\"top\" + 0.013*\"ranking\" + 0.012*\"london\" + 0.011*\"also\"\n",
      "2019-10-29 00:41:24,464 : INFO : topic #0 (0.100): 0.045*\"city\" + 0.034*\"weekend\" + 0.019*\"break\" + 0.018*\"destination\" + 0.017*\"best\" + 0.016*\"bar\" + 0.014*\"top\" + 0.014*\"ranking\" + 0.013*\"new\" + 0.012*\"cultural\"\n",
      "2019-10-29 00:41:24,466 : INFO : topic #5 (0.100): 0.054*\"city\" + 0.022*\"break\" + 0.022*\"destination\" + 0.021*\"weekend\" + 0.017*\"best\" + 0.014*\"bar\" + 0.013*\"ranking\" + 0.012*\"cultural\" + 0.012*\"new\" + 0.011*\"top\"\n",
      "2019-10-29 00:41:24,467 : INFO : topic #2 (0.100): 0.045*\"city\" + 0.035*\"weekend\" + 0.022*\"destination\" + 0.019*\"best\" + 0.018*\"break\" + 0.016*\"ranking\" + 0.013*\"top\" + 0.013*\"bar\" + 0.013*\"also\" + 0.011*\"london\"\n",
      "2019-10-29 00:41:24,469 : INFO : topic #3 (0.100): 0.045*\"city\" + 0.034*\"weekend\" + 0.025*\"break\" + 0.016*\"ranking\" + 0.015*\"destination\" + 0.015*\"best\" + 0.013*\"top\" + 0.012*\"bar\" + 0.011*\"cultural\" + 0.011*\"known\"\n",
      "2019-10-29 00:41:24,470 : INFO : topic diff=0.855909, rho=1.000000\n",
      "2019-10-29 00:41:24,890 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:24,892 : INFO : built Dictionary(88 unique tokens: ['forward', 'surrounding', 'help', 'travel', 'flight']...) from 5 documents (total 675 corpus positions)\n",
      "2019-10-29 00:41:24,894 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:24,896 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:24,901 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:24,905 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:24,907 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:24,956 : INFO : -6.631 per-word bound, 99.1 perplexity estimate based on a held-out corpus of 5 documents with 675 words\n",
      "2019-10-29 00:41:24,957 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:24,964 : INFO : topic #2 (0.100): 0.063*\"secretary\" + 0.039*\"hargan\" + 0.036*\"trump\" + 0.029*\"hhs\" + 0.022*\"price\" + 0.021*\"charter\" + 0.020*\"eric\" + 0.020*\"deputy\" + 0.019*\"health\" + 0.018*\"experience\"\n",
      "2019-10-29 00:41:24,969 : INFO : topic #5 (0.100): 0.054*\"hargan\" + 0.049*\"secretary\" + 0.035*\"hhs\" + 0.030*\"price\" + 0.027*\"trump\" + 0.026*\"acting\" + 0.025*\"deputy\" + 0.021*\"eric\" + 0.019*\"health\" + 0.017*\"american\"\n",
      "2019-10-29 00:41:24,972 : INFO : topic #7 (0.100): 0.060*\"hargan\" + 0.056*\"secretary\" + 0.033*\"hhs\" + 0.030*\"trump\" + 0.030*\"deputy\" + 0.021*\"eric\" + 0.020*\"price\" + 0.020*\"charter\" + 0.019*\"travel\" + 0.019*\"acting\"\n",
      "2019-10-29 00:41:24,974 : INFO : topic #9 (0.100): 0.054*\"secretary\" + 0.050*\"hargan\" + 0.041*\"hhs\" + 0.036*\"trump\" + 0.029*\"price\" + 0.026*\"deputy\" + 0.025*\"charter\" + 0.023*\"acting\" + 0.019*\"eric\" + 0.019*\"health\"\n",
      "2019-10-29 00:41:24,977 : INFO : topic #8 (0.100): 0.048*\"secretary\" + 0.035*\"hhs\" + 0.034*\"hargan\" + 0.030*\"price\" + 0.025*\"deputy\" + 0.025*\"eric\" + 0.024*\"trump\" + 0.023*\"acting\" + 0.022*\"health\" + 0.020*\"charter\"\n",
      "2019-10-29 00:41:24,980 : INFO : topic diff=0.840982, rho=1.000000\n",
      "2019-10-29 00:41:25,360 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:25,362 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:41:25,363 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:25,365 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:25,366 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:25,368 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:25,369 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:25,383 : INFO : -6.045 per-word bound, 66.0 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:41:25,385 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:25,391 : INFO : topic #9 (0.100): 0.197*\"transcript\" + 0.081*\"page\" + 0.050*\"later\" + 0.049*\"new\" + 0.048*\"updated\" + 0.046*\"back\" + 0.044*\"specific\" + 0.044*\"october\" + 0.043*\"continually\" + 0.043*\"cannot\"\n",
      "2019-10-29 00:41:25,393 : INFO : topic #5 (0.100): 0.165*\"transcript\" + 0.084*\"page\" + 0.058*\"later\" + 0.049*\"find\" + 0.048*\"become\" + 0.048*\"new\" + 0.046*\"continually\" + 0.046*\"main\" + 0.045*\"note\" + 0.045*\"cannot\"\n",
      "2019-10-29 00:41:25,394 : INFO : topic #3 (0.100): 0.169*\"transcript\" + 0.081*\"page\" + 0.054*\"note\" + 0.052*\"continually\" + 0.048*\"become\" + 0.048*\"specific\" + 0.047*\"return\" + 0.047*\"cannot\" + 0.046*\"find\" + 0.046*\"october\"\n",
      "2019-10-29 00:41:25,395 : INFO : topic #1 (0.100): 0.162*\"transcript\" + 0.077*\"page\" + 0.057*\"note\" + 0.051*\"segment\" + 0.049*\"available\" + 0.048*\"become\" + 0.048*\"specific\" + 0.047*\"check\" + 0.044*\"cnn\" + 0.044*\"find\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:25,397 : INFO : topic #8 (0.100): 0.173*\"transcript\" + 0.070*\"page\" + 0.053*\"back\" + 0.052*\"return\" + 0.051*\"cnn\" + 0.050*\"updated\" + 0.048*\"become\" + 0.048*\"specific\" + 0.045*\"continually\" + 0.045*\"main\"\n",
      "2019-10-29 00:41:25,398 : INFO : topic diff=0.713337, rho=1.000000\n",
      "2019-10-29 00:41:25,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:25,893 : INFO : built Dictionary(288 unique tokens: ['cortex', 'single', 'size', 'zurich', 'come']...) from 5 documents (total 2460 corpus positions)\n",
      "2019-10-29 00:41:25,931 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:25,935 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:25,938 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:25,942 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:25,946 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:26,099 : INFO : -7.551 per-word bound, 187.5 perplexity estimate based on a held-out corpus of 5 documents with 2460 words\n",
      "2019-10-29 00:41:26,101 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:26,112 : INFO : topic #4 (0.100): 0.026*\"male\" + 0.022*\"woman\" + 0.021*\"men\" + 0.020*\"female\" + 0.017*\"said\" + 0.016*\"brain\" + 0.014*\"dopamine\" + 0.014*\"study\" + 0.014*\"murphy\" + 0.013*\"tobler\"\n",
      "2019-10-29 00:41:26,115 : INFO : topic #8 (0.100): 0.025*\"men\" + 0.024*\"brain\" + 0.020*\"male\" + 0.019*\"female\" + 0.018*\"said\" + 0.017*\"woman\" + 0.016*\"tobler\" + 0.015*\"study\" + 0.012*\"difference\" + 0.011*\"murphy\"\n",
      "2019-10-29 00:41:26,118 : INFO : topic #6 (0.100): 0.037*\"brain\" + 0.025*\"female\" + 0.019*\"woman\" + 0.017*\"male\" + 0.015*\"dopamine\" + 0.015*\"men\" + 0.013*\"study\" + 0.012*\"tobler\" + 0.012*\"system\" + 0.011*\"difference\"\n",
      "2019-10-29 00:41:26,122 : INFO : topic #0 (0.100): 0.028*\"brain\" + 0.027*\"male\" + 0.025*\"said\" + 0.023*\"woman\" + 0.022*\"men\" + 0.020*\"female\" + 0.016*\"dopamine\" + 0.015*\"difference\" + 0.014*\"study\" + 0.011*\"murphy\"\n",
      "2019-10-29 00:41:26,124 : INFO : topic #3 (0.100): 0.029*\"female\" + 0.025*\"woman\" + 0.024*\"brain\" + 0.018*\"men\" + 0.018*\"dopamine\" + 0.016*\"male\" + 0.016*\"study\" + 0.016*\"said\" + 0.014*\"tobler\" + 0.013*\"murphy\"\n",
      "2019-10-29 00:41:26,127 : INFO : topic diff=0.852627, rho=1.000000\n",
      "2019-10-29 00:41:26,586 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:26,588 : INFO : built Dictionary(82 unique tokens: ['help', 'drought', 'security', 'population', 'food']...) from 5 documents (total 575 corpus positions)\n",
      "2019-10-29 00:41:26,589 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:26,592 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:26,596 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:26,599 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:26,605 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:26,656 : INFO : -6.731 per-word bound, 106.2 perplexity estimate based on a held-out corpus of 5 documents with 575 words\n",
      "2019-10-29 00:41:26,658 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:26,667 : INFO : topic #4 (0.100): 0.050*\"people\" + 0.031*\"south\" + 0.030*\"famine\" + 0.029*\"food\" + 0.028*\"need\" + 0.026*\"million\" + 0.025*\"sudan\" + 0.024*\"country\" + 0.021*\"un\" + 0.020*\"drought\"\n",
      "2019-10-29 00:41:26,671 : INFO : topic #6 (0.100): 0.051*\"people\" + 0.038*\"million\" + 0.034*\"famine\" + 0.028*\"un\" + 0.026*\"country\" + 0.025*\"need\" + 0.024*\"sudan\" + 0.024*\"food\" + 0.020*\"south\" + 0.019*\"left\"\n",
      "2019-10-29 00:41:26,674 : INFO : topic #8 (0.100): 0.039*\"million\" + 0.034*\"famine\" + 0.033*\"people\" + 0.027*\"un\" + 0.026*\"country\" + 0.026*\"need\" + 0.025*\"sudan\" + 0.024*\"south\" + 0.023*\"across\" + 0.021*\"food\"\n",
      "2019-10-29 00:41:26,676 : INFO : topic #0 (0.100): 0.047*\"people\" + 0.037*\"million\" + 0.035*\"need\" + 0.027*\"south\" + 0.026*\"sudan\" + 0.024*\"famine\" + 0.023*\"un\" + 0.023*\"country\" + 0.022*\"food\" + 0.021*\"four\"\n",
      "2019-10-29 00:41:26,678 : INFO : topic #9 (0.100): 0.053*\"people\" + 0.033*\"million\" + 0.031*\"sudan\" + 0.031*\"need\" + 0.030*\"famine\" + 0.025*\"un\" + 0.022*\"food\" + 0.021*\"south\" + 0.020*\"country\" + 0.020*\"somalia\"\n",
      "2019-10-29 00:41:26,680 : INFO : topic diff=0.799426, rho=1.000000\n",
      "2019-10-29 00:41:27,120 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:27,128 : INFO : built Dictionary(410 unique tokens: ['energy', 'advantage', 'prime', 'expert', 'supported']...) from 5 documents (total 3635 corpus positions)\n",
      "2019-10-29 00:41:27,134 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:27,135 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:27,136 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:27,140 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:27,143 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:27,281 : INFO : -7.837 per-word bound, 228.7 perplexity estimate based on a held-out corpus of 5 documents with 3635 words\n",
      "2019-10-29 00:41:27,283 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:27,291 : INFO : topic #7 (0.100): 0.036*\"day\" + 0.033*\"hour\" + 0.022*\"working\" + 0.020*\"work\" + 0.017*\"schedule\" + 0.017*\"employee\" + 0.015*\"four\" + 0.013*\"workweek\" + 0.011*\"time\" + 0.011*\"worker\"\n",
      "2019-10-29 00:41:27,293 : INFO : topic #6 (0.100): 0.035*\"hour\" + 0.030*\"day\" + 0.022*\"work\" + 0.018*\"four\" + 0.017*\"schedule\" + 0.016*\"working\" + 0.015*\"employee\" + 0.013*\"week\" + 0.012*\"many\" + 0.012*\"workweek\"\n",
      "2019-10-29 00:41:27,295 : INFO : topic #2 (0.100): 0.036*\"hour\" + 0.033*\"day\" + 0.020*\"four\" + 0.017*\"schedule\" + 0.015*\"employee\" + 0.014*\"working\" + 0.013*\"work\" + 0.012*\"workweek\" + 0.012*\"time\" + 0.011*\"health\"\n",
      "2019-10-29 00:41:27,296 : INFO : topic #1 (0.100): 0.037*\"day\" + 0.028*\"hour\" + 0.024*\"working\" + 0.017*\"four\" + 0.016*\"employee\" + 0.016*\"work\" + 0.016*\"schedule\" + 0.012*\"many\" + 0.012*\"study\" + 0.011*\"time\"\n",
      "2019-10-29 00:41:27,298 : INFO : topic #3 (0.100): 0.037*\"day\" + 0.031*\"hour\" + 0.024*\"four\" + 0.023*\"work\" + 0.016*\"schedule\" + 0.015*\"employee\" + 0.015*\"working\" + 0.013*\"many\" + 0.013*\"workweek\" + 0.011*\"per\"\n",
      "2019-10-29 00:41:27,299 : INFO : topic diff=0.950699, rho=1.000000\n",
      "2019-10-29 00:41:27,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:27,695 : INFO : built Dictionary(69 unique tokens: ['posting', 'caste', 'dalitlivesmatter', 'mrdalit', 'beaten']...) from 5 documents (total 560 corpus positions)\n",
      "2019-10-29 00:41:27,697 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:27,698 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:27,700 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:27,703 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:27,704 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:27,737 : INFO : -6.342 per-word bound, 81.1 perplexity estimate based on a held-out corpus of 5 documents with 560 words\n",
      "2019-10-29 00:41:27,740 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:27,748 : INFO : topic #2 (0.100): 0.080*\"mustache\" + 0.060*\"caste\" + 0.043*\"men\" + 0.036*\"dalit\" + 0.029*\"india\" + 0.029*\"traditionally\" + 0.028*\"sporting\" + 0.027*\"upper\" + 0.023*\"worn\" + 0.022*\"selfies\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:27,752 : INFO : topic #3 (0.100): 0.087*\"mustache\" + 0.051*\"men\" + 0.039*\"dalit\" + 0.031*\"caste\" + 0.027*\"worn\" + 0.027*\"sporting\" + 0.026*\"selfies\" + 0.024*\"upper\" + 0.022*\"traditionally\" + 0.020*\"beaten\"\n",
      "2019-10-29 00:41:27,757 : INFO : topic #0 (0.100): 0.056*\"mustache\" + 0.054*\"men\" + 0.041*\"caste\" + 0.039*\"dalit\" + 0.031*\"sporting\" + 0.031*\"indian\" + 0.028*\"traditionally\" + 0.024*\"worn\" + 0.024*\"selfies\" + 0.022*\"india\"\n",
      "2019-10-29 00:41:27,758 : INFO : topic #9 (0.100): 0.059*\"mustache\" + 0.051*\"men\" + 0.041*\"dalit\" + 0.035*\"caste\" + 0.028*\"selfies\" + 0.028*\"india\" + 0.027*\"upper\" + 0.027*\"indian\" + 0.025*\"worn\" + 0.023*\"traditionally\"\n",
      "2019-10-29 00:41:27,760 : INFO : topic #7 (0.100): 0.066*\"mustache\" + 0.060*\"men\" + 0.044*\"dalit\" + 0.035*\"caste\" + 0.030*\"worn\" + 0.027*\"indian\" + 0.026*\"sporting\" + 0.026*\"upper\" + 0.026*\"traditionally\" + 0.025*\"selfies\"\n",
      "2019-10-29 00:41:27,761 : INFO : topic diff=0.864061, rho=1.000000\n",
      "2019-10-29 00:41:28,225 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:28,232 : INFO : built Dictionary(393 unique tokens: ['although', 'offered', 'energy', 'bone', 'banana']...) from 5 documents (total 4230 corpus positions)\n",
      "2019-10-29 00:41:28,240 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:28,241 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:28,242 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:28,246 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:28,248 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:28,362 : INFO : -7.574 per-word bound, 190.6 perplexity estimate based on a held-out corpus of 5 documents with 4230 words\n",
      "2019-10-29 00:41:28,363 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:28,372 : INFO : topic #0 (0.100): 0.023*\"egg\" + 0.019*\"bagel\" + 0.019*\"sugar\" + 0.017*\"fat\" + 0.016*\"cheese\" + 0.015*\"dunkin\" + 0.014*\"gram\" + 0.013*\"calorie\" + 0.012*\"latte\" + 0.012*\"meal\"\n",
      "2019-10-29 00:41:28,373 : INFO : topic #5 (0.100): 0.020*\"sugar\" + 0.019*\"cheese\" + 0.018*\"egg\" + 0.017*\"gram\" + 0.017*\"muffin\" + 0.015*\"dunkin\" + 0.015*\"calorie\" + 0.014*\"bagel\" + 0.014*\"milk\" + 0.013*\"fat\"\n",
      "2019-10-29 00:41:28,375 : INFO : topic #9 (0.100): 0.020*\"egg\" + 0.019*\"gram\" + 0.017*\"sugar\" + 0.017*\"calorie\" + 0.015*\"cheese\" + 0.015*\"bagel\" + 0.015*\"fat\" + 0.015*\"dunkin\" + 0.014*\"muffin\" + 0.013*\"latte\"\n",
      "2019-10-29 00:41:28,377 : INFO : topic #6 (0.100): 0.023*\"egg\" + 0.018*\"bagel\" + 0.018*\"sugar\" + 0.016*\"dunkin\" + 0.016*\"gram\" + 0.015*\"muffin\" + 0.015*\"cheese\" + 0.013*\"fat\" + 0.013*\"calorie\" + 0.012*\"latte\"\n",
      "2019-10-29 00:41:28,379 : INFO : topic #4 (0.100): 0.022*\"dunkin\" + 0.020*\"egg\" + 0.018*\"calorie\" + 0.017*\"sugar\" + 0.016*\"cheese\" + 0.016*\"bagel\" + 0.014*\"gram\" + 0.014*\"muffin\" + 0.012*\"skim\" + 0.012*\"wrap\"\n",
      "2019-10-29 00:41:28,381 : INFO : topic diff=1.029538, rho=1.000000\n",
      "2019-10-29 00:41:28,808 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:28,815 : INFO : built Dictionary(339 unique tokens: ['previously', 'violence', 'perhaps', 'glamorous', 'sideline']...) from 5 documents (total 2290 corpus positions)\n",
      "2019-10-29 00:41:28,820 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:28,821 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:28,823 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:28,827 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:28,828 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:28,949 : INFO : -8.063 per-word bound, 267.4 perplexity estimate based on a held-out corpus of 5 documents with 2290 words\n",
      "2019-10-29 00:41:28,951 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:28,957 : INFO : topic #4 (0.100): 0.024*\"la\" + 0.019*\"raza\" + 0.015*\"chicano\" + 0.014*\"los\" + 0.010*\"angeles\" + 0.010*\"photography\" + 0.010*\"art\" + 0.009*\"hand\" + 0.008*\"like\" + 0.007*\"camera\"\n",
      "2019-10-29 00:41:28,959 : INFO : topic #1 (0.100): 0.023*\"la\" + 0.019*\"raza\" + 0.015*\"chicano\" + 0.011*\"angeles\" + 0.008*\"photography\" + 0.008*\"art\" + 0.008*\"representation\" + 0.007*\"hand\" + 0.007*\"photographer\" + 0.007*\"activist\"\n",
      "2019-10-29 00:41:28,962 : INFO : topic #0 (0.100): 0.024*\"raza\" + 0.019*\"la\" + 0.013*\"chicano\" + 0.012*\"los\" + 0.011*\"art\" + 0.009*\"like\" + 0.008*\"archive\" + 0.007*\"angeles\" + 0.007*\"award\" + 0.007*\"scene\"\n",
      "2019-10-29 00:41:28,965 : INFO : topic #9 (0.100): 0.026*\"la\" + 0.020*\"raza\" + 0.013*\"angeles\" + 0.012*\"chicano\" + 0.010*\"archive\" + 0.010*\"los\" + 0.009*\"hand\" + 0.009*\"photographer\" + 0.009*\"representation\" + 0.008*\"art\"\n",
      "2019-10-29 00:41:28,967 : INFO : topic #5 (0.100): 0.024*\"raza\" + 0.022*\"la\" + 0.011*\"chicano\" + 0.009*\"art\" + 0.009*\"angeles\" + 0.008*\"photography\" + 0.008*\"los\" + 0.008*\"archive\" + 0.008*\"representation\" + 0.008*\"photographer\"\n",
      "2019-10-29 00:41:28,970 : INFO : topic diff=0.770588, rho=1.000000\n",
      "2019-10-29 00:41:29,439 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:29,448 : INFO : built Dictionary(404 unique tokens: ['deep', 'party', 'advantage', 'asked', 'caucus']...) from 5 documents (total 4950 corpus positions)\n",
      "2019-10-29 00:41:29,457 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:29,460 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:29,463 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:29,468 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:29,471 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:29,615 : INFO : -7.463 per-word bound, 176.5 perplexity estimate based on a held-out corpus of 5 documents with 4950 words\n",
      "2019-10-29 00:41:29,617 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:29,627 : INFO : topic #0 (0.100): 0.060*\"white\" + 0.037*\"class\" + 0.035*\"working\" + 0.032*\"college\" + 0.022*\"say\" + 0.017*\"trump\" + 0.017*\"voter\" + 0.016*\"among\" + 0.016*\"degree\" + 0.014*\"democrat\"\n",
      "2019-10-29 00:41:29,630 : INFO : topic #3 (0.100): 0.043*\"white\" + 0.036*\"college\" + 0.036*\"class\" + 0.025*\"among\" + 0.022*\"say\" + 0.022*\"working\" + 0.021*\"degree\" + 0.019*\"voter\" + 0.018*\"trump\" + 0.013*\"poll\"\n",
      "2019-10-29 00:41:29,633 : INFO : topic #2 (0.100): 0.069*\"white\" + 0.041*\"working\" + 0.029*\"class\" + 0.025*\"college\" + 0.022*\"among\" + 0.020*\"say\" + 0.019*\"trump\" + 0.019*\"degree\" + 0.015*\"voter\" + 0.011*\"poll\"\n",
      "2019-10-29 00:41:29,636 : INFO : topic #1 (0.100): 0.069*\"white\" + 0.034*\"working\" + 0.030*\"class\" + 0.027*\"college\" + 0.022*\"say\" + 0.018*\"degree\" + 0.017*\"among\" + 0.013*\"voter\" + 0.013*\"non\" + 0.012*\"trump\"\n",
      "2019-10-29 00:41:29,638 : INFO : topic #7 (0.100): 0.046*\"white\" + 0.033*\"class\" + 0.032*\"working\" + 0.027*\"college\" + 0.025*\"among\" + 0.020*\"degree\" + 0.018*\"voter\" + 0.017*\"say\" + 0.017*\"poll\" + 0.016*\"trump\"\n",
      "2019-10-29 00:41:29,641 : INFO : topic diff=1.084229, rho=1.000000\n",
      "2019-10-29 00:41:30,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:30,111 : INFO : built Dictionary(157 unique tokens: ['military', 'discrepancy', 'learn', 'provided', 'joined']...) from 5 documents (total 1400 corpus positions)\n",
      "2019-10-29 00:41:30,115 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:30,116 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:30,118 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:30,122 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:30,123 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:30,196 : INFO : -6.930 per-word bound, 122.0 perplexity estimate based on a held-out corpus of 5 documents with 1400 words\n",
      "2019-10-29 00:41:30,198 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:30,204 : INFO : topic #7 (0.100): 0.041*\"mnuchin\" + 0.039*\"treasury\" + 0.026*\"report\" + 0.025*\"new\" + 0.022*\"york\" + 0.020*\"said\" + 0.020*\"general\" + 0.017*\"commercial\" + 0.017*\"delmar\" + 0.015*\"inspector\"\n",
      "2019-10-29 00:41:30,207 : INFO : topic #5 (0.100): 0.037*\"new\" + 0.030*\"treasury\" + 0.027*\"mnuchin\" + 0.026*\"york\" + 0.025*\"report\" + 0.021*\"inspector\" + 0.021*\"cnnmoney\" + 0.021*\"general\" + 0.017*\"flight\" + 0.017*\"commercial\"\n",
      "2019-10-29 00:41:30,212 : INFO : topic #3 (0.100): 0.050*\"mnuchin\" + 0.041*\"treasury\" + 0.030*\"new\" + 0.025*\"york\" + 0.023*\"said\" + 0.021*\"report\" + 0.018*\"secretary\" + 0.017*\"general\" + 0.017*\"commercial\" + 0.016*\"cnnmoney\"\n",
      "2019-10-29 00:41:30,215 : INFO : topic #8 (0.100): 0.041*\"mnuchin\" + 0.037*\"new\" + 0.034*\"treasury\" + 0.026*\"general\" + 0.025*\"report\" + 0.022*\"said\" + 0.019*\"york\" + 0.017*\"commercial\" + 0.015*\"cnnmoney\" + 0.015*\"trip\"\n",
      "2019-10-29 00:41:30,220 : INFO : topic #4 (0.100): 0.031*\"york\" + 0.029*\"mnuchin\" + 0.027*\"treasury\" + 0.025*\"new\" + 0.024*\"report\" + 0.019*\"said\" + 0.019*\"commercial\" + 0.018*\"inspector\" + 0.017*\"flight\" + 0.015*\"secretary\"\n",
      "2019-10-29 00:41:30,223 : INFO : topic diff=0.916251, rho=1.000000\n",
      "2019-10-29 00:41:30,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:30,631 : INFO : built Dictionary(88 unique tokens: ['concern', 'nation', 'josh', 'something', 'option']...) from 5 documents (total 535 corpus positions)\n",
      "2019-10-29 00:41:30,634 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:30,635 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:30,637 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:30,639 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:30,641 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:30,688 : INFO : -7.055 per-word bound, 133.0 perplexity estimate based on a held-out corpus of 5 documents with 535 words\n",
      "2019-10-29 00:41:30,691 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:30,702 : INFO : topic #5 (0.100): 0.028*\"hope\" + 0.027*\"people\" + 0.022*\"actually\" + 0.022*\"trump\" + 0.020*\"offer\" + 0.018*\"member\" + 0.018*\"technology\" + 0.018*\"help\" + 0.018*\"provide\" + 0.017*\"message\"\n",
      "2019-10-29 00:41:30,707 : INFO : topic #3 (0.100): 0.040*\"hope\" + 0.032*\"people\" + 0.022*\"member\" + 0.021*\"built\" + 0.021*\"bot\" + 0.021*\"action\" + 0.020*\"provide\" + 0.018*\"new\" + 0.017*\"trump\" + 0.017*\"offer\"\n",
      "2019-10-29 00:41:30,711 : INFO : topic #1 (0.100): 0.031*\"people\" + 0.030*\"hope\" + 0.019*\"political\" + 0.019*\"technology\" + 0.018*\"new\" + 0.018*\"help\" + 0.017*\"trump\" + 0.017*\"action\" + 0.017*\"bot\" + 0.017*\"actually\"\n",
      "2019-10-29 00:41:30,715 : INFO : topic #8 (0.100): 0.042*\"people\" + 0.031*\"hope\" + 0.021*\"provide\" + 0.019*\"political\" + 0.019*\"built\" + 0.019*\"message\" + 0.018*\"help\" + 0.018*\"actually\" + 0.018*\"new\" + 0.017*\"bot\"\n",
      "2019-10-29 00:41:30,717 : INFO : topic #4 (0.100): 0.039*\"hope\" + 0.038*\"people\" + 0.020*\"built\" + 0.019*\"action\" + 0.019*\"help\" + 0.019*\"trump\" + 0.019*\"actually\" + 0.018*\"bot\" + 0.018*\"technology\" + 0.018*\"political\"\n",
      "2019-10-29 00:41:30,720 : INFO : topic diff=0.672640, rho=1.000000\n",
      "2019-10-29 00:41:31,151 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:31,157 : INFO : built Dictionary(388 unique tokens: ['pediatrician', 'incremental', 'focus', 'belle', 'u']...) from 5 documents (total 3440 corpus positions)\n",
      "2019-10-29 00:41:31,162 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:31,163 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:31,166 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:31,170 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:31,172 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:31,301 : INFO : -7.784 per-word bound, 220.5 perplexity estimate based on a held-out corpus of 5 documents with 3440 words\n",
      "2019-10-29 00:41:31,303 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:31,311 : INFO : topic #9 (0.100): 0.049*\"child\" + 0.021*\"school\" + 0.017*\"care\" + 0.016*\"health\" + 0.013*\"home\" + 0.012*\"education\" + 0.011*\"work\" + 0.011*\"need\" + 0.010*\"stress\" + 0.009*\"toxic\"\n",
      "2019-10-29 00:41:31,313 : INFO : topic #3 (0.100): 0.036*\"child\" + 0.019*\"health\" + 0.017*\"school\" + 0.017*\"care\" + 0.013*\"stress\" + 0.011*\"home\" + 0.010*\"parent\" + 0.010*\"education\" + 0.009*\"need\" + 0.009*\"support\"\n",
      "2019-10-29 00:41:31,316 : INFO : topic #0 (0.100): 0.031*\"child\" + 0.019*\"health\" + 0.017*\"school\" + 0.016*\"care\" + 0.014*\"stress\" + 0.012*\"need\" + 0.012*\"work\" + 0.012*\"education\" + 0.010*\"family\" + 0.009*\"system\"\n",
      "2019-10-29 00:41:31,318 : INFO : topic #7 (0.100): 0.038*\"child\" + 0.021*\"health\" + 0.016*\"care\" + 0.016*\"school\" + 0.012*\"home\" + 0.010*\"stress\" + 0.010*\"build\" + 0.009*\"toxic\" + 0.009*\"support\" + 0.009*\"need\"\n",
      "2019-10-29 00:41:31,320 : INFO : topic #1 (0.100): 0.030*\"child\" + 0.018*\"school\" + 0.018*\"health\" + 0.012*\"education\" + 0.011*\"care\" + 0.011*\"need\" + 0.010*\"parent\" + 0.010*\"home\" + 0.010*\"stress\" + 0.010*\"build\"\n",
      "2019-10-29 00:41:31,322 : INFO : topic diff=0.910970, rho=1.000000\n",
      "2019-10-29 00:41:31,757 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:31,763 : INFO : built Dictionary(476 unique tokens: ['extensive', 'skeptical', 'take', 'party', 'drive']...) from 5 documents (total 4675 corpus positions)\n",
      "2019-10-29 00:41:31,768 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:31,770 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:31,771 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:31,775 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:31,776 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:31,925 : INFO : -7.851 per-word bound, 230.8 perplexity estimate based on a held-out corpus of 5 documents with 4675 words\n",
      "2019-10-29 00:41:31,926 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:31,936 : INFO : topic #4 (0.100): 0.026*\"said\" + 0.017*\"coal\" + 0.014*\"year\" + 0.013*\"say\" + 0.012*\"people\" + 0.011*\"working\" + 0.011*\"trump\" + 0.011*\"class\" + 0.010*\"county\" + 0.009*\"clinton\"\n",
      "2019-10-29 00:41:31,939 : INFO : topic #7 (0.100): 0.020*\"said\" + 0.019*\"coal\" + 0.014*\"year\" + 0.014*\"white\" + 0.011*\"county\" + 0.011*\"people\" + 0.011*\"working\" + 0.011*\"say\" + 0.010*\"class\" + 0.009*\"trump\"\n",
      "2019-10-29 00:41:31,942 : INFO : topic #9 (0.100): 0.022*\"said\" + 0.022*\"coal\" + 0.013*\"white\" + 0.012*\"people\" + 0.012*\"trump\" + 0.012*\"clinton\" + 0.011*\"working\" + 0.011*\"say\" + 0.011*\"year\" + 0.011*\"county\"\n",
      "2019-10-29 00:41:31,945 : INFO : topic #5 (0.100): 0.015*\"people\" + 0.015*\"said\" + 0.014*\"class\" + 0.013*\"coal\" + 0.013*\"year\" + 0.013*\"white\" + 0.012*\"say\" + 0.011*\"one\" + 0.011*\"virginia\" + 0.011*\"county\"\n",
      "2019-10-29 00:41:31,950 : INFO : topic #8 (0.100): 0.019*\"coal\" + 0.016*\"said\" + 0.014*\"class\" + 0.013*\"say\" + 0.013*\"working\" + 0.013*\"trump\" + 0.012*\"county\" + 0.012*\"white\" + 0.012*\"year\" + 0.011*\"industry\"\n",
      "2019-10-29 00:41:31,953 : INFO : topic diff=0.944847, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:32,444 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:32,450 : INFO : built Dictionary(287 unique tokens: ['violence', 'acceptable', 'end', 'nation', 'come']...) from 5 documents (total 2200 corpus positions)\n",
      "2019-10-29 00:41:32,453 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:32,455 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:32,456 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:32,460 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:32,462 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:32,573 : INFO : -7.706 per-word bound, 208.8 perplexity estimate based on a held-out corpus of 5 documents with 2200 words\n",
      "2019-10-29 00:41:32,574 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:32,583 : INFO : topic #6 (0.100): 0.027*\"muslim\" + 0.027*\"gay\" + 0.025*\"darjes\" + 0.018*\"said\" + 0.014*\"people\" + 0.012*\"religion\" + 0.011*\"time\" + 0.011*\"also\" + 0.011*\"feeling\" + 0.010*\"first\"\n",
      "2019-10-29 00:41:32,586 : INFO : topic #4 (0.100): 0.030*\"darjes\" + 0.026*\"gay\" + 0.025*\"muslim\" + 0.019*\"said\" + 0.014*\"feeling\" + 0.013*\"first\" + 0.012*\"people\" + 0.011*\"told\" + 0.010*\"mosque\" + 0.010*\"time\"\n",
      "2019-10-29 00:41:32,589 : INFO : topic #0 (0.100): 0.028*\"gay\" + 0.024*\"darjes\" + 0.020*\"muslim\" + 0.016*\"said\" + 0.016*\"feeling\" + 0.015*\"people\" + 0.013*\"also\" + 0.012*\"time\" + 0.011*\"told\" + 0.011*\"first\"\n",
      "2019-10-29 00:41:32,591 : INFO : topic #3 (0.100): 0.026*\"gay\" + 0.023*\"darjes\" + 0.023*\"muslim\" + 0.016*\"said\" + 0.015*\"feeling\" + 0.015*\"time\" + 0.014*\"told\" + 0.011*\"photographer\" + 0.010*\"also\" + 0.009*\"religion\"\n",
      "2019-10-29 00:41:32,594 : INFO : topic #1 (0.100): 0.026*\"gay\" + 0.023*\"darjes\" + 0.020*\"muslim\" + 0.018*\"said\" + 0.014*\"people\" + 0.012*\"feeling\" + 0.012*\"time\" + 0.011*\"religion\" + 0.010*\"told\" + 0.010*\"also\"\n",
      "2019-10-29 00:41:32,597 : INFO : topic diff=0.846022, rho=1.000000\n",
      "2019-10-29 00:41:33,010 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:33,012 : INFO : built Dictionary(37 unique tokens: ['amazing', 'america', 'kidssome', 'oc', 'orange']...) from 5 documents (total 245 corpus positions)\n",
      "2019-10-29 00:41:33,013 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:33,014 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:33,016 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:33,017 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:33,019 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:33,041 : INFO : -6.226 per-word bound, 74.8 perplexity estimate based on a held-out corpus of 5 documents with 245 words\n",
      "2019-10-29 00:41:33,043 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:33,052 : INFO : topic #7 (0.100): 0.097*\"halloween\" + 0.072*\"costume\" + 0.057*\"best\" + 0.043*\"place\" + 0.042*\"county\" + 0.038*\"orange\" + 0.028*\"ask\" + 0.026*\"culture\" + 0.025*\"adult\" + 0.025*\"america\"\n",
      "2019-10-29 00:41:33,054 : INFO : topic #1 (0.100): 0.083*\"halloween\" + 0.081*\"costume\" + 0.054*\"best\" + 0.041*\"orange\" + 0.035*\"place\" + 0.033*\"county\" + 0.027*\"near\" + 0.027*\"creepy\" + 0.025*\"anaheim\" + 0.025*\"next\"\n",
      "2019-10-29 00:41:33,057 : INFO : topic #5 (0.100): 0.097*\"halloween\" + 0.066*\"best\" + 0.061*\"costume\" + 0.050*\"place\" + 0.034*\"orange\" + 0.029*\"next\" + 0.028*\"county\" + 0.025*\"anaheim\" + 0.024*\"kidssome\" + 0.024*\"fantasy\"\n",
      "2019-10-29 00:41:33,062 : INFO : topic #0 (0.100): 0.090*\"halloween\" + 0.074*\"costume\" + 0.059*\"best\" + 0.042*\"county\" + 0.040*\"place\" + 0.027*\"orange\" + 0.026*\"amazing\" + 0.024*\"expert\" + 0.024*\"reflection\" + 0.024*\"make\"\n",
      "2019-10-29 00:41:33,067 : INFO : topic #8 (0.100): 0.088*\"halloween\" + 0.068*\"costume\" + 0.061*\"best\" + 0.049*\"county\" + 0.042*\"place\" + 0.036*\"orange\" + 0.028*\"canyon\" + 0.026*\"twitter\" + 0.026*\"kid\" + 0.026*\"shocking\"\n",
      "2019-10-29 00:41:33,069 : INFO : topic diff=0.769479, rho=1.000000\n",
      "2019-10-29 00:41:33,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:33,546 : INFO : built Dictionary(554 unique tokens: ['jazz', 'located', 'wave', '81st', 'party']...) from 5 documents (total 4995 corpus positions)\n",
      "2019-10-29 00:41:33,555 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:33,556 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:33,559 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:33,562 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:33,564 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:33,750 : INFO : -8.110 per-word bound, 276.3 perplexity estimate based on a held-out corpus of 5 documents with 4995 words\n",
      "2019-10-29 00:41:33,752 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:33,762 : INFO : topic #6 (0.100): 0.056*\"bar\" + 0.012*\"tower\" + 0.012*\"highest\" + 0.011*\"floor\" + 0.009*\"rooftop\" + 0.009*\"view\" + 0.009*\"hotel\" + 0.008*\"city\" + 0.008*\"bangkok\" + 0.007*\"world\"\n",
      "2019-10-29 00:41:33,764 : INFO : topic #0 (0.100): 0.047*\"bar\" + 0.014*\"floor\" + 0.012*\"highest\" + 0.011*\"tower\" + 0.009*\"world\" + 0.009*\"view\" + 0.008*\"hotel\" + 0.008*\"bangkok\" + 0.008*\"city\" + 0.007*\"alfresco\"\n",
      "2019-10-29 00:41:33,767 : INFO : topic #8 (0.100): 0.055*\"bar\" + 0.017*\"floor\" + 0.016*\"highest\" + 0.014*\"hotel\" + 0.014*\"tower\" + 0.009*\"world\" + 0.008*\"bangkok\" + 0.008*\"city\" + 0.007*\"cocktail\" + 0.007*\"view\"\n",
      "2019-10-29 00:41:33,769 : INFO : topic #4 (0.100): 0.055*\"bar\" + 0.014*\"highest\" + 0.012*\"tower\" + 0.011*\"floor\" + 0.009*\"hotel\" + 0.009*\"world\" + 0.009*\"view\" + 0.008*\"lounge\" + 0.008*\"city\" + 0.008*\"one\"\n",
      "2019-10-29 00:41:33,772 : INFO : topic #7 (0.100): 0.042*\"bar\" + 0.013*\"tower\" + 0.012*\"floor\" + 0.011*\"world\" + 0.010*\"highest\" + 0.009*\"bangkok\" + 0.008*\"one\" + 0.008*\"hotel\" + 0.008*\"view\" + 0.008*\"city\"\n",
      "2019-10-29 00:41:33,775 : INFO : topic diff=0.936745, rho=1.000000\n",
      "2019-10-29 00:41:34,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:34,177 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:41:34,178 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:34,179 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:34,182 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:34,183 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:34,185 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:34,201 : INFO : -6.048 per-word bound, 66.2 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:41:34,202 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:34,207 : INFO : topic #0 (0.100): 0.174*\"transcript\" + 0.103*\"page\" + 0.048*\"available\" + 0.047*\"cannot\" + 0.046*\"continually\" + 0.045*\"find\" + 0.044*\"cnn\" + 0.044*\"main\" + 0.044*\"specific\" + 0.043*\"new\"\n",
      "2019-10-29 00:41:34,209 : INFO : topic #1 (0.100): 0.127*\"transcript\" + 0.086*\"page\" + 0.057*\"continually\" + 0.056*\"available\" + 0.053*\"later\" + 0.050*\"become\" + 0.050*\"cannot\" + 0.047*\"back\" + 0.047*\"cnn\" + 0.047*\"check\"\n",
      "2019-10-29 00:41:34,210 : INFO : topic #2 (0.100): 0.119*\"transcript\" + 0.070*\"new\" + 0.064*\"page\" + 0.062*\"updated\" + 0.058*\"specific\" + 0.051*\"note\" + 0.050*\"cannot\" + 0.050*\"cnn\" + 0.049*\"become\" + 0.048*\"return\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:34,211 : INFO : topic #4 (0.100): 0.141*\"transcript\" + 0.071*\"page\" + 0.054*\"new\" + 0.053*\"note\" + 0.051*\"later\" + 0.050*\"back\" + 0.049*\"cnn\" + 0.048*\"check\" + 0.048*\"october\" + 0.047*\"main\"\n",
      "2019-10-29 00:41:34,212 : INFO : topic #6 (0.100): 0.179*\"transcript\" + 0.091*\"page\" + 0.050*\"cannot\" + 0.049*\"find\" + 0.048*\"main\" + 0.048*\"check\" + 0.046*\"specific\" + 0.045*\"cnn\" + 0.044*\"october\" + 0.042*\"return\"\n",
      "2019-10-29 00:41:34,213 : INFO : topic diff=0.718474, rho=1.000000\n",
      "2019-10-29 00:41:34,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:34,607 : INFO : built Dictionary(57 unique tokens: ['b', 'night', 'single', 'kendrick', 'home']...) from 5 documents (total 400 corpus positions)\n",
      "2019-10-29 00:41:34,609 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:34,610 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:34,611 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:34,613 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:34,615 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:34,647 : INFO : -6.432 per-word bound, 86.3 perplexity estimate based on a held-out corpus of 5 documents with 400 words\n",
      "2019-10-29 00:41:34,648 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:34,657 : INFO : topic #8 (0.100): 0.046*\"award\" + 0.040*\"cardi\" + 0.038*\"trump\" + 0.034*\"b\" + 0.032*\"freestyle\" + 0.029*\"eminem\" + 0.026*\"hip\" + 0.026*\"hop\" + 0.025*\"single\" + 0.023*\"night\"\n",
      "2019-10-29 00:41:34,658 : INFO : topic #5 (0.100): 0.055*\"b\" + 0.054*\"cardi\" + 0.052*\"award\" + 0.042*\"eminem\" + 0.036*\"trump\" + 0.032*\"freestyle\" + 0.029*\"hop\" + 0.029*\"video\" + 0.025*\"night\" + 0.024*\"attack\"\n",
      "2019-10-29 00:41:34,660 : INFO : topic #2 (0.100): 0.053*\"b\" + 0.052*\"award\" + 0.043*\"eminem\" + 0.038*\"cardi\" + 0.034*\"trump\" + 0.031*\"single\" + 0.030*\"freestyle\" + 0.027*\"winner\" + 0.027*\"video\" + 0.024*\"night\"\n",
      "2019-10-29 00:41:34,661 : INFO : topic #3 (0.100): 0.046*\"cardi\" + 0.045*\"award\" + 0.044*\"b\" + 0.033*\"trump\" + 0.032*\"eminem\" + 0.031*\"single\" + 0.029*\"hop\" + 0.028*\"freestyle\" + 0.025*\"attack\" + 0.024*\"hip\"\n",
      "2019-10-29 00:41:34,663 : INFO : topic #4 (0.100): 0.049*\"cardi\" + 0.041*\"freestyle\" + 0.033*\"award\" + 0.032*\"b\" + 0.032*\"hip\" + 0.031*\"eminem\" + 0.031*\"trump\" + 0.030*\"single\" + 0.029*\"attack\" + 0.027*\"hop\"\n",
      "2019-10-29 00:41:34,672 : INFO : topic diff=0.766705, rho=1.000000\n",
      "2019-10-29 00:41:35,158 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:35,169 : INFO : built Dictionary(786 unique tokens: ['although', 'located', 'selection', 'drinking', 'focus']...) from 5 documents (total 6605 corpus positions)\n",
      "2019-10-29 00:41:35,178 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:35,179 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:35,180 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:35,186 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:35,188 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:35,430 : INFO : -8.539 per-word bound, 372.0 perplexity estimate based on a held-out corpus of 5 documents with 6605 words\n",
      "2019-10-29 00:41:35,432 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:35,444 : INFO : topic #8 (0.100): 0.017*\"german\" + 0.015*\"restaurant\" + 0.010*\"beer\" + 0.010*\"bar\" + 0.009*\"content\" + 0.008*\"munich\" + 0.007*\"world\" + 0.006*\"one\" + 0.006*\"come\" + 0.006*\"old\"\n",
      "2019-10-29 00:41:35,447 : INFO : topic #4 (0.100): 0.025*\"german\" + 0.015*\"beer\" + 0.012*\"bar\" + 0.012*\"restaurant\" + 0.007*\"world\" + 0.007*\"york\" + 0.006*\"one\" + 0.006*\"related\" + 0.006*\"come\" + 0.006*\"content\"\n",
      "2019-10-29 00:41:35,450 : INFO : topic #5 (0.100): 0.029*\"german\" + 0.010*\"beer\" + 0.010*\"restaurant\" + 0.009*\"bar\" + 0.008*\"munich\" + 0.008*\"world\" + 0.008*\"brauhaus\" + 0.007*\"related\" + 0.007*\"heidelberg\" + 0.006*\"content\"\n",
      "2019-10-29 00:41:35,454 : INFO : topic #6 (0.100): 0.028*\"german\" + 0.011*\"restaurant\" + 0.010*\"bar\" + 0.010*\"beer\" + 0.008*\"come\" + 0.008*\"one\" + 0.006*\"world\" + 0.006*\"munich\" + 0.006*\"new\" + 0.006*\"brauhaus\"\n",
      "2019-10-29 00:41:35,457 : INFO : topic #3 (0.100): 0.033*\"german\" + 0.011*\"restaurant\" + 0.011*\"beer\" + 0.008*\"world\" + 0.008*\"bar\" + 0.007*\"related\" + 0.007*\"munich\" + 0.007*\"brauhaus\" + 0.006*\"content\" + 0.006*\"new\"\n",
      "2019-10-29 00:41:35,460 : INFO : topic diff=0.869605, rho=1.000000\n",
      "2019-10-29 00:41:35,906 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:35,908 : INFO : built Dictionary(12 unique tokens: ['happening', 'weinstein', 'facebook', 'messenger', 'condemned']...) from 5 documents (total 60 corpus positions)\n",
      "2019-10-29 00:41:35,909 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:35,910 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:35,911 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:35,913 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:35,914 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:35,924 : INFO : -6.384 per-word bound, 83.5 perplexity estimate based on a held-out corpus of 5 documents with 60 words\n",
      "2019-10-29 00:41:35,925 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:35,931 : INFO : topic #4 (0.100): 0.099*\"unfolds\" + 0.094*\"chat\" + 0.091*\"democrat\" + 0.091*\"hollywood\" + 0.091*\"condemned\" + 0.089*\"messenger\" + 0.083*\"weinstein\" + 0.079*\"u\" + 0.077*\"happening\" + 0.071*\"find\"\n",
      "2019-10-29 00:41:35,932 : INFO : topic #0 (0.100): 0.112*\"unfolds\" + 0.097*\"chat\" + 0.085*\"messenger\" + 0.084*\"hollywood\" + 0.082*\"world\" + 0.081*\"facebook\" + 0.080*\"find\" + 0.078*\"condemned\" + 0.077*\"democrat\" + 0.077*\"weinstein\"\n",
      "2019-10-29 00:41:35,934 : INFO : topic #7 (0.100): 0.098*\"happening\" + 0.091*\"u\" + 0.088*\"democrat\" + 0.088*\"messenger\" + 0.088*\"condemned\" + 0.087*\"hollywood\" + 0.084*\"weinstein\" + 0.082*\"world\" + 0.076*\"chat\" + 0.075*\"facebook\"\n",
      "2019-10-29 00:41:35,936 : INFO : topic #5 (0.100): 0.103*\"u\" + 0.102*\"hollywood\" + 0.093*\"find\" + 0.092*\"chat\" + 0.088*\"democrat\" + 0.081*\"world\" + 0.077*\"condemned\" + 0.076*\"messenger\" + 0.075*\"happening\" + 0.073*\"weinstein\"\n",
      "2019-10-29 00:41:35,937 : INFO : topic #2 (0.100): 0.100*\"weinstein\" + 0.093*\"world\" + 0.087*\"messenger\" + 0.086*\"find\" + 0.085*\"unfolds\" + 0.085*\"chat\" + 0.084*\"facebook\" + 0.082*\"happening\" + 0.080*\"u\" + 0.076*\"democrat\"\n",
      "2019-10-29 00:41:35,939 : INFO : topic diff=0.501379, rho=1.000000\n",
      "2019-10-29 00:41:36,367 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:36,372 : INFO : built Dictionary(367 unique tokens: ['specie', 'energy', 'wave', 'bone', 'focus']...) from 5 documents (total 2945 corpus positions)\n",
      "2019-10-29 00:41:36,377 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:36,378 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:36,380 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:36,384 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:36,385 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:36,524 : INFO : -7.870 per-word bound, 234.0 perplexity estimate based on a held-out corpus of 5 documents with 2945 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:36,525 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:36,533 : INFO : topic #9 (0.100): 0.024*\"extinction\" + 0.012*\"world\" + 0.012*\"climate\" + 0.011*\"population\" + 0.010*\"must\" + 0.009*\"said\" + 0.009*\"fuel\" + 0.009*\"watch\" + 0.008*\"change\" + 0.008*\"billion\"\n",
      "2019-10-29 00:41:36,536 : INFO : topic #5 (0.100): 0.021*\"extinction\" + 0.012*\"world\" + 0.011*\"year\" + 0.009*\"must\" + 0.009*\"like\" + 0.009*\"watch\" + 0.009*\"change\" + 0.008*\"nature\" + 0.008*\"billion\" + 0.008*\"stop\"\n",
      "2019-10-29 00:41:36,537 : INFO : topic #1 (0.100): 0.016*\"extinction\" + 0.011*\"climate\" + 0.010*\"population\" + 0.010*\"world\" + 0.010*\"must\" + 0.009*\"said\" + 0.009*\"year\" + 0.008*\"need\" + 0.008*\"billion\" + 0.008*\"fuel\"\n",
      "2019-10-29 00:41:36,539 : INFO : topic #3 (0.100): 0.025*\"extinction\" + 0.012*\"billion\" + 0.011*\"world\" + 0.010*\"video\" + 0.010*\"climate\" + 0.010*\"fuel\" + 0.010*\"watch\" + 0.009*\"must\" + 0.009*\"stanford\" + 0.008*\"ocean\"\n",
      "2019-10-29 00:41:36,540 : INFO : topic #8 (0.100): 0.022*\"extinction\" + 0.011*\"population\" + 0.010*\"like\" + 0.010*\"billion\" + 0.009*\"video\" + 0.009*\"market\" + 0.009*\"climate\" + 0.009*\"said\" + 0.009*\"elephant\" + 0.009*\"nature\"\n",
      "2019-10-29 00:41:36,543 : INFO : topic diff=0.851538, rho=1.000000\n",
      "2019-10-29 00:41:37,053 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:37,062 : INFO : built Dictionary(567 unique tokens: ['swarmed', 'hadithi', 'happy', 'concern', 'reluctant']...) from 5 documents (total 5340 corpus positions)\n",
      "2019-10-29 00:41:37,071 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:37,075 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:37,079 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:37,084 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:37,087 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:37,342 : INFO : -8.078 per-word bound, 270.2 perplexity estimate based on a held-out corpus of 5 documents with 5340 words\n",
      "2019-10-29 00:41:37,344 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:37,355 : INFO : topic #2 (0.100): 0.031*\"isi\" + 0.024*\"say\" + 0.015*\"nadia\" + 0.012*\"iraq\" + 0.011*\"crime\" + 0.009*\"government\" + 0.009*\"wiley\" + 0.008*\"yazidi\" + 0.007*\"member\" + 0.007*\"war\"\n",
      "2019-10-29 00:41:37,358 : INFO : topic #8 (0.100): 0.040*\"isi\" + 0.016*\"iraq\" + 0.016*\"nadia\" + 0.013*\"say\" + 0.010*\"crime\" + 0.010*\"government\" + 0.008*\"iraqi\" + 0.008*\"member\" + 0.008*\"want\" + 0.007*\"court\"\n",
      "2019-10-29 00:41:37,361 : INFO : topic #6 (0.100): 0.030*\"isi\" + 0.019*\"nadia\" + 0.014*\"say\" + 0.013*\"iraq\" + 0.011*\"government\" + 0.010*\"crime\" + 0.009*\"wiley\" + 0.008*\"yazidi\" + 0.008*\"want\" + 0.008*\"slave\"\n",
      "2019-10-29 00:41:37,364 : INFO : topic #9 (0.100): 0.033*\"isi\" + 0.020*\"say\" + 0.015*\"nadia\" + 0.012*\"government\" + 0.011*\"crime\" + 0.010*\"iraq\" + 0.009*\"yazidi\" + 0.007*\"war\" + 0.007*\"wiley\" + 0.007*\"iraqi\"\n",
      "2019-10-29 00:41:37,367 : INFO : topic #1 (0.100): 0.035*\"isi\" + 0.025*\"say\" + 0.017*\"nadia\" + 0.015*\"iraq\" + 0.012*\"government\" + 0.008*\"crime\" + 0.008*\"iraqi\" + 0.007*\"yazidi\" + 0.007*\"justice\" + 0.007*\"fighter\"\n",
      "2019-10-29 00:41:37,369 : INFO : topic diff=0.917150, rho=1.000000\n",
      "2019-10-29 00:41:37,841 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:37,849 : INFO : built Dictionary(642 unique tokens: ['vacation', 'located', 'selection', 'person', 'shower']...) from 5 documents (total 5080 corpus positions)\n",
      "2019-10-29 00:41:37,856 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:37,857 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:37,859 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:37,864 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:37,866 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:38,054 : INFO : -8.425 per-word bound, 343.6 perplexity estimate based on a held-out corpus of 5 documents with 5080 words\n",
      "2019-10-29 00:41:38,055 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:38,065 : INFO : topic #3 (0.100): 0.015*\"room\" + 0.014*\"lodge\" + 0.010*\"hotel\" + 0.007*\"inn\" + 0.006*\"placid\" + 0.006*\"lake\" + 0.006*\"spa\" + 0.006*\"ranch\" + 0.006*\"mountain\" + 0.006*\"style\"\n",
      "2019-10-29 00:41:38,067 : INFO : topic #0 (0.100): 0.012*\"hotel\" + 0.011*\"lodge\" + 0.011*\"room\" + 0.009*\"lake\" + 0.007*\"spa\" + 0.007*\"inn\" + 0.006*\"fireplace\" + 0.006*\"fall\" + 0.006*\"style\" + 0.005*\"placid\"\n",
      "2019-10-29 00:41:38,068 : INFO : topic #9 (0.100): 0.016*\"room\" + 0.011*\"lodge\" + 0.010*\"hotel\" + 0.008*\"lake\" + 0.006*\"inn\" + 0.006*\"mountain\" + 0.006*\"b\" + 0.006*\"spa\" + 0.006*\"ranch\" + 0.006*\"include\"\n",
      "2019-10-29 00:41:38,070 : INFO : topic #6 (0.100): 0.015*\"room\" + 0.010*\"hotel\" + 0.009*\"lodge\" + 0.007*\"spa\" + 0.007*\"lake\" + 0.007*\"inn\" + 0.006*\"fireplace\" + 0.006*\"fall\" + 0.005*\"mountain\" + 0.005*\"ranch\"\n",
      "2019-10-29 00:41:38,072 : INFO : topic #2 (0.100): 0.014*\"lodge\" + 0.014*\"room\" + 0.012*\"hotel\" + 0.010*\"lake\" + 0.008*\"spa\" + 0.007*\"fall\" + 0.006*\"ranch\" + 0.006*\"october\" + 0.006*\"mountain\" + 0.005*\"b\"\n",
      "2019-10-29 00:41:38,073 : INFO : topic diff=0.833089, rho=1.000000\n",
      "2019-10-29 00:41:38,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:38,510 : INFO : built Dictionary(175 unique tokens: ['wince', 'prime', 'nation', 'francisco', 'game']...) from 5 documents (total 1920 corpus positions)\n",
      "2019-10-29 00:41:38,514 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:38,519 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:38,522 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:38,555 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:38,564 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:38,663 : INFO : -6.777 per-word bound, 109.7 perplexity estimate based on a held-out corpus of 5 documents with 1920 words\n",
      "2019-10-29 00:41:38,664 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:38,672 : INFO : topic #4 (0.100): 0.095*\"hot\" + 0.085*\"dog\" + 0.062*\"hide\" + 0.059*\"photo\" + 0.042*\"caption\" + 0.037*\"nation\" + 0.016*\"york\" + 0.016*\"new\" + 0.016*\"contest\" + 0.010*\"eats\"\n",
      "2019-10-29 00:41:38,675 : INFO : topic #0 (0.100): 0.101*\"dog\" + 0.072*\"hot\" + 0.054*\"nation\" + 0.052*\"caption\" + 0.046*\"photo\" + 0.032*\"hide\" + 0.018*\"new\" + 0.017*\"york\" + 0.014*\"contest\" + 0.008*\"eats\"\n",
      "2019-10-29 00:41:38,678 : INFO : topic #3 (0.100): 0.117*\"hot\" + 0.106*\"dog\" + 0.053*\"nation\" + 0.052*\"caption\" + 0.048*\"photo\" + 0.047*\"hide\" + 0.018*\"new\" + 0.013*\"york\" + 0.013*\"contest\" + 0.011*\"game\"\n",
      "2019-10-29 00:41:38,681 : INFO : topic #1 (0.100): 0.118*\"hot\" + 0.089*\"dog\" + 0.062*\"caption\" + 0.055*\"nation\" + 0.043*\"hide\" + 0.040*\"photo\" + 0.016*\"york\" + 0.015*\"new\" + 0.013*\"game\" + 0.009*\"contest\"\n",
      "2019-10-29 00:41:38,683 : INFO : topic #2 (0.100): 0.111*\"hot\" + 0.079*\"dog\" + 0.050*\"photo\" + 0.046*\"caption\" + 0.046*\"hide\" + 0.044*\"nation\" + 0.015*\"new\" + 0.014*\"contest\" + 0.013*\"york\" + 0.011*\"game\"\n",
      "2019-10-29 00:41:38,685 : INFO : topic diff=1.084443, rho=1.000000\n",
      "2019-10-29 00:41:39,121 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:39,125 : INFO : built Dictionary(286 unique tokens: ['let', 'floating', 'wave', 'watch', 'hero']...) from 5 documents (total 2365 corpus positions)\n",
      "2019-10-29 00:41:39,129 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:39,131 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:39,132 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:39,137 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:39,139 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:39,229 : INFO : -7.590 per-word bound, 192.7 perplexity estimate based on a held-out corpus of 5 documents with 2365 words\n",
      "2019-10-29 00:41:39,230 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:39,237 : INFO : topic #0 (0.100): 0.029*\"manzi\" + 0.018*\"surf\" + 0.016*\"veteran\" + 0.015*\"cnn\" + 0.014*\"beach\" + 0.014*\"go\" + 0.013*\"life\" + 0.012*\"family\" + 0.011*\"day\" + 0.010*\"really\"\n",
      "2019-10-29 00:41:39,239 : INFO : topic #7 (0.100): 0.027*\"manzi\" + 0.024*\"veteran\" + 0.020*\"surf\" + 0.015*\"life\" + 0.014*\"beach\" + 0.014*\"cnn\" + 0.012*\"warrior\" + 0.012*\"wait\" + 0.011*\"go\" + 0.010*\"said\"\n",
      "2019-10-29 00:41:39,240 : INFO : topic #2 (0.100): 0.027*\"manzi\" + 0.023*\"veteran\" + 0.018*\"life\" + 0.018*\"surf\" + 0.017*\"wait\" + 0.016*\"cnn\" + 0.015*\"beach\" + 0.012*\"go\" + 0.012*\"family\" + 0.012*\"want\"\n",
      "2019-10-29 00:41:39,242 : INFO : topic #9 (0.100): 0.028*\"manzi\" + 0.021*\"veteran\" + 0.019*\"surf\" + 0.017*\"life\" + 0.016*\"beach\" + 0.015*\"get\" + 0.014*\"cnn\" + 0.012*\"wait\" + 0.012*\"really\" + 0.011*\"family\"\n",
      "2019-10-29 00:41:39,243 : INFO : topic #5 (0.100): 0.027*\"manzi\" + 0.020*\"surf\" + 0.017*\"cnn\" + 0.014*\"veteran\" + 0.012*\"life\" + 0.012*\"beach\" + 0.011*\"go\" + 0.011*\"family\" + 0.011*\"said\" + 0.011*\"want\"\n",
      "2019-10-29 00:41:39,245 : INFO : topic diff=0.879510, rho=1.000000\n",
      "2019-10-29 00:41:39,677 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:39,683 : INFO : built Dictionary(309 unique tokens: ['although', 'energy', 'portion', 'end', 'joint']...) from 5 documents (total 3010 corpus positions)\n",
      "2019-10-29 00:41:39,687 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:39,688 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:39,690 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:39,693 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:39,694 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:39,802 : INFO : -7.448 per-word bound, 174.6 perplexity estimate based on a held-out corpus of 5 documents with 3010 words\n",
      "2019-10-29 00:41:39,804 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:39,812 : INFO : topic #5 (0.100): 0.041*\"calorie\" + 0.039*\"restaurant\" + 0.026*\"said\" + 0.021*\"chain\" + 0.015*\"robert\" + 0.013*\"eat\" + 0.013*\"would\" + 0.012*\"meal\" + 0.012*\"non\" + 0.011*\"consumer\"\n",
      "2019-10-29 00:41:39,815 : INFO : topic #8 (0.100): 0.044*\"restaurant\" + 0.037*\"calorie\" + 0.029*\"said\" + 0.018*\"chain\" + 0.015*\"robert\" + 0.015*\"meal\" + 0.015*\"portion\" + 0.012*\"eat\" + 0.011*\"would\" + 0.010*\"jarlenski\"\n",
      "2019-10-29 00:41:39,818 : INFO : topic #4 (0.100): 0.038*\"calorie\" + 0.035*\"restaurant\" + 0.025*\"said\" + 0.019*\"robert\" + 0.016*\"chain\" + 0.013*\"eat\" + 0.011*\"meal\" + 0.011*\"say\" + 0.010*\"jarlenski\" + 0.010*\"portion\"\n",
      "2019-10-29 00:41:39,821 : INFO : topic #2 (0.100): 0.035*\"calorie\" + 0.031*\"restaurant\" + 0.023*\"chain\" + 0.016*\"said\" + 0.014*\"robert\" + 0.014*\"would\" + 0.013*\"eat\" + 0.011*\"better\" + 0.010*\"jarlenski\" + 0.010*\"meal\"\n",
      "2019-10-29 00:41:39,825 : INFO : topic #0 (0.100): 0.045*\"restaurant\" + 0.041*\"calorie\" + 0.030*\"said\" + 0.016*\"chain\" + 0.014*\"would\" + 0.014*\"robert\" + 0.013*\"consumer\" + 0.012*\"meal\" + 0.012*\"eat\" + 0.011*\"portion\"\n",
      "2019-10-29 00:41:39,828 : INFO : topic diff=0.932943, rho=1.000000\n",
      "2019-10-29 00:41:40,283 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:40,289 : INFO : built Dictionary(389 unique tokens: ['deep', 'advantage', 'troop', 'spokesman', 'one']...) from 5 documents (total 3885 corpus positions)\n",
      "2019-10-29 00:41:40,293 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:40,294 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:40,296 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:40,300 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:40,302 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:40,415 : INFO : -7.641 per-word bound, 199.6 perplexity estimate based on a held-out corpus of 5 documents with 3885 words\n",
      "2019-10-29 00:41:40,416 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:40,425 : INFO : topic #3 (0.100): 0.052*\"u\" + 0.030*\"niger\" + 0.018*\"force\" + 0.013*\"africa\" + 0.013*\"operation\" + 0.012*\"killed\" + 0.012*\"french\" + 0.012*\"attack\" + 0.011*\"isi\" + 0.010*\"official\"\n",
      "2019-10-29 00:41:40,426 : INFO : topic #8 (0.100): 0.039*\"u\" + 0.036*\"niger\" + 0.016*\"force\" + 0.015*\"operation\" + 0.015*\"killed\" + 0.012*\"africa\" + 0.012*\"official\" + 0.012*\"command\" + 0.011*\"isi\" + 0.009*\"military\"\n",
      "2019-10-29 00:41:40,427 : INFO : topic #2 (0.100): 0.044*\"u\" + 0.028*\"niger\" + 0.019*\"force\" + 0.017*\"military\" + 0.016*\"africa\" + 0.016*\"operation\" + 0.013*\"command\" + 0.011*\"french\" + 0.011*\"attack\" + 0.010*\"official\"\n",
      "2019-10-29 00:41:40,429 : INFO : topic #6 (0.100): 0.040*\"u\" + 0.025*\"niger\" + 0.019*\"force\" + 0.015*\"command\" + 0.013*\"isi\" + 0.013*\"military\" + 0.013*\"official\" + 0.012*\"africa\" + 0.012*\"said\" + 0.011*\"operation\"\n",
      "2019-10-29 00:41:40,430 : INFO : topic #9 (0.100): 0.044*\"u\" + 0.024*\"niger\" + 0.015*\"africa\" + 0.014*\"isi\" + 0.014*\"french\" + 0.013*\"killed\" + 0.012*\"operation\" + 0.012*\"force\" + 0.011*\"military\" + 0.011*\"attack\"\n",
      "2019-10-29 00:41:40,432 : INFO : topic diff=0.935663, rho=1.000000\n",
      "2019-10-29 00:41:40,922 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:40,928 : INFO : built Dictionary(522 unique tokens: ['prime', 'pushed', 'inquiry', 'transport', 'spark']...) from 5 documents (total 4380 corpus positions)\n",
      "2019-10-29 00:41:40,936 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:40,937 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:40,939 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:40,945 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:40,948 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:41,132 : INFO : -8.143 per-word bound, 282.6 perplexity estimate based on a held-out corpus of 5 documents with 4380 words\n",
      "2019-10-29 00:41:41,134 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:41,142 : INFO : topic #4 (0.100): 0.025*\"train\" + 0.024*\"mumbai\" + 0.017*\"station\" + 0.014*\"stampede\" + 0.013*\"people\" + 0.012*\"railway\" + 0.012*\"commuter\" + 0.008*\"city\" + 0.008*\"risk\" + 0.008*\"track\"\n",
      "2019-10-29 00:41:41,144 : INFO : topic #8 (0.100): 0.026*\"mumbai\" + 0.024*\"train\" + 0.020*\"station\" + 0.015*\"stampede\" + 0.013*\"railway\" + 0.012*\"city\" + 0.011*\"people\" + 0.011*\"commuter\" + 0.009*\"prabhadevi\" + 0.008*\"risk\"\n",
      "2019-10-29 00:41:41,147 : INFO : topic #0 (0.100): 0.024*\"train\" + 0.022*\"station\" + 0.022*\"mumbai\" + 0.016*\"stampede\" + 0.015*\"people\" + 0.011*\"commuter\" + 0.009*\"city\" + 0.008*\"railway\" + 0.008*\"passenger\" + 0.007*\"prabhadevi\"\n",
      "2019-10-29 00:41:41,148 : INFO : topic #2 (0.100): 0.026*\"train\" + 0.025*\"mumbai\" + 0.022*\"station\" + 0.015*\"people\" + 0.012*\"commuter\" + 0.012*\"stampede\" + 0.011*\"city\" + 0.009*\"prabhadevi\" + 0.009*\"risk\" + 0.008*\"railway\"\n",
      "2019-10-29 00:41:41,151 : INFO : topic #7 (0.100): 0.025*\"train\" + 0.024*\"mumbai\" + 0.016*\"station\" + 0.013*\"people\" + 0.012*\"stampede\" + 0.010*\"city\" + 0.009*\"get\" + 0.009*\"railway\" + 0.008*\"risk\" + 0.008*\"commuter\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:41,153 : INFO : topic diff=0.885961, rho=1.000000\n",
      "2019-10-29 00:41:41,591 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:41,600 : INFO : built Dictionary(639 unique tokens: ['located', 'rumor', 'bone', 'deep', 'relax']...) from 5 documents (total 4835 corpus positions)\n",
      "2019-10-29 00:41:41,608 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:41,609 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:41,610 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:41,614 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:41,616 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:41,819 : INFO : -8.489 per-word bound, 359.3 perplexity estimate based on a held-out corpus of 5 documents with 4835 words\n",
      "2019-10-29 00:41:41,821 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:41,833 : INFO : topic #8 (0.100): 0.016*\"island\" + 0.010*\"aeolian\" + 0.008*\"restaurant\" + 0.007*\"stromboli\" + 0.006*\"village\" + 0.006*\"sea\" + 0.006*\"local\" + 0.006*\"hotel\" + 0.005*\"also\" + 0.005*\"former\"\n",
      "2019-10-29 00:41:41,836 : INFO : topic #6 (0.100): 0.018*\"island\" + 0.011*\"beach\" + 0.009*\"sea\" + 0.009*\"restaurant\" + 0.008*\"hotel\" + 0.008*\"aeolian\" + 0.006*\"boat\" + 0.006*\"guided\" + 0.006*\"stromboli\" + 0.006*\"village\"\n",
      "2019-10-29 00:41:41,839 : INFO : topic #7 (0.100): 0.014*\"island\" + 0.013*\"aeolian\" + 0.007*\"beach\" + 0.007*\"village\" + 0.007*\"sea\" + 0.006*\"restaurant\" + 0.006*\"hotel\" + 0.005*\"panarea\" + 0.005*\"former\" + 0.005*\"boat\"\n",
      "2019-10-29 00:41:41,842 : INFO : topic #1 (0.100): 0.016*\"island\" + 0.010*\"beach\" + 0.008*\"aeolian\" + 0.008*\"sea\" + 0.008*\"restaurant\" + 0.007*\"village\" + 0.006*\"hotel\" + 0.006*\"stromboli\" + 0.006*\"boat\" + 0.005*\"also\"\n",
      "2019-10-29 00:41:41,845 : INFO : topic #9 (0.100): 0.017*\"island\" + 0.009*\"hotel\" + 0.009*\"sea\" + 0.008*\"beach\" + 0.008*\"aeolian\" + 0.007*\"restaurant\" + 0.006*\"village\" + 0.006*\"good\" + 0.005*\"filicudi\" + 0.005*\"rent\"\n",
      "2019-10-29 00:41:41,848 : INFO : topic diff=0.821105, rho=1.000000\n",
      "2019-10-29 00:41:42,323 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:42,330 : INFO : built Dictionary(518 unique tokens: ['anniversary', 'let', 'energy', 'han', 'reach']...) from 5 documents (total 4510 corpus positions)\n",
      "2019-10-29 00:41:42,336 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:42,337 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:42,339 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:42,343 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:42,344 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:42,513 : INFO : -8.092 per-word bound, 272.8 perplexity estimate based on a held-out corpus of 5 documents with 4510 words\n",
      "2019-10-29 00:41:42,514 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:42,523 : INFO : topic #3 (0.100): 0.022*\"sottsass\" + 0.018*\"design\" + 0.013*\"designer\" + 0.013*\"work\" + 0.012*\"like\" + 0.012*\"memphis\" + 0.011*\"ettore\" + 0.009*\"u\" + 0.008*\"world\" + 0.008*\"credit\"\n",
      "2019-10-29 00:41:42,525 : INFO : topic #1 (0.100): 0.030*\"sottsass\" + 0.021*\"design\" + 0.014*\"ettore\" + 0.012*\"like\" + 0.012*\"memphis\" + 0.010*\"designer\" + 0.008*\"different\" + 0.008*\"work\" + 0.008*\"one\" + 0.008*\"u\"\n",
      "2019-10-29 00:41:42,528 : INFO : topic #2 (0.100): 0.026*\"design\" + 0.021*\"sottsass\" + 0.013*\"memphis\" + 0.013*\"like\" + 0.012*\"designer\" + 0.011*\"house\" + 0.011*\"work\" + 0.009*\"different\" + 0.009*\"ettore\" + 0.007*\"life\"\n",
      "2019-10-29 00:41:42,530 : INFO : topic #9 (0.100): 0.024*\"sottsass\" + 0.017*\"design\" + 0.016*\"like\" + 0.013*\"memphis\" + 0.012*\"designer\" + 0.010*\"work\" + 0.010*\"house\" + 0.009*\"thing\" + 0.009*\"ettore\" + 0.008*\"u\"\n",
      "2019-10-29 00:41:42,531 : INFO : topic #4 (0.100): 0.030*\"sottsass\" + 0.017*\"design\" + 0.016*\"memphis\" + 0.011*\"designer\" + 0.011*\"work\" + 0.010*\"ettore\" + 0.009*\"like\" + 0.008*\"thing\" + 0.008*\"house\" + 0.007*\"u\"\n",
      "2019-10-29 00:41:42,534 : INFO : topic diff=0.891655, rho=1.000000\n",
      "2019-10-29 00:41:42,929 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:42,930 : INFO : built Dictionary(47 unique tokens: ['working', 'help', 'school', 'learn', 'let']...) from 5 documents (total 345 corpus positions)\n",
      "2019-10-29 00:41:42,932 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:42,933 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:42,934 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:42,936 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:42,937 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:42,964 : INFO : -6.205 per-word bound, 73.8 perplexity estimate based on a held-out corpus of 5 documents with 345 words\n",
      "2019-10-29 00:41:42,965 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:42,974 : INFO : topic #5 (0.100): 0.073*\"girl\" + 0.046*\"cnn\" + 0.045*\"educate\" + 0.038*\"u\" + 0.033*\"around\" + 0.032*\"help\" + 0.030*\"world\" + 0.029*\"obama\" + 0.027*\"october\" + 0.027*\"initiative\"\n",
      "2019-10-29 00:41:42,977 : INFO : topic #7 (0.100): 0.091*\"girl\" + 0.045*\"around\" + 0.044*\"cnn\" + 0.044*\"world\" + 0.041*\"michelle\" + 0.036*\"educate\" + 0.031*\"mission\" + 0.028*\"obama\" + 0.027*\"international\" + 0.027*\"help\"\n",
      "2019-10-29 00:41:42,981 : INFO : topic #0 (0.100): 0.050*\"world\" + 0.049*\"girl\" + 0.040*\"around\" + 0.038*\"educate\" + 0.035*\"initiative\" + 0.031*\"obama\" + 0.031*\"cnn\" + 0.031*\"help\" + 0.030*\"october\" + 0.028*\"michelle\"\n",
      "2019-10-29 00:41:42,984 : INFO : topic #6 (0.100): 0.063*\"girl\" + 0.043*\"world\" + 0.039*\"around\" + 0.038*\"international\" + 0.034*\"educate\" + 0.034*\"education\" + 0.033*\"michelle\" + 0.032*\"u\" + 0.031*\"initiative\" + 0.030*\"cnn\"\n",
      "2019-10-29 00:41:42,992 : INFO : topic #3 (0.100): 0.099*\"girl\" + 0.045*\"world\" + 0.043*\"cnn\" + 0.042*\"educate\" + 0.037*\"education\" + 0.036*\"around\" + 0.032*\"october\" + 0.030*\"obama\" + 0.027*\"help\" + 0.026*\"international\"\n",
      "2019-10-29 00:41:42,995 : INFO : topic diff=0.753383, rho=1.000000\n",
      "2019-10-29 00:41:43,470 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:43,479 : INFO : built Dictionary(546 unique tokens: ['dating', 'paradise', 'deep', 'chun', 'spokesperson']...) from 5 documents (total 4390 corpus positions)\n",
      "2019-10-29 00:41:43,485 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:43,486 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:43,488 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:43,492 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:43,495 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:43,653 : INFO : -8.249 per-word bound, 304.3 perplexity estimate based on a held-out corpus of 5 documents with 4390 words\n",
      "2019-10-29 00:41:43,655 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:43,665 : INFO : topic #3 (0.100): 0.028*\"kulangsu\" + 0.023*\"island\" + 0.013*\"piano\" + 0.012*\"china\" + 0.010*\"xiamen\" + 0.009*\"garden\" + 0.008*\"beach\" + 0.008*\"fresh\" + 0.008*\"goldstein\" + 0.007*\"music\"\n",
      "2019-10-29 00:41:43,667 : INFO : topic #7 (0.100): 0.025*\"kulangsu\" + 0.019*\"island\" + 0.016*\"piano\" + 0.014*\"china\" + 0.010*\"xiamen\" + 0.009*\"museum\" + 0.008*\"garden\" + 0.008*\"fresh\" + 0.008*\"goldstein\" + 0.007*\"one\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:43,670 : INFO : topic #2 (0.100): 0.029*\"kulangsu\" + 0.025*\"island\" + 0.012*\"piano\" + 0.012*\"china\" + 0.009*\"goldstein\" + 0.009*\"fresh\" + 0.009*\"music\" + 0.008*\"museum\" + 0.007*\"xiamen\" + 0.007*\"one\"\n",
      "2019-10-29 00:41:43,673 : INFO : topic #0 (0.100): 0.027*\"island\" + 0.023*\"kulangsu\" + 0.012*\"piano\" + 0.010*\"china\" + 0.009*\"xiamen\" + 0.009*\"beach\" + 0.008*\"one\" + 0.007*\"music\" + 0.007*\"fresh\" + 0.006*\"goldstein\"\n",
      "2019-10-29 00:41:43,674 : INFO : topic #9 (0.100): 0.025*\"kulangsu\" + 0.023*\"island\" + 0.013*\"piano\" + 0.011*\"china\" + 0.010*\"xiamen\" + 0.008*\"beach\" + 0.008*\"garden\" + 0.008*\"goldstein\" + 0.008*\"fresh\" + 0.007*\"music\"\n",
      "2019-10-29 00:41:43,676 : INFO : topic diff=0.851363, rho=1.000000\n",
      "2019-10-29 00:41:44,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:44,076 : INFO : built Dictionary(9 unique tokens: ['chat', 'world', 'unfolds', 'facebook', 'messenger']...) from 5 documents (total 45 corpus positions)\n",
      "2019-10-29 00:41:44,077 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:44,078 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:44,079 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:44,081 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:44,082 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:44,097 : INFO : -6.337 per-word bound, 80.9 perplexity estimate based on a held-out corpus of 5 documents with 45 words\n",
      "2019-10-29 00:41:44,099 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:44,104 : INFO : topic #8 (0.100): 0.128*\"happening\" + 0.118*\"world\" + 0.118*\"messenger\" + 0.115*\"facebook\" + 0.111*\"chat\" + 0.111*\"away\" + 0.105*\"u\" + 0.102*\"unfolds\" + 0.092*\"find\"\n",
      "2019-10-29 00:41:44,107 : INFO : topic #2 (0.100): 0.135*\"u\" + 0.128*\"away\" + 0.120*\"facebook\" + 0.107*\"happening\" + 0.106*\"find\" + 0.106*\"unfolds\" + 0.104*\"messenger\" + 0.099*\"world\" + 0.095*\"chat\"\n",
      "2019-10-29 00:41:44,110 : INFO : topic #6 (0.100): 0.133*\"world\" + 0.130*\"happening\" + 0.121*\"find\" + 0.113*\"facebook\" + 0.111*\"away\" + 0.110*\"chat\" + 0.104*\"messenger\" + 0.095*\"unfolds\" + 0.082*\"u\"\n",
      "2019-10-29 00:41:44,113 : INFO : topic #1 (0.100): 0.144*\"happening\" + 0.118*\"world\" + 0.116*\"find\" + 0.116*\"u\" + 0.114*\"chat\" + 0.113*\"away\" + 0.110*\"facebook\" + 0.095*\"unfolds\" + 0.074*\"messenger\"\n",
      "2019-10-29 00:41:44,117 : INFO : topic #4 (0.100): 0.144*\"messenger\" + 0.119*\"happening\" + 0.113*\"u\" + 0.109*\"find\" + 0.107*\"away\" + 0.107*\"chat\" + 0.103*\"unfolds\" + 0.099*\"world\" + 0.098*\"facebook\"\n",
      "2019-10-29 00:41:44,120 : INFO : topic diff=0.508312, rho=1.000000\n",
      "2019-10-29 00:41:44,531 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:44,533 : INFO : built Dictionary(84 unique tokens: ['civilian', 'help', 'completely', 'special', 'issue']...) from 5 documents (total 570 corpus positions)\n",
      "2019-10-29 00:41:44,536 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:44,537 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:44,538 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:44,540 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:44,541 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:44,578 : INFO : -6.804 per-word bound, 111.7 perplexity estimate based on a held-out corpus of 5 documents with 570 words\n",
      "2019-10-29 00:41:44,581 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:44,590 : INFO : topic #5 (0.100): 0.047*\"iraq\" + 0.036*\"duval\" + 0.034*\"son\" + 0.032*\"simon\" + 0.029*\"dog\" + 0.021*\"warrior\" + 0.021*\"tracking\" + 0.019*\"k9s\" + 0.018*\"work\" + 0.017*\"shari\"\n",
      "2019-10-29 00:41:44,592 : INFO : topic #9 (0.100): 0.050*\"son\" + 0.040*\"iraq\" + 0.031*\"k9s\" + 0.031*\"dog\" + 0.029*\"simon\" + 0.027*\"duval\" + 0.025*\"warrior\" + 0.020*\"veteran\" + 0.020*\"explosive\" + 0.019*\"mission\"\n",
      "2019-10-29 00:41:44,594 : INFO : topic #1 (0.100): 0.043*\"iraq\" + 0.039*\"son\" + 0.036*\"dog\" + 0.029*\"warrior\" + 0.028*\"duval\" + 0.025*\"simon\" + 0.022*\"k9s\" + 0.020*\"shari\" + 0.019*\"help\" + 0.019*\"tracking\"\n",
      "2019-10-29 00:41:44,597 : INFO : topic #7 (0.100): 0.037*\"iraq\" + 0.034*\"duval\" + 0.033*\"son\" + 0.031*\"simon\" + 0.030*\"k9s\" + 0.026*\"dog\" + 0.022*\"warrior\" + 0.019*\"traumatic\" + 0.019*\"returned\" + 0.019*\"veteran\"\n",
      "2019-10-29 00:41:44,600 : INFO : topic #0 (0.100): 0.044*\"son\" + 0.043*\"iraq\" + 0.033*\"dog\" + 0.032*\"duval\" + 0.026*\"k9s\" + 0.023*\"simon\" + 0.021*\"help\" + 0.020*\"veteran\" + 0.018*\"mission\" + 0.018*\"warrior\"\n",
      "2019-10-29 00:41:44,609 : INFO : topic diff=0.771766, rho=1.000000\n",
      "2019-10-29 00:41:45,023 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:45,026 : INFO : built Dictionary(14 unique tokens: ['unfolds', 'happening', 'meeting', 'facebook', 'messenger']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:41:45,027 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:45,031 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:45,034 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:45,037 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:45,040 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:45,054 : INFO : -6.429 per-word bound, 86.1 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:41:45,057 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:45,078 : INFO : topic #6 (0.100): 0.079*\"find\" + 0.077*\"facebook\" + 0.076*\"unfolds\" + 0.075*\"u\" + 0.075*\"world\" + 0.073*\"epa\" + 0.073*\"chat\" + 0.071*\"ceo\" + 0.070*\"happening\" + 0.070*\"protection\"\n",
      "2019-10-29 00:41:45,082 : INFO : topic #2 (0.100): 0.087*\"epa\" + 0.078*\"happening\" + 0.076*\"salmon\" + 0.075*\"unfolds\" + 0.073*\"ceo\" + 0.073*\"u\" + 0.071*\"reversed\" + 0.071*\"facebook\" + 0.070*\"chat\" + 0.070*\"find\"\n",
      "2019-10-29 00:41:45,085 : INFO : topic #9 (0.100): 0.089*\"happening\" + 0.084*\"u\" + 0.083*\"unfolds\" + 0.077*\"ceo\" + 0.077*\"find\" + 0.076*\"chat\" + 0.071*\"meeting\" + 0.071*\"facebook\" + 0.069*\"messenger\" + 0.066*\"salmon\"\n",
      "2019-10-29 00:41:45,102 : INFO : topic #1 (0.100): 0.083*\"u\" + 0.083*\"find\" + 0.082*\"meeting\" + 0.081*\"epa\" + 0.078*\"messenger\" + 0.076*\"salmon\" + 0.072*\"world\" + 0.070*\"ceo\" + 0.067*\"protection\" + 0.067*\"happening\"\n",
      "2019-10-29 00:41:45,107 : INFO : topic #3 (0.100): 0.092*\"protection\" + 0.088*\"facebook\" + 0.087*\"meeting\" + 0.078*\"reversed\" + 0.076*\"chat\" + 0.075*\"unfolds\" + 0.072*\"ceo\" + 0.069*\"u\" + 0.064*\"messenger\" + 0.061*\"find\"\n",
      "2019-10-29 00:41:45,110 : INFO : topic diff=0.502138, rho=1.000000\n",
      "2019-10-29 00:41:45,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:45,565 : INFO : built Dictionary(380 unique tokens: ['let', 'phase', 'relation', 'focus', 'distorted']...) from 5 documents (total 3020 corpus positions)\n",
      "2019-10-29 00:41:45,569 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:45,570 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:45,572 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:45,576 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:45,577 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:45,702 : INFO : -7.913 per-word bound, 241.1 perplexity estimate based on a held-out corpus of 5 documents with 3020 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:45,704 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:45,710 : INFO : topic #3 (0.100): 0.036*\"xu\" + 0.026*\"art\" + 0.020*\"company\" + 0.015*\"madein\" + 0.015*\"work\" + 0.014*\"zhen\" + 0.013*\"artist\" + 0.011*\"year\" + 0.009*\"said\" + 0.009*\"china\"\n",
      "2019-10-29 00:41:45,713 : INFO : topic #2 (0.100): 0.038*\"xu\" + 0.032*\"art\" + 0.021*\"work\" + 0.021*\"company\" + 0.019*\"madein\" + 0.015*\"zhen\" + 0.014*\"artist\" + 0.011*\"year\" + 0.011*\"said\" + 0.009*\"china\"\n",
      "2019-10-29 00:41:45,714 : INFO : topic #8 (0.100): 0.028*\"xu\" + 0.027*\"art\" + 0.020*\"madein\" + 0.018*\"work\" + 0.018*\"company\" + 0.012*\"china\" + 0.012*\"artist\" + 0.010*\"year\" + 0.010*\"one\" + 0.010*\"think\"\n",
      "2019-10-29 00:41:45,716 : INFO : topic #6 (0.100): 0.042*\"xu\" + 0.024*\"company\" + 0.023*\"work\" + 0.021*\"art\" + 0.020*\"madein\" + 0.013*\"artist\" + 0.012*\"year\" + 0.012*\"zhen\" + 0.010*\"china\" + 0.010*\"said\"\n",
      "2019-10-29 00:41:45,717 : INFO : topic #9 (0.100): 0.036*\"xu\" + 0.027*\"madein\" + 0.025*\"art\" + 0.020*\"company\" + 0.018*\"artist\" + 0.018*\"work\" + 0.016*\"zhen\" + 0.012*\"china\" + 0.011*\"year\" + 0.009*\"said\"\n",
      "2019-10-29 00:41:45,719 : INFO : topic diff=0.877523, rho=1.000000\n",
      "2019-10-29 00:41:46,142 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:46,146 : INFO : built Dictionary(266 unique tokens: ['although', 'deter', 'product', 'spot', 'advantage']...) from 5 documents (total 2115 corpus positions)\n",
      "2019-10-29 00:41:46,149 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:46,150 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:46,152 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:46,156 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:46,158 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:46,257 : INFO : -7.578 per-word bound, 191.0 perplexity estimate based on a held-out corpus of 5 documents with 2115 words\n",
      "2019-10-29 00:41:46,258 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:46,266 : INFO : topic #9 (0.100): 0.026*\"said\" + 0.025*\"opioid\" + 0.023*\"cigna\" + 0.016*\"abuse\" + 0.015*\"oxycontin\" + 0.012*\"drug\" + 0.012*\"pill\" + 0.011*\"pain\" + 0.010*\"xtampza\" + 0.010*\"still\"\n",
      "2019-10-29 00:41:46,267 : INFO : topic #8 (0.100): 0.028*\"said\" + 0.021*\"cigna\" + 0.020*\"opioid\" + 0.015*\"oxycontin\" + 0.015*\"abuse\" + 0.012*\"american\" + 0.012*\"pain\" + 0.012*\"pill\" + 0.010*\"decision\" + 0.010*\"medication\"\n",
      "2019-10-29 00:41:46,268 : INFO : topic #5 (0.100): 0.023*\"said\" + 0.022*\"opioid\" + 0.019*\"pill\" + 0.018*\"cigna\" + 0.017*\"oxycontin\" + 0.014*\"abuse\" + 0.013*\"drug\" + 0.010*\"dosage\" + 0.010*\"still\" + 0.009*\"xtampza\"\n",
      "2019-10-29 00:41:46,270 : INFO : topic #7 (0.100): 0.027*\"said\" + 0.026*\"cigna\" + 0.025*\"opioid\" + 0.016*\"oxycontin\" + 0.016*\"abuse\" + 0.015*\"pain\" + 0.013*\"pill\" + 0.010*\"release\" + 0.010*\"still\" + 0.009*\"medication\"\n",
      "2019-10-29 00:41:46,272 : INFO : topic #3 (0.100): 0.024*\"opioid\" + 0.021*\"said\" + 0.019*\"cigna\" + 0.019*\"oxycontin\" + 0.015*\"abuse\" + 0.011*\"pill\" + 0.010*\"prescription\" + 0.010*\"drug\" + 0.010*\"dosage\" + 0.009*\"american\"\n",
      "2019-10-29 00:41:46,274 : INFO : topic diff=0.836404, rho=1.000000\n",
      "2019-10-29 00:41:46,718 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:46,721 : INFO : built Dictionary(237 unique tokens: ['although', 'located', 'energy', 'de', 'advantage']...) from 5 documents (total 1830 corpus positions)\n",
      "2019-10-29 00:41:46,724 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:46,725 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:46,727 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:46,733 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:46,737 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:46,820 : INFO : -7.506 per-word bound, 181.8 perplexity estimate based on a held-out corpus of 5 documents with 1830 words\n",
      "2019-10-29 00:41:46,822 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:46,828 : INFO : topic #4 (0.100): 0.044*\"airport\" + 0.031*\"solar\" + 0.030*\"south\" + 0.029*\"africa\" + 0.017*\"power\" + 0.016*\"energy\" + 0.011*\"grid\" + 0.011*\"plant\" + 0.010*\"future\" + 0.009*\"part\"\n",
      "2019-10-29 00:41:46,830 : INFO : topic #5 (0.100): 0.045*\"airport\" + 0.042*\"solar\" + 0.028*\"south\" + 0.027*\"africa\" + 0.021*\"power\" + 0.012*\"energy\" + 0.011*\"grid\" + 0.011*\"plant\" + 0.010*\"future\" + 0.009*\"country\"\n",
      "2019-10-29 00:41:46,832 : INFO : topic #0 (0.100): 0.046*\"airport\" + 0.036*\"solar\" + 0.025*\"africa\" + 0.024*\"power\" + 0.022*\"south\" + 0.014*\"energy\" + 0.011*\"country\" + 0.010*\"future\" + 0.010*\"grid\" + 0.008*\"reserve\"\n",
      "2019-10-29 00:41:46,833 : INFO : topic #1 (0.100): 0.046*\"airport\" + 0.034*\"africa\" + 0.032*\"solar\" + 0.025*\"south\" + 0.022*\"power\" + 0.013*\"energy\" + 0.011*\"grid\" + 0.009*\"country\" + 0.009*\"say\" + 0.009*\"future\"\n",
      "2019-10-29 00:41:46,835 : INFO : topic #2 (0.100): 0.046*\"solar\" + 0.043*\"airport\" + 0.037*\"africa\" + 0.034*\"south\" + 0.021*\"energy\" + 0.016*\"power\" + 0.012*\"future\" + 0.011*\"grid\" + 0.009*\"country\" + 0.009*\"year\"\n",
      "2019-10-29 00:41:46,837 : INFO : topic diff=0.854074, rho=1.000000\n",
      "2019-10-29 00:41:47,274 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:47,278 : INFO : built Dictionary(322 unique tokens: ['relation', 'concern', 'perhaps', 'locked', 'watch']...) from 5 documents (total 2765 corpus positions)\n",
      "2019-10-29 00:41:47,283 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:47,284 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:47,286 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:47,289 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:47,291 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:47,394 : INFO : -7.647 per-word bound, 200.4 perplexity estimate based on a held-out corpus of 5 documents with 2765 words\n",
      "2019-10-29 00:41:47,395 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:47,403 : INFO : topic #0 (0.100): 0.027*\"saudi\" + 0.024*\"report\" + 0.022*\"child\" + 0.021*\"yemen\" + 0.021*\"arabia\" + 0.021*\"coalition\" + 0.019*\"said\" + 0.017*\"un\" + 0.015*\"conflict\" + 0.011*\"al\"\n",
      "2019-10-29 00:41:47,405 : INFO : topic #8 (0.100): 0.048*\"saudi\" + 0.036*\"child\" + 0.026*\"report\" + 0.022*\"arabia\" + 0.019*\"yemen\" + 0.017*\"said\" + 0.016*\"un\" + 0.015*\"coalition\" + 0.012*\"conflict\" + 0.011*\"secretary\"\n",
      "2019-10-29 00:41:47,406 : INFO : topic #6 (0.100): 0.044*\"saudi\" + 0.031*\"child\" + 0.026*\"un\" + 0.021*\"yemen\" + 0.018*\"coalition\" + 0.018*\"arabia\" + 0.017*\"report\" + 0.017*\"said\" + 0.012*\"conflict\" + 0.011*\"al\"\n",
      "2019-10-29 00:41:47,409 : INFO : topic #2 (0.100): 0.042*\"saudi\" + 0.027*\"report\" + 0.027*\"child\" + 0.025*\"un\" + 0.020*\"yemen\" + 0.017*\"coalition\" + 0.016*\"arabia\" + 0.015*\"conflict\" + 0.013*\"said\" + 0.011*\"led\"\n",
      "2019-10-29 00:41:47,411 : INFO : topic #7 (0.100): 0.034*\"saudi\" + 0.025*\"child\" + 0.025*\"yemen\" + 0.022*\"un\" + 0.020*\"arabia\" + 0.018*\"report\" + 0.016*\"said\" + 0.014*\"conflict\" + 0.014*\"coalition\" + 0.011*\"al\"\n",
      "2019-10-29 00:41:47,414 : INFO : topic diff=0.912751, rho=1.000000\n",
      "2019-10-29 00:41:47,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:47,881 : INFO : built Dictionary(296 unique tokens: ['previously', 'relation', 'campaign', 'come', 'remained']...) from 5 documents (total 2540 corpus positions)\n",
      "2019-10-29 00:41:47,885 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:47,886 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:47,888 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:47,893 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:47,896 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:48,018 : INFO : -7.575 per-word bound, 190.6 perplexity estimate based on a held-out corpus of 5 documents with 2540 words\n",
      "2019-10-29 00:41:48,020 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:48,029 : INFO : topic #4 (0.100): 0.045*\"kaepernick\" + 0.027*\"colin\" + 0.016*\"like\" + 0.012*\"eminem\" + 0.011*\"rapper\" + 0.010*\"would\" + 0.010*\"stand\" + 0.009*\"hip\" + 0.009*\"song\" + 0.009*\"lyric\"\n",
      "2019-10-29 00:41:48,032 : INFO : topic #8 (0.100): 0.058*\"kaepernick\" + 0.018*\"colin\" + 0.018*\"like\" + 0.012*\"song\" + 0.011*\"rapper\" + 0.011*\"stand\" + 0.011*\"eminem\" + 0.010*\"lyric\" + 0.009*\"hop\" + 0.009*\"would\"\n",
      "2019-10-29 00:41:48,035 : INFO : topic #7 (0.100): 0.070*\"kaepernick\" + 0.019*\"colin\" + 0.015*\"like\" + 0.011*\"lyric\" + 0.011*\"would\" + 0.010*\"rapper\" + 0.010*\"eminem\" + 0.009*\"song\" + 0.009*\"former\" + 0.009*\"stand\"\n",
      "2019-10-29 00:41:48,039 : INFO : topic #3 (0.100): 0.050*\"kaepernick\" + 0.021*\"colin\" + 0.013*\"like\" + 0.012*\"hip\" + 0.012*\"song\" + 0.010*\"rapper\" + 0.010*\"hop\" + 0.010*\"stand\" + 0.009*\"police\" + 0.009*\"would\"\n",
      "2019-10-29 00:41:48,042 : INFO : topic #2 (0.100): 0.041*\"kaepernick\" + 0.018*\"like\" + 0.017*\"colin\" + 0.014*\"rapper\" + 0.012*\"song\" + 0.012*\"stand\" + 0.011*\"would\" + 0.010*\"hop\" + 0.009*\"released\" + 0.009*\"hip\"\n",
      "2019-10-29 00:41:48,045 : INFO : topic diff=0.871719, rho=1.000000\n",
      "2019-10-29 00:41:48,512 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:48,516 : INFO : built Dictionary(271 unique tokens: ['forward', 'puerto', 'campaign', 'hero', 'come']...) from 5 documents (total 1770 corpus positions)\n",
      "2019-10-29 00:41:48,519 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:48,521 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:48,523 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:48,528 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:48,531 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:48,613 : INFO : -7.911 per-word bound, 240.7 perplexity estimate based on a held-out corpus of 5 documents with 1770 words\n",
      "2019-10-29 00:41:48,614 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:48,622 : INFO : topic #5 (0.100): 0.022*\"cause\" + 0.016*\"like\" + 0.016*\"trump\" + 0.015*\"f\" + 0.013*\"get\" + 0.011*\"come\" + 0.010*\"got\" + 0.009*\"king\" + 0.008*\"donald\" + 0.008*\"keep\"\n",
      "2019-10-29 00:41:48,625 : INFO : topic #6 (0.100): 0.027*\"cause\" + 0.020*\"like\" + 0.017*\"trump\" + 0.014*\"come\" + 0.013*\"f\" + 0.011*\"gonna\" + 0.010*\"freestyle\" + 0.009*\"get\" + 0.009*\"k\" + 0.008*\"say\"\n",
      "2019-10-29 00:41:48,628 : INFO : topic #4 (0.100): 0.028*\"cause\" + 0.016*\"f\" + 0.015*\"like\" + 0.014*\"trump\" + 0.012*\"come\" + 0.011*\"get\" + 0.010*\"gonna\" + 0.010*\"got\" + 0.009*\"storm\" + 0.008*\"full\"\n",
      "2019-10-29 00:41:48,635 : INFO : topic #7 (0.100): 0.024*\"cause\" + 0.019*\"like\" + 0.016*\"f\" + 0.015*\"trump\" + 0.012*\"gonna\" + 0.011*\"get\" + 0.010*\"got\" + 0.009*\"say\" + 0.009*\"k\" + 0.009*\"come\"\n",
      "2019-10-29 00:41:48,639 : INFO : topic #1 (0.100): 0.027*\"cause\" + 0.018*\"like\" + 0.017*\"f\" + 0.015*\"trump\" + 0.012*\"come\" + 0.010*\"eminem\" + 0.010*\"got\" + 0.010*\"til\" + 0.009*\"storm\" + 0.009*\"gonna\"\n",
      "2019-10-29 00:41:48,642 : INFO : topic diff=0.757446, rho=1.000000\n",
      "2019-10-29 00:41:49,114 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:49,127 : INFO : built Dictionary(748 unique tokens: ['although', 'earned', 'across', 'florida', 'advantage']...) from 5 documents (total 7450 corpus positions)\n",
      "2019-10-29 00:41:49,134 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:49,135 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:49,137 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:49,141 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:49,142 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:49,368 : INFO : -8.281 per-word bound, 311.0 perplexity estimate based on a held-out corpus of 5 documents with 7450 words\n",
      "2019-10-29 00:41:49,369 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:49,380 : INFO : topic #9 (0.100): 0.021*\"working\" + 0.019*\"white\" + 0.015*\"class\" + 0.013*\"college\" + 0.012*\"job\" + 0.011*\"year\" + 0.011*\"worker\" + 0.010*\"black\" + 0.009*\"life\" + 0.008*\"average\"\n",
      "2019-10-29 00:41:49,381 : INFO : topic #2 (0.100): 0.020*\"white\" + 0.017*\"working\" + 0.013*\"college\" + 0.011*\"class\" + 0.011*\"year\" + 0.009*\"job\" + 0.009*\"life\" + 0.009*\"many\" + 0.009*\"average\" + 0.008*\"worker\"\n",
      "2019-10-29 00:41:49,383 : INFO : topic #5 (0.100): 0.019*\"working\" + 0.018*\"white\" + 0.017*\"college\" + 0.013*\"job\" + 0.013*\"class\" + 0.011*\"year\" + 0.010*\"worker\" + 0.010*\"black\" + 0.010*\"degree\" + 0.007*\"average\"\n",
      "2019-10-29 00:41:49,384 : INFO : topic #0 (0.100): 0.031*\"white\" + 0.018*\"college\" + 0.016*\"working\" + 0.014*\"class\" + 0.013*\"year\" + 0.012*\"job\" + 0.011*\"worker\" + 0.011*\"black\" + 0.009*\"many\" + 0.008*\"degree\"\n",
      "2019-10-29 00:41:49,385 : INFO : topic #4 (0.100): 0.026*\"white\" + 0.014*\"college\" + 0.013*\"working\" + 0.012*\"class\" + 0.012*\"worker\" + 0.011*\"year\" + 0.010*\"life\" + 0.009*\"average\" + 0.009*\"men\" + 0.009*\"black\"\n",
      "2019-10-29 00:41:49,388 : INFO : topic diff=0.968777, rho=1.000000\n",
      "2019-10-29 00:41:49,850 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:49,858 : INFO : built Dictionary(629 unique tokens: ['reunion', 'rumor', 'bone', 'jamie', 'drinking']...) from 5 documents (total 5980 corpus positions)\n",
      "2019-10-29 00:41:49,866 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:49,870 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:49,873 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:49,879 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:49,882 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:50,092 : INFO : -8.171 per-word bound, 288.1 perplexity estimate based on a held-out corpus of 5 documents with 5980 words\n",
      "2019-10-29 00:41:50,095 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:50,107 : INFO : topic #2 (0.100): 0.018*\"people\" + 0.010*\"get\" + 0.008*\"vega\" + 0.008*\"floor\" + 0.008*\"festival\" + 0.007*\"inside\" + 0.007*\"gunfire\" + 0.007*\"say\" + 0.006*\"police\" + 0.006*\"hopkins\"\n",
      "2019-10-29 00:41:50,110 : INFO : topic #9 (0.100): 0.017*\"people\" + 0.012*\"say\" + 0.010*\"get\" + 0.009*\"vega\" + 0.008*\"go\" + 0.008*\"inside\" + 0.007*\"one\" + 0.007*\"floor\" + 0.007*\"gunfire\" + 0.007*\"la\"\n",
      "2019-10-29 00:41:50,113 : INFO : topic #8 (0.100): 0.014*\"people\" + 0.011*\"get\" + 0.009*\"vega\" + 0.008*\"one\" + 0.008*\"la\" + 0.007*\"gunfire\" + 0.007*\"say\" + 0.007*\"inside\" + 0.007*\"police\" + 0.007*\"minute\"\n",
      "2019-10-29 00:41:50,116 : INFO : topic #0 (0.100): 0.017*\"people\" + 0.008*\"get\" + 0.008*\"la\" + 0.007*\"floor\" + 0.007*\"go\" + 0.007*\"police\" + 0.007*\"minute\" + 0.007*\"inside\" + 0.007*\"gunfire\" + 0.007*\"say\"\n",
      "2019-10-29 00:41:50,118 : INFO : topic #4 (0.100): 0.015*\"people\" + 0.011*\"get\" + 0.010*\"festival\" + 0.009*\"say\" + 0.009*\"inside\" + 0.008*\"gunfire\" + 0.007*\"one\" + 0.007*\"la\" + 0.007*\"vega\" + 0.007*\"police\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:50,121 : INFO : topic diff=0.901091, rho=1.000000\n",
      "2019-10-29 00:41:50,596 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:50,605 : INFO : built Dictionary(687 unique tokens: ['earned', 'wave', 'congressman', 'energy', 'recalled']...) from 5 documents (total 6680 corpus positions)\n",
      "2019-10-29 00:41:50,612 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:50,613 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:50,616 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:50,620 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:50,622 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:50,829 : INFO : -8.232 per-word bound, 300.6 perplexity estimate based on a held-out corpus of 5 documents with 6680 words\n",
      "2019-10-29 00:41:50,831 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:50,841 : INFO : topic #4 (0.100): 0.040*\"colbert\" + 0.038*\"biden\" + 0.032*\"photo\" + 0.030*\"caption\" + 0.018*\"president\" + 0.018*\"hide\" + 0.018*\"joe\" + 0.016*\"stephen\" + 0.012*\"funnyman\" + 0.010*\"vice\"\n",
      "2019-10-29 00:41:50,843 : INFO : topic #5 (0.100): 0.039*\"photo\" + 0.035*\"colbert\" + 0.033*\"hide\" + 0.029*\"biden\" + 0.029*\"caption\" + 0.017*\"president\" + 0.016*\"joe\" + 0.016*\"vice\" + 0.015*\"stephen\" + 0.010*\"funnyman\"\n",
      "2019-10-29 00:41:50,844 : INFO : topic #0 (0.100): 0.034*\"biden\" + 0.032*\"photo\" + 0.027*\"colbert\" + 0.021*\"president\" + 0.019*\"caption\" + 0.018*\"hide\" + 0.016*\"vice\" + 0.015*\"funnyman\" + 0.015*\"joe\" + 0.014*\"stephen\"\n",
      "2019-10-29 00:41:50,845 : INFO : topic #2 (0.100): 0.037*\"colbert\" + 0.030*\"biden\" + 0.029*\"photo\" + 0.026*\"hide\" + 0.019*\"president\" + 0.019*\"caption\" + 0.017*\"joe\" + 0.015*\"funnyman\" + 0.012*\"stephen\" + 0.010*\"show\"\n",
      "2019-10-29 00:41:50,848 : INFO : topic #7 (0.100): 0.034*\"colbert\" + 0.033*\"biden\" + 0.030*\"photo\" + 0.021*\"hide\" + 0.020*\"president\" + 0.017*\"caption\" + 0.016*\"joe\" + 0.015*\"stephen\" + 0.012*\"funnyman\" + 0.010*\"vice\"\n",
      "2019-10-29 00:41:50,849 : INFO : topic diff=0.947891, rho=1.000000\n",
      "2019-10-29 00:41:51,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:51,249 : INFO : built Dictionary(61 unique tokens: ['may', 'thoughtful', 'hijab', 'emoji', 'life']...) from 5 documents (total 380 corpus positions)\n",
      "2019-10-29 00:41:51,251 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:51,253 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:51,254 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:51,259 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:51,263 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:51,308 : INFO : -6.716 per-word bound, 105.1 perplexity estimate based on a held-out corpus of 5 documents with 380 words\n",
      "2019-10-29 00:41:51,312 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:51,319 : INFO : topic #0 (0.100): 0.045*\"emoji\" + 0.042*\"woman\" + 0.032*\"old\" + 0.030*\"rayouf\" + 0.029*\"year\" + 0.028*\"hijabi\" + 0.026*\"muslim\" + 0.025*\"headscarf\" + 0.024*\"represent\" + 0.023*\"cnn\"\n",
      "2019-10-29 00:41:51,324 : INFO : topic #5 (0.100): 0.049*\"emoji\" + 0.032*\"woman\" + 0.029*\"unicode\" + 0.027*\"year\" + 0.027*\"teen\" + 0.027*\"old\" + 0.026*\"muslim\" + 0.025*\"rayouf\" + 0.024*\"hijabi\" + 0.023*\"cnn\"\n",
      "2019-10-29 00:41:51,334 : INFO : topic #6 (0.100): 0.049*\"woman\" + 0.037*\"emoji\" + 0.031*\"teen\" + 0.029*\"year\" + 0.028*\"hijabi\" + 0.026*\"muslim\" + 0.024*\"represent\" + 0.022*\"unicode\" + 0.022*\"rayouf\" + 0.022*\"cnn\"\n",
      "2019-10-29 00:41:51,342 : INFO : topic #8 (0.100): 0.034*\"emoji\" + 0.033*\"headscarf\" + 0.031*\"represent\" + 0.030*\"woman\" + 0.027*\"unicode\" + 0.025*\"cnn\" + 0.024*\"teen\" + 0.023*\"old\" + 0.023*\"muslim\" + 0.023*\"rayouf\"\n",
      "2019-10-29 00:41:51,345 : INFO : topic #4 (0.100): 0.054*\"emoji\" + 0.032*\"woman\" + 0.030*\"unicode\" + 0.029*\"muslim\" + 0.028*\"old\" + 0.028*\"headscarf\" + 0.028*\"cnn\" + 0.024*\"year\" + 0.022*\"teen\" + 0.022*\"represent\"\n",
      "2019-10-29 00:41:51,348 : INFO : topic diff=0.675432, rho=1.000000\n",
      "2019-10-29 00:41:51,925 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:51,934 : INFO : built Dictionary(685 unique tokens: ['located', 'cambodian', 'camp', 'headquartered', 'golden']...) from 5 documents (total 6360 corpus positions)\n",
      "2019-10-29 00:41:51,941 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:51,942 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:51,944 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:51,949 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:51,951 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:52,163 : INFO : -8.280 per-word bound, 310.8 perplexity estimate based on a held-out corpus of 5 documents with 6360 words\n",
      "2019-10-29 00:41:52,165 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:52,176 : INFO : topic #6 (0.100): 0.028*\"camp\" + 0.013*\"tent\" + 0.011*\"tented\" + 0.010*\"elephant\" + 0.008*\"luxury\" + 0.008*\"safari\" + 0.008*\"traveler\" + 0.008*\"open\" + 0.008*\"jungle\" + 0.007*\"tiger\"\n",
      "2019-10-29 00:41:52,178 : INFO : topic #8 (0.100): 0.026*\"camp\" + 0.014*\"tent\" + 0.013*\"tented\" + 0.013*\"elephant\" + 0.009*\"wildlife\" + 0.009*\"safari\" + 0.009*\"jungle\" + 0.007*\"traveler\" + 0.006*\"glamping\" + 0.006*\"tiger\"\n",
      "2019-10-29 00:41:52,180 : INFO : topic #1 (0.100): 0.019*\"camp\" + 0.015*\"tent\" + 0.012*\"elephant\" + 0.011*\"traveler\" + 0.010*\"tiger\" + 0.009*\"jungle\" + 0.009*\"tented\" + 0.008*\"safari\" + 0.008*\"wildlife\" + 0.008*\"experience\"\n",
      "2019-10-29 00:41:52,183 : INFO : topic #5 (0.100): 0.021*\"camp\" + 0.018*\"tent\" + 0.017*\"elephant\" + 0.010*\"safari\" + 0.010*\"jungle\" + 0.010*\"tented\" + 0.009*\"wildlife\" + 0.008*\"luxury\" + 0.008*\"private\" + 0.007*\"traveler\"\n",
      "2019-10-29 00:41:52,185 : INFO : topic #2 (0.100): 0.025*\"camp\" + 0.013*\"elephant\" + 0.012*\"tent\" + 0.012*\"tented\" + 0.009*\"traveler\" + 0.009*\"wildlife\" + 0.008*\"safari\" + 0.008*\"luxury\" + 0.008*\"experience\" + 0.007*\"open\"\n",
      "2019-10-29 00:41:52,187 : INFO : topic diff=0.912519, rho=1.000000\n",
      "2019-10-29 00:41:52,624 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:52,630 : INFO : built Dictionary(417 unique tokens: ['let', 'phase', 'florida', 'troop', 'drive']...) from 5 documents (total 3520 corpus positions)\n",
      "2019-10-29 00:41:52,635 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:52,639 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:52,643 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:52,648 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:52,651 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:52,782 : INFO : -7.923 per-word bound, 242.7 perplexity estimate based on a held-out corpus of 5 documents with 3520 words\n",
      "2019-10-29 00:41:52,784 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:52,792 : INFO : topic #2 (0.100): 0.014*\"people\" + 0.014*\"response\" + 0.012*\"hurricane\" + 0.012*\"katrina\" + 0.011*\"government\" + 0.010*\"recovery\" + 0.010*\"plan\" + 0.009*\"volunteer\" + 0.009*\"help\" + 0.009*\"disaster\"\n",
      "2019-10-29 00:41:52,795 : INFO : topic #4 (0.100): 0.020*\"hurricane\" + 0.013*\"government\" + 0.011*\"people\" + 0.011*\"plan\" + 0.010*\"response\" + 0.009*\"federal\" + 0.009*\"disaster\" + 0.009*\"recovery\" + 0.009*\"shelter\" + 0.008*\"volunteer\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:52,797 : INFO : topic #7 (0.100): 0.018*\"katrina\" + 0.016*\"hurricane\" + 0.015*\"government\" + 0.013*\"people\" + 0.012*\"response\" + 0.010*\"shelter\" + 0.009*\"recovery\" + 0.009*\"plan\" + 0.008*\"disaster\" + 0.007*\"volunteer\"\n",
      "2019-10-29 00:41:52,798 : INFO : topic #1 (0.100): 0.017*\"hurricane\" + 0.014*\"people\" + 0.012*\"response\" + 0.010*\"recovery\" + 0.010*\"local\" + 0.009*\"federal\" + 0.009*\"need\" + 0.008*\"katrina\" + 0.008*\"government\" + 0.008*\"part\"\n",
      "2019-10-29 00:41:52,800 : INFO : topic #9 (0.100): 0.018*\"hurricane\" + 0.013*\"people\" + 0.011*\"katrina\" + 0.010*\"government\" + 0.009*\"recovery\" + 0.009*\"response\" + 0.009*\"shelter\" + 0.009*\"local\" + 0.009*\"volunteer\" + 0.008*\"federal\"\n",
      "2019-10-29 00:41:52,801 : INFO : topic diff=0.867099, rho=1.000000\n",
      "2019-10-29 00:41:53,220 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:53,224 : INFO : built Dictionary(244 unique tokens: ['let', 'school', 'septic', 'portion', 'stop']...) from 5 documents (total 1830 corpus positions)\n",
      "2019-10-29 00:41:53,227 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:53,228 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:53,230 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:53,233 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:53,235 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:53,320 : INFO : -7.589 per-word bound, 192.6 perplexity estimate based on a held-out corpus of 5 documents with 1830 words\n",
      "2019-10-29 00:41:53,321 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:53,329 : INFO : topic #6 (0.100): 0.038*\"martinez\" + 0.035*\"said\" + 0.019*\"life\" + 0.015*\"marine\" + 0.014*\"husband\" + 0.012*\"david\" + 0.010*\"see\" + 0.010*\"could\" + 0.010*\"year\" + 0.009*\"back\"\n",
      "2019-10-29 00:41:53,331 : INFO : topic #5 (0.100): 0.037*\"said\" + 0.032*\"martinez\" + 0.019*\"david\" + 0.019*\"husband\" + 0.016*\"life\" + 0.011*\"marine\" + 0.010*\"could\" + 0.010*\"bacteria\" + 0.009*\"eating\" + 0.009*\"see\"\n",
      "2019-10-29 00:41:53,334 : INFO : topic #2 (0.100): 0.043*\"martinez\" + 0.026*\"said\" + 0.018*\"life\" + 0.014*\"marine\" + 0.014*\"husband\" + 0.013*\"david\" + 0.011*\"bacteria\" + 0.010*\"could\" + 0.009*\"strength\" + 0.009*\"challenge\"\n",
      "2019-10-29 00:41:53,337 : INFO : topic #3 (0.100): 0.035*\"martinez\" + 0.030*\"said\" + 0.018*\"life\" + 0.016*\"husband\" + 0.014*\"david\" + 0.010*\"bacteria\" + 0.010*\"marine\" + 0.010*\"flesh\" + 0.009*\"kid\" + 0.009*\"amputation\"\n",
      "2019-10-29 00:41:53,339 : INFO : topic #0 (0.100): 0.039*\"martinez\" + 0.029*\"said\" + 0.020*\"life\" + 0.019*\"husband\" + 0.013*\"could\" + 0.012*\"david\" + 0.010*\"marine\" + 0.010*\"cindy\" + 0.009*\"pound\" + 0.009*\"see\"\n",
      "2019-10-29 00:41:53,341 : INFO : topic diff=0.820613, rho=1.000000\n",
      "2019-10-29 00:41:54,162 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:54,221 : INFO : built Dictionary(2566 unique tokens: ['earned', 'cambodian', 'laboratory', 'tradition', 'let']...) from 5 documents (total 33675 corpus positions)\n",
      "2019-10-29 00:41:54,253 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:54,255 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:54,259 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:54,269 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:54,271 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:54,994 : INFO : -9.227 per-word bound, 599.2 perplexity estimate based on a held-out corpus of 5 documents with 33675 words\n",
      "2019-10-29 00:41:54,996 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:55,018 : INFO : topic #8 (0.100): 0.026*\"caption\" + 0.024*\"photo\" + 0.020*\"hide\" + 0.019*\"moment\" + 0.011*\"1970s\" + 0.010*\"historic\" + 0.009*\"iconic\" + 0.008*\"1960s\" + 0.007*\"first\" + 0.007*\"generation\"\n",
      "2019-10-29 00:41:55,020 : INFO : topic #1 (0.100): 0.023*\"photo\" + 0.021*\"caption\" + 0.020*\"moment\" + 0.018*\"hide\" + 0.012*\"1970s\" + 0.010*\"historic\" + 0.008*\"1960s\" + 0.008*\"iconic\" + 0.007*\"u\" + 0.007*\"generation\"\n",
      "2019-10-29 00:41:55,023 : INFO : topic #2 (0.100): 0.024*\"hide\" + 0.023*\"moment\" + 0.018*\"caption\" + 0.016*\"photo\" + 0.012*\"historic\" + 0.011*\"iconic\" + 0.009*\"1970s\" + 0.008*\"1960s\" + 0.008*\"first\" + 0.008*\"u\"\n",
      "2019-10-29 00:41:55,026 : INFO : topic #5 (0.100): 0.021*\"hide\" + 0.020*\"caption\" + 0.019*\"moment\" + 0.017*\"photo\" + 0.011*\"iconic\" + 0.009*\"historic\" + 0.008*\"1960s\" + 0.008*\"u\" + 0.007*\"1970s\" + 0.006*\"generation\"\n",
      "2019-10-29 00:41:55,028 : INFO : topic #3 (0.100): 0.016*\"moment\" + 0.014*\"hide\" + 0.013*\"caption\" + 0.013*\"photo\" + 0.011*\"1960s\" + 0.011*\"historic\" + 0.010*\"first\" + 0.009*\"u\" + 0.009*\"iconic\" + 0.008*\"1970s\"\n",
      "2019-10-29 00:41:55,031 : INFO : topic diff=1.079459, rho=1.000000\n",
      "2019-10-29 00:41:55,457 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:55,459 : INFO : built Dictionary(77 unique tokens: ['online', 'helpful', 'review', 'customer', 'come']...) from 5 documents (total 610 corpus positions)\n",
      "2019-10-29 00:41:55,461 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:55,462 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:55,468 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:55,471 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:55,475 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:55,514 : INFO : -6.468 per-word bound, 88.5 perplexity estimate based on a held-out corpus of 5 documents with 610 words\n",
      "2019-10-29 00:41:55,517 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:55,525 : INFO : topic #4 (0.100): 0.061*\"card\" + 0.057*\"cash\" + 0.043*\"back\" + 0.039*\"reward\" + 0.039*\"purchase\" + 0.025*\"month\" + 0.024*\"credit\" + 0.022*\"u\" + 0.019*\"earn\" + 0.017*\"everyday\"\n",
      "2019-10-29 00:41:55,530 : INFO : topic #6 (0.100): 0.060*\"card\" + 0.058*\"cash\" + 0.051*\"back\" + 0.049*\"purchase\" + 0.042*\"reward\" + 0.026*\"month\" + 0.024*\"u\" + 0.020*\"credit\" + 0.018*\"balance\" + 0.018*\"everyday\"\n",
      "2019-10-29 00:41:55,533 : INFO : topic #2 (0.100): 0.068*\"cash\" + 0.066*\"card\" + 0.047*\"back\" + 0.037*\"purchase\" + 0.036*\"reward\" + 0.026*\"month\" + 0.022*\"u\" + 0.021*\"statement\" + 0.020*\"credit\" + 0.019*\"come\"\n",
      "2019-10-29 00:41:55,535 : INFO : topic #1 (0.100): 0.055*\"card\" + 0.042*\"cash\" + 0.041*\"reward\" + 0.038*\"purchase\" + 0.033*\"back\" + 0.030*\"u\" + 0.028*\"credit\" + 0.021*\"month\" + 0.018*\"account\" + 0.017*\"everyday\"\n",
      "2019-10-29 00:41:55,538 : INFO : topic #0 (0.100): 0.064*\"card\" + 0.056*\"cash\" + 0.043*\"back\" + 0.037*\"reward\" + 0.034*\"purchase\" + 0.030*\"credit\" + 0.022*\"month\" + 0.022*\"u\" + 0.019*\"account\" + 0.018*\"balance\"\n",
      "2019-10-29 00:41:55,540 : INFO : topic diff=0.860108, rho=1.000000\n",
      "2019-10-29 00:41:55,935 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:55,937 : INFO : built Dictionary(58 unique tokens: ['80th', 'nashville', 'scheduled', 'walk', 'get']...) from 5 documents (total 450 corpus positions)\n",
      "2019-10-29 00:41:55,939 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:55,940 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:55,941 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:55,943 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:55,944 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:55,974 : INFO : -6.262 per-word bound, 76.8 perplexity estimate based on a held-out corpus of 5 documents with 450 words\n",
      "2019-10-29 00:41:55,976 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:55,980 : INFO : topic #8 (0.100): 0.076*\"music\" + 0.056*\"rogers\" + 0.049*\"walk\" + 0.048*\"kenny\" + 0.047*\"fame\" + 0.038*\"star\" + 0.032*\"one\" + 0.031*\"city\" + 0.030*\"nashville\" + 0.023*\"said\"\n",
      "2019-10-29 00:41:55,982 : INFO : topic #1 (0.100): 0.066*\"rogers\" + 0.064*\"music\" + 0.059*\"walk\" + 0.050*\"city\" + 0.046*\"fame\" + 0.045*\"star\" + 0.043*\"kenny\" + 0.035*\"one\" + 0.020*\"said\" + 0.018*\"nashville\"\n",
      "2019-10-29 00:41:55,984 : INFO : topic #5 (0.100): 0.091*\"music\" + 0.056*\"rogers\" + 0.053*\"fame\" + 0.045*\"walk\" + 0.041*\"star\" + 0.041*\"city\" + 0.033*\"one\" + 0.030*\"kenny\" + 0.021*\"said\" + 0.020*\"nashville\"\n",
      "2019-10-29 00:41:55,987 : INFO : topic #2 (0.100): 0.064*\"music\" + 0.057*\"fame\" + 0.052*\"rogers\" + 0.050*\"city\" + 0.045*\"kenny\" + 0.043*\"walk\" + 0.040*\"star\" + 0.036*\"one\" + 0.024*\"nashville\" + 0.017*\"said\"\n",
      "2019-10-29 00:41:55,991 : INFO : topic #7 (0.100): 0.077*\"rogers\" + 0.075*\"music\" + 0.051*\"walk\" + 0.043*\"star\" + 0.041*\"kenny\" + 0.041*\"fame\" + 0.033*\"one\" + 0.032*\"city\" + 0.023*\"said\" + 0.017*\"nashville\"\n",
      "2019-10-29 00:41:55,994 : INFO : topic diff=0.931298, rho=1.000000\n",
      "2019-10-29 00:41:56,392 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:56,395 : INFO : built Dictionary(117 unique tokens: ['filmed', 'pepper', 'french', 'apace', 'messi']...) from 5 documents (total 755 corpus positions)\n",
      "2019-10-29 00:41:56,397 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:56,399 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:56,400 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:56,402 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:56,404 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:56,458 : INFO : -7.181 per-word bound, 145.1 perplexity estimate based on a held-out corpus of 5 documents with 755 words\n",
      "2019-10-29 00:41:56,461 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:56,476 : INFO : topic #2 (0.100): 0.030*\"clasico\" + 0.024*\"real\" + 0.021*\"el\" + 0.020*\"riot\" + 0.020*\"barcelona\" + 0.020*\"player\" + 0.019*\"police\" + 0.016*\"madrid\" + 0.016*\"catalan\" + 0.014*\"video\"\n",
      "2019-10-29 00:41:56,479 : INFO : topic #6 (0.100): 0.031*\"clasico\" + 0.028*\"real\" + 0.024*\"el\" + 0.021*\"madrid\" + 0.019*\"player\" + 0.018*\"riot\" + 0.018*\"barcelona\" + 0.015*\"video\" + 0.015*\"police\" + 0.014*\"spoof\"\n",
      "2019-10-29 00:41:56,483 : INFO : topic #8 (0.100): 0.032*\"clasico\" + 0.029*\"el\" + 0.024*\"real\" + 0.021*\"player\" + 0.020*\"police\" + 0.018*\"riot\" + 0.017*\"barcelona\" + 0.016*\"madrid\" + 0.015*\"crisis\" + 0.015*\"video\"\n",
      "2019-10-29 00:41:56,486 : INFO : topic #1 (0.100): 0.036*\"real\" + 0.030*\"clasico\" + 0.027*\"riot\" + 0.022*\"el\" + 0.019*\"police\" + 0.019*\"player\" + 0.019*\"barcelona\" + 0.015*\"barca\" + 0.014*\"spoof\" + 0.014*\"messi\"\n",
      "2019-10-29 00:41:56,489 : INFO : topic #4 (0.100): 0.033*\"el\" + 0.028*\"clasico\" + 0.025*\"real\" + 0.018*\"barcelona\" + 0.018*\"madrid\" + 0.017*\"riot\" + 0.016*\"satirical\" + 0.016*\"police\" + 0.015*\"spanish\" + 0.015*\"catalonia\"\n",
      "2019-10-29 00:41:56,491 : INFO : topic diff=0.735028, rho=1.000000\n",
      "2019-10-29 00:41:56,919 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:56,923 : INFO : built Dictionary(273 unique tokens: ['blocked', 'prescription', 'sorry', 'person', 'watch']...) from 5 documents (total 2210 corpus positions)\n",
      "2019-10-29 00:41:56,926 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:56,929 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:56,933 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:56,937 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:56,940 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:57,045 : INFO : -7.577 per-word bound, 190.9 perplexity estimate based on a held-out corpus of 5 documents with 2210 words\n",
      "2019-10-29 00:41:57,047 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:57,054 : INFO : topic #3 (0.100): 0.031*\"gun\" + 0.029*\"buy\" + 0.016*\"sudafed\" + 0.014*\"year\" + 0.011*\"purchase\" + 0.011*\"medicine\" + 0.010*\"two\" + 0.010*\"nevada\" + 0.010*\"state\" + 0.009*\"drug\"\n",
      "2019-10-29 00:41:57,056 : INFO : topic #0 (0.100): 0.035*\"buy\" + 0.020*\"sudafed\" + 0.019*\"gun\" + 0.011*\"two\" + 0.011*\"purchase\" + 0.010*\"pse\" + 0.010*\"drug\" + 0.010*\"state\" + 0.009*\"medicine\" + 0.009*\"firearm\"\n",
      "2019-10-29 00:41:57,057 : INFO : topic #9 (0.100): 0.022*\"gun\" + 0.019*\"buy\" + 0.016*\"nevada\" + 0.014*\"purchase\" + 0.013*\"sudafed\" + 0.012*\"year\" + 0.010*\"one\" + 0.009*\"pse\" + 0.009*\"ammunition\" + 0.009*\"medicine\"\n",
      "2019-10-29 00:41:57,059 : INFO : topic #1 (0.100): 0.031*\"buy\" + 0.020*\"gun\" + 0.019*\"sudafed\" + 0.014*\"nevada\" + 0.011*\"two\" + 0.011*\"day\" + 0.010*\"purchase\" + 0.010*\"drug\" + 0.010*\"medicine\" + 0.010*\"pseudoephedrine\"\n",
      "2019-10-29 00:41:57,060 : INFO : topic #7 (0.100): 0.022*\"gun\" + 0.019*\"buy\" + 0.018*\"sudafed\" + 0.015*\"purchase\" + 0.011*\"year\" + 0.011*\"two\" + 0.010*\"day\" + 0.010*\"medicine\" + 0.010*\"nevada\" + 0.009*\"law\"\n",
      "2019-10-29 00:41:57,062 : INFO : topic diff=0.815468, rho=1.000000\n",
      "2019-10-29 00:41:57,476 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:57,477 : INFO : built Dictionary(1 unique tokens: ['nan']) from 5 documents (total 5 corpus positions)\n",
      "2019-10-29 00:41:57,478 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:57,480 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:57,481 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:57,482 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:57,483 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:57,488 : INFO : -4.936 per-word bound, 30.6 perplexity estimate based on a held-out corpus of 5 documents with 5 words\n",
      "2019-10-29 00:41:57,490 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:57,494 : INFO : topic #4 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:41:57,496 : INFO : topic #1 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:41:57,497 : INFO : topic #2 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:41:57,498 : INFO : topic #6 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:41:57,499 : INFO : topic #5 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:41:57,500 : INFO : topic diff=0.000000, rho=1.000000\n",
      "2019-10-29 00:41:57,943 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:57,946 : INFO : built Dictionary(119 unique tokens: ['rage', 'ch', 'rockhall', 'special', 'industry']...) from 5 documents (total 915 corpus positions)\n",
      "2019-10-29 00:41:57,948 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:57,950 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:57,951 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:57,954 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:57,956 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:58,008 : INFO : -6.894 per-word bound, 118.9 perplexity estimate based on a held-out corpus of 5 documents with 915 words\n",
      "2019-10-29 00:41:58,009 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:41:58,017 : INFO : topic #1 (0.100): 0.035*\"hall\" + 0.032*\"induction\" + 0.027*\"nominee\" + 0.027*\"fame\" + 0.025*\"fan\" + 0.025*\"broadcast\" + 0.025*\"year\" + 0.021*\"roll\" + 0.020*\"inductee\" + 0.020*\"ballot\"\n",
      "2019-10-29 00:41:58,018 : INFO : topic #3 (0.100): 0.029*\"induction\" + 0.029*\"announced\" + 0.028*\"hall\" + 0.024*\"year\" + 0.024*\"nominee\" + 0.023*\"rock\" + 0.023*\"fame\" + 0.021*\"roll\" + 0.019*\"fan\" + 0.019*\"first\"\n",
      "2019-10-29 00:41:58,020 : INFO : topic #8 (0.100): 0.033*\"hall\" + 0.030*\"induction\" + 0.028*\"fame\" + 0.027*\"rock\" + 0.024*\"fan\" + 0.023*\"announced\" + 0.021*\"nominee\" + 0.021*\"year\" + 0.019*\"vote\" + 0.019*\"ballot\"\n",
      "2019-10-29 00:41:58,022 : INFO : topic #9 (0.100): 0.038*\"fame\" + 0.032*\"induction\" + 0.029*\"hall\" + 0.028*\"nominee\" + 0.024*\"broadcast\" + 0.023*\"rock\" + 0.023*\"announced\" + 0.022*\"roll\" + 0.021*\"ballot\" + 0.019*\"fan\"\n",
      "2019-10-29 00:41:58,024 : INFO : topic #5 (0.100): 0.037*\"fame\" + 0.028*\"year\" + 0.028*\"nominee\" + 0.027*\"rock\" + 0.027*\"hall\" + 0.023*\"induction\" + 0.023*\"broadcast\" + 0.021*\"announced\" + 0.021*\"roll\" + 0.020*\"fan\"\n",
      "2019-10-29 00:41:58,025 : INFO : topic diff=0.877021, rho=1.000000\n",
      "2019-10-29 00:41:58,619 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:58,634 : INFO : built Dictionary(1025 unique tokens: ['residency', 'let', 'retreat', 'real', 'notice']...) from 5 documents (total 11210 corpus positions)\n",
      "2019-10-29 00:41:58,649 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:58,653 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:58,655 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:58,663 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:58,665 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:59,020 : INFO : -8.486 per-word bound, 358.6 perplexity estimate based on a held-out corpus of 5 documents with 11210 words\n",
      "2019-10-29 00:41:59,021 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:59,033 : INFO : topic #4 (0.100): 0.030*\"say\" + 0.027*\"city\" + 0.016*\"winston\" + 0.014*\"salem\" + 0.008*\"immigrant\" + 0.008*\"people\" + 0.008*\"council\" + 0.007*\"meeting\" + 0.006*\"welcoming\" + 0.006*\"fleming\"\n",
      "2019-10-29 00:41:59,035 : INFO : topic #5 (0.100): 0.022*\"say\" + 0.021*\"city\" + 0.012*\"winston\" + 0.008*\"fleming\" + 0.008*\"salem\" + 0.008*\"people\" + 0.007*\"one\" + 0.007*\"welcoming\" + 0.007*\"feel\" + 0.006*\"meeting\"\n",
      "2019-10-29 00:41:59,038 : INFO : topic #6 (0.100): 0.031*\"say\" + 0.018*\"city\" + 0.014*\"winston\" + 0.010*\"salem\" + 0.007*\"immigrant\" + 0.007*\"welcoming\" + 0.007*\"feel\" + 0.007*\"one\" + 0.007*\"resolution\" + 0.006*\"fleming\"\n",
      "2019-10-29 00:41:59,040 : INFO : topic #0 (0.100): 0.025*\"say\" + 0.025*\"city\" + 0.014*\"salem\" + 0.011*\"winston\" + 0.008*\"people\" + 0.008*\"fleming\" + 0.008*\"immigrant\" + 0.007*\"make\" + 0.007*\"welcoming\" + 0.007*\"feel\"\n",
      "2019-10-29 00:41:59,042 : INFO : topic #9 (0.100): 0.035*\"say\" + 0.024*\"city\" + 0.012*\"winston\" + 0.012*\"salem\" + 0.008*\"resolution\" + 0.008*\"fleming\" + 0.007*\"welcoming\" + 0.007*\"people\" + 0.007*\"feel\" + 0.006*\"immigrant\"\n",
      "2019-10-29 00:41:59,045 : INFO : topic diff=1.018488, rho=1.000000\n",
      "2019-10-29 00:41:59,592 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:41:59,608 : INFO : built Dictionary(939 unique tokens: ['hijacking', 'acceptable', 'wave', 'hayes', 'let']...) from 5 documents (total 13025 corpus positions)\n",
      "2019-10-29 00:41:59,618 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:41:59,620 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:41:59,622 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:41:59,627 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:41:59,632 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:41:59,916 : INFO : -8.174 per-word bound, 288.9 perplexity estimate based on a held-out corpus of 5 documents with 13025 words\n",
      "2019-10-29 00:41:59,917 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:41:59,930 : INFO : topic #2 (0.100): 0.036*\"hide\" + 0.034*\"obama\" + 0.031*\"photo\" + 0.030*\"caption\" + 0.027*\"sasha\" + 0.026*\"inauguration\" + 0.019*\"president\" + 0.017*\"since\" + 0.017*\"presidential\" + 0.014*\"present\"\n",
      "2019-10-29 00:41:59,933 : INFO : topic #0 (0.100): 0.031*\"obama\" + 0.029*\"caption\" + 0.028*\"photo\" + 0.026*\"inauguration\" + 0.025*\"hide\" + 0.021*\"president\" + 0.019*\"sasha\" + 0.018*\"presidential\" + 0.016*\"since\" + 0.016*\"malia\"\n",
      "2019-10-29 00:41:59,936 : INFO : topic #3 (0.100): 0.038*\"photo\" + 0.033*\"hide\" + 0.031*\"obama\" + 0.024*\"inauguration\" + 0.023*\"caption\" + 0.016*\"malia\" + 0.016*\"since\" + 0.015*\"michelle\" + 0.015*\"presidential\" + 0.015*\"president\"\n",
      "2019-10-29 00:41:59,939 : INFO : topic #1 (0.100): 0.040*\"photo\" + 0.032*\"hide\" + 0.028*\"caption\" + 0.025*\"obama\" + 0.024*\"inauguration\" + 0.022*\"malia\" + 0.020*\"presidential\" + 0.019*\"sasha\" + 0.018*\"since\" + 0.016*\"move\"\n",
      "2019-10-29 00:41:59,942 : INFO : topic #8 (0.100): 0.044*\"caption\" + 0.036*\"obama\" + 0.032*\"hide\" + 0.026*\"photo\" + 0.025*\"sasha\" + 0.022*\"inauguration\" + 0.017*\"malia\" + 0.016*\"since\" + 0.016*\"let\" + 0.016*\"presidential\"\n",
      "2019-10-29 00:41:59,946 : INFO : topic diff=1.207732, rho=1.000000\n",
      "2019-10-29 00:42:00,404 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:00,412 : INFO : built Dictionary(636 unique tokens: ['let', 'person', 'semiautomatic', 'refugee', 'earned']...) from 5 documents (total 5210 corpus positions)\n",
      "2019-10-29 00:42:00,419 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:00,421 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:00,423 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:00,427 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:00,430 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:00,617 : INFO : -8.368 per-word bound, 330.3 perplexity estimate based on a held-out corpus of 5 documents with 5210 words\n",
      "2019-10-29 00:42:00,619 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:00,628 : INFO : topic #1 (0.100): 0.050*\"gun\" + 0.015*\"say\" + 0.011*\"nra\" + 0.009*\"american\" + 0.008*\"people\" + 0.008*\"atlanta\" + 0.007*\"would\" + 0.007*\"many\" + 0.006*\"country\" + 0.006*\"tell\"\n",
      "2019-10-29 00:42:00,631 : INFO : topic #4 (0.100): 0.032*\"gun\" + 0.013*\"say\" + 0.009*\"nra\" + 0.007*\"people\" + 0.007*\"would\" + 0.007*\"tell\" + 0.007*\"first\" + 0.007*\"american\" + 0.006*\"convention\" + 0.006*\"many\"\n",
      "2019-10-29 00:42:00,634 : INFO : topic #0 (0.100): 0.036*\"gun\" + 0.015*\"say\" + 0.011*\"nra\" + 0.009*\"american\" + 0.008*\"people\" + 0.007*\"convention\" + 0.007*\"many\" + 0.007*\"want\" + 0.006*\"first\" + 0.006*\"atlanta\"\n",
      "2019-10-29 00:42:00,636 : INFO : topic #8 (0.100): 0.041*\"gun\" + 0.012*\"say\" + 0.012*\"nra\" + 0.008*\"american\" + 0.007*\"people\" + 0.007*\"atlanta\" + 0.007*\"convention\" + 0.006*\"right\" + 0.006*\"many\" + 0.006*\"tell\"\n",
      "2019-10-29 00:42:00,639 : INFO : topic #2 (0.100): 0.036*\"gun\" + 0.015*\"say\" + 0.011*\"nra\" + 0.008*\"many\" + 0.007*\"american\" + 0.007*\"would\" + 0.007*\"tell\" + 0.007*\"people\" + 0.006*\"country\" + 0.006*\"convention\"\n",
      "2019-10-29 00:42:00,642 : INFO : topic diff=0.865593, rho=1.000000\n",
      "2019-10-29 00:42:01,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:01,083 : INFO : built Dictionary(384 unique tokens: ['although', 'refugee', 'focus', 'regime', 'ally']...) from 5 documents (total 2710 corpus positions)\n",
      "2019-10-29 00:42:01,089 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:01,091 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:01,094 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:01,099 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:01,101 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:01,227 : INFO : -8.108 per-word bound, 275.9 perplexity estimate based on a held-out corpus of 5 documents with 2710 words\n",
      "2019-10-29 00:42:01,228 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:01,235 : INFO : topic #1 (0.100): 0.019*\"refugee\" + 0.017*\"crisis\" + 0.014*\"world\" + 0.014*\"syria\" + 0.013*\"conflict\" + 0.012*\"state\" + 0.012*\"people\" + 0.011*\"war\" + 0.011*\"zone\" + 0.011*\"safe\"\n",
      "2019-10-29 00:42:01,237 : INFO : topic #2 (0.100): 0.018*\"world\" + 0.015*\"refugee\" + 0.013*\"syria\" + 0.013*\"war\" + 0.012*\"country\" + 0.011*\"crisis\" + 0.011*\"united\" + 0.011*\"syrian\" + 0.011*\"safe\" + 0.011*\"conflict\"\n",
      "2019-10-29 00:42:01,238 : INFO : topic #4 (0.100): 0.016*\"refugee\" + 0.016*\"world\" + 0.015*\"syria\" + 0.014*\"country\" + 0.013*\"war\" + 0.013*\"state\" + 0.013*\"crisis\" + 0.011*\"syrian\" + 0.010*\"zone\" + 0.010*\"safe\"\n",
      "2019-10-29 00:42:01,241 : INFO : topic #8 (0.100): 0.018*\"refugee\" + 0.017*\"syria\" + 0.014*\"country\" + 0.014*\"crisis\" + 0.014*\"world\" + 0.011*\"state\" + 0.011*\"syrian\" + 0.011*\"zone\" + 0.010*\"war\" + 0.010*\"conflict\"\n",
      "2019-10-29 00:42:01,242 : INFO : topic #9 (0.100): 0.020*\"world\" + 0.014*\"syria\" + 0.014*\"crisis\" + 0.014*\"refugee\" + 0.012*\"syrian\" + 0.012*\"conflict\" + 0.011*\"war\" + 0.010*\"state\" + 0.010*\"country\" + 0.010*\"safe\"\n",
      "2019-10-29 00:42:01,245 : INFO : topic diff=0.802679, rho=1.000000\n",
      "2019-10-29 00:42:01,702 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:01,711 : INFO : built Dictionary(712 unique tokens: ['rage', 'drinking', 'sixty', 'recalled', 'self']...) from 5 documents (total 6175 corpus positions)\n",
      "2019-10-29 00:42:01,719 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:01,720 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:01,725 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:01,731 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:01,734 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:01,974 : INFO : -8.402 per-word bound, 338.2 perplexity estimate based on a held-out corpus of 5 documents with 6175 words\n",
      "2019-10-29 00:42:01,975 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:01,986 : INFO : topic #9 (0.100): 0.014*\"think\" + 0.013*\"clinton\" + 0.010*\"people\" + 0.009*\"time\" + 0.009*\"change\" + 0.008*\"thing\" + 0.008*\"year\" + 0.008*\"generation\" + 0.007*\"would\" + 0.007*\"world\"\n",
      "2019-10-29 00:42:01,987 : INFO : topic #5 (0.100): 0.014*\"clinton\" + 0.014*\"think\" + 0.011*\"people\" + 0.009*\"change\" + 0.008*\"thing\" + 0.008*\"world\" + 0.007*\"make\" + 0.007*\"war\" + 0.007*\"day\" + 0.006*\"year\"\n",
      "2019-10-29 00:42:01,990 : INFO : topic #3 (0.100): 0.016*\"think\" + 0.010*\"change\" + 0.009*\"people\" + 0.009*\"clinton\" + 0.008*\"thing\" + 0.007*\"important\" + 0.007*\"world\" + 0.007*\"much\" + 0.006*\"good\" + 0.006*\"able\"\n",
      "2019-10-29 00:42:01,993 : INFO : topic #8 (0.100): 0.016*\"think\" + 0.011*\"people\" + 0.009*\"make\" + 0.009*\"change\" + 0.007*\"world\" + 0.007*\"clinton\" + 0.007*\"important\" + 0.006*\"generation\" + 0.006*\"war\" + 0.006*\"year\"\n",
      "2019-10-29 00:42:01,995 : INFO : topic #0 (0.100): 0.015*\"think\" + 0.014*\"clinton\" + 0.008*\"people\" + 0.008*\"make\" + 0.008*\"change\" + 0.008*\"thing\" + 0.007*\"good\" + 0.007*\"world\" + 0.007*\"would\" + 0.006*\"generation\"\n",
      "2019-10-29 00:42:01,997 : INFO : topic diff=0.861882, rho=1.000000\n",
      "2019-10-29 00:42:02,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:02,467 : INFO : built Dictionary(302 unique tokens: ['energy', 'weinstein', '1990s', 'come', 'proud']...) from 5 documents (total 2510 corpus positions)\n",
      "2019-10-29 00:42:02,471 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:02,473 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:02,474 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:02,478 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:02,480 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:02,590 : INFO : -7.634 per-word bound, 198.7 perplexity estimate based on a held-out corpus of 5 documents with 2510 words\n",
      "2019-10-29 00:42:02,592 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:02,600 : INFO : topic #0 (0.100): 0.060*\"weinstein\" + 0.019*\"said\" + 0.018*\"told\" + 0.018*\"allegation\" + 0.016*\"new\" + 0.014*\"story\" + 0.012*\"advance\" + 0.011*\"rape\" + 0.011*\"actress\" + 0.010*\"company\"\n",
      "2019-10-29 00:42:02,603 : INFO : topic #1 (0.100): 0.070*\"weinstein\" + 0.019*\"allegation\" + 0.019*\"new\" + 0.015*\"told\" + 0.015*\"actress\" + 0.013*\"sexual\" + 0.013*\"said\" + 0.011*\"story\" + 0.010*\"harvey\" + 0.010*\"tuesday\"\n",
      "2019-10-29 00:42:02,606 : INFO : topic #9 (0.100): 0.062*\"weinstein\" + 0.019*\"new\" + 0.018*\"allegation\" + 0.017*\"said\" + 0.014*\"told\" + 0.013*\"mr\" + 0.012*\"company\" + 0.011*\"farrow\" + 0.011*\"sexual\" + 0.011*\"story\"\n",
      "2019-10-29 00:42:02,609 : INFO : topic #6 (0.100): 0.058*\"weinstein\" + 0.017*\"allegation\" + 0.017*\"story\" + 0.016*\"told\" + 0.014*\"new\" + 0.014*\"actress\" + 0.013*\"said\" + 0.013*\"sexual\" + 0.013*\"farrow\" + 0.012*\"rape\"\n",
      "2019-10-29 00:42:02,612 : INFO : topic #7 (0.100): 0.075*\"weinstein\" + 0.018*\"allegation\" + 0.017*\"told\" + 0.015*\"new\" + 0.013*\"mr\" + 0.013*\"company\" + 0.012*\"said\" + 0.012*\"harvey\" + 0.012*\"farrow\" + 0.012*\"story\"\n",
      "2019-10-29 00:42:02,614 : INFO : topic diff=0.881467, rho=1.000000\n",
      "2019-10-29 00:42:03,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:03,035 : INFO : built Dictionary(335 unique tokens: ['let', 'filed', 'end', 'attending', 'offered']...) from 5 documents (total 2655 corpus positions)\n",
      "2019-10-29 00:42:03,040 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:03,042 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:03,046 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:03,050 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:03,054 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:03,188 : INFO : -7.800 per-word bound, 222.8 perplexity estimate based on a held-out corpus of 5 documents with 2655 words\n",
      "2019-10-29 00:42:03,190 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:03,198 : INFO : topic #9 (0.100): 0.035*\"daca\" + 0.026*\"state\" + 0.014*\"country\" + 0.014*\"myth\" + 0.013*\"recipient\" + 0.012*\"dreamer\" + 0.011*\"united\" + 0.011*\"program\" + 0.008*\"tax\" + 0.008*\"student\"\n",
      "2019-10-29 00:42:03,199 : INFO : topic #2 (0.100): 0.041*\"daca\" + 0.024*\"state\" + 0.013*\"myth\" + 0.013*\"country\" + 0.012*\"dreamer\" + 0.010*\"recipient\" + 0.010*\"tax\" + 0.010*\"said\" + 0.009*\"student\" + 0.009*\"university\"\n",
      "2019-10-29 00:42:03,201 : INFO : topic #5 (0.100): 0.040*\"daca\" + 0.027*\"state\" + 0.017*\"country\" + 0.016*\"myth\" + 0.011*\"dreamer\" + 0.010*\"student\" + 0.010*\"recipient\" + 0.009*\"tax\" + 0.009*\"program\" + 0.009*\"united\"\n",
      "2019-10-29 00:42:03,203 : INFO : topic #1 (0.100): 0.031*\"state\" + 0.030*\"daca\" + 0.014*\"myth\" + 0.012*\"dreamer\" + 0.012*\"country\" + 0.012*\"program\" + 0.011*\"recipient\" + 0.011*\"student\" + 0.009*\"said\" + 0.009*\"pay\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:03,204 : INFO : topic #8 (0.100): 0.026*\"state\" + 0.022*\"daca\" + 0.014*\"myth\" + 0.014*\"country\" + 0.013*\"dreamer\" + 0.011*\"student\" + 0.011*\"program\" + 0.010*\"tax\" + 0.010*\"recipient\" + 0.009*\"said\"\n",
      "2019-10-29 00:42:03,206 : INFO : topic diff=0.854623, rho=1.000000\n",
      "2019-10-29 00:42:03,689 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:03,701 : INFO : built Dictionary(989 unique tokens: ['although', 'ulwaluko', 'archaeologist', 'golden', 'mounting']...) from 5 documents (total 8405 corpus positions)\n",
      "2019-10-29 00:42:03,711 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:03,714 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:03,719 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:03,727 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:03,730 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:04,047 : INFO : -8.751 per-word bound, 430.9 perplexity estimate based on a held-out corpus of 5 documents with 8405 words\n",
      "2019-10-29 00:42:04,049 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:04,065 : INFO : topic #4 (0.100): 0.011*\"woman\" + 0.009*\"hide\" + 0.009*\"men\" + 0.008*\"hadza\" + 0.007*\"caption\" + 0.007*\"photo\" + 0.006*\"tribe\" + 0.005*\"one\" + 0.005*\"year\" + 0.005*\"lewis\"\n",
      "2019-10-29 00:42:04,068 : INFO : topic #1 (0.100): 0.009*\"woman\" + 0.009*\"men\" + 0.008*\"caption\" + 0.007*\"one\" + 0.007*\"photo\" + 0.006*\"lewis\" + 0.006*\"hide\" + 0.005*\"day\" + 0.005*\"tribe\" + 0.005*\"say\"\n",
      "2019-10-29 00:42:04,070 : INFO : topic #9 (0.100): 0.010*\"woman\" + 0.009*\"men\" + 0.008*\"hadza\" + 0.007*\"caption\" + 0.006*\"lewis\" + 0.006*\"hide\" + 0.006*\"photo\" + 0.006*\"tribe\" + 0.005*\"one\" + 0.005*\"microbiome\"\n",
      "2019-10-29 00:42:04,073 : INFO : topic #5 (0.100): 0.011*\"woman\" + 0.010*\"hadza\" + 0.008*\"men\" + 0.007*\"photo\" + 0.006*\"one\" + 0.006*\"hide\" + 0.006*\"year\" + 0.006*\"tribe\" + 0.006*\"caption\" + 0.005*\"lewis\"\n",
      "2019-10-29 00:42:04,076 : INFO : topic #3 (0.100): 0.008*\"woman\" + 0.008*\"caption\" + 0.007*\"men\" + 0.007*\"photo\" + 0.006*\"hadza\" + 0.006*\"one\" + 0.005*\"hide\" + 0.005*\"lewis\" + 0.005*\"microbe\" + 0.005*\"africa\"\n",
      "2019-10-29 00:42:04,078 : INFO : topic diff=0.836267, rho=1.000000\n",
      "2019-10-29 00:42:04,510 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:04,512 : INFO : built Dictionary(75 unique tokens: ['abused', 'came', 'bail', 'filed', 'time']...) from 5 documents (total 515 corpus positions)\n",
      "2019-10-29 00:42:04,514 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:04,516 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:04,520 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:04,524 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:04,527 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:04,571 : INFO : -6.690 per-word bound, 103.3 perplexity estimate based on a held-out corpus of 5 documents with 515 words\n",
      "2019-10-29 00:42:04,574 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:04,583 : INFO : topic #6 (0.100): 0.038*\"nicol\" + 0.037*\"year\" + 0.028*\"county\" + 0.025*\"kennewick\" + 0.024*\"courtroom\" + 0.022*\"convicted\" + 0.022*\"sentence\" + 0.022*\"petra\" + 0.021*\"verdict\" + 0.021*\"california\"\n",
      "2019-10-29 00:42:04,586 : INFO : topic #2 (0.100): 0.070*\"nicol\" + 0.036*\"year\" + 0.032*\"county\" + 0.025*\"courtroom\" + 0.025*\"convicted\" + 0.024*\"california\" + 0.024*\"kennewick\" + 0.023*\"prison\" + 0.022*\"imperial\" + 0.021*\"count\"\n",
      "2019-10-29 00:42:04,594 : INFO : topic #9 (0.100): 0.058*\"nicol\" + 0.033*\"year\" + 0.030*\"kennewick\" + 0.025*\"courtroom\" + 0.023*\"degree\" + 0.023*\"oct\" + 0.023*\"county\" + 0.021*\"verdict\" + 0.021*\"bail\" + 0.020*\"child\"\n",
      "2019-10-29 00:42:04,601 : INFO : topic #5 (0.100): 0.057*\"nicol\" + 0.042*\"year\" + 0.034*\"kennewick\" + 0.029*\"courtroom\" + 0.023*\"county\" + 0.023*\"degree\" + 0.022*\"sentence\" + 0.020*\"imperial\" + 0.020*\"oct\" + 0.019*\"bail\"\n",
      "2019-10-29 00:42:04,604 : INFO : topic #7 (0.100): 0.054*\"nicol\" + 0.040*\"county\" + 0.028*\"year\" + 0.025*\"courtroom\" + 0.024*\"petra\" + 0.023*\"kennewick\" + 0.019*\"child\" + 0.019*\"convicted\" + 0.019*\"imperial\" + 0.019*\"california\"\n",
      "2019-10-29 00:42:04,607 : INFO : topic diff=0.741094, rho=1.000000\n",
      "2019-10-29 00:42:05,070 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:05,076 : INFO : built Dictionary(330 unique tokens: ['rookie', 'let', 'story', 'superb', 'sochi']...) from 5 documents (total 4550 corpus positions)\n",
      "2019-10-29 00:42:05,080 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:05,082 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:05,083 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:05,087 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:05,090 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:05,210 : INFO : -7.164 per-word bound, 143.4 perplexity estimate based on a held-out corpus of 5 documents with 4550 words\n",
      "2019-10-29 00:42:05,212 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:05,221 : INFO : topic #7 (0.100): 0.045*\"point\" + 0.043*\"hamilton\" + 0.043*\"vettel\" + 0.034*\"race\" + 0.034*\"bottas\" + 0.022*\"far\" + 0.022*\"season\" + 0.021*\"driver\" + 0.019*\"title\" + 0.018*\"story\"\n",
      "2019-10-29 00:42:05,224 : INFO : topic #6 (0.100): 0.067*\"point\" + 0.039*\"hamilton\" + 0.038*\"vettel\" + 0.027*\"race\" + 0.023*\"bottas\" + 0.020*\"photo\" + 0.019*\"caption\" + 0.019*\"season\" + 0.019*\"hide\" + 0.018*\"title\"\n",
      "2019-10-29 00:42:05,226 : INFO : topic #1 (0.100): 0.054*\"point\" + 0.046*\"vettel\" + 0.042*\"hamilton\" + 0.028*\"race\" + 0.024*\"season\" + 0.022*\"bottas\" + 0.020*\"title\" + 0.017*\"far\" + 0.016*\"round\" + 0.016*\"hide\"\n",
      "2019-10-29 00:42:05,229 : INFO : topic #2 (0.100): 0.047*\"point\" + 0.046*\"hamilton\" + 0.045*\"vettel\" + 0.035*\"bottas\" + 0.027*\"season\" + 0.025*\"race\" + 0.024*\"title\" + 0.017*\"round\" + 0.017*\"driver\" + 0.017*\"hide\"\n",
      "2019-10-29 00:42:05,232 : INFO : topic #0 (0.100): 0.065*\"point\" + 0.053*\"hamilton\" + 0.050*\"vettel\" + 0.021*\"race\" + 0.020*\"far\" + 0.020*\"bottas\" + 0.020*\"season\" + 0.018*\"photo\" + 0.018*\"title\" + 0.017*\"round\"\n",
      "2019-10-29 00:42:05,235 : INFO : topic diff=1.239244, rho=1.000000\n",
      "2019-10-29 00:42:05,643 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:05,648 : INFO : built Dictionary(373 unique tokens: ['offered', 'marched', 'u', 'new', 'building']...) from 5 documents (total 2745 corpus positions)\n",
      "2019-10-29 00:42:05,652 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:05,654 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:05,655 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:05,659 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:05,660 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:05,780 : INFO : -8.014 per-word bound, 258.5 perplexity estimate based on a held-out corpus of 5 documents with 2745 words\n",
      "2019-10-29 00:42:05,782 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:05,792 : INFO : topic #8 (0.100): 0.030*\"great\" + 0.029*\"portrait\" + 0.025*\"photo\" + 0.022*\"injustice\" + 0.022*\"caption\" + 0.019*\"hide\" + 0.013*\"u\" + 0.009*\"people\" + 0.007*\"remembrance\" + 0.007*\"camp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:05,795 : INFO : topic #9 (0.100): 0.031*\"injustice\" + 0.021*\"portrait\" + 0.020*\"caption\" + 0.020*\"great\" + 0.019*\"photo\" + 0.018*\"hide\" + 0.016*\"u\" + 0.009*\"remembrance\" + 0.008*\"day\" + 0.007*\"people\"\n",
      "2019-10-29 00:42:05,798 : INFO : topic #2 (0.100): 0.029*\"photo\" + 0.026*\"hide\" + 0.024*\"great\" + 0.023*\"portrait\" + 0.023*\"caption\" + 0.022*\"injustice\" + 0.016*\"u\" + 0.008*\"day\" + 0.008*\"camp\" + 0.008*\"life\"\n",
      "2019-10-29 00:42:05,802 : INFO : topic #0 (0.100): 0.032*\"injustice\" + 0.028*\"portrait\" + 0.027*\"photo\" + 0.027*\"great\" + 0.023*\"hide\" + 0.021*\"caption\" + 0.012*\"u\" + 0.012*\"day\" + 0.008*\"people\" + 0.007*\"would\"\n",
      "2019-10-29 00:42:05,805 : INFO : topic #4 (0.100): 0.029*\"caption\" + 0.027*\"great\" + 0.026*\"portrait\" + 0.023*\"injustice\" + 0.018*\"hide\" + 0.018*\"photo\" + 0.017*\"u\" + 0.009*\"day\" + 0.008*\"year\" + 0.008*\"would\"\n",
      "2019-10-29 00:42:05,808 : INFO : topic diff=0.839633, rho=1.000000\n",
      "2019-10-29 00:42:06,290 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:06,297 : INFO : built Dictionary(536 unique tokens: ['although', 'nature', 'real', 'lens', 'diagnostic']...) from 5 documents (total 4945 corpus positions)\n",
      "2019-10-29 00:42:06,304 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:06,305 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:06,307 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:06,311 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:06,313 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:06,474 : INFO : -8.049 per-word bound, 264.8 perplexity estimate based on a held-out corpus of 5 documents with 4945 words\n",
      "2019-10-29 00:42:06,476 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:06,485 : INFO : topic #6 (0.100): 0.052*\"sex\" + 0.039*\"addiction\" + 0.018*\"people\" + 0.014*\"addict\" + 0.014*\"behavior\" + 0.012*\"therapist\" + 0.011*\"sexual\" + 0.009*\"may\" + 0.008*\"problem\" + 0.008*\"issue\"\n",
      "2019-10-29 00:42:06,487 : INFO : topic #2 (0.100): 0.049*\"sex\" + 0.030*\"addiction\" + 0.017*\"people\" + 0.016*\"addict\" + 0.016*\"behavior\" + 0.014*\"therapist\" + 0.009*\"sexual\" + 0.009*\"drug\" + 0.009*\"porn\" + 0.009*\"many\"\n",
      "2019-10-29 00:42:06,490 : INFO : topic #7 (0.100): 0.049*\"sex\" + 0.036*\"addiction\" + 0.014*\"addict\" + 0.013*\"behavior\" + 0.013*\"therapist\" + 0.013*\"people\" + 0.012*\"sexual\" + 0.009*\"porn\" + 0.009*\"problem\" + 0.008*\"addictive\"\n",
      "2019-10-29 00:42:06,492 : INFO : topic #3 (0.100): 0.067*\"sex\" + 0.043*\"addiction\" + 0.015*\"behavior\" + 0.013*\"therapist\" + 0.013*\"addict\" + 0.013*\"people\" + 0.011*\"sexual\" + 0.010*\"problem\" + 0.008*\"porn\" + 0.008*\"brain\"\n",
      "2019-10-29 00:42:06,494 : INFO : topic #0 (0.100): 0.041*\"sex\" + 0.025*\"addiction\" + 0.014*\"people\" + 0.014*\"addict\" + 0.012*\"therapist\" + 0.011*\"behavior\" + 0.010*\"sexual\" + 0.010*\"one\" + 0.009*\"feel\" + 0.009*\"may\"\n",
      "2019-10-29 00:42:06,497 : INFO : topic diff=0.935746, rho=1.000000\n",
      "2019-10-29 00:42:06,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:06,923 : INFO : built Dictionary(322 unique tokens: ['previously', 'let', 'filed', '1990s', 'tube']...) from 5 documents (total 2745 corpus positions)\n",
      "2019-10-29 00:42:06,928 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:06,929 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:06,929 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:06,932 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:06,934 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:07,053 : INFO : -7.659 per-word bound, 202.2 perplexity estimate based on a held-out corpus of 5 documents with 2745 words\n",
      "2019-10-29 00:42:07,055 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:07,063 : INFO : topic #7 (0.100): 0.025*\"polst\" + 0.022*\"form\" + 0.019*\"said\" + 0.017*\"patient\" + 0.017*\"health\" + 0.017*\"care\" + 0.016*\"life\" + 0.015*\"access\" + 0.014*\"oregon\" + 0.013*\"state\"\n",
      "2019-10-29 00:42:07,066 : INFO : topic #9 (0.100): 0.024*\"said\" + 0.022*\"polst\" + 0.021*\"form\" + 0.016*\"care\" + 0.015*\"health\" + 0.015*\"oregon\" + 0.013*\"medical\" + 0.012*\"access\" + 0.012*\"state\" + 0.012*\"patient\"\n",
      "2019-10-29 00:42:07,069 : INFO : topic #5 (0.100): 0.027*\"polst\" + 0.026*\"form\" + 0.020*\"health\" + 0.020*\"care\" + 0.018*\"said\" + 0.015*\"life\" + 0.014*\"state\" + 0.013*\"patient\" + 0.012*\"hospital\" + 0.011*\"oregon\"\n",
      "2019-10-29 00:42:07,072 : INFO : topic #4 (0.100): 0.031*\"form\" + 0.021*\"polst\" + 0.018*\"care\" + 0.017*\"said\" + 0.016*\"health\" + 0.016*\"state\" + 0.016*\"patient\" + 0.013*\"oregon\" + 0.013*\"life\" + 0.012*\"medical\"\n",
      "2019-10-29 00:42:07,075 : INFO : topic #3 (0.100): 0.029*\"polst\" + 0.026*\"form\" + 0.021*\"health\" + 0.019*\"care\" + 0.018*\"said\" + 0.018*\"life\" + 0.015*\"oregon\" + 0.014*\"patient\" + 0.013*\"ohsu\" + 0.012*\"medical\"\n",
      "2019-10-29 00:42:07,079 : INFO : topic diff=0.890119, rho=1.000000\n",
      "2019-10-29 00:42:07,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:07,536 : INFO : built Dictionary(384 unique tokens: ['although', 'real', 'francisco', 'coleman', 'brittany']...) from 5 documents (total 3190 corpus positions)\n",
      "2019-10-29 00:42:07,540 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:07,541 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:07,542 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:07,547 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:07,549 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:07,682 : INFO : -7.865 per-word bound, 233.2 perplexity estimate based on a held-out corpus of 5 documents with 3190 words\n",
      "2019-10-29 00:42:07,683 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:07,692 : INFO : topic #2 (0.100): 0.026*\"helton\" + 0.020*\"coleman\" + 0.017*\"drug\" + 0.016*\"naloxone\" + 0.016*\"people\" + 0.016*\"life\" + 0.011*\"said\" + 0.009*\"year\" + 0.009*\"three\" + 0.009*\"get\"\n",
      "2019-10-29 00:42:07,693 : INFO : topic #4 (0.100): 0.019*\"people\" + 0.017*\"coleman\" + 0.016*\"helton\" + 0.015*\"life\" + 0.014*\"naloxone\" + 0.014*\"drug\" + 0.013*\"said\" + 0.011*\"year\" + 0.010*\"told\" + 0.010*\"addiction\"\n",
      "2019-10-29 00:42:07,695 : INFO : topic #3 (0.100): 0.024*\"coleman\" + 0.020*\"helton\" + 0.018*\"life\" + 0.015*\"people\" + 0.013*\"said\" + 0.012*\"naloxone\" + 0.012*\"drug\" + 0.012*\"heroin\" + 0.011*\"year\" + 0.010*\"dos\"\n",
      "2019-10-29 00:42:07,696 : INFO : topic #6 (0.100): 0.026*\"coleman\" + 0.026*\"helton\" + 0.016*\"drug\" + 0.016*\"naloxone\" + 0.012*\"life\" + 0.012*\"people\" + 0.011*\"dos\" + 0.011*\"said\" + 0.010*\"year\" + 0.009*\"get\"\n",
      "2019-10-29 00:42:07,698 : INFO : topic #9 (0.100): 0.023*\"coleman\" + 0.022*\"naloxone\" + 0.021*\"helton\" + 0.019*\"life\" + 0.015*\"people\" + 0.013*\"drug\" + 0.011*\"said\" + 0.010*\"addiction\" + 0.009*\"told\" + 0.009*\"year\"\n",
      "2019-10-29 00:42:07,700 : INFO : topic diff=0.867232, rho=1.000000\n",
      "2019-10-29 00:42:08,121 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:08,123 : INFO : built Dictionary(153 unique tokens: ['october', 'previously', 'completely', 'bone', 'want']...) from 5 documents (total 1205 corpus positions)\n",
      "2019-10-29 00:42:08,126 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:08,127 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:08,128 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:08,133 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:08,137 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:08,197 : INFO : -7.078 per-word bound, 135.1 perplexity estimate based on a held-out corpus of 5 documents with 1205 words\n",
      "2019-10-29 00:42:08,199 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:08,208 : INFO : topic #8 (0.100): 0.036*\"eye\" + 0.028*\"ball\" + 0.027*\"foul\" + 0.023*\"loo\" + 0.020*\"cub\" + 0.018*\"said\" + 0.018*\"hit\" + 0.016*\"netting\" + 0.015*\"face\" + 0.015*\"every\"\n",
      "2019-10-29 00:42:08,210 : INFO : topic #2 (0.100): 0.030*\"ball\" + 0.028*\"cub\" + 0.027*\"foul\" + 0.024*\"eye\" + 0.022*\"loo\" + 0.019*\"face\" + 0.018*\"said\" + 0.018*\"netting\" + 0.018*\"hit\" + 0.016*\"girl\"\n",
      "2019-10-29 00:42:08,212 : INFO : topic #6 (0.100): 0.035*\"loo\" + 0.032*\"foul\" + 0.026*\"ball\" + 0.023*\"said\" + 0.021*\"eye\" + 0.020*\"hit\" + 0.019*\"cub\" + 0.019*\"netting\" + 0.018*\"fan\" + 0.014*\"face\"\n",
      "2019-10-29 00:42:08,215 : INFO : topic #7 (0.100): 0.031*\"loo\" + 0.027*\"foul\" + 0.023*\"ball\" + 0.023*\"eye\" + 0.021*\"said\" + 0.021*\"cub\" + 0.018*\"fan\" + 0.016*\"netting\" + 0.015*\"hit\" + 0.014*\"face\"\n",
      "2019-10-29 00:42:08,218 : INFO : topic #9 (0.100): 0.030*\"ball\" + 0.028*\"eye\" + 0.027*\"foul\" + 0.024*\"loo\" + 0.024*\"cub\" + 0.019*\"hit\" + 0.017*\"said\" + 0.017*\"fan\" + 0.015*\"netting\" + 0.013*\"mlb\"\n",
      "2019-10-29 00:42:08,221 : INFO : topic diff=0.815920, rho=1.000000\n",
      "2019-10-29 00:42:08,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:08,616 : INFO : built Dictionary(16 unique tokens: ['agreeing', 'could', 'changed', 'privacy', 'policy']...) from 5 documents (total 100 corpus positions)\n",
      "2019-10-29 00:42:08,617 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:08,618 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:08,620 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:08,621 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:08,624 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:08,638 : INFO : -5.881 per-word bound, 58.9 perplexity estimate based on a held-out corpus of 5 documents with 100 words\n",
      "2019-10-29 00:42:08,639 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:08,643 : INFO : topic #8 (0.100): 0.120*\"policy\" + 0.105*\"privacy\" + 0.098*\"service\" + 0.090*\"term\" + 0.061*\"agreeing\" + 0.056*\"new\" + 0.056*\"tax\" + 0.053*\"changed\" + 0.052*\"chopping\" + 0.049*\"continuing\"\n",
      "2019-10-29 00:42:08,645 : INFO : topic #4 (0.100): 0.115*\"policy\" + 0.105*\"term\" + 0.090*\"privacy\" + 0.079*\"service\" + 0.061*\"tax\" + 0.060*\"use\" + 0.054*\"changed\" + 0.053*\"chopping\" + 0.051*\"block\" + 0.051*\"new\"\n",
      "2019-10-29 00:42:08,647 : INFO : topic #3 (0.100): 0.099*\"service\" + 0.094*\"term\" + 0.093*\"policy\" + 0.091*\"privacy\" + 0.068*\"site\" + 0.059*\"use\" + 0.059*\"continuing\" + 0.056*\"could\" + 0.055*\"new\" + 0.054*\"break\"\n",
      "2019-10-29 00:42:08,648 : INFO : topic #0 (0.100): 0.101*\"service\" + 0.098*\"term\" + 0.093*\"privacy\" + 0.073*\"policy\" + 0.071*\"chopping\" + 0.069*\"block\" + 0.063*\"tax\" + 0.056*\"popular\" + 0.054*\"use\" + 0.051*\"continuing\"\n",
      "2019-10-29 00:42:08,649 : INFO : topic #7 (0.100): 0.101*\"privacy\" + 0.093*\"term\" + 0.083*\"policy\" + 0.082*\"service\" + 0.067*\"could\" + 0.061*\"tax\" + 0.056*\"break\" + 0.055*\"chopping\" + 0.055*\"block\" + 0.054*\"changed\"\n",
      "2019-10-29 00:42:08,651 : INFO : topic diff=0.623038, rho=1.000000\n",
      "2019-10-29 00:42:09,059 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:09,062 : INFO : built Dictionary(153 unique tokens: ['forward', 'previously', 'story', 'completely', 'honorary']...) from 5 documents (total 1120 corpus positions)\n",
      "2019-10-29 00:42:09,065 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:09,066 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:09,070 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:09,075 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:09,078 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:09,154 : INFO : -7.194 per-word bound, 146.4 perplexity estimate based on a held-out corpus of 5 documents with 1120 words\n",
      "2019-10-29 00:42:09,156 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:09,163 : INFO : topic #9 (0.100): 0.054*\"weinstein\" + 0.030*\"bafta\" + 0.023*\"british\" + 0.022*\"woman\" + 0.019*\"membership\" + 0.018*\"said\" + 0.015*\"hollywood\" + 0.014*\"academy\" + 0.013*\"art\" + 0.012*\"film\"\n",
      "2019-10-29 00:42:09,166 : INFO : topic #6 (0.100): 0.045*\"weinstein\" + 0.031*\"bafta\" + 0.020*\"woman\" + 0.020*\"membership\" + 0.018*\"british\" + 0.017*\"academy\" + 0.015*\"allegation\" + 0.015*\"said\" + 0.014*\"industry\" + 0.014*\"behavior\"\n",
      "2019-10-29 00:42:09,169 : INFO : topic #5 (0.100): 0.061*\"weinstein\" + 0.023*\"bafta\" + 0.022*\"academy\" + 0.021*\"british\" + 0.017*\"sexual\" + 0.016*\"said\" + 0.015*\"woman\" + 0.014*\"industry\" + 0.014*\"membership\" + 0.014*\"allegation\"\n",
      "2019-10-29 00:42:09,171 : INFO : topic #0 (0.100): 0.061*\"weinstein\" + 0.021*\"bafta\" + 0.021*\"british\" + 0.019*\"academy\" + 0.019*\"woman\" + 0.018*\"said\" + 0.017*\"membership\" + 0.015*\"sexual\" + 0.014*\"art\" + 0.014*\"harvey\"\n",
      "2019-10-29 00:42:09,176 : INFO : topic #3 (0.100): 0.044*\"weinstein\" + 0.024*\"bafta\" + 0.022*\"woman\" + 0.019*\"said\" + 0.017*\"allegation\" + 0.016*\"academy\" + 0.016*\"british\" + 0.015*\"hollywood\" + 0.014*\"art\" + 0.014*\"behavior\"\n",
      "2019-10-29 00:42:09,179 : INFO : topic diff=0.821133, rho=1.000000\n",
      "2019-10-29 00:42:09,614 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:09,617 : INFO : built Dictionary(90 unique tokens: ['creating', 'catholic', 'book', 'way', 'focus']...) from 5 documents (total 645 corpus positions)\n",
      "2019-10-29 00:42:09,622 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:09,625 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:09,628 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:09,631 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:09,633 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:09,682 : INFO : -6.770 per-word bound, 109.1 perplexity estimate based on a held-out corpus of 5 documents with 645 words\n",
      "2019-10-29 00:42:09,686 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:09,695 : INFO : topic #2 (0.100): 0.047*\"read\" + 0.036*\"word\" + 0.032*\"week\" + 0.027*\"hope\" + 0.025*\"book\" + 0.022*\"bernardini\" + 0.022*\"joy\" + 0.021*\"change\" + 0.020*\"one\" + 0.018*\"life\"\n",
      "2019-10-29 00:42:09,697 : INFO : topic #7 (0.100): 0.041*\"word\" + 0.035*\"read\" + 0.035*\"week\" + 0.031*\"hope\" + 0.026*\"joy\" + 0.023*\"would\" + 0.022*\"change\" + 0.020*\"year\" + 0.018*\"needed\" + 0.018*\"life\"\n",
      "2019-10-29 00:42:09,700 : INFO : topic #5 (0.100): 0.042*\"read\" + 0.035*\"word\" + 0.035*\"week\" + 0.033*\"hope\" + 0.027*\"bernardini\" + 0.026*\"would\" + 0.025*\"life\" + 0.024*\"book\" + 0.021*\"change\" + 0.019*\"needed\"\n",
      "2019-10-29 00:42:09,703 : INFO : topic #6 (0.100): 0.037*\"word\" + 0.031*\"week\" + 0.030*\"read\" + 0.028*\"hope\" + 0.027*\"change\" + 0.027*\"would\" + 0.022*\"bernardini\" + 0.021*\"life\" + 0.021*\"needed\" + 0.021*\"joy\"\n",
      "2019-10-29 00:42:09,709 : INFO : topic #4 (0.100): 0.038*\"week\" + 0.036*\"read\" + 0.033*\"word\" + 0.033*\"hope\" + 0.027*\"joy\" + 0.025*\"would\" + 0.022*\"needed\" + 0.022*\"change\" + 0.020*\"bernardini\" + 0.019*\"life\"\n",
      "2019-10-29 00:42:09,711 : INFO : topic diff=0.818436, rho=1.000000\n",
      "2019-10-29 00:42:10,164 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:10,169 : INFO : built Dictionary(405 unique tokens: ['let', 'stadium', 'hero', 'francisco', 'dad']...) from 5 documents (total 3245 corpus positions)\n",
      "2019-10-29 00:42:10,174 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:10,174 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:10,176 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:10,179 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:10,181 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:10,358 : INFO : -7.965 per-word bound, 249.9 perplexity estimate based on a held-out corpus of 5 documents with 3245 words\n",
      "2019-10-29 00:42:10,360 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:10,371 : INFO : topic #9 (0.100): 0.017*\"game\" + 0.015*\"bill\" + 0.013*\"nfl\" + 0.011*\"buffalo\" + 0.010*\"even\" + 0.010*\"player\" + 0.009*\"made\" + 0.008*\"home\" + 0.008*\"kemp\" + 0.008*\"feel\"\n",
      "2019-10-29 00:42:10,374 : INFO : topic #5 (0.100): 0.020*\"game\" + 0.015*\"bill\" + 0.012*\"player\" + 0.012*\"nfl\" + 0.010*\"made\" + 0.009*\"home\" + 0.008*\"buffalo\" + 0.008*\"feel\" + 0.007*\"knee\" + 0.007*\"meyers\"\n",
      "2019-10-29 00:42:10,377 : INFO : topic #1 (0.100): 0.020*\"bill\" + 0.017*\"game\" + 0.014*\"nfl\" + 0.011*\"player\" + 0.011*\"home\" + 0.010*\"even\" + 0.010*\"made\" + 0.009*\"buffalo\" + 0.007*\"get\" + 0.007*\"always\"\n",
      "2019-10-29 00:42:10,381 : INFO : topic #6 (0.100): 0.023*\"bill\" + 0.017*\"game\" + 0.012*\"nfl\" + 0.012*\"player\" + 0.009*\"buffalo\" + 0.009*\"home\" + 0.009*\"combat\" + 0.009*\"kemp\" + 0.008*\"boy\" + 0.008*\"always\"\n",
      "2019-10-29 00:42:10,389 : INFO : topic #0 (0.100): 0.022*\"game\" + 0.013*\"nfl\" + 0.013*\"bill\" + 0.012*\"home\" + 0.012*\"buffalo\" + 0.009*\"even\" + 0.009*\"veteran\" + 0.009*\"kemp\" + 0.008*\"player\" + 0.008*\"anthem\"\n",
      "2019-10-29 00:42:10,392 : INFO : topic diff=0.875068, rho=1.000000\n",
      "2019-10-29 00:42:10,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:10,907 : INFO : built Dictionary(436 unique tokens: ['party', 'hong', 'remained', 'language', 'one']...) from 5 documents (total 3485 corpus positions)\n",
      "2019-10-29 00:42:10,913 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:10,914 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:10,915 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:10,920 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:10,923 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:11,057 : INFO : -8.045 per-word bound, 264.1 perplexity estimate based on a held-out corpus of 5 documents with 3485 words\n",
      "2019-10-29 00:42:11,059 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:11,066 : INFO : topic #1 (0.100): 0.050*\"art\" + 0.023*\"collector\" + 0.015*\"huang\" + 0.014*\"said\" + 0.014*\"chinese\" + 0.012*\"china\" + 0.012*\"auction\" + 0.010*\"like\" + 0.009*\"artist\" + 0.009*\"kong\"\n",
      "2019-10-29 00:42:11,068 : INFO : topic #6 (0.100): 0.041*\"art\" + 0.025*\"collector\" + 0.018*\"china\" + 0.014*\"auction\" + 0.013*\"huang\" + 0.012*\"said\" + 0.012*\"chinese\" + 0.010*\"artist\" + 0.008*\"kong\" + 0.008*\"year\"\n",
      "2019-10-29 00:42:11,071 : INFO : topic #4 (0.100): 0.025*\"collector\" + 0.025*\"art\" + 0.017*\"huang\" + 0.015*\"auction\" + 0.012*\"china\" + 0.012*\"chinese\" + 0.011*\"artist\" + 0.011*\"said\" + 0.009*\"fair\" + 0.008*\"like\"\n",
      "2019-10-29 00:42:11,074 : INFO : topic #3 (0.100): 0.046*\"art\" + 0.021*\"china\" + 0.020*\"collector\" + 0.013*\"auction\" + 0.012*\"said\" + 0.012*\"chinese\" + 0.011*\"huang\" + 0.010*\"artist\" + 0.008*\"hong\" + 0.008*\"contemporary\"\n",
      "2019-10-29 00:42:11,077 : INFO : topic #2 (0.100): 0.039*\"art\" + 0.022*\"collector\" + 0.020*\"chinese\" + 0.014*\"huang\" + 0.012*\"china\" + 0.010*\"year\" + 0.010*\"artist\" + 0.008*\"auction\" + 0.008*\"like\" + 0.008*\"cheng\"\n",
      "2019-10-29 00:42:11,079 : INFO : topic diff=0.890255, rho=1.000000\n",
      "2019-10-29 00:42:11,481 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:11,484 : INFO : built Dictionary(75 unique tokens: ['previously', 'care', 'single', 'take', 'come']...) from 5 documents (total 505 corpus positions)\n",
      "2019-10-29 00:42:11,486 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:11,488 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:11,491 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:11,494 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:11,496 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:11,527 : INFO : -6.730 per-word bound, 106.2 perplexity estimate based on a held-out corpus of 5 documents with 505 words\n",
      "2019-10-29 00:42:11,529 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:11,538 : INFO : topic #7 (0.100): 0.069*\"insurance\" + 0.027*\"keep\" + 0.027*\"medicaid\" + 0.026*\"toribio\" + 0.022*\"pregnant\" + 0.021*\"said\" + 0.020*\"change\" + 0.019*\"expansion\" + 0.019*\"million\" + 0.019*\"would\"\n",
      "2019-10-29 00:42:11,540 : INFO : topic #1 (0.100): 0.061*\"insurance\" + 0.035*\"keep\" + 0.028*\"medicaid\" + 0.027*\"said\" + 0.022*\"pregnant\" + 0.021*\"thousand\" + 0.020*\"thanks\" + 0.020*\"debate\" + 0.020*\"home\" + 0.019*\"expansion\"\n",
      "2019-10-29 00:42:11,542 : INFO : topic #6 (0.100): 0.062*\"insurance\" + 0.034*\"medicaid\" + 0.030*\"keep\" + 0.025*\"kentuckian\" + 0.025*\"said\" + 0.025*\"debate\" + 0.023*\"would\" + 0.022*\"million\" + 0.021*\"thanks\" + 0.020*\"pregnant\"\n",
      "2019-10-29 00:42:11,546 : INFO : topic #2 (0.100): 0.064*\"insurance\" + 0.029*\"said\" + 0.028*\"medicaid\" + 0.024*\"expansion\" + 0.024*\"keep\" + 0.023*\"son\" + 0.023*\"change\" + 0.023*\"kentuckian\" + 0.022*\"home\" + 0.022*\"debate\"\n",
      "2019-10-29 00:42:11,549 : INFO : topic #4 (0.100): 0.059*\"insurance\" + 0.029*\"said\" + 0.028*\"keep\" + 0.027*\"medicaid\" + 0.027*\"thanks\" + 0.022*\"thousand\" + 0.022*\"health\" + 0.021*\"million\" + 0.020*\"son\" + 0.020*\"pregnant\"\n",
      "2019-10-29 00:42:11,552 : INFO : topic diff=0.726135, rho=1.000000\n",
      "2019-10-29 00:42:12,043 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:12,049 : INFO : built Dictionary(406 unique tokens: ['although', 'size', 'drinking', 'burly', 'perhaps']...) from 5 documents (total 3245 corpus positions)\n",
      "2019-10-29 00:42:12,054 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:12,056 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:12,061 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:12,066 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:12,069 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:12,252 : INFO : -7.973 per-word bound, 251.2 perplexity estimate based on a held-out corpus of 5 documents with 3245 words\n",
      "2019-10-29 00:42:12,254 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:12,264 : INFO : topic #5 (0.100): 0.034*\"celebrity\" + 0.033*\"transformation\" + 0.031*\"caption\" + 0.029*\"hide\" + 0.026*\"photo\" + 0.013*\"lost\" + 0.012*\"weight\" + 0.012*\"pound\" + 0.011*\"left\" + 0.008*\"star\"\n",
      "2019-10-29 00:42:12,266 : INFO : topic #4 (0.100): 0.039*\"photo\" + 0.034*\"transformation\" + 0.033*\"caption\" + 0.031*\"celebrity\" + 0.031*\"hide\" + 0.011*\"weight\" + 0.011*\"lost\" + 0.011*\"star\" + 0.010*\"said\" + 0.010*\"left\"\n",
      "2019-10-29 00:42:12,269 : INFO : topic #0 (0.100): 0.041*\"photo\" + 0.033*\"celebrity\" + 0.032*\"transformation\" + 0.029*\"caption\" + 0.029*\"hide\" + 0.014*\"weight\" + 0.013*\"pound\" + 0.010*\"lost\" + 0.009*\"said\" + 0.008*\"star\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:12,272 : INFO : topic #9 (0.100): 0.035*\"transformation\" + 0.031*\"photo\" + 0.031*\"celebrity\" + 0.030*\"hide\" + 0.027*\"caption\" + 0.013*\"pound\" + 0.012*\"lost\" + 0.009*\"weight\" + 0.009*\"left\" + 0.008*\"said\"\n",
      "2019-10-29 00:42:12,274 : INFO : topic #6 (0.100): 0.037*\"transformation\" + 0.035*\"hide\" + 0.030*\"caption\" + 0.030*\"celebrity\" + 0.029*\"photo\" + 0.013*\"weight\" + 0.012*\"pound\" + 0.009*\"left\" + 0.009*\"said\" + 0.009*\"star\"\n",
      "2019-10-29 00:42:12,277 : INFO : topic diff=0.900272, rho=1.000000\n",
      "2019-10-29 00:42:12,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:12,797 : INFO : built Dictionary(522 unique tokens: ['let', 'assignment', 'size', 'focus', 'asked']...) from 5 documents (total 5520 corpus positions)\n",
      "2019-10-29 00:42:12,807 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:12,810 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:12,813 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:12,817 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:12,821 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:13,034 : INFO : -7.864 per-word bound, 233.0 perplexity estimate based on a held-out corpus of 5 documents with 5520 words\n",
      "2019-10-29 00:42:13,037 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:13,048 : INFO : topic #4 (0.100): 0.021*\"work\" + 0.019*\"woman\" + 0.017*\"said\" + 0.016*\"back\" + 0.014*\"brody\" + 0.013*\"trimester\" + 0.012*\"going\" + 0.011*\"time\" + 0.010*\"new\" + 0.010*\"month\"\n",
      "2019-10-29 00:42:13,050 : INFO : topic #5 (0.100): 0.024*\"work\" + 0.019*\"woman\" + 0.016*\"trimester\" + 0.013*\"back\" + 0.013*\"month\" + 0.012*\"new\" + 0.011*\"brody\" + 0.011*\"said\" + 0.010*\"fifth\" + 0.009*\"time\"\n",
      "2019-10-29 00:42:13,053 : INFO : topic #8 (0.100): 0.023*\"woman\" + 0.022*\"work\" + 0.016*\"back\" + 0.014*\"brody\" + 0.013*\"month\" + 0.013*\"new\" + 0.012*\"said\" + 0.011*\"trimester\" + 0.011*\"going\" + 0.009*\"first\"\n",
      "2019-10-29 00:42:13,057 : INFO : topic #2 (0.100): 0.026*\"work\" + 0.021*\"woman\" + 0.014*\"brody\" + 0.014*\"back\" + 0.012*\"month\" + 0.012*\"trimester\" + 0.011*\"said\" + 0.010*\"time\" + 0.009*\"fifth\" + 0.008*\"first\"\n",
      "2019-10-29 00:42:13,059 : INFO : topic #9 (0.100): 0.024*\"woman\" + 0.022*\"work\" + 0.018*\"brody\" + 0.018*\"back\" + 0.016*\"said\" + 0.014*\"month\" + 0.013*\"new\" + 0.011*\"time\" + 0.010*\"really\" + 0.009*\"trimester\"\n",
      "2019-10-29 00:42:13,062 : INFO : topic diff=0.973237, rho=1.000000\n",
      "2019-10-29 00:42:13,574 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:13,583 : INFO : built Dictionary(375 unique tokens: ['specie', 'across', 'laboratory', 'located', 'extinction']...) from 5 documents (total 3350 corpus positions)\n",
      "2019-10-29 00:42:13,591 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:13,593 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:13,597 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:13,601 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:13,604 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:13,757 : INFO : -7.746 per-word bound, 214.7 perplexity estimate based on a held-out corpus of 5 documents with 3350 words\n",
      "2019-10-29 00:42:13,759 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:13,769 : INFO : topic #8 (0.100): 0.068*\"turtle\" + 0.029*\"sea\" + 0.027*\"hainan\" + 0.015*\"said\" + 0.013*\"yeh\" + 0.012*\"conservation\" + 0.012*\"china\" + 0.010*\"tourist\" + 0.010*\"island\" + 0.008*\"university\"\n",
      "2019-10-29 00:42:13,771 : INFO : topic #9 (0.100): 0.053*\"turtle\" + 0.037*\"sea\" + 0.022*\"hainan\" + 0.016*\"yeh\" + 0.016*\"said\" + 0.013*\"tourist\" + 0.012*\"conservation\" + 0.011*\"island\" + 0.011*\"university\" + 0.010*\"china\"\n",
      "2019-10-29 00:42:13,775 : INFO : topic #6 (0.100): 0.059*\"turtle\" + 0.032*\"sea\" + 0.020*\"hainan\" + 0.016*\"said\" + 0.016*\"conservation\" + 0.013*\"china\" + 0.012*\"yeh\" + 0.011*\"tourist\" + 0.011*\"university\" + 0.010*\"shi\"\n",
      "2019-10-29 00:42:13,778 : INFO : topic #0 (0.100): 0.064*\"turtle\" + 0.040*\"sea\" + 0.023*\"hainan\" + 0.018*\"yeh\" + 0.017*\"said\" + 0.015*\"china\" + 0.014*\"conservation\" + 0.012*\"tourist\" + 0.009*\"university\" + 0.009*\"hospital\"\n",
      "2019-10-29 00:42:13,781 : INFO : topic #5 (0.100): 0.048*\"turtle\" + 0.034*\"sea\" + 0.018*\"hainan\" + 0.017*\"said\" + 0.015*\"conservation\" + 0.012*\"tourist\" + 0.011*\"yeh\" + 0.011*\"china\" + 0.010*\"shi\" + 0.010*\"beach\"\n",
      "2019-10-29 00:42:13,784 : INFO : topic diff=0.931038, rho=1.000000\n",
      "2019-10-29 00:42:14,313 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:14,320 : INFO : built Dictionary(463 unique tokens: ['anniversary', 'located', 'catholic', 'diaz', 'median']...) from 5 documents (total 5825 corpus positions)\n",
      "2019-10-29 00:42:14,325 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:14,327 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:14,329 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:14,333 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:14,335 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:14,533 : INFO : -7.573 per-word bound, 190.4 perplexity estimate based on a held-out corpus of 5 documents with 5825 words\n",
      "2019-10-29 00:42:14,536 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:14,547 : INFO : topic #0 (0.100): 0.022*\"venezuela\" + 0.015*\"venezuelan\" + 0.014*\"chavez\" + 0.014*\"maduro\" + 0.011*\"national\" + 0.011*\"opposition\" + 0.011*\"assembly\" + 0.011*\"say\" + 0.009*\"constitution\" + 0.008*\"power\"\n",
      "2019-10-29 00:42:14,550 : INFO : topic #1 (0.100): 0.019*\"venezuela\" + 0.018*\"maduro\" + 0.015*\"chavez\" + 0.014*\"venezuelan\" + 0.012*\"vote\" + 0.011*\"president\" + 0.010*\"assembly\" + 0.010*\"opposition\" + 0.010*\"power\" + 0.009*\"say\"\n",
      "2019-10-29 00:42:14,553 : INFO : topic #3 (0.100): 0.023*\"venezuela\" + 0.016*\"chavez\" + 0.014*\"maduro\" + 0.013*\"venezuelan\" + 0.011*\"opposition\" + 0.011*\"assembly\" + 0.010*\"national\" + 0.010*\"say\" + 0.010*\"vote\" + 0.010*\"president\"\n",
      "2019-10-29 00:42:14,555 : INFO : topic #9 (0.100): 0.018*\"venezuela\" + 0.017*\"chavez\" + 0.014*\"maduro\" + 0.014*\"power\" + 0.013*\"venezuelan\" + 0.012*\"assembly\" + 0.012*\"opposition\" + 0.012*\"government\" + 0.010*\"president\" + 0.010*\"say\"\n",
      "2019-10-29 00:42:14,558 : INFO : topic #5 (0.100): 0.022*\"venezuela\" + 0.014*\"assembly\" + 0.013*\"maduro\" + 0.013*\"chavez\" + 0.012*\"venezuelan\" + 0.011*\"opposition\" + 0.011*\"power\" + 0.010*\"country\" + 0.010*\"national\" + 0.009*\"say\"\n",
      "2019-10-29 00:42:14,560 : INFO : topic diff=0.816482, rho=1.000000\n",
      "2019-10-29 00:42:14,985 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:14,988 : INFO : built Dictionary(21 unique tokens: ['week', 'hurricane', 'st', 'brace', 'battered']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:42:14,989 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:14,991 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:14,996 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:14,999 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:15,002 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:15,019 : INFO : -6.335 per-word bound, 80.7 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:15,022 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:15,028 : INFO : topic #1 (0.100): 0.123*\"hurricane\" + 0.058*\"another\" + 0.054*\"gas\" + 0.052*\"irma\" + 0.050*\"brace\" + 0.048*\"small\" + 0.046*\"food\" + 0.045*\"still\" + 0.044*\"st\" + 0.044*\"island\"\n",
      "2019-10-29 00:42:15,031 : INFO : topic #8 (0.100): 0.112*\"hurricane\" + 0.054*\"battered\" + 0.053*\"st\" + 0.052*\"week\" + 0.050*\"still\" + 0.050*\"food\" + 0.050*\"martin\" + 0.049*\"power\" + 0.048*\"irma\" + 0.044*\"without\"\n",
      "2019-10-29 00:42:15,038 : INFO : topic #3 (0.100): 0.102*\"hurricane\" + 0.053*\"food\" + 0.052*\"preparing\" + 0.052*\"without\" + 0.051*\"cnn\" + 0.051*\"still\" + 0.049*\"week\" + 0.048*\"st\" + 0.047*\"small\" + 0.047*\"irma\"\n",
      "2019-10-29 00:42:15,041 : INFO : topic #4 (0.100): 0.115*\"hurricane\" + 0.054*\"power\" + 0.052*\"cnn\" + 0.051*\"still\" + 0.051*\"island\" + 0.050*\"gas\" + 0.049*\"last\" + 0.048*\"resident\" + 0.047*\"small\" + 0.047*\"without\"\n",
      "2019-10-29 00:42:15,042 : INFO : topic #0 (0.100): 0.114*\"hurricane\" + 0.055*\"week\" + 0.054*\"resident\" + 0.050*\"gas\" + 0.047*\"brace\" + 0.046*\"last\" + 0.045*\"caribbean\" + 0.045*\"cnn\" + 0.044*\"preparing\" + 0.044*\"power\"\n",
      "2019-10-29 00:42:15,044 : INFO : topic diff=0.614930, rho=1.000000\n",
      "2019-10-29 00:42:15,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:15,487 : INFO : built Dictionary(117 unique tokens: ['filmed', 'pepper', 'french', 'apace', 'messi']...) from 5 documents (total 755 corpus positions)\n",
      "2019-10-29 00:42:15,490 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:15,491 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:15,493 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:15,496 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:15,497 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:15,581 : INFO : -7.180 per-word bound, 145.0 perplexity estimate based on a held-out corpus of 5 documents with 755 words\n",
      "2019-10-29 00:42:15,584 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:15,592 : INFO : topic #3 (0.100): 0.027*\"real\" + 0.026*\"clasico\" + 0.021*\"madrid\" + 0.021*\"el\" + 0.021*\"player\" + 0.019*\"riot\" + 0.017*\"barcelona\" + 0.016*\"police\" + 0.015*\"crisis\" + 0.015*\"situation\"\n",
      "2019-10-29 00:42:15,595 : INFO : topic #1 (0.100): 0.029*\"clasico\" + 0.026*\"real\" + 0.023*\"barcelona\" + 0.023*\"el\" + 0.021*\"player\" + 0.021*\"madrid\" + 0.020*\"riot\" + 0.017*\"police\" + 0.015*\"spanish\" + 0.014*\"catalonia\"\n",
      "2019-10-29 00:42:15,598 : INFO : topic #4 (0.100): 0.041*\"clasico\" + 0.028*\"real\" + 0.020*\"el\" + 0.019*\"player\" + 0.019*\"police\" + 0.018*\"madrid\" + 0.016*\"messi\" + 0.015*\"barcelona\" + 0.015*\"spoof\" + 0.015*\"treatment\"\n",
      "2019-10-29 00:42:15,601 : INFO : topic #7 (0.100): 0.037*\"clasico\" + 0.031*\"real\" + 0.022*\"el\" + 0.021*\"police\" + 0.018*\"player\" + 0.017*\"riot\" + 0.016*\"barcelona\" + 0.016*\"madrid\" + 0.014*\"spanish\" + 0.014*\"catalan\"\n",
      "2019-10-29 00:42:15,604 : INFO : topic #5 (0.100): 0.024*\"clasico\" + 0.023*\"real\" + 0.021*\"riot\" + 0.021*\"el\" + 0.020*\"player\" + 0.020*\"madrid\" + 0.018*\"police\" + 0.017*\"barcelona\" + 0.016*\"catalan\" + 0.015*\"video\"\n",
      "2019-10-29 00:42:15,606 : INFO : topic diff=0.736960, rho=1.000000\n",
      "2019-10-29 00:42:16,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:16,048 : INFO : built Dictionary(17 unique tokens: ['agree', 'paris', 'revised', 'policy', 'week']...) from 5 documents (total 95 corpus positions)\n",
      "2019-10-29 00:42:16,049 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:16,050 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:16,052 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:16,054 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:16,055 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:16,071 : INFO : -6.185 per-word bound, 72.8 perplexity estimate based on a held-out corpus of 5 documents with 95 words\n",
      "2019-10-29 00:42:16,072 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:16,081 : INFO : topic #8 (0.100): 0.109*\"cooky\" + 0.093*\"use\" + 0.071*\"policy\" + 0.059*\"information\" + 0.059*\"continuing\" + 0.054*\"spring\" + 0.054*\"revised\" + 0.054*\"highlight\" + 0.053*\"agree\" + 0.053*\"privacy\"\n",
      "2019-10-29 00:42:16,084 : INFO : topic #4 (0.100): 0.114*\"cooky\" + 0.091*\"use\" + 0.062*\"term\" + 0.062*\"agree\" + 0.060*\"week\" + 0.058*\"policy\" + 0.055*\"spring\" + 0.054*\"information\" + 0.052*\"continuing\" + 0.052*\"highlight\"\n",
      "2019-10-29 00:42:16,086 : INFO : topic #3 (0.100): 0.099*\"use\" + 0.098*\"cooky\" + 0.069*\"highlight\" + 0.061*\"privacy\" + 0.058*\"summer\" + 0.058*\"site\" + 0.058*\"agree\" + 0.057*\"term\" + 0.056*\"browse\" + 0.052*\"fashion\"\n",
      "2019-10-29 00:42:16,089 : INFO : topic #6 (0.100): 0.115*\"use\" + 0.085*\"cooky\" + 0.064*\"fashion\" + 0.063*\"week\" + 0.062*\"continuing\" + 0.060*\"site\" + 0.058*\"paris\" + 0.057*\"information\" + 0.056*\"spring\" + 0.052*\"agree\"\n",
      "2019-10-29 00:42:16,092 : INFO : topic #1 (0.100): 0.102*\"use\" + 0.095*\"cooky\" + 0.063*\"spring\" + 0.062*\"site\" + 0.061*\"week\" + 0.054*\"information\" + 0.054*\"fashion\" + 0.054*\"highlight\" + 0.053*\"revised\" + 0.052*\"agree\"\n",
      "2019-10-29 00:42:16,102 : INFO : topic diff=0.596881, rho=1.000000\n",
      "2019-10-29 00:42:16,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:16,616 : INFO : built Dictionary(454 unique tokens: ['let', 'entitled', 'focus', 'school', 'label']...) from 5 documents (total 3615 corpus positions)\n",
      "2019-10-29 00:42:16,624 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:16,625 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:16,629 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:16,634 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:16,638 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:16,846 : INFO : -8.086 per-word bound, 271.7 perplexity estimate based on a held-out corpus of 5 documents with 3615 words\n",
      "2019-10-29 00:42:16,849 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:16,860 : INFO : topic #7 (0.100): 0.028*\"restroom\" + 0.017*\"use\" + 0.017*\"gender\" + 0.014*\"public\" + 0.011*\"sheffield\" + 0.011*\"toilet\" + 0.010*\"people\" + 0.009*\"men\" + 0.009*\"law\" + 0.008*\"transgender\"\n",
      "2019-10-29 00:42:16,862 : INFO : topic #5 (0.100): 0.037*\"restroom\" + 0.016*\"gender\" + 0.016*\"use\" + 0.012*\"sheffield\" + 0.012*\"toilet\" + 0.011*\"transgender\" + 0.010*\"public\" + 0.010*\"men\" + 0.009*\"people\" + 0.008*\"time\"\n",
      "2019-10-29 00:42:16,864 : INFO : topic #0 (0.100): 0.038*\"restroom\" + 0.017*\"use\" + 0.014*\"gender\" + 0.012*\"men\" + 0.012*\"sheffield\" + 0.010*\"public\" + 0.009*\"toilet\" + 0.009*\"people\" + 0.008*\"could\" + 0.008*\"said\"\n",
      "2019-10-29 00:42:16,866 : INFO : topic #8 (0.100): 0.049*\"restroom\" + 0.016*\"gender\" + 0.014*\"use\" + 0.012*\"people\" + 0.012*\"toilet\" + 0.012*\"sheffield\" + 0.011*\"transgender\" + 0.010*\"said\" + 0.010*\"men\" + 0.009*\"public\"\n",
      "2019-10-29 00:42:16,878 : INFO : topic #2 (0.100): 0.037*\"restroom\" + 0.018*\"use\" + 0.016*\"gender\" + 0.012*\"sheffield\" + 0.011*\"public\" + 0.011*\"said\" + 0.010*\"toilet\" + 0.008*\"men\" + 0.008*\"time\" + 0.008*\"people\"\n",
      "2019-10-29 00:42:16,881 : INFO : topic diff=0.853559, rho=1.000000\n",
      "2019-10-29 00:42:17,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:17,362 : INFO : built Dictionary(311 unique tokens: ['previously', 'earned', 'prime', 'pushed', 'catalonia']...) from 5 documents (total 2680 corpus positions)\n",
      "2019-10-29 00:42:17,366 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:17,368 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:17,369 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:17,373 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:17,374 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:17,486 : INFO : -7.618 per-word bound, 196.5 perplexity estimate based on a held-out corpus of 5 documents with 2680 words\n",
      "2019-10-29 00:42:17,487 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:17,494 : INFO : topic #9 (0.100): 0.028*\"puigdemont\" + 0.020*\"catalan\" + 0.019*\"said\" + 0.016*\"rajoy\" + 0.016*\"government\" + 0.016*\"catalonia\" + 0.015*\"talk\" + 0.015*\"independence\" + 0.012*\"declaration\" + 0.011*\"spanish\"\n",
      "2019-10-29 00:42:17,496 : INFO : topic #1 (0.100): 0.031*\"puigdemont\" + 0.022*\"spanish\" + 0.021*\"said\" + 0.020*\"catalonia\" + 0.019*\"catalan\" + 0.015*\"independence\" + 0.014*\"rajoy\" + 0.014*\"talk\" + 0.014*\"government\" + 0.011*\"people\"\n",
      "2019-10-29 00:42:17,499 : INFO : topic #3 (0.100): 0.029*\"catalonia\" + 0.027*\"said\" + 0.023*\"puigdemont\" + 0.019*\"independence\" + 0.018*\"spanish\" + 0.014*\"catalan\" + 0.014*\"rajoy\" + 0.013*\"talk\" + 0.012*\"declaration\" + 0.012*\"government\"\n",
      "2019-10-29 00:42:17,501 : INFO : topic #7 (0.100): 0.025*\"puigdemont\" + 0.022*\"catalonia\" + 0.021*\"said\" + 0.019*\"catalan\" + 0.015*\"independence\" + 0.014*\"talk\" + 0.014*\"rajoy\" + 0.013*\"spanish\" + 0.012*\"declaration\" + 0.011*\"people\"\n",
      "2019-10-29 00:42:17,504 : INFO : topic #5 (0.100): 0.029*\"puigdemont\" + 0.026*\"said\" + 0.018*\"spanish\" + 0.017*\"independence\" + 0.016*\"catalonia\" + 0.015*\"rajoy\" + 0.013*\"catalan\" + 0.013*\"talk\" + 0.012*\"government\" + 0.012*\"declaration\"\n",
      "2019-10-29 00:42:17,506 : INFO : topic diff=0.912076, rho=1.000000\n",
      "2019-10-29 00:42:17,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:17,921 : INFO : built Dictionary(299 unique tokens: ['specie', 'trying', 'bone', 'deep', 'come']...) from 5 documents (total 2400 corpus positions)\n",
      "2019-10-29 00:42:17,925 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:17,927 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:17,928 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:17,931 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:17,932 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:18,032 : INFO : -7.675 per-word bound, 204.4 perplexity estimate based on a held-out corpus of 5 documents with 2400 words\n",
      "2019-10-29 00:42:18,034 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:18,042 : INFO : topic #5 (0.100): 0.036*\"caviar\" + 0.032*\"petrossian\" + 0.028*\"say\" + 0.022*\"tin\" + 0.013*\"first\" + 0.011*\"taste\" + 0.010*\"egg\" + 0.010*\"experience\" + 0.010*\"one\" + 0.009*\"usually\"\n",
      "2019-10-29 00:42:18,046 : INFO : topic #8 (0.100): 0.047*\"caviar\" + 0.035*\"say\" + 0.035*\"petrossian\" + 0.013*\"tin\" + 0.012*\"first\" + 0.010*\"taste\" + 0.010*\"egg\" + 0.010*\"experience\" + 0.008*\"mouth\" + 0.008*\"usually\"\n",
      "2019-10-29 00:42:18,050 : INFO : topic #3 (0.100): 0.045*\"caviar\" + 0.039*\"petrossian\" + 0.037*\"say\" + 0.017*\"tin\" + 0.014*\"first\" + 0.011*\"taste\" + 0.008*\"time\" + 0.008*\"egg\" + 0.008*\"come\" + 0.008*\"want\"\n",
      "2019-10-29 00:42:18,054 : INFO : topic #2 (0.100): 0.044*\"caviar\" + 0.034*\"petrossian\" + 0.030*\"say\" + 0.013*\"tin\" + 0.012*\"taste\" + 0.012*\"first\" + 0.009*\"egg\" + 0.009*\"grade\" + 0.008*\"one\" + 0.007*\"time\"\n",
      "2019-10-29 00:42:18,057 : INFO : topic #0 (0.100): 0.044*\"caviar\" + 0.031*\"petrossian\" + 0.030*\"say\" + 0.015*\"first\" + 0.012*\"tin\" + 0.010*\"egg\" + 0.010*\"taste\" + 0.008*\"usually\" + 0.008*\"fish\" + 0.008*\"time\"\n",
      "2019-10-29 00:42:18,061 : INFO : topic diff=0.865542, rho=1.000000\n",
      "2019-10-29 00:42:18,504 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:18,510 : INFO : built Dictionary(302 unique tokens: ['although', 'let', 'seems', 'weinstein', 'campaign']...) from 5 documents (total 2310 corpus positions)\n",
      "2019-10-29 00:42:18,513 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:18,514 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:18,516 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:18,519 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:18,521 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:18,620 : INFO : -7.758 per-word bound, 216.4 perplexity estimate based on a held-out corpus of 5 documents with 2310 words\n",
      "2019-10-29 00:42:18,621 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:18,637 : INFO : topic #3 (0.100): 0.021*\"trump\" + 0.020*\"woman\" + 0.015*\"voter\" + 0.014*\"said\" + 0.013*\"clinton\" + 0.011*\"public\" + 0.011*\"allegation\" + 0.010*\"powerful\" + 0.010*\"sexual\" + 0.010*\"bill\"\n",
      "2019-10-29 00:42:18,640 : INFO : topic #8 (0.100): 0.022*\"trump\" + 0.017*\"woman\" + 0.015*\"clinton\" + 0.013*\"sexual\" + 0.011*\"voter\" + 0.011*\"weinstein\" + 0.011*\"medium\" + 0.010*\"company\" + 0.010*\"ailes\" + 0.010*\"news\"\n",
      "2019-10-29 00:42:18,643 : INFO : topic #7 (0.100): 0.018*\"woman\" + 0.016*\"trump\" + 0.013*\"said\" + 0.013*\"voter\" + 0.012*\"bill\" + 0.010*\"weinstein\" + 0.010*\"sexual\" + 0.010*\"clinton\" + 0.009*\"ailes\" + 0.009*\"allegation\"\n",
      "2019-10-29 00:42:18,646 : INFO : topic #2 (0.100): 0.022*\"trump\" + 0.021*\"woman\" + 0.014*\"clinton\" + 0.013*\"weinstein\" + 0.012*\"voter\" + 0.010*\"job\" + 0.010*\"allegation\" + 0.010*\"sexual\" + 0.009*\"news\" + 0.008*\"said\"\n",
      "2019-10-29 00:42:18,649 : INFO : topic #9 (0.100): 0.020*\"woman\" + 0.017*\"trump\" + 0.013*\"said\" + 0.013*\"voter\" + 0.011*\"clinton\" + 0.010*\"allegation\" + 0.010*\"ailes\" + 0.010*\"men\" + 0.010*\"treatment\" + 0.009*\"bill\"\n",
      "2019-10-29 00:42:18,651 : INFO : topic diff=0.819801, rho=1.000000\n",
      "2019-10-29 00:42:19,054 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:19,058 : INFO : built Dictionary(137 unique tokens: ['wilderness', 'small', 'book', 'come', 'grounded']...) from 5 documents (total 795 corpus positions)\n",
      "2019-10-29 00:42:19,061 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:19,062 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:19,064 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:19,066 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:19,067 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:19,122 : INFO : -7.527 per-word bound, 184.4 perplexity estimate based on a held-out corpus of 5 documents with 795 words\n",
      "2019-10-29 00:42:19,124 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:19,130 : INFO : topic #0 (0.100): 0.022*\"mountain\" + 0.020*\"ben\" + 0.019*\"elba\" + 0.018*\"winslet\" + 0.016*\"people\" + 0.014*\"life\" + 0.014*\"like\" + 0.014*\"two\" + 0.013*\"come\" + 0.012*\"based\"\n",
      "2019-10-29 00:42:19,132 : INFO : topic #2 (0.100): 0.022*\"mountain\" + 0.019*\"winslet\" + 0.016*\"way\" + 0.015*\"elba\" + 0.013*\"two\" + 0.013*\"idris\" + 0.013*\"ben\" + 0.012*\"come\" + 0.011*\"life\" + 0.011*\"alive\"\n",
      "2019-10-29 00:42:19,134 : INFO : topic #1 (0.100): 0.023*\"mountain\" + 0.018*\"ben\" + 0.016*\"winslet\" + 0.015*\"kate\" + 0.015*\"alex\" + 0.015*\"elba\" + 0.014*\"idris\" + 0.013*\"way\" + 0.012*\"based\" + 0.012*\"alive\"\n",
      "2019-10-29 00:42:19,137 : INFO : topic #6 (0.100): 0.025*\"mountain\" + 0.021*\"winslet\" + 0.015*\"u\" + 0.014*\"ben\" + 0.013*\"idris\" + 0.013*\"elba\" + 0.013*\"life\" + 0.012*\"like\" + 0.012*\"movie\" + 0.012*\"based\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:19,141 : INFO : topic #8 (0.100): 0.022*\"mountain\" + 0.020*\"elba\" + 0.016*\"winslet\" + 0.016*\"ben\" + 0.015*\"idris\" + 0.014*\"come\" + 0.014*\"u\" + 0.013*\"people\" + 0.013*\"alex\" + 0.012*\"based\"\n",
      "2019-10-29 00:42:19,145 : INFO : topic diff=0.659264, rho=1.000000\n",
      "2019-10-29 00:42:19,593 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:19,601 : INFO : built Dictionary(469 unique tokens: ['although', 'prime', 'phase', 'squeezed', 'dictator']...) from 5 documents (total 3905 corpus positions)\n",
      "2019-10-29 00:42:19,606 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:19,608 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:19,609 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:19,613 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:19,616 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:19,759 : INFO : -8.051 per-word bound, 265.2 perplexity estimate based on a held-out corpus of 5 documents with 3905 words\n",
      "2019-10-29 00:42:19,760 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:19,770 : INFO : topic #8 (0.100): 0.023*\"kirkuk\" + 0.019*\"kurdish\" + 0.015*\"iraqi\" + 0.014*\"say\" + 0.010*\"isi\" + 0.010*\"u\" + 0.009*\"referendum\" + 0.009*\"hawija\" + 0.008*\"peshmerga\" + 0.008*\"kurd\"\n",
      "2019-10-29 00:42:19,773 : INFO : topic #0 (0.100): 0.019*\"say\" + 0.019*\"kirkuk\" + 0.017*\"iraqi\" + 0.015*\"kurdish\" + 0.010*\"u\" + 0.009*\"arab\" + 0.009*\"kurd\" + 0.009*\"isi\" + 0.009*\"majeed\" + 0.009*\"referendum\"\n",
      "2019-10-29 00:42:19,776 : INFO : topic #5 (0.100): 0.021*\"kirkuk\" + 0.019*\"say\" + 0.016*\"kurdish\" + 0.015*\"iraqi\" + 0.015*\"isi\" + 0.009*\"hawija\" + 0.009*\"arab\" + 0.009*\"majeed\" + 0.009*\"referendum\" + 0.008*\"peshmerga\"\n",
      "2019-10-29 00:42:19,779 : INFO : topic #1 (0.100): 0.018*\"say\" + 0.016*\"iraqi\" + 0.015*\"kirkuk\" + 0.014*\"kurdish\" + 0.012*\"arab\" + 0.011*\"referendum\" + 0.011*\"isi\" + 0.009*\"majeed\" + 0.009*\"peshmerga\" + 0.009*\"kurd\"\n",
      "2019-10-29 00:42:19,783 : INFO : topic #6 (0.100): 0.023*\"kirkuk\" + 0.018*\"kurdish\" + 0.016*\"say\" + 0.015*\"iraqi\" + 0.010*\"outpost\" + 0.010*\"kurd\" + 0.010*\"iraq\" + 0.010*\"isi\" + 0.009*\"state\" + 0.008*\"u\"\n",
      "2019-10-29 00:42:19,786 : INFO : topic diff=0.873778, rho=1.000000\n",
      "2019-10-29 00:42:20,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:20,288 : INFO : built Dictionary(677 unique tokens: ['although', 'nh', 'acceptable', 'real', 'notice']...) from 5 documents (total 6925 corpus positions)\n",
      "2019-10-29 00:42:20,296 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:20,297 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:20,299 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:20,304 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:20,306 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:20,560 : INFO : -8.153 per-word bound, 284.6 perplexity estimate based on a held-out corpus of 5 documents with 6925 words\n",
      "2019-10-29 00:42:20,562 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:20,574 : INFO : topic #1 (0.100): 0.036*\"care\" + 0.023*\"health\" + 0.021*\"said\" + 0.017*\"patient\" + 0.013*\"people\" + 0.012*\"uk\" + 0.010*\"hospital\" + 0.007*\"bed\" + 0.006*\"national\" + 0.006*\"mckee\"\n",
      "2019-10-29 00:42:20,577 : INFO : topic #6 (0.100): 0.035*\"care\" + 0.024*\"health\" + 0.021*\"patient\" + 0.014*\"said\" + 0.013*\"uk\" + 0.011*\"hospital\" + 0.011*\"people\" + 0.008*\"service\" + 0.007*\"bed\" + 0.006*\"social\"\n",
      "2019-10-29 00:42:20,579 : INFO : topic #8 (0.100): 0.030*\"health\" + 0.029*\"care\" + 0.021*\"patient\" + 0.016*\"said\" + 0.011*\"uk\" + 0.010*\"people\" + 0.010*\"hospital\" + 0.008*\"mckee\" + 0.007*\"kerr\" + 0.007*\"practice\"\n",
      "2019-10-29 00:42:20,582 : INFO : topic #7 (0.100): 0.029*\"care\" + 0.024*\"health\" + 0.022*\"patient\" + 0.018*\"said\" + 0.011*\"people\" + 0.010*\"hospital\" + 0.010*\"uk\" + 0.007*\"mckee\" + 0.007*\"u\" + 0.007*\"country\"\n",
      "2019-10-29 00:42:20,585 : INFO : topic #0 (0.100): 0.029*\"care\" + 0.022*\"patient\" + 0.022*\"health\" + 0.016*\"said\" + 0.014*\"people\" + 0.013*\"uk\" + 0.009*\"u\" + 0.008*\"mckee\" + 0.008*\"hospital\" + 0.007*\"bed\"\n",
      "2019-10-29 00:42:20,588 : INFO : topic diff=0.956837, rho=1.000000\n",
      "2019-10-29 00:42:21,055 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:21,059 : INFO : built Dictionary(277 unique tokens: ['previously', 'concern', 'book', 'wading', 'come']...) from 5 documents (total 2245 corpus positions)\n",
      "2019-10-29 00:42:21,062 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:21,064 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:21,065 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:21,069 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:21,070 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:21,171 : INFO : -7.584 per-word bound, 191.9 perplexity estimate based on a held-out corpus of 5 documents with 2245 words\n",
      "2019-10-29 00:42:21,173 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:21,180 : INFO : topic #2 (0.100): 0.041*\"trump\" + 0.029*\"first\" + 0.019*\"said\" + 0.019*\"lady\" + 0.017*\"president\" + 0.017*\"donald\" + 0.012*\"book\" + 0.012*\"wife\" + 0.011*\"ivana\" + 0.011*\"melania\"\n",
      "2019-10-29 00:42:21,182 : INFO : topic #1 (0.100): 0.053*\"trump\" + 0.026*\"first\" + 0.024*\"said\" + 0.018*\"president\" + 0.015*\"melania\" + 0.015*\"lady\" + 0.015*\"ivana\" + 0.012*\"donald\" + 0.012*\"really\" + 0.012*\"book\"\n",
      "2019-10-29 00:42:21,185 : INFO : topic #5 (0.100): 0.041*\"trump\" + 0.022*\"said\" + 0.021*\"first\" + 0.019*\"president\" + 0.017*\"donald\" + 0.014*\"lady\" + 0.013*\"ivana\" + 0.013*\"book\" + 0.011*\"wife\" + 0.010*\"melania\"\n",
      "2019-10-29 00:42:21,186 : INFO : topic #3 (0.100): 0.048*\"trump\" + 0.022*\"said\" + 0.020*\"first\" + 0.017*\"president\" + 0.017*\"lady\" + 0.014*\"ivana\" + 0.014*\"wife\" + 0.012*\"donald\" + 0.011*\"day\" + 0.011*\"really\"\n",
      "2019-10-29 00:42:21,188 : INFO : topic #7 (0.100): 0.059*\"trump\" + 0.022*\"first\" + 0.020*\"said\" + 0.020*\"lady\" + 0.017*\"donald\" + 0.015*\"really\" + 0.013*\"president\" + 0.012*\"wife\" + 0.011*\"ivana\" + 0.010*\"ex\"\n",
      "2019-10-29 00:42:21,190 : INFO : topic diff=0.851990, rho=1.000000\n",
      "2019-10-29 00:42:21,577 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:21,580 : INFO : built Dictionary(145 unique tokens: ['realm', 'earned', 'colleague', 'others', 'beginning']...) from 5 documents (total 880 corpus positions)\n",
      "2019-10-29 00:42:21,582 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:21,587 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:21,591 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:21,594 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:21,597 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:21,668 : INFO : -7.484 per-word bound, 179.0 perplexity estimate based on a held-out corpus of 5 documents with 880 words\n",
      "2019-10-29 00:42:21,670 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:21,677 : INFO : topic #6 (0.100): 0.049*\"spielberg\" + 0.021*\"movie\" + 0.019*\"director\" + 0.017*\"one\" + 0.017*\"film\" + 0.014*\"perhaps\" + 0.013*\"blockbuster\" + 0.012*\"making\" + 0.012*\"tv\" + 0.012*\"early\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:21,680 : INFO : topic #2 (0.100): 0.050*\"spielberg\" + 0.019*\"director\" + 0.019*\"movie\" + 0.017*\"film\" + 0.016*\"perhaps\" + 0.015*\"one\" + 0.012*\"half\" + 0.011*\"tv\" + 0.011*\"documentary\" + 0.011*\"best\"\n",
      "2019-10-29 00:42:21,682 : INFO : topic #8 (0.100): 0.053*\"spielberg\" + 0.020*\"movie\" + 0.015*\"director\" + 0.015*\"perhaps\" + 0.015*\"one\" + 0.014*\"film\" + 0.013*\"best\" + 0.013*\"coppola\" + 0.012*\"tv\" + 0.012*\"documentary\"\n",
      "2019-10-29 00:42:21,685 : INFO : topic #4 (0.100): 0.048*\"spielberg\" + 0.026*\"director\" + 0.023*\"movie\" + 0.020*\"perhaps\" + 0.016*\"film\" + 0.015*\"one\" + 0.013*\"half\" + 0.012*\"best\" + 0.011*\"coppola\" + 0.010*\"early\"\n",
      "2019-10-29 00:42:21,688 : INFO : topic #5 (0.100): 0.048*\"spielberg\" + 0.026*\"director\" + 0.022*\"movie\" + 0.017*\"one\" + 0.017*\"perhaps\" + 0.013*\"film\" + 0.012*\"portrait\" + 0.011*\"making\" + 0.011*\"early\" + 0.011*\"helped\"\n",
      "2019-10-29 00:42:21,690 : INFO : topic diff=0.700162, rho=1.000000\n",
      "2019-10-29 00:42:22,146 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:22,152 : INFO : built Dictionary(473 unique tokens: ['extensive', 'happy', 'let', 'focus', 'spoke']...) from 5 documents (total 4930 corpus positions)\n",
      "2019-10-29 00:42:22,157 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:22,158 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:22,160 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:22,164 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:22,166 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:22,311 : INFO : -7.786 per-word bound, 220.7 perplexity estimate based on a held-out corpus of 5 documents with 4930 words\n",
      "2019-10-29 00:42:22,313 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:22,321 : INFO : topic #4 (0.100): 0.026*\"said\" + 0.019*\"body\" + 0.016*\"daughter\" + 0.014*\"mom\" + 0.014*\"want\" + 0.012*\"girl\" + 0.012*\"think\" + 0.012*\"feel\" + 0.010*\"way\" + 0.010*\"going\"\n",
      "2019-10-29 00:42:22,322 : INFO : topic #2 (0.100): 0.030*\"said\" + 0.017*\"mom\" + 0.015*\"body\" + 0.014*\"girl\" + 0.013*\"want\" + 0.013*\"daughter\" + 0.012*\"image\" + 0.012*\"feel\" + 0.012*\"woman\" + 0.010*\"think\"\n",
      "2019-10-29 00:42:22,324 : INFO : topic #5 (0.100): 0.028*\"said\" + 0.019*\"body\" + 0.015*\"want\" + 0.014*\"mom\" + 0.013*\"think\" + 0.013*\"girl\" + 0.012*\"image\" + 0.011*\"look\" + 0.010*\"daughter\" + 0.009*\"like\"\n",
      "2019-10-29 00:42:22,326 : INFO : topic #3 (0.100): 0.022*\"body\" + 0.019*\"said\" + 0.015*\"want\" + 0.014*\"think\" + 0.014*\"daughter\" + 0.012*\"mom\" + 0.011*\"look\" + 0.011*\"image\" + 0.011*\"girl\" + 0.009*\"choate\"\n",
      "2019-10-29 00:42:22,327 : INFO : topic #1 (0.100): 0.024*\"said\" + 0.016*\"want\" + 0.014*\"image\" + 0.014*\"mom\" + 0.013*\"daughter\" + 0.012*\"body\" + 0.012*\"girl\" + 0.011*\"feel\" + 0.011*\"think\" + 0.010*\"hard\"\n",
      "2019-10-29 00:42:22,330 : INFO : topic diff=1.007107, rho=1.000000\n",
      "2019-10-29 00:42:22,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:22,747 : INFO : built Dictionary(83 unique tokens: ['b', 'military', 'bomber', 'simulated', 'warplane']...) from 5 documents (total 845 corpus positions)\n",
      "2019-10-29 00:42:22,751 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:22,753 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:22,754 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:22,756 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:22,757 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:22,798 : INFO : -6.187 per-word bound, 72.9 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n",
      "2019-10-29 00:42:22,801 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:22,806 : INFO : topic #0 (0.100): 0.071*\"korean\" + 0.053*\"force\" + 0.044*\"u\" + 0.043*\"air\" + 0.040*\"south\" + 0.031*\"bomber\" + 0.029*\"military\" + 0.029*\"said\" + 0.028*\"korea\" + 0.028*\"exercise\"\n",
      "2019-10-29 00:42:22,809 : INFO : topic #3 (0.100): 0.062*\"force\" + 0.060*\"korean\" + 0.044*\"south\" + 0.042*\"u\" + 0.040*\"air\" + 0.032*\"bomber\" + 0.030*\"military\" + 0.029*\"drill\" + 0.025*\"b\" + 0.025*\"said\"\n",
      "2019-10-29 00:42:22,811 : INFO : topic #9 (0.100): 0.044*\"force\" + 0.043*\"korean\" + 0.041*\"u\" + 0.040*\"south\" + 0.033*\"said\" + 0.032*\"military\" + 0.031*\"air\" + 0.029*\"bomber\" + 0.028*\"drill\" + 0.026*\"exercise\"\n",
      "2019-10-29 00:42:22,814 : INFO : topic #2 (0.100): 0.072*\"korean\" + 0.044*\"south\" + 0.038*\"force\" + 0.037*\"bomber\" + 0.035*\"air\" + 0.035*\"u\" + 0.032*\"drill\" + 0.030*\"said\" + 0.029*\"b\" + 0.027*\"military\"\n",
      "2019-10-29 00:42:22,819 : INFO : topic #5 (0.100): 0.066*\"korean\" + 0.050*\"force\" + 0.047*\"air\" + 0.040*\"south\" + 0.037*\"bomber\" + 0.034*\"said\" + 0.029*\"drill\" + 0.026*\"u\" + 0.025*\"military\" + 0.024*\"b\"\n",
      "2019-10-29 00:42:22,822 : INFO : topic diff=1.028526, rho=1.000000\n",
      "2019-10-29 00:42:23,303 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:23,314 : INFO : built Dictionary(376 unique tokens: ['although', 'pediatrician', 'energy', 'restricting', 'revealed']...) from 5 documents (total 3580 corpus positions)\n",
      "2019-10-29 00:42:23,322 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:23,325 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:23,328 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:23,339 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:23,345 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:23,479 : INFO : -7.665 per-word bound, 203.0 perplexity estimate based on a held-out corpus of 5 documents with 3580 words\n",
      "2019-10-29 00:42:23,480 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:23,488 : INFO : topic #1 (0.100): 0.026*\"said\" + 0.022*\"child\" + 0.022*\"obesity\" + 0.017*\"adolescent\" + 0.016*\"underweight\" + 0.016*\"country\" + 0.011*\"obese\" + 0.010*\"hu\" + 0.010*\"health\" + 0.009*\"ezzati\"\n",
      "2019-10-29 00:42:23,489 : INFO : topic #0 (0.100): 0.029*\"child\" + 0.026*\"said\" + 0.022*\"obesity\" + 0.016*\"country\" + 0.015*\"obese\" + 0.014*\"underweight\" + 0.009*\"data\" + 0.008*\"health\" + 0.008*\"food\" + 0.008*\"adolescent\"\n",
      "2019-10-29 00:42:23,491 : INFO : topic #2 (0.100): 0.029*\"obesity\" + 0.026*\"said\" + 0.024*\"child\" + 0.015*\"country\" + 0.014*\"underweight\" + 0.014*\"adolescent\" + 0.013*\"obese\" + 0.012*\"health\" + 0.009*\"ezzati\" + 0.009*\"problem\"\n",
      "2019-10-29 00:42:23,493 : INFO : topic #5 (0.100): 0.026*\"child\" + 0.022*\"said\" + 0.020*\"obesity\" + 0.018*\"country\" + 0.015*\"obese\" + 0.013*\"underweight\" + 0.011*\"adolescent\" + 0.010*\"hu\" + 0.009*\"health\" + 0.007*\"including\"\n",
      "2019-10-29 00:42:23,496 : INFO : topic #3 (0.100): 0.029*\"said\" + 0.027*\"obesity\" + 0.026*\"child\" + 0.015*\"underweight\" + 0.013*\"adolescent\" + 0.013*\"obese\" + 0.012*\"country\" + 0.009*\"hu\" + 0.009*\"health\" + 0.008*\"income\"\n",
      "2019-10-29 00:42:23,497 : INFO : topic diff=0.910856, rho=1.000000\n",
      "2019-10-29 00:42:23,915 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:23,920 : INFO : built Dictionary(315 unique tokens: ['forward', 'even', 'acceptable', 'reach', 'campaign']...) from 5 documents (total 2550 corpus positions)\n",
      "2019-10-29 00:42:23,924 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:23,926 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:23,927 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:23,931 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:23,933 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:24,042 : INFO : -7.703 per-word bound, 208.4 perplexity estimate based on a held-out corpus of 5 documents with 2550 words\n",
      "2019-10-29 00:42:24,044 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:24,051 : INFO : topic #5 (0.100): 0.039*\"transgender\" + 0.027*\"fashion\" + 0.018*\"think\" + 0.016*\"people\" + 0.015*\"model\" + 0.014*\"come\" + 0.013*\"trans\" + 0.013*\"like\" + 0.012*\"quinlivan\" + 0.010*\"show\"\n",
      "2019-10-29 00:42:24,054 : INFO : topic #9 (0.100): 0.029*\"transgender\" + 0.021*\"fashion\" + 0.018*\"people\" + 0.017*\"quinlivan\" + 0.016*\"model\" + 0.014*\"said\" + 0.014*\"trans\" + 0.013*\"come\" + 0.013*\"new\" + 0.013*\"like\"\n",
      "2019-10-29 00:42:24,056 : INFO : topic #6 (0.100): 0.034*\"transgender\" + 0.025*\"fashion\" + 0.022*\"quinlivan\" + 0.016*\"trans\" + 0.016*\"model\" + 0.014*\"said\" + 0.014*\"people\" + 0.012*\"think\" + 0.012*\"woman\" + 0.011*\"time\"\n",
      "2019-10-29 00:42:24,059 : INFO : topic #4 (0.100): 0.030*\"transgender\" + 0.022*\"quinlivan\" + 0.021*\"fashion\" + 0.018*\"people\" + 0.018*\"trans\" + 0.017*\"think\" + 0.015*\"model\" + 0.014*\"come\" + 0.013*\"industry\" + 0.012*\"new\"\n",
      "2019-10-29 00:42:24,061 : INFO : topic #8 (0.100): 0.028*\"transgender\" + 0.025*\"fashion\" + 0.023*\"trans\" + 0.018*\"think\" + 0.018*\"people\" + 0.016*\"model\" + 0.016*\"quinlivan\" + 0.011*\"come\" + 0.010*\"new\" + 0.010*\"woman\"\n",
      "2019-10-29 00:42:24,064 : INFO : topic diff=0.898423, rho=1.000000\n",
      "2019-10-29 00:42:24,519 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:24,524 : INFO : built Dictionary(256 unique tokens: ['liability', 'let', 'trying', 'filed', 'bone']...) from 5 documents (total 2065 corpus positions)\n",
      "2019-10-29 00:42:24,528 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:24,530 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:24,532 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:24,535 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:24,537 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:24,632 : INFO : -7.521 per-word bound, 183.7 perplexity estimate based on a held-out corpus of 5 documents with 2065 words\n",
      "2019-10-29 00:42:24,634 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:24,643 : INFO : topic #2 (0.100): 0.038*\"said\" + 0.026*\"loo\" + 0.019*\"baseball\" + 0.018*\"league\" + 0.016*\"ball\" + 0.014*\"cub\" + 0.013*\"eye\" + 0.012*\"area\" + 0.012*\"one\" + 0.012*\"game\"\n",
      "2019-10-29 00:42:24,646 : INFO : topic #6 (0.100): 0.030*\"said\" + 0.027*\"loo\" + 0.020*\"baseball\" + 0.017*\"eye\" + 0.017*\"ball\" + 0.015*\"major\" + 0.014*\"cub\" + 0.013*\"league\" + 0.012*\"lawsuit\" + 0.012*\"u\"\n",
      "2019-10-29 00:42:24,648 : INFO : topic #1 (0.100): 0.029*\"said\" + 0.025*\"loo\" + 0.018*\"baseball\" + 0.016*\"major\" + 0.015*\"fan\" + 0.014*\"ball\" + 0.014*\"league\" + 0.012*\"eye\" + 0.012*\"lawsuit\" + 0.011*\"game\"\n",
      "2019-10-29 00:42:24,651 : INFO : topic #8 (0.100): 0.042*\"said\" + 0.025*\"loo\" + 0.017*\"baseball\" + 0.014*\"foul\" + 0.014*\"fan\" + 0.013*\"ball\" + 0.013*\"eye\" + 0.012*\"league\" + 0.012*\"lawsuit\" + 0.012*\"netting\"\n",
      "2019-10-29 00:42:24,654 : INFO : topic #5 (0.100): 0.039*\"said\" + 0.028*\"loo\" + 0.017*\"baseball\" + 0.014*\"ball\" + 0.014*\"u\" + 0.014*\"fan\" + 0.013*\"eye\" + 0.013*\"league\" + 0.013*\"major\" + 0.012*\"area\"\n",
      "2019-10-29 00:42:24,656 : INFO : topic diff=0.862143, rho=1.000000\n",
      "2019-10-29 00:42:25,062 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:25,064 : INFO : built Dictionary(13 unique tokens: ['today', 'president', 'watch', 'trump', 'watched']...) from 5 documents (total 90 corpus positions)\n",
      "2019-10-29 00:42:25,065 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:25,066 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:25,068 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:25,069 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:25,070 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:25,083 : INFO : -5.565 per-word bound, 47.3 perplexity estimate based on a held-out corpus of 5 documents with 90 words\n",
      "2019-10-29 00:42:25,084 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:25,091 : INFO : topic #2 (0.100): 0.153*\"today\" + 0.120*\"story\" + 0.106*\"following\" + 0.069*\"catch\" + 0.069*\"update\" + 0.066*\"trump\" + 0.064*\"video\" + 0.062*\"replay\" + 0.062*\"must\" + 0.058*\"president\"\n",
      "2019-10-29 00:42:25,094 : INFO : topic #0 (0.100): 0.138*\"today\" + 0.125*\"story\" + 0.105*\"following\" + 0.099*\"catch\" + 0.068*\"video\" + 0.066*\"replay\" + 0.064*\"watched\" + 0.063*\"watch\" + 0.056*\"president\" + 0.056*\"trump\"\n",
      "2019-10-29 00:42:25,097 : INFO : topic #7 (0.100): 0.158*\"today\" + 0.114*\"story\" + 0.110*\"catch\" + 0.093*\"following\" + 0.067*\"trump\" + 0.066*\"watched\" + 0.064*\"video\" + 0.061*\"update\" + 0.057*\"replay\" + 0.056*\"president\"\n",
      "2019-10-29 00:42:25,101 : INFO : topic #6 (0.100): 0.158*\"today\" + 0.125*\"following\" + 0.108*\"story\" + 0.106*\"catch\" + 0.069*\"president\" + 0.065*\"must\" + 0.061*\"trump\" + 0.061*\"watched\" + 0.053*\"live\" + 0.052*\"video\"\n",
      "2019-10-29 00:42:25,105 : INFO : topic #1 (0.100): 0.177*\"today\" + 0.104*\"following\" + 0.102*\"catch\" + 0.096*\"story\" + 0.076*\"watch\" + 0.067*\"update\" + 0.065*\"live\" + 0.062*\"must\" + 0.055*\"replay\" + 0.054*\"president\"\n",
      "2019-10-29 00:42:25,108 : INFO : topic diff=0.698541, rho=1.000000\n",
      "2019-10-29 00:42:25,529 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:25,532 : INFO : built Dictionary(159 unique tokens: ['oxford', 'produce', 'product', 'french', 'recently']...) from 5 documents (total 1145 corpus positions)\n",
      "2019-10-29 00:42:25,535 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:25,537 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:25,538 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:25,541 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:25,542 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:25,603 : INFO : -7.259 per-word bound, 153.2 perplexity estimate based on a held-out corpus of 5 documents with 1145 words\n",
      "2019-10-29 00:42:25,605 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:25,612 : INFO : topic #0 (0.100): 0.031*\"comma\" + 0.023*\"distribution\" + 0.023*\"oxford\" + 0.018*\"packing\" + 0.017*\"feel\" + 0.017*\"overtime\" + 0.014*\"john\" + 0.013*\"shipment\" + 0.013*\"egg\" + 0.013*\"contract\"\n",
      "2019-10-29 00:42:25,614 : INFO : topic #8 (0.100): 0.031*\"oxford\" + 0.031*\"comma\" + 0.023*\"overtime\" + 0.020*\"distribution\" + 0.017*\"packing\" + 0.017*\"feel\" + 0.016*\"granted\" + 0.015*\"mcwhorter\" + 0.014*\"parent\" + 0.014*\"opposed\"\n",
      "2019-10-29 00:42:25,617 : INFO : topic #6 (0.100): 0.039*\"oxford\" + 0.029*\"comma\" + 0.021*\"overtime\" + 0.018*\"distribution\" + 0.018*\"packing\" + 0.016*\"one\" + 0.015*\"feel\" + 0.013*\"contract\" + 0.013*\"opposed\" + 0.013*\"egg\"\n",
      "2019-10-29 00:42:25,619 : INFO : topic #7 (0.100): 0.033*\"oxford\" + 0.028*\"comma\" + 0.021*\"overtime\" + 0.017*\"feel\" + 0.016*\"distribution\" + 0.015*\"parent\" + 0.015*\"packing\" + 0.014*\"contract\" + 0.013*\"john\" + 0.013*\"thing\"\n",
      "2019-10-29 00:42:25,621 : INFO : topic #5 (0.100): 0.034*\"comma\" + 0.024*\"oxford\" + 0.022*\"distribution\" + 0.019*\"overtime\" + 0.016*\"packing\" + 0.015*\"granted\" + 0.015*\"parent\" + 0.014*\"feel\" + 0.013*\"mcwhorter\" + 0.013*\"opposed\"\n",
      "2019-10-29 00:42:25,624 : INFO : topic diff=0.799539, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:26,023 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:26,028 : INFO : built Dictionary(273 unique tokens: ['let', 'school', 'teen', 'end', 'come']...) from 5 documents (total 2235 corpus positions)\n",
      "2019-10-29 00:42:26,032 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:26,033 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:26,034 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:26,038 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:26,039 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:26,153 : INFO : -7.553 per-word bound, 187.8 perplexity estimate based on a held-out corpus of 5 documents with 2235 words\n",
      "2019-10-29 00:42:26,155 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:26,163 : INFO : topic #0 (0.100): 0.037*\"tyler\" + 0.018*\"said\" + 0.018*\"coast\" + 0.017*\"helicopter\" + 0.016*\"frank\" + 0.016*\"cell\" + 0.015*\"guard\" + 0.014*\"siri\" + 0.012*\"mother\" + 0.011*\"sick\"\n",
      "2019-10-29 00:42:26,165 : INFO : topic #6 (0.100): 0.028*\"tyler\" + 0.019*\"said\" + 0.017*\"helicopter\" + 0.013*\"guard\" + 0.012*\"coast\" + 0.012*\"cell\" + 0.012*\"siri\" + 0.011*\"hospital\" + 0.011*\"sickle\" + 0.011*\"told\"\n",
      "2019-10-29 00:42:26,168 : INFO : topic #9 (0.100): 0.046*\"tyler\" + 0.019*\"helicopter\" + 0.019*\"said\" + 0.016*\"coast\" + 0.015*\"cell\" + 0.014*\"siri\" + 0.013*\"frank\" + 0.012*\"guard\" + 0.012*\"family\" + 0.012*\"sickle\"\n",
      "2019-10-29 00:42:26,171 : INFO : topic #4 (0.100): 0.036*\"tyler\" + 0.018*\"said\" + 0.015*\"frank\" + 0.015*\"guard\" + 0.015*\"siri\" + 0.014*\"helicopter\" + 0.014*\"brother\" + 0.014*\"coast\" + 0.013*\"cell\" + 0.011*\"hospital\"\n",
      "2019-10-29 00:42:26,173 : INFO : topic #1 (0.100): 0.053*\"tyler\" + 0.019*\"said\" + 0.014*\"frank\" + 0.012*\"mother\" + 0.012*\"siri\" + 0.011*\"sickle\" + 0.011*\"brother\" + 0.011*\"cell\" + 0.011*\"family\" + 0.010*\"hospital\"\n",
      "2019-10-29 00:42:26,176 : INFO : topic diff=0.890278, rho=1.000000\n",
      "2019-10-29 00:42:26,611 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:26,613 : INFO : built Dictionary(59 unique tokens: ['military', 'paris', 'french', 'two', 'death']...) from 5 documents (total 400 corpus positions)\n",
      "2019-10-29 00:42:26,614 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:26,615 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:26,617 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:26,620 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:26,621 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:26,654 : INFO : -6.525 per-word bound, 92.1 perplexity estimate based on a held-out corpus of 5 documents with 400 words\n",
      "2019-10-29 00:42:26,656 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:26,663 : INFO : topic #5 (0.100): 0.043*\"identity\" + 0.042*\"marseille\" + 0.040*\"train\" + 0.037*\"man\" + 0.034*\"station\" + 0.033*\"attacker\" + 0.029*\"sunday\" + 0.029*\"french\" + 0.028*\"charles\" + 0.025*\"authority\"\n",
      "2019-10-29 00:42:26,667 : INFO : topic #4 (0.100): 0.057*\"identity\" + 0.038*\"marseille\" + 0.033*\"man\" + 0.031*\"attacker\" + 0.030*\"train\" + 0.029*\"station\" + 0.027*\"saint\" + 0.025*\"authority\" + 0.023*\"french\" + 0.023*\"paris\"\n",
      "2019-10-29 00:42:26,672 : INFO : topic #1 (0.100): 0.054*\"identity\" + 0.041*\"station\" + 0.038*\"man\" + 0.038*\"attacker\" + 0.031*\"molins\" + 0.031*\"train\" + 0.025*\"authority\" + 0.024*\"french\" + 0.024*\"police\" + 0.023*\"paris\"\n",
      "2019-10-29 00:42:26,675 : INFO : topic #2 (0.100): 0.043*\"identity\" + 0.037*\"attacker\" + 0.037*\"train\" + 0.037*\"station\" + 0.034*\"marseille\" + 0.030*\"man\" + 0.029*\"police\" + 0.026*\"charles\" + 0.024*\"authority\" + 0.024*\"sunday\"\n",
      "2019-10-29 00:42:26,677 : INFO : topic #3 (0.100): 0.051*\"identity\" + 0.037*\"marseille\" + 0.034*\"train\" + 0.032*\"attacker\" + 0.030*\"station\" + 0.028*\"charles\" + 0.027*\"paris\" + 0.026*\"authority\" + 0.025*\"molins\" + 0.025*\"man\"\n",
      "2019-10-29 00:42:26,679 : INFO : topic diff=0.750940, rho=1.000000\n",
      "2019-10-29 00:42:27,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:27,110 : INFO : built Dictionary(275 unique tokens: ['forward', 'let', 'prime', 'party', 'come']...) from 5 documents (total 2235 corpus positions)\n",
      "2019-10-29 00:42:27,113 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:27,115 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:27,116 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:27,119 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:27,120 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:27,210 : INFO : -7.582 per-word bound, 191.5 perplexity estimate based on a held-out corpus of 5 documents with 2235 words\n",
      "2019-10-29 00:42:27,211 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:27,219 : INFO : topic #3 (0.100): 0.034*\"u\" + 0.026*\"turkish\" + 0.021*\"said\" + 0.016*\"journalist\" + 0.016*\"turkey\" + 0.013*\"ambassador\" + 0.013*\"detained\" + 0.012*\"ankara\" + 0.012*\"bass\" + 0.011*\"arrest\"\n",
      "2019-10-29 00:42:27,222 : INFO : topic #6 (0.100): 0.033*\"u\" + 0.022*\"turkish\" + 0.020*\"turkey\" + 0.016*\"said\" + 0.015*\"ankara\" + 0.013*\"arrest\" + 0.012*\"washington\" + 0.012*\"ambassador\" + 0.012*\"detained\" + 0.011*\"bass\"\n",
      "2019-10-29 00:42:27,224 : INFO : topic #4 (0.100): 0.029*\"u\" + 0.020*\"turkish\" + 0.019*\"turkey\" + 0.015*\"said\" + 0.015*\"journalist\" + 0.013*\"bass\" + 0.012*\"government\" + 0.012*\"ambassador\" + 0.011*\"ankara\" + 0.011*\"visa\"\n",
      "2019-10-29 00:42:27,227 : INFO : topic #2 (0.100): 0.027*\"u\" + 0.021*\"turkey\" + 0.020*\"turkish\" + 0.017*\"bass\" + 0.015*\"ambassador\" + 0.014*\"said\" + 0.012*\"ankara\" + 0.012*\"detained\" + 0.011*\"arrest\" + 0.010*\"erdogan\"\n",
      "2019-10-29 00:42:27,230 : INFO : topic #7 (0.100): 0.032*\"u\" + 0.023*\"turkish\" + 0.021*\"turkey\" + 0.017*\"said\" + 0.014*\"ankara\" + 0.013*\"bass\" + 0.011*\"washington\" + 0.011*\"staff\" + 0.011*\"detained\" + 0.011*\"arrest\"\n",
      "2019-10-29 00:42:27,232 : INFO : topic diff=0.855893, rho=1.000000\n",
      "2019-10-29 00:42:27,667 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:27,676 : INFO : built Dictionary(384 unique tokens: ['sucrose', 'golden', 'transport', 'enjoy', 'u']...) from 5 documents (total 3445 corpus positions)\n",
      "2019-10-29 00:42:27,685 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:27,687 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:27,695 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:27,699 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:27,702 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:27,843 : INFO : -7.753 per-word bound, 215.8 perplexity estimate based on a held-out corpus of 5 documents with 3445 words\n",
      "2019-10-29 00:42:27,844 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:27,851 : INFO : topic #8 (0.100): 0.082*\"pumpkin\" + 0.051*\"spice\" + 0.033*\"said\" + 0.013*\"food\" + 0.013*\"flavor\" + 0.010*\"brain\" + 0.010*\"used\" + 0.009*\"often\" + 0.009*\"shelke\" + 0.008*\"franssen\"\n",
      "2019-10-29 00:42:27,853 : INFO : topic #6 (0.100): 0.050*\"pumpkin\" + 0.048*\"spice\" + 0.036*\"said\" + 0.016*\"franssen\" + 0.013*\"flavor\" + 0.011*\"shelke\" + 0.010*\"food\" + 0.009*\"brain\" + 0.008*\"like\" + 0.007*\"used\"\n",
      "2019-10-29 00:42:27,856 : INFO : topic #0 (0.100): 0.063*\"pumpkin\" + 0.056*\"spice\" + 0.032*\"said\" + 0.013*\"flavor\" + 0.011*\"franssen\" + 0.011*\"shelke\" + 0.010*\"food\" + 0.010*\"used\" + 0.009*\"like\" + 0.009*\"brain\"\n",
      "2019-10-29 00:42:27,857 : INFO : topic #4 (0.100): 0.049*\"pumpkin\" + 0.042*\"spice\" + 0.039*\"said\" + 0.015*\"franssen\" + 0.014*\"shelke\" + 0.013*\"food\" + 0.011*\"flavor\" + 0.010*\"like\" + 0.009*\"used\" + 0.008*\"often\"\n",
      "2019-10-29 00:42:27,859 : INFO : topic #2 (0.100): 0.058*\"spice\" + 0.054*\"pumpkin\" + 0.039*\"said\" + 0.012*\"flavor\" + 0.012*\"franssen\" + 0.012*\"food\" + 0.010*\"brain\" + 0.009*\"mixture\" + 0.008*\"like\" + 0.008*\"baked\"\n",
      "2019-10-29 00:42:27,861 : INFO : topic diff=0.884692, rho=1.000000\n",
      "2019-10-29 00:42:28,277 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:28,282 : INFO : built Dictionary(314 unique tokens: ['concern', 'acceptable', 'small', 'crawl', 'game']...) from 5 documents (total 2685 corpus positions)\n",
      "2019-10-29 00:42:28,287 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:28,288 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:28,289 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:28,293 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:28,294 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:28,407 : INFO : -7.629 per-word bound, 197.9 perplexity estimate based on a held-out corpus of 5 documents with 2685 words\n",
      "2019-10-29 00:42:28,408 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:28,416 : INFO : topic #1 (0.100): 0.048*\"chemical\" + 0.019*\"found\" + 0.019*\"dust\" + 0.018*\"said\" + 0.015*\"home\" + 0.014*\"exposure\" + 0.013*\"child\" + 0.012*\"study\" + 0.012*\"product\" + 0.011*\"zota\"\n",
      "2019-10-29 00:42:28,418 : INFO : topic #7 (0.100): 0.031*\"chemical\" + 0.019*\"exposure\" + 0.018*\"found\" + 0.018*\"home\" + 0.017*\"said\" + 0.016*\"study\" + 0.014*\"zota\" + 0.014*\"dust\" + 0.012*\"child\" + 0.011*\"phthalates\"\n",
      "2019-10-29 00:42:28,419 : INFO : topic #2 (0.100): 0.037*\"chemical\" + 0.024*\"exposure\" + 0.020*\"found\" + 0.016*\"study\" + 0.013*\"dust\" + 0.013*\"said\" + 0.013*\"home\" + 0.013*\"product\" + 0.011*\"child\" + 0.011*\"zota\"\n",
      "2019-10-29 00:42:28,420 : INFO : topic #0 (0.100): 0.046*\"chemical\" + 0.027*\"exposure\" + 0.017*\"home\" + 0.017*\"dust\" + 0.016*\"study\" + 0.016*\"found\" + 0.013*\"zota\" + 0.010*\"said\" + 0.010*\"environmental\" + 0.010*\"child\"\n",
      "2019-10-29 00:42:28,422 : INFO : topic #3 (0.100): 0.035*\"chemical\" + 0.022*\"exposure\" + 0.022*\"found\" + 0.017*\"zota\" + 0.016*\"said\" + 0.015*\"dust\" + 0.014*\"home\" + 0.014*\"study\" + 0.013*\"child\" + 0.013*\"phthalates\"\n",
      "2019-10-29 00:42:28,424 : INFO : topic diff=0.914646, rho=1.000000\n",
      "2019-10-29 00:42:28,831 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:28,833 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:42:28,834 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:28,839 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:28,841 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:28,843 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:28,844 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:28,861 : INFO : -6.043 per-word bound, 65.9 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:42:28,862 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:28,868 : INFO : topic #7 (0.100): 0.138*\"transcript\" + 0.086*\"page\" + 0.058*\"back\" + 0.054*\"cnn\" + 0.053*\"october\" + 0.049*\"main\" + 0.049*\"new\" + 0.049*\"updated\" + 0.049*\"return\" + 0.047*\"check\"\n",
      "2019-10-29 00:42:28,871 : INFO : topic #9 (0.100): 0.142*\"transcript\" + 0.072*\"page\" + 0.058*\"new\" + 0.056*\"return\" + 0.055*\"continually\" + 0.055*\"note\" + 0.051*\"october\" + 0.051*\"available\" + 0.050*\"become\" + 0.049*\"later\"\n",
      "2019-10-29 00:42:28,874 : INFO : topic #1 (0.100): 0.133*\"transcript\" + 0.098*\"page\" + 0.054*\"available\" + 0.053*\"become\" + 0.053*\"segment\" + 0.050*\"main\" + 0.049*\"specific\" + 0.048*\"note\" + 0.048*\"updated\" + 0.046*\"back\"\n",
      "2019-10-29 00:42:28,877 : INFO : topic #0 (0.100): 0.160*\"transcript\" + 0.089*\"page\" + 0.052*\"cannot\" + 0.050*\"available\" + 0.049*\"return\" + 0.049*\"october\" + 0.047*\"note\" + 0.047*\"back\" + 0.046*\"updated\" + 0.044*\"find\"\n",
      "2019-10-29 00:42:28,881 : INFO : topic #8 (0.100): 0.172*\"transcript\" + 0.076*\"page\" + 0.052*\"cnn\" + 0.051*\"continually\" + 0.051*\"return\" + 0.050*\"updated\" + 0.050*\"become\" + 0.047*\"check\" + 0.045*\"note\" + 0.044*\"october\"\n",
      "2019-10-29 00:42:28,884 : INFO : topic diff=0.706845, rho=1.000000\n",
      "2019-10-29 00:42:29,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:29,318 : INFO : built Dictionary(281 unique tokens: ['forward', 'fox', 'energy', 'retreat', 'review']...) from 5 documents (total 2175 corpus positions)\n",
      "2019-10-29 00:42:29,321 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:29,323 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:29,326 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:29,331 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:29,334 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:29,455 : INFO : -7.671 per-word bound, 203.8 perplexity estimate based on a held-out corpus of 5 documents with 2175 words\n",
      "2019-10-29 00:42:29,457 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:29,467 : INFO : topic #8 (0.100): 0.031*\"plan\" + 0.028*\"epa\" + 0.021*\"clean\" + 0.020*\"power\" + 0.019*\"said\" + 0.015*\"repeal\" + 0.015*\"proposal\" + 0.013*\"rule\" + 0.012*\"climate\" + 0.011*\"pruitt\"\n",
      "2019-10-29 00:42:29,470 : INFO : topic #7 (0.100): 0.033*\"plan\" + 0.028*\"clean\" + 0.027*\"epa\" + 0.022*\"repeal\" + 0.020*\"said\" + 0.017*\"power\" + 0.014*\"rule\" + 0.014*\"proposal\" + 0.013*\"pruitt\" + 0.010*\"climate\"\n",
      "2019-10-29 00:42:29,473 : INFO : topic #3 (0.100): 0.030*\"plan\" + 0.029*\"clean\" + 0.028*\"power\" + 0.020*\"epa\" + 0.018*\"said\" + 0.017*\"repeal\" + 0.016*\"proposal\" + 0.013*\"rule\" + 0.013*\"pruitt\" + 0.012*\"climate\"\n",
      "2019-10-29 00:42:29,475 : INFO : topic #5 (0.100): 0.038*\"plan\" + 0.030*\"clean\" + 0.026*\"epa\" + 0.021*\"power\" + 0.018*\"repeal\" + 0.015*\"proposal\" + 0.013*\"pruitt\" + 0.013*\"said\" + 0.011*\"rule\" + 0.011*\"climate\"\n",
      "2019-10-29 00:42:29,478 : INFO : topic #4 (0.100): 0.039*\"plan\" + 0.028*\"clean\" + 0.024*\"epa\" + 0.023*\"power\" + 0.019*\"said\" + 0.019*\"proposal\" + 0.013*\"repeal\" + 0.013*\"rule\" + 0.012*\"pruitt\" + 0.010*\"climate\"\n",
      "2019-10-29 00:42:29,481 : INFO : topic diff=0.866802, rho=1.000000\n",
      "2019-10-29 00:42:29,960 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:29,966 : INFO : built Dictionary(283 unique tokens: ['although', 'womb', 'nancy', 'reach', 'happy']...) from 5 documents (total 2305 corpus positions)\n",
      "2019-10-29 00:42:29,970 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:29,972 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:29,974 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:29,977 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:29,979 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:30,100 : INFO : -7.604 per-word bound, 194.6 perplexity estimate based on a held-out corpus of 5 documents with 2305 words\n",
      "2019-10-29 00:42:30,102 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:30,111 : INFO : topic #7 (0.100): 0.034*\"dominique\" + 0.017*\"surgery\" + 0.013*\"family\" + 0.013*\"swabb\" + 0.013*\"twin\" + 0.012*\"child\" + 0.012*\"parasitic\" + 0.012*\"back\" + 0.011*\"life\" + 0.011*\"medical\"\n",
      "2019-10-29 00:42:30,113 : INFO : topic #9 (0.100): 0.043*\"dominique\" + 0.023*\"surgery\" + 0.019*\"family\" + 0.012*\"care\" + 0.012*\"twin\" + 0.011*\"swabb\" + 0.011*\"life\" + 0.011*\"parasitic\" + 0.010*\"see\" + 0.010*\"child\"\n",
      "2019-10-29 00:42:30,115 : INFO : topic #3 (0.100): 0.050*\"dominique\" + 0.016*\"surgery\" + 0.014*\"life\" + 0.013*\"family\" + 0.012*\"child\" + 0.011*\"swabb\" + 0.011*\"twin\" + 0.011*\"see\" + 0.010*\"doctor\" + 0.010*\"medical\"\n",
      "2019-10-29 00:42:30,117 : INFO : topic #4 (0.100): 0.042*\"dominique\" + 0.017*\"surgery\" + 0.015*\"twin\" + 0.015*\"swabb\" + 0.014*\"family\" + 0.012*\"life\" + 0.011*\"see\" + 0.011*\"child\" + 0.011*\"medical\" + 0.010*\"parasitic\"\n",
      "2019-10-29 00:42:30,118 : INFO : topic #8 (0.100): 0.048*\"dominique\" + 0.018*\"surgery\" + 0.016*\"family\" + 0.014*\"life\" + 0.013*\"child\" + 0.012*\"care\" + 0.011*\"twin\" + 0.011*\"home\" + 0.011*\"back\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:42:30,120 : INFO : topic diff=0.867005, rho=1.000000\n",
      "2019-10-29 00:42:30,542 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:30,545 : INFO : built Dictionary(241 unique tokens: ['racked', 'cylinder', 'stop', 'translated', 'ride']...) from 5 documents (total 1735 corpus positions)\n",
      "2019-10-29 00:42:30,550 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:30,552 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:30,556 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:30,560 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:30,567 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:30,659 : INFO : -7.640 per-word bound, 199.5 perplexity estimate based on a held-out corpus of 5 documents with 1735 words\n",
      "2019-10-29 00:42:30,661 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:30,669 : INFO : topic #2 (0.100): 0.042*\"bentley\" + 0.029*\"car\" + 0.020*\"roll\" + 0.016*\"like\" + 0.014*\"race\" + 0.014*\"gooding\" + 0.012*\"owned\" + 0.012*\"royce\" + 0.010*\"would\" + 0.010*\"mile\"\n",
      "2019-10-29 00:42:30,672 : INFO : topic #6 (0.100): 0.028*\"car\" + 0.027*\"bentley\" + 0.019*\"like\" + 0.016*\"race\" + 0.015*\"roll\" + 0.013*\"gooding\" + 0.012*\"royce\" + 0.010*\"owned\" + 0.010*\"could\" + 0.010*\"speed\"\n",
      "2019-10-29 00:42:30,675 : INFO : topic #1 (0.100): 0.027*\"bentley\" + 0.021*\"car\" + 0.019*\"like\" + 0.018*\"roll\" + 0.016*\"race\" + 0.014*\"owned\" + 0.013*\"gooding\" + 0.010*\"royce\" + 0.010*\"big\" + 0.010*\"hour\"\n",
      "2019-10-29 00:42:30,678 : INFO : topic #4 (0.100): 0.043*\"bentley\" + 0.029*\"car\" + 0.017*\"race\" + 0.016*\"like\" + 0.014*\"roll\" + 0.013*\"gooding\" + 0.012*\"royce\" + 0.011*\"owned\" + 0.009*\"hour\" + 0.009*\"would\"\n",
      "2019-10-29 00:42:30,682 : INFO : topic #3 (0.100): 0.032*\"bentley\" + 0.029*\"car\" + 0.018*\"like\" + 0.015*\"roll\" + 0.014*\"race\" + 0.013*\"gooding\" + 0.011*\"royce\" + 0.009*\"mile\" + 0.009*\"big\" + 0.009*\"could\"\n",
      "2019-10-29 00:42:30,685 : INFO : topic diff=0.788947, rho=1.000000\n",
      "2019-10-29 00:42:31,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:31,109 : INFO : built Dictionary(127 unique tokens: ['freelance', 'fox', 'story', 'doc', 'life']...) from 5 documents (total 810 corpus positions)\n",
      "2019-10-29 00:42:31,111 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:31,113 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:31,115 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:31,119 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:31,120 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:31,183 : INFO : -7.275 per-word bound, 154.9 perplexity estimate based on a held-out corpus of 5 documents with 810 words\n",
      "2019-10-29 00:42:31,184 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:31,195 : INFO : topic #5 (0.100): 0.027*\"jaw\" + 0.026*\"shark\" + 0.022*\"movie\" + 0.020*\"back\" + 0.020*\"came\" + 0.019*\"future\" + 0.018*\"prediction\" + 0.018*\"day\" + 0.017*\"true\" + 0.014*\"time\"\n",
      "2019-10-29 00:42:31,198 : INFO : topic #6 (0.100): 0.040*\"jaw\" + 0.024*\"shark\" + 0.023*\"back\" + 0.023*\"future\" + 0.022*\"true\" + 0.021*\"david\" + 0.020*\"wheeler\" + 0.019*\"prediction\" + 0.019*\"day\" + 0.018*\"movie\"\n",
      "2019-10-29 00:42:31,203 : INFO : topic #1 (0.100): 0.027*\"movie\" + 0.026*\"jaw\" + 0.024*\"shark\" + 0.021*\"back\" + 0.020*\"future\" + 0.020*\"wheeler\" + 0.018*\"day\" + 0.017*\"came\" + 0.016*\"david\" + 0.015*\"true\"\n",
      "2019-10-29 00:42:31,205 : INFO : topic #2 (0.100): 0.033*\"shark\" + 0.027*\"future\" + 0.024*\"back\" + 0.022*\"david\" + 0.022*\"movie\" + 0.022*\"jaw\" + 0.017*\"day\" + 0.017*\"prediction\" + 0.016*\"came\" + 0.015*\"wheeler\"\n",
      "2019-10-29 00:42:31,208 : INFO : topic #0 (0.100): 0.029*\"shark\" + 0.024*\"movie\" + 0.023*\"jaw\" + 0.019*\"back\" + 0.018*\"prediction\" + 0.018*\"day\" + 0.018*\"future\" + 0.018*\"true\" + 0.017*\"came\" + 0.015*\"wheeler\"\n",
      "2019-10-29 00:42:31,210 : INFO : topic diff=0.762520, rho=1.000000\n",
      "2019-10-29 00:42:31,698 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:31,704 : INFO : built Dictionary(451 unique tokens: ['mirrored', 'located', 'footprint', 'laboratory', 'party']...) from 5 documents (total 3800 corpus positions)\n",
      "2019-10-29 00:42:31,709 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:31,710 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:31,711 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:31,716 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:31,718 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:31,860 : INFO : -7.997 per-word bound, 255.5 perplexity estimate based on a held-out corpus of 5 documents with 3800 words\n",
      "2019-10-29 00:42:31,862 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:31,870 : INFO : topic #2 (0.100): 0.038*\"house\" + 0.014*\"los\" + 0.013*\"angeles\" + 0.013*\"california\" + 0.012*\"tour\" + 0.010*\"hollyhock\" + 0.010*\"schindler\" + 0.009*\"wright\" + 0.009*\"architecture\" + 0.007*\"space\"\n",
      "2019-10-29 00:42:31,871 : INFO : topic #8 (0.100): 0.030*\"house\" + 0.014*\"california\" + 0.012*\"architecture\" + 0.011*\"los\" + 0.011*\"angeles\" + 0.010*\"hollyhock\" + 0.010*\"neutra\" + 0.010*\"tour\" + 0.010*\"home\" + 0.009*\"schindler\"\n",
      "2019-10-29 00:42:31,873 : INFO : topic #0 (0.100): 0.051*\"house\" + 0.013*\"los\" + 0.013*\"california\" + 0.012*\"tour\" + 0.012*\"neutra\" + 0.011*\"hollyhock\" + 0.010*\"schindler\" + 0.009*\"angeles\" + 0.008*\"wright\" + 0.007*\"home\"\n",
      "2019-10-29 00:42:31,874 : INFO : topic #3 (0.100): 0.048*\"house\" + 0.013*\"hollyhock\" + 0.012*\"california\" + 0.012*\"architecture\" + 0.011*\"schindler\" + 0.011*\"angeles\" + 0.011*\"los\" + 0.011*\"neutra\" + 0.010*\"wright\" + 0.009*\"tour\"\n",
      "2019-10-29 00:42:31,876 : INFO : topic #9 (0.100): 0.031*\"house\" + 0.015*\"los\" + 0.014*\"angeles\" + 0.014*\"california\" + 0.010*\"tour\" + 0.009*\"architecture\" + 0.009*\"hollyhock\" + 0.009*\"neutra\" + 0.008*\"stahl\" + 0.008*\"vdl\"\n",
      "2019-10-29 00:42:31,878 : INFO : topic diff=0.930721, rho=1.000000\n",
      "2019-10-29 00:42:32,271 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:32,274 : INFO : built Dictionary(142 unique tokens: ['school', 'part', 'biodiversity', 'endangered', 'series']...) from 5 documents (total 975 corpus positions)\n",
      "2019-10-29 00:42:32,278 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:32,281 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:32,284 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:32,288 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:32,291 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:32,354 : INFO : -7.236 per-word bound, 150.7 perplexity estimate based on a held-out corpus of 5 documents with 975 words\n",
      "2019-10-29 00:42:32,355 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:32,360 : INFO : topic #7 (0.100): 0.042*\"durian\" + 0.022*\"said\" + 0.022*\"fruit\" + 0.021*\"gene\" + 0.020*\"smell\" + 0.017*\"team\" + 0.016*\"plant\" + 0.015*\"teh\" + 0.013*\"variety\" + 0.013*\"also\"\n",
      "2019-10-29 00:42:32,363 : INFO : topic #9 (0.100): 0.064*\"durian\" + 0.021*\"team\" + 0.018*\"fruit\" + 0.018*\"smell\" + 0.017*\"said\" + 0.016*\"variety\" + 0.015*\"gene\" + 0.015*\"teh\" + 0.015*\"also\" + 0.014*\"plant\"\n",
      "2019-10-29 00:42:32,364 : INFO : topic #5 (0.100): 0.050*\"durian\" + 0.021*\"gene\" + 0.021*\"smell\" + 0.021*\"fruit\" + 0.020*\"team\" + 0.020*\"said\" + 0.018*\"variety\" + 0.018*\"teh\" + 0.015*\"plant\" + 0.013*\"also\"\n",
      "2019-10-29 00:42:32,370 : INFO : topic #0 (0.100): 0.050*\"durian\" + 0.020*\"fruit\" + 0.019*\"said\" + 0.018*\"smell\" + 0.017*\"gene\" + 0.016*\"also\" + 0.016*\"plant\" + 0.015*\"team\" + 0.014*\"variety\" + 0.013*\"king\"\n",
      "2019-10-29 00:42:32,374 : INFO : topic #6 (0.100): 0.059*\"durian\" + 0.020*\"said\" + 0.018*\"gene\" + 0.018*\"fruit\" + 0.017*\"team\" + 0.015*\"also\" + 0.015*\"plant\" + 0.015*\"variety\" + 0.014*\"smell\" + 0.013*\"teh\"\n",
      "2019-10-29 00:42:32,376 : INFO : topic diff=0.768725, rho=1.000000\n",
      "2019-10-29 00:42:32,829 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:32,833 : INFO : built Dictionary(119 unique tokens: ['rage', 'ch', 'rockhall', 'special', 'industry']...) from 5 documents (total 915 corpus positions)\n",
      "2019-10-29 00:42:32,836 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:32,839 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:32,841 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:32,843 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:32,845 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:32,904 : INFO : -6.895 per-word bound, 119.0 perplexity estimate based on a held-out corpus of 5 documents with 915 words\n",
      "2019-10-29 00:42:32,908 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:32,915 : INFO : topic #9 (0.100): 0.033*\"fame\" + 0.032*\"hall\" + 0.025*\"nominee\" + 0.025*\"induction\" + 0.024*\"year\" + 0.023*\"ballot\" + 0.022*\"rock\" + 0.022*\"fan\" + 0.021*\"announced\" + 0.019*\"inductee\"\n",
      "2019-10-29 00:42:32,919 : INFO : topic #2 (0.100): 0.033*\"hall\" + 0.031*\"induction\" + 0.031*\"nominee\" + 0.028*\"rock\" + 0.026*\"year\" + 0.026*\"fame\" + 0.021*\"broadcast\" + 0.021*\"ballot\" + 0.018*\"announced\" + 0.017*\"artist\"\n",
      "2019-10-29 00:42:32,924 : INFO : topic #1 (0.100): 0.035*\"induction\" + 0.034*\"hall\" + 0.028*\"fame\" + 0.027*\"year\" + 0.025*\"rock\" + 0.024*\"nominee\" + 0.022*\"announced\" + 0.021*\"roll\" + 0.020*\"broadcast\" + 0.020*\"ballot\"\n",
      "2019-10-29 00:42:32,927 : INFO : topic #3 (0.100): 0.032*\"induction\" + 0.032*\"hall\" + 0.029*\"fame\" + 0.027*\"roll\" + 0.025*\"fan\" + 0.021*\"announced\" + 0.021*\"nominee\" + 0.021*\"broadcast\" + 0.019*\"rock\" + 0.017*\"vote\"\n",
      "2019-10-29 00:42:32,930 : INFO : topic #7 (0.100): 0.035*\"hall\" + 0.033*\"year\" + 0.032*\"induction\" + 0.029*\"fame\" + 0.027*\"nominee\" + 0.027*\"announced\" + 0.025*\"rock\" + 0.022*\"roll\" + 0.021*\"ballot\" + 0.020*\"fan\"\n",
      "2019-10-29 00:42:32,933 : INFO : topic diff=0.879825, rho=1.000000\n",
      "2019-10-29 00:42:33,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:33,365 : INFO : built Dictionary(307 unique tokens: ['anniversary', 'let', 'seems', 'pulpit', 'nation']...) from 5 documents (total 2350 corpus positions)\n",
      "2019-10-29 00:42:33,368 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:33,369 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:33,370 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:33,375 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:33,377 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:33,476 : INFO : -7.765 per-word bound, 217.6 perplexity estimate based on a held-out corpus of 5 documents with 2350 words\n",
      "2019-10-29 00:42:33,478 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:33,484 : INFO : topic #7 (0.100): 0.052*\"trump\" + 0.038*\"comedian\" + 0.019*\"president\" + 0.016*\"late\" + 0.015*\"night\" + 0.011*\"even\" + 0.010*\"show\" + 0.009*\"time\" + 0.008*\"mocking\" + 0.008*\"one\"\n",
      "2019-10-29 00:42:33,487 : INFO : topic #2 (0.100): 0.058*\"trump\" + 0.031*\"comedian\" + 0.021*\"night\" + 0.019*\"president\" + 0.012*\"late\" + 0.011*\"show\" + 0.009*\"one\" + 0.009*\"mocking\" + 0.008*\"twitter\" + 0.007*\"time\"\n",
      "2019-10-29 00:42:33,489 : INFO : topic #5 (0.100): 0.049*\"trump\" + 0.034*\"comedian\" + 0.018*\"president\" + 0.018*\"late\" + 0.016*\"night\" + 0.009*\"even\" + 0.009*\"show\" + 0.009*\"one\" + 0.009*\"time\" + 0.008*\"twitter\"\n",
      "2019-10-29 00:42:33,492 : INFO : topic #4 (0.100): 0.056*\"trump\" + 0.033*\"comedian\" + 0.018*\"night\" + 0.018*\"president\" + 0.017*\"late\" + 0.012*\"time\" + 0.012*\"even\" + 0.011*\"show\" + 0.010*\"twitter\" + 0.009*\"mocking\"\n",
      "2019-10-29 00:42:33,495 : INFO : topic #1 (0.100): 0.059*\"trump\" + 0.033*\"comedian\" + 0.016*\"president\" + 0.015*\"late\" + 0.015*\"night\" + 0.010*\"even\" + 0.009*\"time\" + 0.008*\"right\" + 0.008*\"show\" + 0.008*\"one\"\n",
      "2019-10-29 00:42:33,497 : INFO : topic diff=0.826973, rho=1.000000\n",
      "2019-10-29 00:42:33,899 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:33,902 : INFO : built Dictionary(149 unique tokens: ['directly', 'product', 'branded', 'kitchen', 'come']...) from 5 documents (total 990 corpus positions)\n",
      "2019-10-29 00:42:33,904 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:33,908 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:33,911 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:33,915 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:33,918 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:33,987 : INFO : -7.340 per-word bound, 162.0 perplexity estimate based on a held-out corpus of 5 documents with 990 words\n",
      "2019-10-29 00:42:33,990 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:33,994 : INFO : topic #1 (0.100): 0.045*\"brand\" + 0.031*\"brandless\" + 0.025*\"sharkey\" + 0.025*\"product\" + 0.025*\"big\" + 0.014*\"buying\" + 0.013*\"launched\" + 0.013*\"shopper\" + 0.012*\"retailer\" + 0.011*\"item\"\n",
      "2019-10-29 00:42:33,997 : INFO : topic #5 (0.100): 0.039*\"brandless\" + 0.032*\"brand\" + 0.027*\"product\" + 0.022*\"sharkey\" + 0.017*\"big\" + 0.016*\"item\" + 0.015*\"buying\" + 0.014*\"name\" + 0.012*\"quality\" + 0.012*\"affordable\"\n",
      "2019-10-29 00:42:33,999 : INFO : topic #9 (0.100): 0.045*\"brand\" + 0.029*\"brandless\" + 0.028*\"sharkey\" + 0.020*\"product\" + 0.015*\"item\" + 0.013*\"big\" + 0.013*\"want\" + 0.013*\"buying\" + 0.012*\"name\" + 0.011*\"affordable\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:34,002 : INFO : topic #6 (0.100): 0.039*\"brandless\" + 0.029*\"brand\" + 0.026*\"product\" + 0.020*\"sharkey\" + 0.020*\"big\" + 0.015*\"item\" + 0.015*\"buying\" + 0.014*\"name\" + 0.012*\"cost\" + 0.011*\"price\"\n",
      "2019-10-29 00:42:34,005 : INFO : topic #0 (0.100): 0.041*\"brandless\" + 0.038*\"brand\" + 0.023*\"big\" + 0.023*\"sharkey\" + 0.019*\"product\" + 0.016*\"item\" + 0.014*\"buying\" + 0.012*\"saving\" + 0.012*\"store\" + 0.011*\"term\"\n",
      "2019-10-29 00:42:34,007 : INFO : topic diff=0.761666, rho=1.000000\n",
      "2019-10-29 00:42:34,454 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:34,460 : INFO : built Dictionary(440 unique tokens: ['let', 'real', 'happy', 'hero', 'advantage']...) from 5 documents (total 4740 corpus positions)\n",
      "2019-10-29 00:42:34,466 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:34,467 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:34,468 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:34,472 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:34,474 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:34,602 : INFO : -7.676 per-word bound, 204.5 perplexity estimate based on a held-out corpus of 5 documents with 4740 words\n",
      "2019-10-29 00:42:34,603 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:34,612 : INFO : topic #9 (0.100): 0.039*\"said\" + 0.039*\"girl\" + 0.038*\"boy\" + 0.020*\"gender\" + 0.018*\"child\" + 0.015*\"kid\" + 0.014*\"say\" + 0.013*\"thing\" + 0.011*\"daughter\" + 0.010*\"hurley\"\n",
      "2019-10-29 00:42:34,613 : INFO : topic #6 (0.100): 0.057*\"girl\" + 0.044*\"said\" + 0.031*\"boy\" + 0.021*\"gender\" + 0.016*\"say\" + 0.015*\"kid\" + 0.015*\"child\" + 0.013*\"like\" + 0.010*\"hurley\" + 0.010*\"daughter\"\n",
      "2019-10-29 00:42:34,615 : INFO : topic #7 (0.100): 0.045*\"boy\" + 0.045*\"girl\" + 0.039*\"said\" + 0.017*\"gender\" + 0.015*\"kid\" + 0.015*\"child\" + 0.015*\"say\" + 0.014*\"hurley\" + 0.010*\"get\" + 0.010*\"would\"\n",
      "2019-10-29 00:42:34,618 : INFO : topic #0 (0.100): 0.045*\"girl\" + 0.036*\"boy\" + 0.030*\"said\" + 0.016*\"hurley\" + 0.016*\"gender\" + 0.015*\"say\" + 0.013*\"child\" + 0.012*\"like\" + 0.011*\"parent\" + 0.011*\"kid\"\n",
      "2019-10-29 00:42:34,619 : INFO : topic #1 (0.100): 0.071*\"girl\" + 0.033*\"said\" + 0.028*\"boy\" + 0.017*\"gender\" + 0.016*\"kid\" + 0.012*\"hurley\" + 0.012*\"like\" + 0.011*\"child\" + 0.011*\"say\" + 0.010*\"would\"\n",
      "2019-10-29 00:42:34,621 : INFO : topic diff=1.001522, rho=1.000000\n",
      "2019-10-29 00:42:35,055 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:35,058 : INFO : built Dictionary(193 unique tokens: ['let', 'campaign', 'marched', 'hunt', 'recent']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:42:35,060 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:35,062 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:35,063 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:35,066 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:35,071 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:35,164 : INFO : -7.839 per-word bound, 228.9 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:42:35,166 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:35,174 : INFO : topic #9 (0.100): 0.014*\"started\" + 0.013*\"found\" + 0.012*\"cartoon\" + 0.012*\"political\" + 0.011*\"view\" + 0.011*\"first\" + 0.010*\"two\" + 0.010*\"hearing\" + 0.010*\"candidate\" + 0.010*\"campaign\"\n",
      "2019-10-29 00:42:35,177 : INFO : topic #7 (0.100): 0.014*\"friend\" + 0.014*\"political\" + 0.014*\"found\" + 0.013*\"started\" + 0.013*\"cartoon\" + 0.012*\"first\" + 0.010*\"mcclure\" + 0.010*\"nation\" + 0.010*\"view\" + 0.010*\"hearing\"\n",
      "2019-10-29 00:42:35,180 : INFO : topic #3 (0.100): 0.014*\"first\" + 0.013*\"cartoon\" + 0.012*\"political\" + 0.011*\"friend\" + 0.011*\"started\" + 0.010*\"mcclure\" + 0.010*\"found\" + 0.010*\"two\" + 0.010*\"season\" + 0.010*\"amazing\"\n",
      "2019-10-29 00:42:35,183 : INFO : topic #0 (0.100): 0.015*\"started\" + 0.011*\"view\" + 0.011*\"first\" + 0.011*\"found\" + 0.010*\"friend\" + 0.010*\"hearing\" + 0.010*\"political\" + 0.010*\"cartoon\" + 0.009*\"year\" + 0.009*\"thomas\"\n",
      "2019-10-29 00:42:35,187 : INFO : topic #6 (0.100): 0.015*\"friend\" + 0.014*\"found\" + 0.014*\"political\" + 0.013*\"cartoon\" + 0.012*\"first\" + 0.010*\"debate\" + 0.010*\"two\" + 0.009*\"get\" + 0.009*\"election\" + 0.009*\"mcclure\"\n",
      "2019-10-29 00:42:35,190 : INFO : topic diff=0.651714, rho=1.000000\n",
      "2019-10-29 00:42:35,618 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:35,626 : INFO : built Dictionary(290 unique tokens: ['prime', 'attacked', 'deep', 'military', 'regime']...) from 5 documents (total 2160 corpus positions)\n",
      "2019-10-29 00:42:35,632 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:35,634 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:35,635 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:35,638 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:35,641 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:35,755 : INFO : -7.757 per-word bound, 216.4 perplexity estimate based on a held-out corpus of 5 documents with 2160 words\n",
      "2019-10-29 00:42:35,757 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:35,765 : INFO : topic #4 (0.100): 0.040*\"hezbollah\" + 0.021*\"u\" + 0.019*\"group\" + 0.016*\"trump\" + 0.016*\"wing\" + 0.012*\"homeland\" + 0.011*\"organization\" + 0.011*\"administration\" + 0.010*\"state\" + 0.009*\"said\"\n",
      "2019-10-29 00:42:35,768 : INFO : topic #7 (0.100): 0.035*\"hezbollah\" + 0.021*\"group\" + 0.021*\"u\" + 0.015*\"trump\" + 0.013*\"wing\" + 0.012*\"homeland\" + 0.010*\"said\" + 0.010*\"state\" + 0.009*\"organization\" + 0.008*\"administration\"\n",
      "2019-10-29 00:42:35,771 : INFO : topic #2 (0.100): 0.042*\"hezbollah\" + 0.017*\"u\" + 0.016*\"organization\" + 0.014*\"group\" + 0.013*\"trump\" + 0.013*\"wing\" + 0.012*\"said\" + 0.012*\"official\" + 0.011*\"homeland\" + 0.009*\"political\"\n",
      "2019-10-29 00:42:35,774 : INFO : topic #0 (0.100): 0.040*\"hezbollah\" + 0.020*\"wing\" + 0.018*\"group\" + 0.017*\"u\" + 0.013*\"trump\" + 0.013*\"organization\" + 0.012*\"said\" + 0.012*\"homeland\" + 0.010*\"administration\" + 0.010*\"state\"\n",
      "2019-10-29 00:42:35,777 : INFO : topic #3 (0.100): 0.043*\"hezbollah\" + 0.021*\"group\" + 0.018*\"trump\" + 0.017*\"u\" + 0.011*\"administration\" + 0.011*\"organization\" + 0.010*\"wing\" + 0.010*\"official\" + 0.009*\"state\" + 0.009*\"sale\"\n",
      "2019-10-29 00:42:35,781 : INFO : topic diff=0.810801, rho=1.000000\n",
      "2019-10-29 00:42:36,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:36,266 : INFO : built Dictionary(343 unique tokens: ['strain', 'backlash', 'expert', 'u', 'sought']...) from 5 documents (total 2575 corpus positions)\n",
      "2019-10-29 00:42:36,272 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:36,275 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:36,276 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:36,280 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:36,283 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:36,410 : INFO : -7.906 per-word bound, 239.8 perplexity estimate based on a held-out corpus of 5 documents with 2575 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:36,412 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:36,419 : INFO : topic #6 (0.100): 0.024*\"marijuana\" + 0.017*\"legalization\" + 0.015*\"cannabis\" + 0.015*\"south\" + 0.012*\"lesotho\" + 0.011*\"year\" + 0.010*\"african\" + 0.010*\"legal\" + 0.010*\"according\" + 0.009*\"continent\"\n",
      "2019-10-29 00:42:36,422 : INFO : topic #3 (0.100): 0.021*\"marijuana\" + 0.014*\"south\" + 0.013*\"according\" + 0.012*\"cannabis\" + 0.012*\"legalization\" + 0.011*\"africa\" + 0.011*\"year\" + 0.010*\"legal\" + 0.010*\"government\" + 0.009*\"medical\"\n",
      "2019-10-29 00:42:36,424 : INFO : topic #5 (0.100): 0.026*\"marijuana\" + 0.014*\"south\" + 0.013*\"legalization\" + 0.013*\"according\" + 0.011*\"cannabis\" + 0.011*\"africa\" + 0.010*\"year\" + 0.010*\"legal\" + 0.009*\"malawi\" + 0.009*\"continent\"\n",
      "2019-10-29 00:42:36,427 : INFO : topic #8 (0.100): 0.028*\"marijuana\" + 0.015*\"cannabis\" + 0.013*\"south\" + 0.012*\"africa\" + 0.011*\"according\" + 0.011*\"year\" + 0.010*\"legalization\" + 0.010*\"could\" + 0.010*\"african\" + 0.009*\"malawi\"\n",
      "2019-10-29 00:42:36,429 : INFO : topic #7 (0.100): 0.030*\"marijuana\" + 0.014*\"legalization\" + 0.014*\"south\" + 0.011*\"cannabis\" + 0.011*\"year\" + 0.011*\"government\" + 0.010*\"africa\" + 0.010*\"according\" + 0.009*\"lesotho\" + 0.008*\"legal\"\n",
      "2019-10-29 00:42:36,431 : INFO : topic diff=0.804449, rho=1.000000\n",
      "2019-10-29 00:42:36,835 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:36,839 : INFO : built Dictionary(275 unique tokens: ['forward', 'let', 'prime', 'party', 'come']...) from 5 documents (total 2235 corpus positions)\n",
      "2019-10-29 00:42:36,842 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:36,844 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:36,846 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:36,849 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:36,851 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:36,958 : INFO : -7.573 per-word bound, 190.4 perplexity estimate based on a held-out corpus of 5 documents with 2235 words\n",
      "2019-10-29 00:42:36,960 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:36,967 : INFO : topic #3 (0.100): 0.021*\"u\" + 0.020*\"turkish\" + 0.017*\"turkey\" + 0.016*\"said\" + 0.015*\"washington\" + 0.013*\"bass\" + 0.012*\"ankara\" + 0.011*\"ambassador\" + 0.011*\"detained\" + 0.010*\"arrest\"\n",
      "2019-10-29 00:42:36,970 : INFO : topic #1 (0.100): 0.034*\"u\" + 0.025*\"turkish\" + 0.020*\"turkey\" + 0.014*\"ambassador\" + 0.014*\"journalist\" + 0.013*\"government\" + 0.013*\"bass\" + 0.013*\"said\" + 0.012*\"ankara\" + 0.011*\"detained\"\n",
      "2019-10-29 00:42:36,973 : INFO : topic #5 (0.100): 0.025*\"u\" + 0.022*\"turkish\" + 0.020*\"turkey\" + 0.017*\"said\" + 0.017*\"journalist\" + 0.015*\"ambassador\" + 0.012*\"bass\" + 0.012*\"arrest\" + 0.011*\"washington\" + 0.011*\"ankara\"\n",
      "2019-10-29 00:42:36,975 : INFO : topic #9 (0.100): 0.035*\"u\" + 0.024*\"turkey\" + 0.017*\"bass\" + 0.015*\"ambassador\" + 0.015*\"said\" + 0.014*\"turkish\" + 0.012*\"journalist\" + 0.010*\"ankara\" + 0.009*\"wednesday\" + 0.009*\"staff\"\n",
      "2019-10-29 00:42:36,978 : INFO : topic #8 (0.100): 0.029*\"u\" + 0.022*\"turkey\" + 0.020*\"turkish\" + 0.015*\"bass\" + 0.015*\"said\" + 0.014*\"ankara\" + 0.011*\"journalist\" + 0.011*\"ambassador\" + 0.010*\"visa\" + 0.010*\"government\"\n",
      "2019-10-29 00:42:36,980 : INFO : topic diff=0.847234, rho=1.000000\n",
      "2019-10-29 00:42:37,428 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:37,435 : INFO : built Dictionary(354 unique tokens: ['let', 'happy', 'backlash', 'lemming', 'game']...) from 5 documents (total 2875 corpus positions)\n",
      "2019-10-29 00:42:37,441 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:37,442 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:37,443 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:37,446 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:37,449 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:37,555 : INFO : -7.816 per-word bound, 225.4 perplexity estimate based on a held-out corpus of 5 documents with 2875 words\n",
      "2019-10-29 00:42:37,556 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:37,565 : INFO : topic #3 (0.100): 0.021*\"hill\" + 0.015*\"espn\" + 0.015*\"tweet\" + 0.014*\"jemele\" + 0.012*\"advertiser\" + 0.010*\"cowboy\" + 0.010*\"player\" + 0.009*\"jones\" + 0.009*\"october\" + 0.009*\"fear\"\n",
      "2019-10-29 00:42:37,567 : INFO : topic #7 (0.100): 0.031*\"hill\" + 0.022*\"jemele\" + 0.014*\"tweet\" + 0.014*\"espn\" + 0.011*\"advertiser\" + 0.011*\"cowboy\" + 0.010*\"http\" + 0.009*\"one\" + 0.009*\"strongly\" + 0.008*\"jones\"\n",
      "2019-10-29 00:42:37,570 : INFO : topic #5 (0.100): 0.024*\"hill\" + 0.016*\"advertiser\" + 0.016*\"espn\" + 0.014*\"tweet\" + 0.014*\"jemele\" + 0.014*\"cowboy\" + 0.010*\"fear\" + 0.009*\"make\" + 0.009*\"co\" + 0.008*\"october\"\n",
      "2019-10-29 00:42:37,572 : INFO : topic #0 (0.100): 0.028*\"hill\" + 0.018*\"jemele\" + 0.016*\"espn\" + 0.013*\"tweet\" + 0.012*\"cowboy\" + 0.010*\"step\" + 0.010*\"advertiser\" + 0.010*\"jones\" + 0.010*\"make\" + 0.009*\"jerry\"\n",
      "2019-10-29 00:42:37,575 : INFO : topic #4 (0.100): 0.024*\"hill\" + 0.023*\"tweet\" + 0.014*\"jemele\" + 0.013*\"cowboy\" + 0.012*\"espn\" + 0.012*\"advertiser\" + 0.010*\"step\" + 0.010*\"jones\" + 0.009*\"jemelehill\" + 0.009*\"make\"\n",
      "2019-10-29 00:42:37,578 : INFO : topic diff=0.820497, rho=1.000000\n",
      "2019-10-29 00:42:37,974 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:37,976 : INFO : built Dictionary(144 unique tokens: ['violence', 'relation', 'security', 'catalonia', 'recently']...) from 5 documents (total 935 corpus positions)\n",
      "2019-10-29 00:42:37,979 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:37,980 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:37,982 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:37,985 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:37,986 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:38,050 : INFO : -7.349 per-word bound, 163.0 perplexity estimate based on a held-out corpus of 5 documents with 935 words\n",
      "2019-10-29 00:42:38,051 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:38,057 : INFO : topic #9 (0.100): 0.030*\"vote\" + 0.027*\"catalan\" + 0.025*\"spanish\" + 0.024*\"government\" + 0.022*\"referendum\" + 0.017*\"catalonia\" + 0.015*\"right\" + 0.015*\"viñolas\" + 0.014*\"world\" + 0.013*\"gloria\"\n",
      "2019-10-29 00:42:38,059 : INFO : topic #4 (0.100): 0.033*\"spanish\" + 0.024*\"government\" + 0.022*\"catalonia\" + 0.020*\"vote\" + 0.020*\"catalan\" + 0.018*\"viñolas\" + 0.016*\"referendum\" + 0.013*\"gloria\" + 0.013*\"witnessed\" + 0.013*\"right\"\n",
      "2019-10-29 00:42:38,061 : INFO : topic #2 (0.100): 0.033*\"spanish\" + 0.024*\"catalan\" + 0.023*\"referendum\" + 0.022*\"vote\" + 0.021*\"government\" + 0.018*\"catalonia\" + 0.016*\"viñolas\" + 0.015*\"gloria\" + 0.015*\"right\" + 0.012*\"violence\"\n",
      "2019-10-29 00:42:38,063 : INFO : topic #6 (0.100): 0.026*\"catalonia\" + 0.026*\"spanish\" + 0.023*\"government\" + 0.020*\"vote\" + 0.018*\"catalan\" + 0.017*\"gloria\" + 0.016*\"referendum\" + 0.016*\"viñolas\" + 0.013*\"right\" + 0.013*\"democracy\"\n",
      "2019-10-29 00:42:38,064 : INFO : topic #8 (0.100): 0.027*\"spanish\" + 0.025*\"catalonia\" + 0.022*\"referendum\" + 0.021*\"government\" + 0.020*\"vote\" + 0.017*\"right\" + 0.017*\"gloria\" + 0.016*\"catalan\" + 0.014*\"viñolas\" + 0.013*\"people\"\n",
      "2019-10-29 00:42:38,066 : INFO : topic diff=0.757185, rho=1.000000\n",
      "2019-10-29 00:42:38,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:38,461 : INFO : built Dictionary(100 unique tokens: ['end', 'fate', 'topic', 'summit', 'diane']...) from 5 documents (total 690 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:38,464 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:38,468 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:38,470 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:38,474 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:38,477 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:38,537 : INFO : -6.919 per-word bound, 121.0 perplexity estimate based on a held-out corpus of 5 documents with 690 words\n",
      "2019-10-29 00:42:38,540 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:38,551 : INFO : topic #2 (0.100): 0.034*\"trump\" + 0.025*\"ivanka\" + 0.024*\"woman\" + 0.023*\"program\" + 0.018*\"issue\" + 0.017*\"month\" + 0.017*\"complicated\" + 0.016*\"immigration\" + 0.016*\"long\" + 0.016*\"act\"\n",
      "2019-10-29 00:42:38,553 : INFO : topic #6 (0.100): 0.052*\"trump\" + 0.028*\"ivanka\" + 0.024*\"issue\" + 0.017*\"immigration\" + 0.016*\"program\" + 0.016*\"young\" + 0.016*\"woman\" + 0.016*\"long\" + 0.015*\"dreamer\" + 0.015*\"month\"\n",
      "2019-10-29 00:42:38,556 : INFO : topic #1 (0.100): 0.035*\"trump\" + 0.026*\"woman\" + 0.021*\"immigration\" + 0.020*\"program\" + 0.020*\"ivanka\" + 0.018*\"topic\" + 0.017*\"congressional\" + 0.017*\"issue\" + 0.016*\"powerful\" + 0.016*\"childhood\"\n",
      "2019-10-29 00:42:38,568 : INFO : topic #7 (0.100): 0.031*\"trump\" + 0.029*\"ivanka\" + 0.026*\"issue\" + 0.024*\"immigration\" + 0.020*\"woman\" + 0.018*\"monday\" + 0.018*\"program\" + 0.017*\"congress\" + 0.016*\"arrival\" + 0.016*\"deferred\"\n",
      "2019-10-29 00:42:38,578 : INFO : topic #4 (0.100): 0.038*\"trump\" + 0.022*\"ivanka\" + 0.021*\"issue\" + 0.020*\"program\" + 0.019*\"need\" + 0.019*\"immigration\" + 0.019*\"powerful\" + 0.018*\"fortune\" + 0.017*\"action\" + 0.017*\"woman\"\n",
      "2019-10-29 00:42:38,582 : INFO : topic diff=0.712306, rho=1.000000\n",
      "2019-10-29 00:42:39,016 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:39,023 : INFO : built Dictionary(293 unique tokens: ['cortex', 'ghostly', 'bone', 'campaign', 'playboy']...) from 5 documents (total 2315 corpus positions)\n",
      "2019-10-29 00:42:39,028 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:39,030 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:39,032 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:39,036 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:39,037 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:39,178 : INFO : -7.678 per-word bound, 204.8 perplexity estimate based on a held-out corpus of 5 documents with 2315 words\n",
      "2019-10-29 00:42:39,180 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:39,188 : INFO : topic #8 (0.100): 0.028*\"image\" + 0.028*\"eckert\" + 0.018*\"sound\" + 0.015*\"see\" + 0.014*\"would\" + 0.012*\"pete\" + 0.012*\"photography\" + 0.010*\"said\" + 0.010*\"mind\" + 0.010*\"touch\"\n",
      "2019-10-29 00:42:39,191 : INFO : topic #4 (0.100): 0.041*\"eckert\" + 0.025*\"image\" + 0.016*\"sound\" + 0.014*\"said\" + 0.014*\"see\" + 0.012*\"photography\" + 0.012*\"like\" + 0.010*\"pete\" + 0.010*\"blind\" + 0.010*\"would\"\n",
      "2019-10-29 00:42:39,194 : INFO : topic #7 (0.100): 0.039*\"eckert\" + 0.021*\"image\" + 0.016*\"see\" + 0.015*\"said\" + 0.015*\"sound\" + 0.012*\"blind\" + 0.011*\"would\" + 0.011*\"mind\" + 0.010*\"layer\" + 0.010*\"credit\"\n",
      "2019-10-29 00:42:39,197 : INFO : topic #9 (0.100): 0.032*\"eckert\" + 0.024*\"image\" + 0.014*\"said\" + 0.013*\"see\" + 0.012*\"blind\" + 0.012*\"pete\" + 0.011*\"sound\" + 0.011*\"photography\" + 0.011*\"would\" + 0.010*\"like\"\n",
      "2019-10-29 00:42:39,201 : INFO : topic #2 (0.100): 0.037*\"eckert\" + 0.022*\"image\" + 0.015*\"said\" + 0.015*\"see\" + 0.013*\"sound\" + 0.012*\"mind\" + 0.012*\"like\" + 0.010*\"pete\" + 0.010*\"blind\" + 0.010*\"layer\"\n",
      "2019-10-29 00:42:39,204 : INFO : topic diff=0.835488, rho=1.000000\n",
      "2019-10-29 00:42:39,605 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:39,608 : INFO : built Dictionary(146 unique tokens: ['book', 'something', 'shockingly', 'clearly', 'relationship']...) from 5 documents (total 1110 corpus positions)\n",
      "2019-10-29 00:42:39,610 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:39,611 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:39,613 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:39,616 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:39,617 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:39,681 : INFO : -7.092 per-word bound, 136.4 perplexity estimate based on a held-out corpus of 5 documents with 1110 words\n",
      "2019-10-29 00:42:39,685 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:39,692 : INFO : topic #6 (0.100): 0.032*\"melania\" + 0.029*\"first\" + 0.025*\"nancy\" + 0.025*\"trump\" + 0.021*\"divorced\" + 0.020*\"lady\" + 0.018*\"child\" + 0.017*\"reagan\" + 0.015*\"book\" + 0.015*\"three\"\n",
      "2019-10-29 00:42:39,695 : INFO : topic #1 (0.100): 0.033*\"first\" + 0.028*\"nancy\" + 0.028*\"reagan\" + 0.027*\"melania\" + 0.025*\"trump\" + 0.018*\"child\" + 0.016*\"lady\" + 0.016*\"said\" + 0.016*\"divorced\" + 0.014*\"wife\"\n",
      "2019-10-29 00:42:39,698 : INFO : topic #9 (0.100): 0.033*\"melania\" + 0.030*\"first\" + 0.030*\"nancy\" + 0.025*\"reagan\" + 0.025*\"trump\" + 0.020*\"lady\" + 0.020*\"brower\" + 0.018*\"divorced\" + 0.018*\"child\" + 0.014*\"statement\"\n",
      "2019-10-29 00:42:39,701 : INFO : topic #5 (0.100): 0.034*\"melania\" + 0.027*\"first\" + 0.025*\"trump\" + 0.023*\"reagan\" + 0.019*\"nancy\" + 0.019*\"lady\" + 0.018*\"brower\" + 0.017*\"said\" + 0.016*\"divorced\" + 0.016*\"kate\"\n",
      "2019-10-29 00:42:39,705 : INFO : topic #3 (0.100): 0.033*\"melania\" + 0.027*\"nancy\" + 0.026*\"reagan\" + 0.026*\"first\" + 0.020*\"trump\" + 0.019*\"brower\" + 0.017*\"child\" + 0.017*\"divorced\" + 0.015*\"book\" + 0.014*\"kate\"\n",
      "2019-10-29 00:42:39,707 : INFO : topic diff=0.850577, rho=1.000000\n",
      "2019-10-29 00:42:40,154 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:40,160 : INFO : built Dictionary(416 unique tokens: ['filed', 'junk', 'task', 'drive', 'still']...) from 5 documents (total 4750 corpus positions)\n",
      "2019-10-29 00:42:40,166 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:40,168 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:40,172 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:40,176 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:40,179 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:40,334 : INFO : -7.568 per-word bound, 189.7 perplexity estimate based on a held-out corpus of 5 documents with 4750 words\n",
      "2019-10-29 00:42:40,336 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:40,344 : INFO : topic #8 (0.100): 0.044*\"hurricane\" + 0.040*\"maria\" + 0.039*\"photo\" + 0.039*\"caribbean\" + 0.037*\"slam\" + 0.031*\"caption\" + 0.029*\"september\" + 0.028*\"hide\" + 0.024*\"rico\" + 0.022*\"puerto\"\n",
      "2019-10-29 00:42:40,347 : INFO : topic #4 (0.100): 0.052*\"hurricane\" + 0.048*\"maria\" + 0.046*\"slam\" + 0.040*\"photo\" + 0.039*\"caribbean\" + 0.035*\"caption\" + 0.033*\"september\" + 0.031*\"hide\" + 0.022*\"rico\" + 0.021*\"puerto\"\n",
      "2019-10-29 00:42:40,349 : INFO : topic #7 (0.100): 0.049*\"caption\" + 0.043*\"hide\" + 0.042*\"maria\" + 0.040*\"hurricane\" + 0.039*\"slam\" + 0.037*\"september\" + 0.037*\"caribbean\" + 0.034*\"photo\" + 0.021*\"island\" + 0.017*\"rico\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:40,352 : INFO : topic #6 (0.100): 0.046*\"hurricane\" + 0.041*\"caption\" + 0.040*\"maria\" + 0.039*\"slam\" + 0.034*\"caribbean\" + 0.031*\"hide\" + 0.031*\"photo\" + 0.027*\"september\" + 0.020*\"puerto\" + 0.018*\"rico\"\n",
      "2019-10-29 00:42:40,354 : INFO : topic #9 (0.100): 0.044*\"caribbean\" + 0.043*\"hurricane\" + 0.041*\"caption\" + 0.034*\"hide\" + 0.034*\"maria\" + 0.031*\"slam\" + 0.030*\"september\" + 0.030*\"photo\" + 0.020*\"rico\" + 0.020*\"puerto\"\n",
      "2019-10-29 00:42:40,357 : INFO : topic diff=1.108174, rho=1.000000\n",
      "2019-10-29 00:42:40,741 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:40,742 : INFO : built Dictionary(13 unique tokens: ['happening', 'unfolds', 'facebook', 'conway', 'double']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:42:40,743 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:40,744 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:40,745 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:40,747 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:40,748 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:40,764 : INFO : -6.406 per-word bound, 84.8 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n",
      "2019-10-29 00:42:40,765 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:40,771 : INFO : topic #4 (0.100): 0.090*\"u\" + 0.090*\"conway\" + 0.086*\"world\" + 0.084*\"trump\" + 0.080*\"standard\" + 0.078*\"chat\" + 0.078*\"find\" + 0.076*\"unfolds\" + 0.074*\"messenger\" + 0.072*\"facebook\"\n",
      "2019-10-29 00:42:40,772 : INFO : topic #3 (0.100): 0.089*\"conway\" + 0.084*\"standard\" + 0.084*\"chat\" + 0.083*\"find\" + 0.081*\"unfolds\" + 0.080*\"double\" + 0.077*\"trump\" + 0.077*\"facebook\" + 0.074*\"happening\" + 0.074*\"messenger\"\n",
      "2019-10-29 00:42:40,774 : INFO : topic #1 (0.100): 0.102*\"messenger\" + 0.091*\"conway\" + 0.087*\"happening\" + 0.081*\"tweet\" + 0.079*\"u\" + 0.074*\"facebook\" + 0.074*\"world\" + 0.071*\"chat\" + 0.070*\"unfolds\" + 0.070*\"trump\"\n",
      "2019-10-29 00:42:40,780 : INFO : topic #0 (0.100): 0.100*\"double\" + 0.086*\"chat\" + 0.085*\"unfolds\" + 0.082*\"facebook\" + 0.078*\"tweet\" + 0.076*\"world\" + 0.075*\"standard\" + 0.075*\"happening\" + 0.075*\"trump\" + 0.073*\"find\"\n",
      "2019-10-29 00:42:40,783 : INFO : topic #5 (0.100): 0.104*\"unfolds\" + 0.092*\"double\" + 0.083*\"facebook\" + 0.080*\"trump\" + 0.079*\"u\" + 0.079*\"find\" + 0.077*\"messenger\" + 0.077*\"tweet\" + 0.076*\"world\" + 0.074*\"chat\"\n",
      "2019-10-29 00:42:40,788 : INFO : topic diff=0.504815, rho=1.000000\n",
      "2019-10-29 00:42:41,280 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:41,294 : INFO : built Dictionary(709 unique tokens: ['let', 'retreat', 'happy', 'focus', 'troll']...) from 5 documents (total 5445 corpus positions)\n",
      "2019-10-29 00:42:41,304 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:41,306 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:41,308 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:41,313 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:41,315 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:41,525 : INFO : -8.568 per-word bound, 379.5 perplexity estimate based on a held-out corpus of 5 documents with 5445 words\n",
      "2019-10-29 00:42:41,526 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:41,538 : INFO : topic #7 (0.100): 0.019*\"yoga\" + 0.008*\"around\" + 0.008*\"world\" + 0.007*\"say\" + 0.006*\"take\" + 0.006*\"swamiji\" + 0.006*\"set\" + 0.006*\"time\" + 0.006*\"lawn\" + 0.006*\"rishikesh\"\n",
      "2019-10-29 00:42:41,540 : INFO : topic #6 (0.100): 0.013*\"yoga\" + 0.008*\"rishikesh\" + 0.008*\"time\" + 0.007*\"take\" + 0.007*\"say\" + 0.007*\"swamiji\" + 0.006*\"meditation\" + 0.006*\"world\" + 0.006*\"back\" + 0.006*\"home\"\n",
      "2019-10-29 00:42:41,543 : INFO : topic #8 (0.100): 0.015*\"yoga\" + 0.008*\"swamiji\" + 0.008*\"rishikesh\" + 0.007*\"also\" + 0.007*\"take\" + 0.006*\"say\" + 0.006*\"time\" + 0.006*\"lawn\" + 0.006*\"set\" + 0.006*\"world\"\n",
      "2019-10-29 00:42:41,546 : INFO : topic #0 (0.100): 0.018*\"yoga\" + 0.013*\"rishikesh\" + 0.008*\"swamiji\" + 0.007*\"say\" + 0.006*\"time\" + 0.006*\"world\" + 0.006*\"new\" + 0.006*\"back\" + 0.006*\"set\" + 0.006*\"life\"\n",
      "2019-10-29 00:42:41,550 : INFO : topic #1 (0.100): 0.018*\"yoga\" + 0.009*\"swamiji\" + 0.008*\"phone\" + 0.007*\"time\" + 0.007*\"rishikesh\" + 0.006*\"new\" + 0.006*\"world\" + 0.006*\"back\" + 0.006*\"work\" + 0.006*\"around\"\n",
      "2019-10-29 00:42:41,553 : INFO : topic diff=0.857165, rho=1.000000\n",
      "2019-10-29 00:42:41,959 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:41,960 : INFO : built Dictionary(36 unique tokens: ['operation', 'construction', 'policy', 'cnn', 'oil']...) from 5 documents (total 220 corpus positions)\n",
      "2019-10-29 00:42:41,962 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:41,963 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:41,965 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:41,967 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:41,969 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:41,993 : INFO : -6.383 per-word bound, 83.4 perplexity estimate based on a held-out corpus of 5 documents with 220 words\n",
      "2019-10-29 00:42:41,995 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:42,001 : INFO : topic #3 (0.100): 0.064*\"dakota\" + 0.051*\"standing\" + 0.051*\"fight\" + 0.051*\"rock\" + 0.045*\"back\" + 0.042*\"north\" + 0.037*\"pipeline\" + 0.028*\"transport\" + 0.027*\"stand\" + 0.026*\"tribe\"\n",
      "2019-10-29 00:42:42,004 : INFO : topic #0 (0.100): 0.062*\"dakota\" + 0.054*\"rock\" + 0.047*\"north\" + 0.044*\"standing\" + 0.043*\"back\" + 0.040*\"fight\" + 0.037*\"pipeline\" + 0.031*\"set\" + 0.030*\"crude\" + 0.028*\"camp\"\n",
      "2019-10-29 00:42:42,006 : INFO : topic #8 (0.100): 0.061*\"dakota\" + 0.050*\"fight\" + 0.043*\"pipeline\" + 0.042*\"rock\" + 0.038*\"north\" + 0.036*\"back\" + 0.032*\"crude\" + 0.030*\"standing\" + 0.029*\"construction\" + 0.029*\"month\"\n",
      "2019-10-29 00:42:42,009 : INFO : topic #9 (0.100): 0.054*\"dakota\" + 0.041*\"pipeline\" + 0.038*\"north\" + 0.038*\"back\" + 0.038*\"standing\" + 0.035*\"fight\" + 0.033*\"rock\" + 0.032*\"access\" + 0.030*\"member\" + 0.029*\"looking\"\n",
      "2019-10-29 00:42:42,010 : INFO : topic #5 (0.100): 0.052*\"pipeline\" + 0.048*\"fight\" + 0.047*\"dakota\" + 0.047*\"back\" + 0.044*\"standing\" + 0.043*\"rock\" + 0.036*\"north\" + 0.030*\"full\" + 0.027*\"tribe\" + 0.027*\"opposed\"\n",
      "2019-10-29 00:42:42,015 : INFO : topic diff=0.662621, rho=1.000000\n",
      "2019-10-29 00:42:42,536 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:42,540 : INFO : built Dictionary(139 unique tokens: ['let', 'catholic', 'total', 'end', 'home']...) from 5 documents (total 895 corpus positions)\n",
      "2019-10-29 00:42:42,544 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:42,546 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:42,548 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:42,550 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:42,552 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:42,602 : INFO : -7.331 per-word bound, 161.0 perplexity estimate based on a held-out corpus of 5 documents with 895 words\n",
      "2019-10-29 00:42:42,605 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:42,612 : INFO : topic #5 (0.100): 0.043*\"fire\" + 0.036*\"said\" + 0.025*\"home\" + 0.021*\"flame\" + 0.019*\"california\" + 0.018*\"devastation\" + 0.018*\"one\" + 0.014*\"wine\" + 0.013*\"mobile\" + 0.013*\"went\"\n",
      "2019-10-29 00:42:42,614 : INFO : topic #8 (0.100): 0.044*\"fire\" + 0.029*\"said\" + 0.024*\"home\" + 0.021*\"california\" + 0.020*\"flame\" + 0.018*\"country\" + 0.017*\"wine\" + 0.016*\"one\" + 0.013*\"image\" + 0.013*\"fast\"\n",
      "2019-10-29 00:42:42,617 : INFO : topic #9 (0.100): 0.041*\"fire\" + 0.029*\"home\" + 0.027*\"said\" + 0.021*\"california\" + 0.020*\"flame\" + 0.017*\"wine\" + 0.013*\"country\" + 0.012*\"devastation\" + 0.012*\"firestorm\" + 0.012*\"rosa\"\n",
      "2019-10-29 00:42:42,620 : INFO : topic #1 (0.100): 0.046*\"fire\" + 0.031*\"said\" + 0.023*\"california\" + 0.023*\"home\" + 0.019*\"devastation\" + 0.018*\"flame\" + 0.018*\"wine\" + 0.015*\"country\" + 0.014*\"one\" + 0.012*\"rosa\"\n",
      "2019-10-29 00:42:42,623 : INFO : topic #0 (0.100): 0.036*\"fire\" + 0.028*\"said\" + 0.028*\"home\" + 0.021*\"california\" + 0.019*\"one\" + 0.018*\"devastation\" + 0.017*\"country\" + 0.017*\"flame\" + 0.014*\"wine\" + 0.014*\"resident\"\n",
      "2019-10-29 00:42:42,625 : INFO : topic diff=0.753168, rho=1.000000\n",
      "2019-10-29 00:42:43,059 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:43,067 : INFO : built Dictionary(520 unique tokens: ['dating', 'deep', 'entitled', 'remained', 'place']...) from 5 documents (total 4350 corpus positions)\n",
      "2019-10-29 00:42:43,073 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:43,075 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:43,077 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:43,082 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:43,083 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:43,282 : INFO : -8.146 per-word bound, 283.3 perplexity estimate based on a held-out corpus of 5 documents with 4350 words\n",
      "2019-10-29 00:42:43,283 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:43,293 : INFO : topic #5 (0.100): 0.035*\"woman\" + 0.019*\"marriage\" + 0.015*\"husband\" + 0.013*\"one\" + 0.012*\"way\" + 0.012*\"many\" + 0.011*\"friend\" + 0.010*\"told\" + 0.009*\"year\" + 0.009*\"another\"\n",
      "2019-10-29 00:42:43,295 : INFO : topic #4 (0.100): 0.033*\"woman\" + 0.019*\"marriage\" + 0.017*\"husband\" + 0.012*\"one\" + 0.011*\"told\" + 0.011*\"friend\" + 0.010*\"way\" + 0.010*\"year\" + 0.010*\"another\" + 0.009*\"infidelity\"\n",
      "2019-10-29 00:42:43,298 : INFO : topic #3 (0.100): 0.028*\"woman\" + 0.020*\"husband\" + 0.017*\"marriage\" + 0.014*\"way\" + 0.012*\"many\" + 0.011*\"infidelity\" + 0.010*\"told\" + 0.009*\"one\" + 0.008*\"family\" + 0.008*\"another\"\n",
      "2019-10-29 00:42:43,300 : INFO : topic #1 (0.100): 0.031*\"woman\" + 0.018*\"marriage\" + 0.015*\"way\" + 0.014*\"husband\" + 0.011*\"friend\" + 0.011*\"one\" + 0.011*\"infidelity\" + 0.010*\"another\" + 0.009*\"many\" + 0.008*\"affair\"\n",
      "2019-10-29 00:42:43,301 : INFO : topic #6 (0.100): 0.038*\"woman\" + 0.015*\"marriage\" + 0.014*\"friend\" + 0.014*\"husband\" + 0.013*\"way\" + 0.011*\"like\" + 0.010*\"infidelity\" + 0.009*\"one\" + 0.008*\"many\" + 0.008*\"affair\"\n",
      "2019-10-29 00:42:43,303 : INFO : topic diff=0.907100, rho=1.000000\n",
      "2019-10-29 00:42:43,762 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:43,772 : INFO : built Dictionary(664 unique tokens: ['although', 'infusion', 'nature', 'deep', 'degeneration']...) from 5 documents (total 6815 corpus positions)\n",
      "2019-10-29 00:42:43,779 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:43,780 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:43,781 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:43,786 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:43,789 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:43,974 : INFO : -8.130 per-word bound, 280.2 perplexity estimate based on a held-out corpus of 5 documents with 6815 words\n",
      "2019-10-29 00:42:43,976 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:43,986 : INFO : topic #5 (0.100): 0.026*\"parkinson\" + 0.025*\"schulman\" + 0.022*\"said\" + 0.015*\"factor\" + 0.014*\"disease\" + 0.011*\"patient\" + 0.010*\"one\" + 0.010*\"dopamine\" + 0.010*\"symptom\" + 0.010*\"time\"\n",
      "2019-10-29 00:42:43,987 : INFO : topic #4 (0.100): 0.026*\"parkinson\" + 0.023*\"said\" + 0.020*\"schulman\" + 0.014*\"factor\" + 0.012*\"people\" + 0.011*\"symptom\" + 0.011*\"disease\" + 0.009*\"time\" + 0.008*\"brain\" + 0.008*\"one\"\n",
      "2019-10-29 00:42:43,988 : INFO : topic #3 (0.100): 0.026*\"parkinson\" + 0.022*\"schulman\" + 0.019*\"factor\" + 0.017*\"disease\" + 0.017*\"said\" + 0.012*\"brain\" + 0.011*\"symptom\" + 0.010*\"people\" + 0.009*\"one\" + 0.009*\"patient\"\n",
      "2019-10-29 00:42:43,991 : INFO : topic #9 (0.100): 0.045*\"parkinson\" + 0.022*\"said\" + 0.016*\"disease\" + 0.015*\"factor\" + 0.013*\"schulman\" + 0.011*\"symptom\" + 0.010*\"get\" + 0.009*\"brain\" + 0.008*\"dopamine\" + 0.008*\"one\"\n",
      "2019-10-29 00:42:43,993 : INFO : topic #6 (0.100): 0.026*\"parkinson\" + 0.020*\"schulman\" + 0.017*\"factor\" + 0.017*\"said\" + 0.014*\"symptom\" + 0.013*\"disease\" + 0.011*\"brain\" + 0.009*\"one\" + 0.008*\"say\" + 0.008*\"people\"\n",
      "2019-10-29 00:42:43,995 : INFO : topic diff=0.964166, rho=1.000000\n",
      "2019-10-29 00:42:44,420 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:44,426 : INFO : built Dictionary(280 unique tokens: ['even', 'product', 'reach', 'grew', 'come']...) from 5 documents (total 2535 corpus positions)\n",
      "2019-10-29 00:42:44,429 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:44,430 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:44,432 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:44,436 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:44,437 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:44,526 : INFO : -7.446 per-word bound, 174.4 perplexity estimate based on a held-out corpus of 5 documents with 2535 words\n",
      "2019-10-29 00:42:44,528 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:44,535 : INFO : topic #8 (0.100): 0.041*\"woman\" + 0.034*\"kagedan\" + 0.031*\"rabbi\" + 0.028*\"orthodox\" + 0.019*\"jewish\" + 0.018*\"say\" + 0.016*\"school\" + 0.015*\"men\" + 0.012*\"congregation\" + 0.011*\"hope\"\n",
      "2019-10-29 00:42:44,538 : INFO : topic #5 (0.100): 0.039*\"rabbi\" + 0.036*\"kagedan\" + 0.032*\"woman\" + 0.025*\"orthodox\" + 0.019*\"say\" + 0.019*\"jewish\" + 0.013*\"new\" + 0.012*\"school\" + 0.011*\"men\" + 0.010*\"hope\"\n",
      "2019-10-29 00:42:44,541 : INFO : topic #2 (0.100): 0.047*\"kagedan\" + 0.033*\"rabbi\" + 0.029*\"woman\" + 0.028*\"orthodox\" + 0.018*\"jewish\" + 0.017*\"say\" + 0.014*\"school\" + 0.010*\"lila\" + 0.010*\"title\" + 0.009*\"sit\"\n",
      "2019-10-29 00:42:44,544 : INFO : topic #0 (0.100): 0.043*\"kagedan\" + 0.028*\"woman\" + 0.024*\"rabbi\" + 0.023*\"say\" + 0.023*\"jewish\" + 0.020*\"orthodox\" + 0.013*\"new\" + 0.013*\"school\" + 0.012*\"community\" + 0.011*\"men\"\n",
      "2019-10-29 00:42:44,548 : INFO : topic #4 (0.100): 0.038*\"kagedan\" + 0.033*\"woman\" + 0.031*\"rabbi\" + 0.028*\"orthodox\" + 0.021*\"say\" + 0.018*\"jewish\" + 0.012*\"school\" + 0.012*\"new\" + 0.011*\"men\" + 0.010*\"title\"\n",
      "2019-10-29 00:42:44,551 : INFO : topic diff=0.920068, rho=1.000000\n",
      "2019-10-29 00:42:44,951 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:44,952 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:42:44,955 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:44,957 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:44,959 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:44,961 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:44,963 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:44,973 : INFO : -6.045 per-word bound, 66.0 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:42:44,975 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:44,979 : INFO : topic #9 (0.100): 0.156*\"transcript\" + 0.076*\"page\" + 0.061*\"available\" + 0.053*\"find\" + 0.052*\"new\" + 0.052*\"back\" + 0.052*\"return\" + 0.050*\"segment\" + 0.046*\"later\" + 0.045*\"note\"\n",
      "2019-10-29 00:42:44,982 : INFO : topic #1 (0.100): 0.172*\"transcript\" + 0.078*\"page\" + 0.057*\"segment\" + 0.057*\"find\" + 0.055*\"become\" + 0.052*\"october\" + 0.050*\"main\" + 0.048*\"note\" + 0.047*\"updated\" + 0.045*\"continually\"\n",
      "2019-10-29 00:42:44,984 : INFO : topic #7 (0.100): 0.158*\"transcript\" + 0.085*\"page\" + 0.058*\"cnn\" + 0.055*\"continually\" + 0.053*\"return\" + 0.050*\"become\" + 0.049*\"cannot\" + 0.048*\"october\" + 0.048*\"specific\" + 0.047*\"back\"\n",
      "2019-10-29 00:42:44,986 : INFO : topic #5 (0.100): 0.125*\"transcript\" + 0.094*\"page\" + 0.063*\"later\" + 0.061*\"specific\" + 0.051*\"continually\" + 0.048*\"updated\" + 0.046*\"cannot\" + 0.045*\"become\" + 0.045*\"cnn\" + 0.045*\"back\"\n",
      "2019-10-29 00:42:44,988 : INFO : topic #6 (0.100): 0.144*\"transcript\" + 0.092*\"page\" + 0.054*\"back\" + 0.052*\"october\" + 0.050*\"check\" + 0.049*\"continually\" + 0.049*\"new\" + 0.049*\"later\" + 0.048*\"available\" + 0.045*\"updated\"\n",
      "2019-10-29 00:42:44,991 : INFO : topic diff=0.721560, rho=1.000000\n",
      "2019-10-29 00:42:45,521 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:45,532 : INFO : built Dictionary(661 unique tokens: ['let', 'acceptable', 'filed', 'happy', 'went']...) from 5 documents (total 7940 corpus positions)\n",
      "2019-10-29 00:42:45,542 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:45,544 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:45,547 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:45,551 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:45,553 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:45,793 : INFO : -7.964 per-word bound, 249.7 perplexity estimate based on a held-out corpus of 5 documents with 7940 words\n",
      "2019-10-29 00:42:45,795 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:45,807 : INFO : topic #0 (0.100): 0.032*\"said\" + 0.028*\"player\" + 0.025*\"coach\" + 0.020*\"team\" + 0.014*\"university\" + 0.011*\"say\" + 0.010*\"one\" + 0.010*\"woman\" + 0.010*\"practice\" + 0.009*\"cnn\"\n",
      "2019-10-29 00:42:45,810 : INFO : topic #8 (0.100): 0.030*\"player\" + 0.025*\"said\" + 0.019*\"coach\" + 0.019*\"say\" + 0.014*\"university\" + 0.012*\"team\" + 0.010*\"former\" + 0.010*\"one\" + 0.010*\"like\" + 0.009*\"practice\"\n",
      "2019-10-29 00:42:45,814 : INFO : topic #9 (0.100): 0.031*\"player\" + 0.024*\"said\" + 0.018*\"coach\" + 0.017*\"team\" + 0.016*\"university\" + 0.015*\"say\" + 0.010*\"former\" + 0.010*\"one\" + 0.009*\"divilbiss\" + 0.009*\"practice\"\n",
      "2019-10-29 00:42:45,817 : INFO : topic #4 (0.100): 0.037*\"player\" + 0.020*\"coach\" + 0.018*\"said\" + 0.015*\"university\" + 0.014*\"former\" + 0.013*\"team\" + 0.011*\"one\" + 0.010*\"say\" + 0.010*\"cnn\" + 0.009*\"knight\"\n",
      "2019-10-29 00:42:45,820 : INFO : topic #1 (0.100): 0.029*\"player\" + 0.024*\"said\" + 0.016*\"coach\" + 0.015*\"university\" + 0.011*\"say\" + 0.011*\"like\" + 0.010*\"cnn\" + 0.010*\"team\" + 0.010*\"former\" + 0.010*\"knight\"\n",
      "2019-10-29 00:42:45,823 : INFO : topic diff=1.000625, rho=1.000000\n",
      "2019-10-29 00:42:46,257 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:46,259 : INFO : built Dictionary(39 unique tokens: ['weeklong', 'senior', 'president', 'businesspeople', 'attending']...) from 5 documents (total 270 corpus positions)\n",
      "2019-10-29 00:42:46,260 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:46,264 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:46,267 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:46,271 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:46,274 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:46,302 : INFO : -6.180 per-word bound, 72.5 perplexity estimate based on a held-out corpus of 5 documents with 270 words\n",
      "2019-10-29 00:42:46,305 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:46,315 : INFO : topic #0 (0.100): 0.079*\"valley\" + 0.059*\"conference\" + 0.055*\"sun\" + 0.051*\"corporate\" + 0.048*\"titan\" + 0.038*\"apple\" + 0.035*\"converge\" + 0.025*\"president\" + 0.025*\"see\" + 0.024*\"co\"\n",
      "2019-10-29 00:42:46,319 : INFO : topic #8 (0.100): 0.079*\"sun\" + 0.075*\"conference\" + 0.065*\"corporate\" + 0.057*\"valley\" + 0.039*\"apple\" + 0.036*\"titan\" + 0.026*\"converge\" + 0.025*\"senior\" + 0.024*\"cue\" + 0.024*\"software\"\n",
      "2019-10-29 00:42:46,322 : INFO : topic #2 (0.100): 0.066*\"sun\" + 0.063*\"valley\" + 0.063*\"conference\" + 0.061*\"titan\" + 0.044*\"corporate\" + 0.039*\"converge\" + 0.033*\"apple\" + 0.025*\"tim\" + 0.023*\"cook\" + 0.023*\"ceo\"\n",
      "2019-10-29 00:42:46,326 : INFO : topic #5 (0.100): 0.073*\"valley\" + 0.065*\"sun\" + 0.062*\"conference\" + 0.047*\"titan\" + 0.046*\"apple\" + 0.045*\"corporate\" + 0.037*\"converge\" + 0.024*\"held\" + 0.023*\"world\" + 0.023*\"wealthy\"\n",
      "2019-10-29 00:42:46,329 : INFO : topic #6 (0.100): 0.076*\"conference\" + 0.066*\"valley\" + 0.056*\"sun\" + 0.050*\"titan\" + 0.049*\"corporate\" + 0.039*\"apple\" + 0.030*\"converge\" + 0.027*\"powerful\" + 0.024*\"weeklong\" + 0.024*\"software\"\n",
      "2019-10-29 00:42:46,333 : INFO : topic diff=0.821501, rho=1.000000\n",
      "2019-10-29 00:42:46,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:46,724 : INFO : built Dictionary(110 unique tokens: ['colleague', 'party', 'may', 'focus', 'spoke']...) from 5 documents (total 810 corpus positions)\n",
      "2019-10-29 00:42:46,726 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:46,727 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:46,729 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:46,732 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:46,733 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:46,775 : INFO : -6.895 per-word bound, 119.0 perplexity estimate based on a held-out corpus of 5 documents with 810 words\n",
      "2019-10-29 00:42:46,777 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:46,785 : INFO : topic #9 (0.100): 0.035*\"cancer\" + 0.029*\"hirono\" + 0.026*\"late\" + 0.025*\"health\" + 0.025*\"sen\" + 0.024*\"kidney\" + 0.024*\"care\" + 0.022*\"vote\" + 0.020*\"obamacare\" + 0.017*\"plan\"\n",
      "2019-10-29 00:42:46,790 : INFO : topic #6 (0.100): 0.030*\"vote\" + 0.026*\"kidney\" + 0.024*\"sen\" + 0.024*\"cancer\" + 0.023*\"care\" + 0.023*\"health\" + 0.021*\"obamacare\" + 0.020*\"late\" + 0.019*\"plan\" + 0.018*\"hirono\"\n",
      "2019-10-29 00:42:46,792 : INFO : topic #5 (0.100): 0.038*\"hirono\" + 0.024*\"cancer\" + 0.024*\"sen\" + 0.024*\"late\" + 0.022*\"kidney\" + 0.021*\"health\" + 0.021*\"vote\" + 0.019*\"care\" + 0.018*\"stage\" + 0.017*\"obamacare\"\n",
      "2019-10-29 00:42:46,795 : INFO : topic #2 (0.100): 0.031*\"cancer\" + 0.026*\"sen\" + 0.024*\"hirono\" + 0.023*\"kidney\" + 0.022*\"late\" + 0.022*\"stage\" + 0.021*\"vote\" + 0.020*\"health\" + 0.019*\"obamacare\" + 0.018*\"care\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:46,800 : INFO : topic #4 (0.100): 0.031*\"hirono\" + 0.028*\"health\" + 0.026*\"cancer\" + 0.025*\"late\" + 0.024*\"sen\" + 0.023*\"vote\" + 0.022*\"stage\" + 0.020*\"kidney\" + 0.019*\"plan\" + 0.018*\"care\"\n",
      "2019-10-29 00:42:46,803 : INFO : topic diff=0.784215, rho=1.000000\n",
      "2019-10-29 00:42:47,238 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:47,247 : INFO : built Dictionary(406 unique tokens: ['deep', 'remained', 'game', 'cull', 'discharging']...) from 5 documents (total 3180 corpus positions)\n",
      "2019-10-29 00:42:47,254 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:47,256 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:47,257 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:47,261 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:47,264 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:47,413 : INFO : -8.002 per-word bound, 256.4 perplexity estimate based on a held-out corpus of 5 documents with 3180 words\n",
      "2019-10-29 00:42:47,414 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:47,423 : INFO : topic #0 (0.100): 0.069*\"elephant\" + 0.016*\"year\" + 0.012*\"census\" + 0.010*\"ingrid\" + 0.010*\"africa\" + 0.009*\"botswana\" + 0.009*\"back\" + 0.009*\"put\" + 0.008*\"shireni\" + 0.008*\"great\"\n",
      "2019-10-29 00:42:47,424 : INFO : topic #3 (0.100): 0.071*\"elephant\" + 0.016*\"year\" + 0.010*\"ingrid\" + 0.010*\"botswana\" + 0.009*\"back\" + 0.009*\"census\" + 0.008*\"chase\" + 0.008*\"say\" + 0.008*\"africa\" + 0.008*\"see\"\n",
      "2019-10-29 00:42:47,426 : INFO : topic #1 (0.100): 0.059*\"elephant\" + 0.019*\"year\" + 0.011*\"say\" + 0.011*\"put\" + 0.010*\"ingrid\" + 0.009*\"chase\" + 0.009*\"botswana\" + 0.009*\"africa\" + 0.009*\"back\" + 0.009*\"great\"\n",
      "2019-10-29 00:42:47,428 : INFO : topic #7 (0.100): 0.078*\"elephant\" + 0.019*\"year\" + 0.012*\"say\" + 0.011*\"ingrid\" + 0.010*\"census\" + 0.009*\"botswana\" + 0.009*\"back\" + 0.009*\"chase\" + 0.008*\"put\" + 0.008*\"africa\"\n",
      "2019-10-29 00:42:47,429 : INFO : topic #4 (0.100): 0.065*\"elephant\" + 0.013*\"year\" + 0.011*\"chase\" + 0.010*\"botswana\" + 0.009*\"census\" + 0.009*\"great\" + 0.008*\"back\" + 0.008*\"put\" + 0.008*\"africa\" + 0.008*\"ingrid\"\n",
      "2019-10-29 00:42:47,431 : INFO : topic diff=0.828040, rho=1.000000\n",
      "2019-10-29 00:42:47,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:47,861 : INFO : built Dictionary(386 unique tokens: ['phase', 'happy', 'injury', 'game', 'excitement']...) from 5 documents (total 3345 corpus positions)\n",
      "2019-10-29 00:42:47,865 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:47,868 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:47,872 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:47,876 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:47,880 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:48,021 : INFO : -7.815 per-word bound, 225.2 perplexity estimate based on a held-out corpus of 5 documents with 3345 words\n",
      "2019-10-29 00:42:48,023 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:48,030 : INFO : topic #3 (0.100): 0.032*\"schmitt\" + 0.020*\"said\" + 0.017*\"game\" + 0.016*\"help\" + 0.015*\"swimming\" + 0.014*\"olympic\" + 0.011*\"depression\" + 0.010*\"could\" + 0.010*\"bauerle\" + 0.009*\"athlete\"\n",
      "2019-10-29 00:42:48,032 : INFO : topic #2 (0.100): 0.036*\"schmitt\" + 0.017*\"game\" + 0.016*\"said\" + 0.016*\"olympic\" + 0.013*\"swimming\" + 0.012*\"help\" + 0.009*\"sport\" + 0.009*\"bauerle\" + 0.009*\"psychologist\" + 0.009*\"coach\"\n",
      "2019-10-29 00:42:48,035 : INFO : topic #0 (0.100): 0.028*\"schmitt\" + 0.021*\"said\" + 0.013*\"swimming\" + 0.013*\"game\" + 0.012*\"bauerle\" + 0.011*\"olympic\" + 0.011*\"depression\" + 0.010*\"help\" + 0.009*\"struggle\" + 0.009*\"team\"\n",
      "2019-10-29 00:42:48,038 : INFO : topic #5 (0.100): 0.029*\"schmitt\" + 0.019*\"said\" + 0.012*\"swimming\" + 0.012*\"game\" + 0.012*\"athlete\" + 0.012*\"olympic\" + 0.011*\"bauerle\" + 0.010*\"coach\" + 0.009*\"help\" + 0.009*\"could\"\n",
      "2019-10-29 00:42:48,040 : INFO : topic #7 (0.100): 0.039*\"schmitt\" + 0.019*\"game\" + 0.017*\"said\" + 0.015*\"olympic\" + 0.013*\"swimming\" + 0.010*\"bauerle\" + 0.010*\"athlete\" + 0.010*\"would\" + 0.008*\"help\" + 0.008*\"coach\"\n",
      "2019-10-29 00:42:48,043 : INFO : topic diff=0.892767, rho=1.000000\n",
      "2019-10-29 00:42:48,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:48,507 : INFO : built Dictionary(336 unique tokens: ['dating', 'even', 'trying', 'book', 'happy']...) from 5 documents (total 2520 corpus positions)\n",
      "2019-10-29 00:42:48,510 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:48,512 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:48,514 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:48,517 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:48,519 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:48,657 : INFO : -7.888 per-word bound, 237.0 perplexity estimate based on a held-out corpus of 5 documents with 2520 words\n",
      "2019-10-29 00:42:48,660 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:48,668 : INFO : topic #6 (0.100): 0.055*\"woman\" + 0.016*\"marriage\" + 0.012*\"want\" + 0.012*\"marry\" + 0.011*\"love\" + 0.010*\"life\" + 0.010*\"single\" + 0.010*\"u\" + 0.009*\"deal\" + 0.008*\"good\"\n",
      "2019-10-29 00:42:48,671 : INFO : topic #4 (0.100): 0.052*\"woman\" + 0.013*\"marriage\" + 0.013*\"life\" + 0.013*\"marry\" + 0.012*\"single\" + 0.011*\"want\" + 0.009*\"make\" + 0.008*\"may\" + 0.008*\"could\" + 0.008*\"deal\"\n",
      "2019-10-29 00:42:48,673 : INFO : topic #7 (0.100): 0.046*\"woman\" + 0.016*\"want\" + 0.016*\"single\" + 0.016*\"marriage\" + 0.013*\"marry\" + 0.013*\"life\" + 0.009*\"family\" + 0.008*\"good\" + 0.008*\"economic\" + 0.008*\"could\"\n",
      "2019-10-29 00:42:48,676 : INFO : topic #9 (0.100): 0.043*\"woman\" + 0.019*\"marriage\" + 0.014*\"life\" + 0.013*\"marry\" + 0.012*\"want\" + 0.010*\"single\" + 0.008*\"make\" + 0.008*\"deal\" + 0.008*\"family\" + 0.008*\"person\"\n",
      "2019-10-29 00:42:48,679 : INFO : topic #2 (0.100): 0.043*\"woman\" + 0.014*\"marriage\" + 0.012*\"marry\" + 0.012*\"life\" + 0.011*\"want\" + 0.010*\"deal\" + 0.010*\"single\" + 0.009*\"u\" + 0.008*\"family\" + 0.008*\"love\"\n",
      "2019-10-29 00:42:48,681 : INFO : topic diff=0.849071, rho=1.000000\n",
      "2019-10-29 00:42:49,092 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:49,100 : INFO : built Dictionary(354 unique tokens: ['let', 'happy', 'backlash', 'lemming', 'game']...) from 5 documents (total 2875 corpus positions)\n",
      "2019-10-29 00:42:49,106 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:49,108 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:49,110 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:49,113 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:49,115 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:49,247 : INFO : -7.819 per-word bound, 225.9 perplexity estimate based on a held-out corpus of 5 documents with 2875 words\n",
      "2019-10-29 00:42:49,248 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:49,258 : INFO : topic #3 (0.100): 0.023*\"hill\" + 0.017*\"tweet\" + 0.015*\"cowboy\" + 0.015*\"espn\" + 0.014*\"jemele\" + 0.011*\"advertiser\" + 0.011*\"make\" + 0.010*\"http\" + 0.009*\"jones\" + 0.009*\"fear\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:49,261 : INFO : topic #1 (0.100): 0.023*\"tweet\" + 0.021*\"hill\" + 0.016*\"cowboy\" + 0.014*\"espn\" + 0.012*\"jemele\" + 0.012*\"advertiser\" + 0.010*\"feel\" + 0.010*\"october\" + 0.009*\"jones\" + 0.009*\"watch\"\n",
      "2019-10-29 00:42:49,264 : INFO : topic #6 (0.100): 0.023*\"hill\" + 0.019*\"jemele\" + 0.019*\"espn\" + 0.016*\"tweet\" + 0.015*\"advertiser\" + 0.014*\"cowboy\" + 0.010*\"jones\" + 0.010*\"fear\" + 0.009*\"step\" + 0.009*\"http\"\n",
      "2019-10-29 00:42:49,267 : INFO : topic #8 (0.100): 0.026*\"hill\" + 0.021*\"tweet\" + 0.018*\"espn\" + 0.018*\"jemele\" + 0.016*\"advertiser\" + 0.012*\"jones\" + 0.011*\"cowboy\" + 0.009*\"make\" + 0.008*\"step\" + 0.008*\"fear\"\n",
      "2019-10-29 00:42:49,270 : INFO : topic #2 (0.100): 0.020*\"hill\" + 0.018*\"jemele\" + 0.017*\"espn\" + 0.014*\"tweet\" + 0.014*\"cowboy\" + 0.012*\"advertiser\" + 0.010*\"make\" + 0.009*\"co\" + 0.009*\"october\" + 0.009*\"jones\"\n",
      "2019-10-29 00:42:49,273 : INFO : topic diff=0.826193, rho=1.000000\n",
      "2019-10-29 00:42:49,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:49,736 : INFO : built Dictionary(596 unique tokens: ['beleaguered', 'notice', 'francisco', 'daniel', 'moraes']...) from 5 documents (total 4555 corpus positions)\n",
      "2019-10-29 00:42:49,741 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:49,743 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:49,744 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:49,749 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:49,751 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:49,932 : INFO : -8.408 per-word bound, 339.8 perplexity estimate based on a held-out corpus of 5 documents with 4555 words\n",
      "2019-10-29 00:42:49,934 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:49,941 : INFO : topic #0 (0.100): 0.014*\"april\" + 0.009*\"one\" + 0.009*\"collection\" + 0.008*\"credit\" + 0.008*\"runner\" + 0.007*\"costume\" + 0.007*\"blade\" + 0.007*\"scott\" + 0.007*\"fashion\" + 0.007*\"world\"\n",
      "2019-10-29 00:42:49,944 : INFO : topic #5 (0.100): 0.010*\"blade\" + 0.010*\"costume\" + 0.010*\"april\" + 0.009*\"designer\" + 0.009*\"collection\" + 0.008*\"one\" + 0.008*\"credit\" + 0.008*\"runner\" + 0.007*\"year\" + 0.007*\"film\"\n",
      "2019-10-29 00:42:49,947 : INFO : topic #9 (0.100): 0.015*\"april\" + 0.010*\"costume\" + 0.009*\"credit\" + 0.009*\"runner\" + 0.009*\"designer\" + 0.008*\"blade\" + 0.008*\"collection\" + 0.007*\"fashion\" + 0.007*\"one\" + 0.006*\"scott\"\n",
      "2019-10-29 00:42:49,949 : INFO : topic #8 (0.100): 0.015*\"april\" + 0.011*\"collection\" + 0.010*\"runner\" + 0.010*\"one\" + 0.009*\"costume\" + 0.008*\"blade\" + 0.007*\"credit\" + 0.007*\"getty\" + 0.007*\"scott\" + 0.007*\"fashion\"\n",
      "2019-10-29 00:42:49,951 : INFO : topic #6 (0.100): 0.015*\"april\" + 0.011*\"collection\" + 0.010*\"one\" + 0.010*\"runner\" + 0.009*\"designer\" + 0.009*\"blade\" + 0.009*\"film\" + 0.007*\"costume\" + 0.007*\"fashion\" + 0.006*\"credit\"\n",
      "2019-10-29 00:42:49,954 : INFO : topic diff=0.839876, rho=1.000000\n",
      "2019-10-29 00:42:50,377 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:50,383 : INFO : built Dictionary(336 unique tokens: ['previously', 'concern', 'every', 'person', 'take']...) from 5 documents (total 2965 corpus positions)\n",
      "2019-10-29 00:42:50,388 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:50,389 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:50,390 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:50,394 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:50,396 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:50,518 : INFO : -7.657 per-word bound, 201.9 perplexity estimate based on a held-out corpus of 5 documents with 2965 words\n",
      "2019-10-29 00:42:50,519 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:50,529 : INFO : topic #6 (0.100): 0.054*\"marine\" + 0.036*\"woman\" + 0.026*\"infantry\" + 0.020*\"officer\" + 0.020*\"female\" + 0.019*\"corp\" + 0.019*\"said\" + 0.009*\"neller\" + 0.009*\"combat\" + 0.008*\"school\"\n",
      "2019-10-29 00:42:50,533 : INFO : topic #7 (0.100): 0.057*\"marine\" + 0.024*\"officer\" + 0.024*\"woman\" + 0.020*\"corp\" + 0.020*\"infantry\" + 0.015*\"said\" + 0.015*\"female\" + 0.011*\"neller\" + 0.009*\"part\" + 0.009*\"made\"\n",
      "2019-10-29 00:42:50,536 : INFO : topic #8 (0.100): 0.054*\"marine\" + 0.037*\"woman\" + 0.020*\"female\" + 0.020*\"said\" + 0.020*\"corp\" + 0.019*\"infantry\" + 0.015*\"officer\" + 0.011*\"neller\" + 0.009*\"culture\" + 0.009*\"one\"\n",
      "2019-10-29 00:42:50,542 : INFO : topic #0 (0.100): 0.043*\"marine\" + 0.035*\"woman\" + 0.023*\"corp\" + 0.022*\"infantry\" + 0.021*\"said\" + 0.020*\"officer\" + 0.017*\"female\" + 0.010*\"instructor\" + 0.010*\"one\" + 0.009*\"school\"\n",
      "2019-10-29 00:42:50,545 : INFO : topic #2 (0.100): 0.055*\"marine\" + 0.027*\"woman\" + 0.025*\"infantry\" + 0.021*\"corp\" + 0.017*\"officer\" + 0.016*\"said\" + 0.015*\"female\" + 0.010*\"neller\" + 0.009*\"school\" + 0.008*\"part\"\n",
      "2019-10-29 00:42:50,548 : INFO : topic diff=0.912197, rho=1.000000\n",
      "2019-10-29 00:42:50,977 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:50,979 : INFO : built Dictionary(92 unique tokens: ['aviation', 'decrease', 'theft', 'filed', 'proactive']...) from 5 documents (total 700 corpus positions)\n",
      "2019-10-29 00:42:50,981 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:50,982 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:50,983 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:50,986 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:50,987 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:51,026 : INFO : -6.684 per-word bound, 102.8 perplexity estimate based on a held-out corpus of 5 documents with 700 words\n",
      "2019-10-29 00:42:51,030 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:51,037 : INFO : topic #3 (0.100): 0.046*\"miami\" + 0.029*\"luggage\" + 0.028*\"police\" + 0.026*\"claim\" + 0.025*\"camera\" + 0.024*\"cnn\" + 0.024*\"missing\" + 0.023*\"airport\" + 0.023*\"hidden\" + 0.022*\"valuable\"\n",
      "2019-10-29 00:42:51,041 : INFO : topic #4 (0.100): 0.037*\"miami\" + 0.031*\"police\" + 0.029*\"claim\" + 0.028*\"luggage\" + 0.026*\"camera\" + 0.024*\"cnn\" + 0.021*\"hidden\" + 0.021*\"airport\" + 0.020*\"investigation\" + 0.019*\"missing\"\n",
      "2019-10-29 00:42:51,046 : INFO : topic #8 (0.100): 0.047*\"miami\" + 0.033*\"luggage\" + 0.031*\"camera\" + 0.027*\"hidden\" + 0.027*\"police\" + 0.025*\"claim\" + 0.024*\"bag\" + 0.021*\"airport\" + 0.019*\"cnn\" + 0.019*\"theft\"\n",
      "2019-10-29 00:42:51,049 : INFO : topic #2 (0.100): 0.036*\"miami\" + 0.028*\"cnn\" + 0.027*\"police\" + 0.025*\"claim\" + 0.024*\"missing\" + 0.023*\"valuable\" + 0.022*\"airport\" + 0.021*\"theft\" + 0.021*\"camera\" + 0.020*\"luggage\"\n",
      "2019-10-29 00:42:51,051 : INFO : topic #1 (0.100): 0.038*\"miami\" + 0.030*\"camera\" + 0.027*\"luggage\" + 0.027*\"claim\" + 0.027*\"valuable\" + 0.025*\"cnn\" + 0.025*\"theft\" + 0.025*\"police\" + 0.022*\"bag\" + 0.021*\"airport\"\n",
      "2019-10-29 00:42:51,054 : INFO : topic diff=0.789341, rho=1.000000\n",
      "2019-10-29 00:42:51,506 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:51,511 : INFO : built Dictionary(386 unique tokens: ['phase', 'happy', 'injury', 'game', 'excitement']...) from 5 documents (total 3345 corpus positions)\n",
      "2019-10-29 00:42:51,516 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:51,517 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:51,518 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:51,522 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:51,523 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:51,651 : INFO : -7.814 per-word bound, 225.0 perplexity estimate based on a held-out corpus of 5 documents with 3345 words\n",
      "2019-10-29 00:42:51,654 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:51,663 : INFO : topic #1 (0.100): 0.036*\"schmitt\" + 0.016*\"said\" + 0.013*\"swimming\" + 0.012*\"game\" + 0.012*\"depression\" + 0.011*\"olympic\" + 0.010*\"help\" + 0.010*\"bauerle\" + 0.010*\"sport\" + 0.010*\"athlete\"\n",
      "2019-10-29 00:42:51,665 : INFO : topic #8 (0.100): 0.032*\"schmitt\" + 0.019*\"game\" + 0.017*\"said\" + 0.013*\"bauerle\" + 0.013*\"swimming\" + 0.012*\"athlete\" + 0.012*\"olympic\" + 0.011*\"help\" + 0.011*\"depression\" + 0.010*\"sport\"\n",
      "2019-10-29 00:42:51,669 : INFO : topic #7 (0.100): 0.034*\"schmitt\" + 0.020*\"said\" + 0.017*\"swimming\" + 0.015*\"game\" + 0.011*\"olympic\" + 0.011*\"athlete\" + 0.010*\"bauerle\" + 0.010*\"sport\" + 0.009*\"would\" + 0.009*\"coach\"\n",
      "2019-10-29 00:42:51,671 : INFO : topic #2 (0.100): 0.033*\"schmitt\" + 0.026*\"said\" + 0.015*\"game\" + 0.013*\"athlete\" + 0.012*\"olympic\" + 0.012*\"swimming\" + 0.011*\"help\" + 0.010*\"depression\" + 0.009*\"sport\" + 0.009*\"coach\"\n",
      "2019-10-29 00:42:51,674 : INFO : topic #5 (0.100): 0.026*\"schmitt\" + 0.020*\"said\" + 0.015*\"help\" + 0.013*\"game\" + 0.012*\"swimming\" + 0.012*\"olympic\" + 0.010*\"could\" + 0.009*\"bauerle\" + 0.009*\"athlete\" + 0.008*\"thought\"\n",
      "2019-10-29 00:42:51,677 : INFO : topic diff=0.894048, rho=1.000000\n",
      "2019-10-29 00:42:52,126 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:52,128 : INFO : built Dictionary(135 unique tokens: ['dry', 'product', 'end', 'industry', 'something']...) from 5 documents (total 1035 corpus positions)\n",
      "2019-10-29 00:42:52,130 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:52,134 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:52,138 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:52,142 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:52,145 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:52,200 : INFO : -7.013 per-word bound, 129.2 perplexity estimate based on a held-out corpus of 5 documents with 1035 words\n",
      "2019-10-29 00:42:52,202 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:52,208 : INFO : topic #8 (0.100): 0.040*\"product\" + 0.029*\"woman\" + 0.028*\"beauty\" + 0.022*\"brand\" + 0.018*\"tell\" + 0.018*\"really\" + 0.016*\"realized\" + 0.016*\"review\" + 0.015*\"makeup\" + 0.015*\"said\"\n",
      "2019-10-29 00:42:52,211 : INFO : topic #2 (0.100): 0.036*\"product\" + 0.026*\"beauty\" + 0.022*\"brand\" + 0.022*\"woman\" + 0.021*\"review\" + 0.018*\"wei\" + 0.016*\"line\" + 0.016*\"wanted\" + 0.016*\"really\" + 0.015*\"glossier\"\n",
      "2019-10-29 00:42:52,214 : INFO : topic #0 (0.100): 0.042*\"product\" + 0.037*\"woman\" + 0.028*\"brand\" + 0.020*\"beauty\" + 0.020*\"review\" + 0.018*\"really\" + 0.018*\"wei\" + 0.017*\"used\" + 0.016*\"line\" + 0.015*\"said\"\n",
      "2019-10-29 00:42:52,216 : INFO : topic #3 (0.100): 0.037*\"woman\" + 0.036*\"product\" + 0.024*\"brand\" + 0.022*\"wei\" + 0.020*\"review\" + 0.018*\"really\" + 0.017*\"realized\" + 0.015*\"beauty\" + 0.015*\"line\" + 0.015*\"tell\"\n",
      "2019-10-29 00:42:52,219 : INFO : topic #9 (0.100): 0.054*\"product\" + 0.031*\"woman\" + 0.029*\"beauty\" + 0.019*\"brand\" + 0.018*\"review\" + 0.015*\"friend\" + 0.015*\"said\" + 0.015*\"glossier\" + 0.014*\"wei\" + 0.014*\"makeup\"\n",
      "2019-10-29 00:42:52,221 : INFO : topic diff=0.833121, rho=1.000000\n",
      "2019-10-29 00:42:52,624 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:52,630 : INFO : built Dictionary(358 unique tokens: ['rage', 'pushed', 'relative', 'party', 'minding']...) from 5 documents (total 2720 corpus positions)\n",
      "2019-10-29 00:42:52,633 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:52,634 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:52,636 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:52,639 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:52,640 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:52,749 : INFO : -7.924 per-word bound, 242.9 perplexity estimate based on a held-out corpus of 5 documents with 2720 words\n",
      "2019-10-29 00:42:52,750 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:52,757 : INFO : topic #1 (0.100): 0.028*\"corker\" + 0.025*\"trump\" + 0.019*\"president\" + 0.013*\"said\" + 0.011*\"secretary\" + 0.010*\"white\" + 0.009*\"would\" + 0.009*\"state\" + 0.007*\"donald\" + 0.007*\"house\"\n",
      "2019-10-29 00:42:52,759 : INFO : topic #6 (0.100): 0.032*\"trump\" + 0.027*\"corker\" + 0.016*\"president\" + 0.015*\"said\" + 0.010*\"would\" + 0.009*\"state\" + 0.008*\"like\" + 0.008*\"care\" + 0.008*\"donald\" + 0.007*\"election\"\n",
      "2019-10-29 00:42:52,762 : INFO : topic #8 (0.100): 0.028*\"trump\" + 0.026*\"corker\" + 0.018*\"said\" + 0.017*\"president\" + 0.010*\"care\" + 0.010*\"secretary\" + 0.010*\"donald\" + 0.009*\"would\" + 0.009*\"state\" + 0.008*\"adult\"\n",
      "2019-10-29 00:42:52,764 : INFO : topic #5 (0.100): 0.032*\"trump\" + 0.026*\"corker\" + 0.018*\"president\" + 0.016*\"said\" + 0.009*\"secretary\" + 0.009*\"state\" + 0.008*\"may\" + 0.008*\"donald\" + 0.008*\"like\" + 0.008*\"would\"\n",
      "2019-10-29 00:42:52,766 : INFO : topic #7 (0.100): 0.036*\"trump\" + 0.026*\"corker\" + 0.017*\"president\" + 0.011*\"said\" + 0.011*\"white\" + 0.009*\"house\" + 0.009*\"would\" + 0.008*\"care\" + 0.008*\"donald\" + 0.007*\"election\"\n",
      "2019-10-29 00:42:52,768 : INFO : topic diff=0.811089, rho=1.000000\n",
      "2019-10-29 00:42:53,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:53,245 : INFO : built Dictionary(298 unique tokens: ['violence', 'even', 'single', 'book', 'campaign']...) from 5 documents (total 1975 corpus positions)\n",
      "2019-10-29 00:42:53,248 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:53,250 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:53,252 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:53,258 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:53,261 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:53,382 : INFO : -7.975 per-word bound, 251.6 perplexity estimate based on a held-out corpus of 5 documents with 1975 words\n",
      "2019-10-29 00:42:53,384 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:53,391 : INFO : topic #0 (0.100): 0.023*\"sirleaf\" + 0.013*\"liberia\" + 0.012*\"leader\" + 0.012*\"africa\" + 0.011*\"country\" + 0.010*\"first\" + 0.009*\"world\" + 0.009*\"peace\" + 0.009*\"year\" + 0.007*\"two\"\n",
      "2019-10-29 00:42:53,393 : INFO : topic #7 (0.100): 0.027*\"sirleaf\" + 0.018*\"country\" + 0.016*\"liberia\" + 0.011*\"major\" + 0.011*\"africa\" + 0.011*\"year\" + 0.010*\"first\" + 0.010*\"leader\" + 0.009*\"elected\" + 0.008*\"nation\"\n",
      "2019-10-29 00:42:53,394 : INFO : topic #3 (0.100): 0.022*\"sirleaf\" + 0.014*\"liberia\" + 0.012*\"leader\" + 0.011*\"country\" + 0.011*\"peace\" + 0.010*\"major\" + 0.009*\"first\" + 0.009*\"office\" + 0.008*\"party\" + 0.008*\"iron\"\n",
      "2019-10-29 00:42:53,395 : INFO : topic #5 (0.100): 0.028*\"sirleaf\" + 0.016*\"country\" + 0.014*\"leader\" + 0.014*\"liberia\" + 0.012*\"year\" + 0.011*\"peace\" + 0.010*\"major\" + 0.010*\"world\" + 0.009*\"nation\" + 0.008*\"first\"\n",
      "2019-10-29 00:42:53,398 : INFO : topic #4 (0.100): 0.023*\"sirleaf\" + 0.011*\"africa\" + 0.010*\"leader\" + 0.010*\"country\" + 0.010*\"liberia\" + 0.009*\"year\" + 0.008*\"peace\" + 0.008*\"elected\" + 0.008*\"world\" + 0.008*\"first\"\n",
      "2019-10-29 00:42:53,400 : INFO : topic diff=0.746573, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:53,794 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:53,796 : INFO : built Dictionary(22 unique tokens: ['manhattan', 'unexpected', 'see', 'cnn', 'extreme']...) from 5 documents (total 120 corpus positions)\n",
      "2019-10-29 00:42:53,797 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:53,799 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:53,800 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:53,801 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:53,803 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:53,823 : INFO : -6.377 per-word bound, 83.1 perplexity estimate based on a held-out corpus of 5 documents with 120 words\n",
      "2019-10-29 00:42:53,827 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:53,837 : INFO : topic #0 (0.100): 0.082*\"nypd\" + 0.079*\"rescue\" + 0.051*\"service\" + 0.049*\"extreme\" + 0.048*\"fly\" + 0.046*\"bridge\" + 0.046*\"one\" + 0.045*\"high\" + 0.044*\"ny\" + 0.043*\"elite\"\n",
      "2019-10-29 00:42:53,843 : INFO : topic #2 (0.100): 0.072*\"nypd\" + 0.067*\"rescue\" + 0.054*\"see\" + 0.050*\"ny\" + 0.048*\"york\" + 0.048*\"elite\" + 0.048*\"team\" + 0.047*\"extreme\" + 0.046*\"unexpected\" + 0.044*\"bridge\"\n",
      "2019-10-29 00:42:53,849 : INFO : topic #5 (0.100): 0.076*\"rescue\" + 0.070*\"nypd\" + 0.053*\"unit\" + 0.052*\"manhattan\" + 0.052*\"elite\" + 0.049*\"new\" + 0.047*\"york\" + 0.047*\"unexpected\" + 0.046*\"bridge\" + 0.045*\"extreme\"\n",
      "2019-10-29 00:42:53,855 : INFO : topic #6 (0.100): 0.075*\"rescue\" + 0.074*\"nypd\" + 0.050*\"emergency\" + 0.048*\"team\" + 0.047*\"manhattan\" + 0.046*\"climbing\" + 0.045*\"unexpected\" + 0.045*\"bridge\" + 0.045*\"see\" + 0.045*\"train\"\n",
      "2019-10-29 00:42:53,858 : INFO : topic #1 (0.100): 0.072*\"rescue\" + 0.060*\"nypd\" + 0.057*\"new\" + 0.053*\"extreme\" + 0.049*\"unit\" + 0.048*\"team\" + 0.047*\"chopper\" + 0.047*\"manhattan\" + 0.046*\"high\" + 0.044*\"bridge\"\n",
      "2019-10-29 00:42:53,861 : INFO : topic diff=0.604149, rho=1.000000\n",
      "2019-10-29 00:42:54,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:54,264 : INFO : built Dictionary(68 unique tokens: ['amsterdam', 'tjeerd', 'editor', 'dutch', 'mccullough']...) from 5 documents (total 1020 corpus positions)\n",
      "2019-10-29 00:42:54,266 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:54,267 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:54,269 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:54,271 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:54,272 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:54,310 : INFO : -5.618 per-word bound, 49.1 perplexity estimate based on a held-out corpus of 5 documents with 1020 words\n",
      "2019-10-29 00:42:54,313 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:54,318 : INFO : topic #6 (0.100): 0.071*\"world\" + 0.061*\"view\" + 0.061*\"america\" + 0.061*\"trump\" + 0.058*\"cartoon\" + 0.058*\"around\" + 0.041*\"cartoonist\" + 0.025*\"photo\" + 0.020*\"j\" + 0.018*\"living\"\n",
      "2019-10-29 00:42:54,320 : INFO : topic #8 (0.100): 0.063*\"america\" + 0.062*\"view\" + 0.060*\"trump\" + 0.060*\"around\" + 0.049*\"cartoon\" + 0.043*\"cartoonist\" + 0.038*\"world\" + 0.029*\"photo\" + 0.026*\"based\" + 0.022*\"editorial\"\n",
      "2019-10-29 00:42:54,323 : INFO : topic #3 (0.100): 0.065*\"world\" + 0.062*\"cartoon\" + 0.051*\"america\" + 0.049*\"around\" + 0.048*\"view\" + 0.046*\"trump\" + 0.037*\"photo\" + 0.031*\"cartoonist\" + 0.021*\"living\" + 0.020*\"year\"\n",
      "2019-10-29 00:42:54,333 : INFO : topic #0 (0.100): 0.070*\"trump\" + 0.067*\"america\" + 0.066*\"cartoon\" + 0.059*\"world\" + 0.054*\"view\" + 0.042*\"around\" + 0.040*\"cartoonist\" + 0.024*\"photo\" + 0.022*\"based\" + 0.021*\"j\"\n",
      "2019-10-29 00:42:54,336 : INFO : topic #4 (0.100): 0.076*\"around\" + 0.066*\"america\" + 0.061*\"cartoon\" + 0.057*\"view\" + 0.056*\"world\" + 0.048*\"trump\" + 0.032*\"cartoonist\" + 0.023*\"living\" + 0.021*\"editorial\" + 0.018*\"photo\"\n",
      "2019-10-29 00:42:54,340 : INFO : topic diff=0.774728, rho=1.000000\n",
      "2019-10-29 00:42:54,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:54,827 : INFO : built Dictionary(315 unique tokens: ['violence', 'let', 'trying', 'frozen', 'catalonia']...) from 5 documents (total 2910 corpus positions)\n",
      "2019-10-29 00:42:54,831 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:54,832 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:54,833 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:54,834 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:54,836 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:54,937 : INFO : -7.542 per-word bound, 186.3 perplexity estimate based on a held-out corpus of 5 documents with 2910 words\n",
      "2019-10-29 00:42:54,939 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:54,946 : INFO : topic #4 (0.100): 0.029*\"catalan\" + 0.027*\"catalonia\" + 0.026*\"independence\" + 0.024*\"spain\" + 0.018*\"people\" + 0.013*\"said\" + 0.013*\"referendum\" + 0.013*\"spanish\" + 0.012*\"politician\" + 0.010*\"government\"\n",
      "2019-10-29 00:42:54,949 : INFO : topic #6 (0.100): 0.032*\"spain\" + 0.028*\"catalonia\" + 0.024*\"independence\" + 0.021*\"catalan\" + 0.017*\"said\" + 0.014*\"spanish\" + 0.013*\"people\" + 0.012*\"referendum\" + 0.010*\"love\" + 0.009*\"would\"\n",
      "2019-10-29 00:42:54,952 : INFO : topic #7 (0.100): 0.028*\"spain\" + 0.023*\"independence\" + 0.021*\"catalonia\" + 0.017*\"catalan\" + 0.017*\"people\" + 0.016*\"said\" + 0.013*\"spanish\" + 0.010*\"referendum\" + 0.010*\"crisis\" + 0.010*\"love\"\n",
      "2019-10-29 00:42:54,954 : INFO : topic #8 (0.100): 0.034*\"spain\" + 0.029*\"catalonia\" + 0.027*\"catalan\" + 0.018*\"said\" + 0.017*\"independence\" + 0.015*\"people\" + 0.013*\"referendum\" + 0.012*\"spanish\" + 0.009*\"love\" + 0.009*\"way\"\n",
      "2019-10-29 00:42:54,955 : INFO : topic #5 (0.100): 0.032*\"spain\" + 0.024*\"catalan\" + 0.023*\"catalonia\" + 0.017*\"people\" + 0.017*\"said\" + 0.015*\"independence\" + 0.012*\"spanish\" + 0.011*\"referendum\" + 0.010*\"love\" + 0.009*\"crisis\"\n",
      "2019-10-29 00:42:54,957 : INFO : topic diff=0.858656, rho=1.000000\n",
      "2019-10-29 00:42:55,402 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:55,405 : INFO : built Dictionary(180 unique tokens: ['anniversary', 'let', 'prove', 'spare', 'job']...) from 5 documents (total 1000 corpus positions)\n",
      "2019-10-29 00:42:55,407 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:55,409 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:55,409 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:55,412 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:55,413 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:55,493 : INFO : -7.858 per-word bound, 232.0 perplexity estimate based on a held-out corpus of 5 documents with 1000 words\n",
      "2019-10-29 00:42:55,495 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:55,501 : INFO : topic #0 (0.100): 0.015*\"show\" + 0.012*\"valley\" + 0.011*\"doctor\" + 0.011*\"yet\" + 0.011*\"paris\" + 0.011*\"op\" + 0.011*\"released\" + 0.010*\"make\" + 0.010*\"next\" + 0.010*\"anniversary\"\n",
      "2019-10-29 00:42:55,503 : INFO : topic #5 (0.100): 0.018*\"show\" + 0.013*\"world\" + 0.012*\"doctor\" + 0.011*\"make\" + 0.010*\"silicon\" + 0.010*\"yet\" + 0.010*\"news\" + 0.010*\"ed\" + 0.010*\"anniversary\" + 0.010*\"paris\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:55,505 : INFO : topic #2 (0.100): 0.017*\"show\" + 0.013*\"artist\" + 0.011*\"op\" + 0.011*\"released\" + 0.011*\"top\" + 0.011*\"yet\" + 0.010*\"next\" + 0.010*\"news\" + 0.010*\"avery\" + 0.009*\"anniversary\"\n",
      "2019-10-29 00:42:55,506 : INFO : topic #8 (0.100): 0.012*\"top\" + 0.012*\"next\" + 0.012*\"people\" + 0.011*\"ed\" + 0.011*\"show\" + 0.010*\"silicon\" + 0.010*\"world\" + 0.010*\"avery\" + 0.010*\"released\" + 0.009*\"anniversary\"\n",
      "2019-10-29 00:42:55,508 : INFO : topic #3 (0.100): 0.019*\"show\" + 0.011*\"make\" + 0.010*\"next\" + 0.010*\"valley\" + 0.010*\"avery\" + 0.010*\"news\" + 0.009*\"top\" + 0.009*\"doctor\" + 0.009*\"artist\" + 0.009*\"op\"\n",
      "2019-10-29 00:42:55,509 : INFO : topic diff=0.617691, rho=1.000000\n",
      "2019-10-29 00:42:56,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:56,034 : INFO : built Dictionary(87 unique tokens: ['offered', 'inquiry', 'open', 'detailed', 'adviser']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:42:56,037 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:56,038 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:56,039 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:56,041 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:56,042 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:56,090 : INFO : -6.825 per-word bound, 113.4 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:42:56,101 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:56,108 : INFO : topic #0 (0.100): 0.057*\"page\" + 0.023*\"publicly\" + 0.023*\"carter\" + 0.023*\"senate\" + 0.022*\"intelligence\" + 0.022*\"committee\" + 0.019*\"demanded\" + 0.019*\"communication\" + 0.018*\"plead\" + 0.017*\"former\"\n",
      "2019-10-29 00:42:56,109 : INFO : topic #8 (0.100): 0.073*\"page\" + 0.026*\"committee\" + 0.025*\"intelligence\" + 0.025*\"senate\" + 0.022*\"carter\" + 0.020*\"fifth\" + 0.019*\"demanded\" + 0.019*\"cnn\" + 0.019*\"government\" + 0.018*\"former\"\n",
      "2019-10-29 00:42:56,110 : INFO : topic #6 (0.100): 0.051*\"page\" + 0.026*\"carter\" + 0.025*\"committee\" + 0.024*\"intelligence\" + 0.022*\"senate\" + 0.021*\"opportunity\" + 0.019*\"trump\" + 0.017*\"warrant\" + 0.017*\"fbi\" + 0.017*\"monitor\"\n",
      "2019-10-29 00:42:56,114 : INFO : topic #5 (0.100): 0.053*\"page\" + 0.022*\"intelligence\" + 0.022*\"senate\" + 0.021*\"obtained\" + 0.021*\"testify\" + 0.021*\"government\" + 0.020*\"committee\" + 0.020*\"carter\" + 0.019*\"trump\" + 0.019*\"adviser\"\n",
      "2019-10-29 00:42:56,119 : INFO : topic #1 (0.100): 0.068*\"page\" + 0.028*\"committee\" + 0.028*\"senate\" + 0.023*\"intelligence\" + 0.023*\"carter\" + 0.019*\"testify\" + 0.019*\"plead\" + 0.018*\"obtained\" + 0.018*\"request\" + 0.018*\"communication\"\n",
      "2019-10-29 00:42:56,122 : INFO : topic diff=0.733591, rho=1.000000\n",
      "2019-10-29 00:42:56,517 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:56,518 : INFO : built Dictionary(13 unique tokens: ['today', 'president', 'watch', 'trump', 'watched']...) from 5 documents (total 90 corpus positions)\n",
      "2019-10-29 00:42:56,520 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:56,522 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:56,523 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:56,525 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:56,526 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:56,541 : INFO : -5.560 per-word bound, 47.2 perplexity estimate based on a held-out corpus of 5 documents with 90 words\n",
      "2019-10-29 00:42:56,543 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:56,550 : INFO : topic #9 (0.100): 0.152*\"today\" + 0.099*\"following\" + 0.089*\"catch\" + 0.089*\"story\" + 0.081*\"trump\" + 0.077*\"video\" + 0.071*\"must\" + 0.069*\"watch\" + 0.062*\"replay\" + 0.057*\"live\"\n",
      "2019-10-29 00:42:56,552 : INFO : topic #2 (0.100): 0.194*\"today\" + 0.102*\"following\" + 0.096*\"story\" + 0.077*\"trump\" + 0.076*\"catch\" + 0.074*\"watch\" + 0.063*\"watched\" + 0.063*\"must\" + 0.062*\"replay\" + 0.053*\"update\"\n",
      "2019-10-29 00:42:56,557 : INFO : topic #4 (0.100): 0.161*\"today\" + 0.124*\"story\" + 0.100*\"catch\" + 0.096*\"following\" + 0.068*\"video\" + 0.064*\"watched\" + 0.062*\"replay\" + 0.060*\"live\" + 0.056*\"watch\" + 0.055*\"must\"\n",
      "2019-10-29 00:42:56,561 : INFO : topic #8 (0.100): 0.137*\"today\" + 0.132*\"catch\" + 0.126*\"following\" + 0.103*\"story\" + 0.069*\"president\" + 0.064*\"live\" + 0.056*\"watched\" + 0.056*\"trump\" + 0.055*\"watch\" + 0.054*\"replay\"\n",
      "2019-10-29 00:42:56,563 : INFO : topic #7 (0.100): 0.158*\"today\" + 0.126*\"story\" + 0.105*\"catch\" + 0.097*\"following\" + 0.067*\"trump\" + 0.061*\"live\" + 0.059*\"video\" + 0.059*\"president\" + 0.058*\"update\" + 0.055*\"replay\"\n",
      "2019-10-29 00:42:56,566 : INFO : topic diff=0.700193, rho=1.000000\n",
      "2019-10-29 00:42:57,014 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:57,017 : INFO : built Dictionary(129 unique tokens: ['decrease', 'school', 'may', 'grounded', 'death']...) from 5 documents (total 980 corpus positions)\n",
      "2019-10-29 00:42:57,021 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:57,024 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:57,028 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:57,032 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:57,035 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:57,099 : INFO : -6.984 per-word bound, 126.6 perplexity estimate based on a held-out corpus of 5 documents with 980 words\n",
      "2019-10-29 00:42:57,106 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:57,111 : INFO : topic #4 (0.100): 0.030*\"could\" + 0.027*\"rate\" + 0.027*\"researcher\" + 0.025*\"lower\" + 0.021*\"woman\" + 0.021*\"death\" + 0.020*\"study\" + 0.019*\"attended\" + 0.018*\"also\" + 0.017*\"church\"\n",
      "2019-10-29 00:42:57,115 : INFO : topic #2 (0.100): 0.028*\"study\" + 0.026*\"lower\" + 0.024*\"rate\" + 0.023*\"church\" + 0.021*\"could\" + 0.020*\"death\" + 0.020*\"also\" + 0.020*\"attended\" + 0.019*\"woman\" + 0.018*\"researcher\"\n",
      "2019-10-29 00:42:57,119 : INFO : topic #6 (0.100): 0.038*\"rate\" + 0.029*\"study\" + 0.024*\"could\" + 0.024*\"lower\" + 0.021*\"church\" + 0.021*\"woman\" + 0.019*\"also\" + 0.017*\"attended\" + 0.016*\"risk\" + 0.016*\"service\"\n",
      "2019-10-29 00:42:57,122 : INFO : topic #1 (0.100): 0.027*\"could\" + 0.025*\"study\" + 0.022*\"lower\" + 0.021*\"attended\" + 0.020*\"also\" + 0.019*\"rate\" + 0.018*\"researcher\" + 0.017*\"death\" + 0.016*\"church\" + 0.016*\"service\"\n",
      "2019-10-29 00:42:57,126 : INFO : topic #3 (0.100): 0.033*\"rate\" + 0.026*\"lower\" + 0.025*\"study\" + 0.024*\"also\" + 0.021*\"death\" + 0.020*\"researcher\" + 0.020*\"could\" + 0.019*\"church\" + 0.016*\"help\" + 0.015*\"attended\"\n",
      "2019-10-29 00:42:57,129 : INFO : topic diff=0.810380, rho=1.000000\n",
      "2019-10-29 00:42:57,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:57,612 : INFO : built Dictionary(694 unique tokens: ['although', 'wave', 'renamed', 'focus', 'asked']...) from 5 documents (total 7005 corpus positions)\n",
      "2019-10-29 00:42:57,621 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:57,623 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:57,627 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:57,632 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:57,634 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:42:57,898 : INFO : -8.195 per-word bound, 293.0 perplexity estimate based on a held-out corpus of 5 documents with 7005 words\n",
      "2019-10-29 00:42:57,900 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:57,912 : INFO : topic #1 (0.100): 0.050*\"woman\" + 0.016*\"war\" + 0.013*\"code\" + 0.012*\"would\" + 0.011*\"book\" + 0.010*\"mundy\" + 0.010*\"breaking\" + 0.009*\"american\" + 0.009*\"story\" + 0.008*\"really\"\n",
      "2019-10-29 00:42:57,914 : INFO : topic #3 (0.100): 0.053*\"woman\" + 0.021*\"code\" + 0.014*\"war\" + 0.013*\"would\" + 0.013*\"work\" + 0.010*\"breaking\" + 0.009*\"really\" + 0.009*\"american\" + 0.008*\"mundy\" + 0.008*\"book\"\n",
      "2019-10-29 00:42:57,916 : INFO : topic #6 (0.100): 0.045*\"woman\" + 0.023*\"code\" + 0.016*\"war\" + 0.012*\"mundy\" + 0.011*\"book\" + 0.010*\"breaking\" + 0.009*\"american\" + 0.009*\"would\" + 0.007*\"story\" + 0.007*\"really\"\n",
      "2019-10-29 00:42:57,919 : INFO : topic #0 (0.100): 0.041*\"woman\" + 0.020*\"code\" + 0.015*\"would\" + 0.015*\"war\" + 0.011*\"story\" + 0.011*\"book\" + 0.010*\"work\" + 0.009*\"american\" + 0.008*\"mundy\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:42:57,921 : INFO : topic #4 (0.100): 0.049*\"woman\" + 0.015*\"would\" + 0.014*\"war\" + 0.014*\"code\" + 0.012*\"work\" + 0.011*\"breaking\" + 0.010*\"book\" + 0.009*\"mundy\" + 0.009*\"american\" + 0.007*\"story\"\n",
      "2019-10-29 00:42:57,923 : INFO : topic diff=0.951153, rho=1.000000\n",
      "2019-10-29 00:42:58,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:58,376 : INFO : built Dictionary(319 unique tokens: ['forward', 'earned', 'school', 'end', 'come']...) from 5 documents (total 2595 corpus positions)\n",
      "2019-10-29 00:42:58,380 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:58,382 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:58,383 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:58,387 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:58,388 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:58,499 : INFO : -7.715 per-word bound, 210.2 perplexity estimate based on a held-out corpus of 5 documents with 2595 words\n",
      "2019-10-29 00:42:58,501 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:58,510 : INFO : topic #1 (0.100): 0.030*\"said\" + 0.024*\"veteran\" + 0.023*\"vance\" + 0.017*\"help\" + 0.013*\"year\" + 0.011*\"martial\" + 0.009*\"anxiety\" + 0.009*\"program\" + 0.008*\"mma\" + 0.008*\"military\"\n",
      "2019-10-29 00:42:58,513 : INFO : topic #4 (0.100): 0.029*\"said\" + 0.022*\"veteran\" + 0.021*\"vance\" + 0.014*\"help\" + 0.013*\"year\" + 0.011*\"program\" + 0.010*\"martial\" + 0.010*\"art\" + 0.009*\"started\" + 0.008*\"mma\"\n",
      "2019-10-29 00:42:58,515 : INFO : topic #0 (0.100): 0.032*\"said\" + 0.027*\"vance\" + 0.020*\"veteran\" + 0.019*\"help\" + 0.013*\"art\" + 0.012*\"martial\" + 0.011*\"program\" + 0.009*\"year\" + 0.009*\"mma\" + 0.009*\"life\"\n",
      "2019-10-29 00:42:58,517 : INFO : topic #9 (0.100): 0.030*\"said\" + 0.025*\"vance\" + 0.020*\"veteran\" + 0.016*\"help\" + 0.012*\"art\" + 0.012*\"life\" + 0.010*\"year\" + 0.010*\"martial\" + 0.009*\"served\" + 0.009*\"program\"\n",
      "2019-10-29 00:42:58,519 : INFO : topic #2 (0.100): 0.028*\"said\" + 0.025*\"vance\" + 0.021*\"help\" + 0.021*\"veteran\" + 0.011*\"art\" + 0.011*\"martial\" + 0.010*\"life\" + 0.009*\"military\" + 0.009*\"year\" + 0.008*\"army\"\n",
      "2019-10-29 00:42:58,522 : INFO : topic diff=0.810729, rho=1.000000\n",
      "2019-10-29 00:42:58,917 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:58,919 : INFO : built Dictionary(124 unique tokens: ['extensive', 'energy', 'gillie', 'crazier', 'sniping']...) from 5 documents (total 725 corpus positions)\n",
      "2019-10-29 00:42:58,921 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:58,924 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:58,925 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:58,927 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:58,928 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:58,983 : INFO : -7.421 per-word bound, 171.4 perplexity estimate based on a held-out corpus of 5 documents with 725 words\n",
      "2019-10-29 00:42:58,985 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:58,993 : INFO : topic #0 (0.100): 0.032*\"blake\" + 0.022*\"fallon\" + 0.022*\"dynasty\" + 0.020*\"original\" + 0.017*\"girl\" + 0.016*\"character\" + 0.015*\"producer\" + 0.013*\"buck\" + 0.013*\"rich\" + 0.013*\"cristal\"\n",
      "2019-10-29 00:42:58,995 : INFO : topic #3 (0.100): 0.028*\"blake\" + 0.020*\"original\" + 0.018*\"dynasty\" + 0.016*\"fallon\" + 0.015*\"girl\" + 0.014*\"cristal\" + 0.014*\"gossip\" + 0.013*\"character\" + 0.012*\"show\" + 0.012*\"buck\"\n",
      "2019-10-29 00:42:58,996 : INFO : topic #4 (0.100): 0.024*\"blake\" + 0.019*\"original\" + 0.018*\"girl\" + 0.018*\"fallon\" + 0.016*\"dynasty\" + 0.016*\"gossip\" + 0.015*\"banging\" + 0.015*\"rich\" + 0.014*\"show\" + 0.014*\"revival\"\n",
      "2019-10-29 00:42:58,998 : INFO : topic #5 (0.100): 0.022*\"dynasty\" + 0.022*\"girl\" + 0.022*\"fallon\" + 0.018*\"blake\" + 0.016*\"original\" + 0.015*\"revival\" + 0.014*\"rich\" + 0.013*\"super\" + 0.013*\"banging\" + 0.012*\"producer\"\n",
      "2019-10-29 00:42:58,999 : INFO : topic #1 (0.100): 0.026*\"blake\" + 0.021*\"dynasty\" + 0.019*\"original\" + 0.016*\"girl\" + 0.016*\"fallon\" + 0.016*\"rich\" + 0.016*\"character\" + 0.015*\"super\" + 0.014*\"gossip\" + 0.013*\"buck\"\n",
      "2019-10-29 00:42:59,000 : INFO : topic diff=0.661182, rho=1.000000\n",
      "2019-10-29 00:42:59,456 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:42:59,461 : INFO : built Dictionary(353 unique tokens: ['party', 'gigabyte', 'sorry', 'computer', 'u']...) from 5 documents (total 3140 corpus positions)\n",
      "2019-10-29 00:42:59,465 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:42:59,466 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:42:59,468 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:42:59,471 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:42:59,473 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:42:59,600 : INFO : -7.696 per-word bound, 207.3 perplexity estimate based on a held-out corpus of 5 documents with 3140 words\n",
      "2019-10-29 00:42:59,601 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:42:59,610 : INFO : topic #2 (0.100): 0.033*\"north\" + 0.026*\"korea\" + 0.019*\"u\" + 0.018*\"korean\" + 0.018*\"said\" + 0.017*\"south\" + 0.012*\"plan\" + 0.011*\"defense\" + 0.010*\"hacker\" + 0.009*\"information\"\n",
      "2019-10-29 00:42:59,613 : INFO : topic #9 (0.100): 0.040*\"north\" + 0.029*\"korea\" + 0.024*\"u\" + 0.018*\"korean\" + 0.018*\"said\" + 0.016*\"south\" + 0.016*\"plan\" + 0.011*\"trump\" + 0.009*\"hacker\" + 0.009*\"would\"\n",
      "2019-10-29 00:42:59,615 : INFO : topic #3 (0.100): 0.037*\"north\" + 0.034*\"korea\" + 0.019*\"said\" + 0.018*\"korean\" + 0.017*\"u\" + 0.014*\"plan\" + 0.013*\"south\" + 0.011*\"nuclear\" + 0.010*\"trump\" + 0.009*\"hacker\"\n",
      "2019-10-29 00:42:59,618 : INFO : topic #5 (0.100): 0.040*\"korea\" + 0.035*\"north\" + 0.018*\"u\" + 0.016*\"korean\" + 0.016*\"south\" + 0.012*\"said\" + 0.011*\"plan\" + 0.010*\"hacker\" + 0.010*\"defense\" + 0.009*\"kaspersky\"\n",
      "2019-10-29 00:42:59,621 : INFO : topic #8 (0.100): 0.038*\"korea\" + 0.029*\"north\" + 0.020*\"korean\" + 0.017*\"u\" + 0.013*\"plan\" + 0.012*\"said\" + 0.012*\"south\" + 0.011*\"defense\" + 0.010*\"operation\" + 0.009*\"hacker\"\n",
      "2019-10-29 00:42:59,623 : INFO : topic diff=0.858370, rho=1.000000\n",
      "2019-10-29 00:43:00,055 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:00,060 : INFO : built Dictionary(349 unique tokens: ['although', 'let', 'nature', 'advantage', 'asleep']...) from 5 documents (total 3315 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:00,066 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:00,067 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:00,071 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:00,076 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:00,079 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:00,222 : INFO : -7.602 per-word bound, 194.3 perplexity estimate based on a held-out corpus of 5 documents with 3315 words\n",
      "2019-10-29 00:43:00,224 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:00,232 : INFO : topic #0 (0.100): 0.052*\"insurance\" + 0.020*\"company\" + 0.016*\"survivor\" + 0.015*\"health\" + 0.015*\"would\" + 0.015*\"said\" + 0.015*\"law\" + 0.012*\"existing\" + 0.012*\"policy\" + 0.012*\"state\"\n",
      "2019-10-29 00:43:00,235 : INFO : topic #1 (0.100): 0.029*\"insurance\" + 0.019*\"health\" + 0.019*\"said\" + 0.017*\"company\" + 0.015*\"survivor\" + 0.014*\"state\" + 0.013*\"would\" + 0.013*\"law\" + 0.012*\"pre\" + 0.012*\"obamacare\"\n",
      "2019-10-29 00:43:00,238 : INFO : topic #2 (0.100): 0.033*\"insurance\" + 0.020*\"survivor\" + 0.019*\"health\" + 0.017*\"said\" + 0.015*\"neal\" + 0.014*\"would\" + 0.014*\"law\" + 0.014*\"company\" + 0.013*\"state\" + 0.013*\"policy\"\n",
      "2019-10-29 00:43:00,241 : INFO : topic #6 (0.100): 0.047*\"insurance\" + 0.022*\"health\" + 0.020*\"company\" + 0.016*\"survivor\" + 0.016*\"said\" + 0.014*\"law\" + 0.013*\"policy\" + 0.012*\"would\" + 0.012*\"pre\" + 0.012*\"condition\"\n",
      "2019-10-29 00:43:00,244 : INFO : topic #9 (0.100): 0.059*\"insurance\" + 0.021*\"health\" + 0.021*\"survivor\" + 0.018*\"state\" + 0.016*\"company\" + 0.015*\"law\" + 0.014*\"said\" + 0.014*\"condition\" + 0.013*\"would\" + 0.011*\"policy\"\n",
      "2019-10-29 00:43:00,248 : INFO : topic diff=0.976010, rho=1.000000\n",
      "2019-10-29 00:43:00,662 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:00,665 : INFO : built Dictionary(147 unique tokens: ['let', 'sorry', 'tax', 'end', 'nation']...) from 5 documents (total 1590 corpus positions)\n",
      "2019-10-29 00:43:00,668 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:00,670 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:00,671 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:00,673 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:00,675 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:00,733 : INFO : -6.635 per-word bound, 99.4 perplexity estimate based on a held-out corpus of 5 documents with 1590 words\n",
      "2019-10-29 00:43:00,735 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:00,744 : INFO : topic #1 (0.100): 0.057*\"highest\" + 0.039*\"taxed\" + 0.036*\"said\" + 0.034*\"nation\" + 0.034*\"president\" + 0.032*\"sander\" + 0.029*\"world\" + 0.024*\"yingst\" + 0.022*\"trump\" + 0.022*\"corporate\"\n",
      "2019-10-29 00:43:00,746 : INFO : topic #0 (0.100): 0.048*\"taxed\" + 0.042*\"sander\" + 0.038*\"highest\" + 0.036*\"said\" + 0.036*\"nation\" + 0.028*\"president\" + 0.025*\"world\" + 0.024*\"tax\" + 0.023*\"yingst\" + 0.023*\"trump\"\n",
      "2019-10-29 00:43:00,748 : INFO : topic #9 (0.100): 0.050*\"taxed\" + 0.049*\"highest\" + 0.033*\"sander\" + 0.031*\"world\" + 0.028*\"said\" + 0.027*\"nation\" + 0.025*\"president\" + 0.025*\"yingst\" + 0.025*\"trump\" + 0.020*\"corporate\"\n",
      "2019-10-29 00:43:00,749 : INFO : topic #5 (0.100): 0.054*\"taxed\" + 0.041*\"highest\" + 0.036*\"said\" + 0.035*\"sander\" + 0.031*\"nation\" + 0.030*\"president\" + 0.027*\"corporate\" + 0.022*\"world\" + 0.020*\"saying\" + 0.020*\"trump\"\n",
      "2019-10-29 00:43:00,752 : INFO : topic #7 (0.100): 0.046*\"sander\" + 0.043*\"highest\" + 0.038*\"taxed\" + 0.035*\"nation\" + 0.028*\"president\" + 0.026*\"world\" + 0.026*\"said\" + 0.026*\"trump\" + 0.023*\"corporate\" + 0.023*\"u\"\n",
      "2019-10-29 00:43:00,753 : INFO : topic diff=1.046506, rho=1.000000\n",
      "2019-10-29 00:43:01,226 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:01,232 : INFO : built Dictionary(250 unique tokens: ['let', 'trying', 'weinstein', 'industry', 'mounting']...) from 5 documents (total 2045 corpus positions)\n",
      "2019-10-29 00:43:01,236 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:01,238 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:01,240 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:01,243 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:01,245 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:01,369 : INFO : -7.482 per-word bound, 178.8 perplexity estimate based on a held-out corpus of 5 documents with 2045 words\n",
      "2019-10-29 00:43:01,372 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:01,380 : INFO : topic #2 (0.100): 0.039*\"weinstein\" + 0.029*\"harvey\" + 0.026*\"brother\" + 0.021*\"said\" + 0.019*\"board\" + 0.018*\"source\" + 0.017*\"bob\" + 0.014*\"company\" + 0.014*\"two\" + 0.012*\"time\"\n",
      "2019-10-29 00:43:01,383 : INFO : topic #4 (0.100): 0.042*\"weinstein\" + 0.035*\"harvey\" + 0.025*\"bob\" + 0.022*\"said\" + 0.016*\"brother\" + 0.016*\"board\" + 0.016*\"company\" + 0.016*\"time\" + 0.014*\"source\" + 0.014*\"two\"\n",
      "2019-10-29 00:43:01,387 : INFO : topic #5 (0.100): 0.038*\"weinstein\" + 0.030*\"harvey\" + 0.025*\"said\" + 0.022*\"brother\" + 0.019*\"board\" + 0.018*\"bob\" + 0.017*\"time\" + 0.015*\"company\" + 0.014*\"two\" + 0.012*\"friend\"\n",
      "2019-10-29 00:43:01,390 : INFO : topic #8 (0.100): 0.054*\"weinstein\" + 0.026*\"harvey\" + 0.026*\"bob\" + 0.025*\"brother\" + 0.019*\"said\" + 0.016*\"company\" + 0.015*\"board\" + 0.013*\"two\" + 0.012*\"fired\" + 0.012*\"source\"\n",
      "2019-10-29 00:43:01,393 : INFO : topic #1 (0.100): 0.039*\"weinstein\" + 0.025*\"harvey\" + 0.025*\"bob\" + 0.021*\"brother\" + 0.019*\"board\" + 0.019*\"source\" + 0.019*\"said\" + 0.015*\"two\" + 0.014*\"fired\" + 0.013*\"company\"\n",
      "2019-10-29 00:43:01,396 : INFO : topic diff=0.878093, rho=1.000000\n",
      "2019-10-29 00:43:01,844 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:01,850 : INFO : built Dictionary(392 unique tokens: ['rage', 'earned', 'deep', 'party', 'drive']...) from 5 documents (total 2900 corpus positions)\n",
      "2019-10-29 00:43:01,854 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:01,855 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:01,857 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:01,861 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:01,864 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:01,978 : INFO : -8.056 per-word bound, 266.1 perplexity estimate based on a held-out corpus of 5 documents with 2900 words\n",
      "2019-10-29 00:43:01,980 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:01,987 : INFO : topic #4 (0.100): 0.035*\"trump\" + 0.026*\"tax\" + 0.015*\"republican\" + 0.012*\"corker\" + 0.011*\"chance\" + 0.009*\"washington\" + 0.008*\"plan\" + 0.008*\"bob\" + 0.008*\"reform\" + 0.007*\"could\"\n",
      "2019-10-29 00:43:01,990 : INFO : topic #5 (0.100): 0.037*\"trump\" + 0.018*\"tax\" + 0.014*\"corker\" + 0.014*\"chance\" + 0.013*\"republican\" + 0.010*\"washington\" + 0.009*\"reform\" + 0.008*\"president\" + 0.008*\"sen\" + 0.007*\"could\"\n",
      "2019-10-29 00:43:01,992 : INFO : topic #7 (0.100): 0.024*\"trump\" + 0.021*\"tax\" + 0.020*\"republican\" + 0.018*\"corker\" + 0.011*\"chance\" + 0.009*\"bob\" + 0.008*\"washington\" + 0.008*\"reform\" + 0.008*\"first\" + 0.008*\"could\"\n",
      "2019-10-29 00:43:01,995 : INFO : topic #0 (0.100): 0.029*\"trump\" + 0.028*\"tax\" + 0.016*\"republican\" + 0.013*\"corker\" + 0.011*\"reform\" + 0.009*\"bob\" + 0.009*\"president\" + 0.008*\"could\" + 0.008*\"chance\" + 0.008*\"washington\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:01,997 : INFO : topic #3 (0.100): 0.031*\"trump\" + 0.023*\"tax\" + 0.015*\"republican\" + 0.014*\"chance\" + 0.013*\"corker\" + 0.011*\"reform\" + 0.011*\"bob\" + 0.008*\"may\" + 0.008*\"first\" + 0.007*\"year\"\n",
      "2019-10-29 00:43:02,000 : INFO : topic diff=0.809935, rho=1.000000\n",
      "2019-10-29 00:43:02,383 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:02,385 : INFO : built Dictionary(75 unique tokens: ['civilian', 'operation', 'defeat', 'ii', 'campaign']...) from 5 documents (total 485 corpus positions)\n",
      "2019-10-29 00:43:02,387 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:02,388 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:02,390 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:02,393 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:02,394 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:02,430 : INFO : -6.806 per-word bound, 111.9 perplexity estimate based on a held-out corpus of 5 documents with 485 words\n",
      "2019-10-29 00:43:02,432 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:02,438 : INFO : topic #8 (0.100): 0.037*\"iraqi\" + 0.033*\"said\" + 0.031*\"force\" + 0.030*\"isi\" + 0.027*\"city\" + 0.024*\"statement\" + 0.022*\"hawija\" + 0.021*\"center\" + 0.021*\"partner\" + 0.020*\"lt\"\n",
      "2019-10-29 00:43:02,440 : INFO : topic #2 (0.100): 0.046*\"said\" + 0.042*\"isi\" + 0.040*\"iraqi\" + 0.026*\"force\" + 0.025*\"city\" + 0.022*\"partner\" + 0.022*\"hawija\" + 0.021*\"gen\" + 0.020*\"lt\" + 0.019*\"operation\"\n",
      "2019-10-29 00:43:02,443 : INFO : topic #1 (0.100): 0.045*\"isi\" + 0.043*\"force\" + 0.031*\"iraqi\" + 0.028*\"hawija\" + 0.022*\"said\" + 0.022*\"partner\" + 0.022*\"joint\" + 0.022*\"center\" + 0.021*\"city\" + 0.020*\"gen\"\n",
      "2019-10-29 00:43:02,448 : INFO : topic #6 (0.100): 0.043*\"iraqi\" + 0.038*\"force\" + 0.032*\"isi\" + 0.031*\"hawija\" + 0.025*\"said\" + 0.025*\"center\" + 0.022*\"gen\" + 0.022*\"statement\" + 0.021*\"thursday\" + 0.020*\"joint\"\n",
      "2019-10-29 00:43:02,451 : INFO : topic #9 (0.100): 0.046*\"force\" + 0.041*\"iraqi\" + 0.041*\"isi\" + 0.031*\"hawija\" + 0.023*\"lt\" + 0.021*\"said\" + 0.021*\"operation\" + 0.020*\"joint\" + 0.020*\"gen\" + 0.020*\"center\"\n",
      "2019-10-29 00:43:02,454 : INFO : topic diff=0.737604, rho=1.000000\n",
      "2019-10-29 00:43:02,883 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:02,885 : INFO : built Dictionary(1 unique tokens: ['nan']) from 5 documents (total 5 corpus positions)\n",
      "2019-10-29 00:43:02,887 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:02,890 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:02,892 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:02,895 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:02,897 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:02,904 : INFO : -4.922 per-word bound, 30.3 perplexity estimate based on a held-out corpus of 5 documents with 5 words\n",
      "2019-10-29 00:43:02,906 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:02,910 : INFO : topic #0 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:43:02,913 : INFO : topic #9 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:43:02,915 : INFO : topic #4 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:43:02,918 : INFO : topic #7 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:43:02,921 : INFO : topic #3 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:43:02,923 : INFO : topic diff=0.000000, rho=1.000000\n",
      "2019-10-29 00:43:03,326 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:03,328 : INFO : built Dictionary(74 unique tokens: ['several', 'burying', 'trillion', 'end', 'battered']...) from 5 documents (total 510 corpus positions)\n",
      "2019-10-29 00:43:03,329 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:03,331 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:03,335 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:03,339 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:03,342 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:03,374 : INFO : -6.673 per-word bound, 102.1 perplexity estimate based on a held-out corpus of 5 documents with 510 words\n",
      "2019-10-29 00:43:03,379 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:03,386 : INFO : topic #7 (0.100): 0.055*\"hurricane\" + 0.051*\"storm\" + 0.033*\"harvey\" + 0.030*\"south\" + 0.028*\"area\" + 0.022*\"hit\" + 0.021*\"state\" + 0.021*\"look\" + 0.020*\"irma\" + 0.019*\"texas\"\n",
      "2019-10-29 00:43:03,391 : INFO : topic #2 (0.100): 0.052*\"storm\" + 0.043*\"harvey\" + 0.041*\"hurricane\" + 0.030*\"area\" + 0.029*\"south\" + 0.023*\"texas\" + 0.022*\"irma\" + 0.020*\"caribbean\" + 0.020*\"hit\" + 0.020*\"multiple\"\n",
      "2019-10-29 00:43:03,397 : INFO : topic #3 (0.100): 0.060*\"hurricane\" + 0.039*\"harvey\" + 0.038*\"storm\" + 0.027*\"area\" + 0.026*\"south\" + 0.023*\"caribbean\" + 0.023*\"also\" + 0.023*\"look\" + 0.022*\"state\" + 0.020*\"louisiana\"\n",
      "2019-10-29 00:43:03,400 : INFO : topic #8 (0.100): 0.061*\"hurricane\" + 0.047*\"storm\" + 0.031*\"harvey\" + 0.025*\"also\" + 0.024*\"south\" + 0.024*\"area\" + 0.021*\"caribbean\" + 0.021*\"season\" + 0.021*\"brutal\" + 0.021*\"hit\"\n",
      "2019-10-29 00:43:03,402 : INFO : topic #6 (0.100): 0.050*\"hurricane\" + 0.046*\"storm\" + 0.032*\"harvey\" + 0.030*\"area\" + 0.027*\"south\" + 0.024*\"multiple\" + 0.022*\"season\" + 0.020*\"texas\" + 0.020*\"state\" + 0.019*\"irma\"\n",
      "2019-10-29 00:43:03,404 : INFO : topic diff=0.751869, rho=1.000000\n",
      "2019-10-29 00:43:03,839 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:03,842 : INFO : built Dictionary(36 unique tokens: ['considered', 'myanmar', 'since', 'rakhine', 'nation']...) from 5 documents (total 200 corpus positions)\n",
      "2019-10-29 00:43:03,844 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:03,846 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:03,848 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:03,850 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:03,851 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:03,879 : INFO : -6.597 per-word bound, 96.8 perplexity estimate based on a held-out corpus of 5 documents with 200 words\n",
      "2019-10-29 00:43:03,881 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:03,888 : INFO : topic #5 (0.100): 0.087*\"rohingya\" + 0.049*\"bangladesh\" + 0.047*\"muslim\" + 0.031*\"people\" + 0.031*\"myanmar\" + 0.030*\"live\" + 0.030*\"world\" + 0.029*\"group\" + 0.029*\"state\" + 0.029*\"refugee\"\n",
      "2019-10-29 00:43:03,892 : INFO : topic #0 (0.100): 0.072*\"rohingya\" + 0.052*\"muslim\" + 0.036*\"bangladesh\" + 0.031*\"refugee\" + 0.031*\"considered\" + 0.031*\"human\" + 0.031*\"recognized\" + 0.030*\"friday\" + 0.030*\"support\" + 0.028*\"september\"\n",
      "2019-10-29 00:43:03,894 : INFO : topic #3 (0.100): 0.062*\"rohingya\" + 0.041*\"muslim\" + 0.035*\"bangladesh\" + 0.033*\"refugee\" + 0.033*\"friday\" + 0.032*\"united\" + 0.031*\"fled\" + 0.031*\"show\" + 0.031*\"government\" + 0.031*\"august\"\n",
      "2019-10-29 00:43:03,897 : INFO : topic #8 (0.100): 0.071*\"rohingya\" + 0.047*\"muslim\" + 0.045*\"bangladesh\" + 0.034*\"right\" + 0.032*\"demonstration\" + 0.032*\"rakhine\" + 0.031*\"nation\" + 0.028*\"among\" + 0.028*\"according\" + 0.028*\"many\"\n",
      "2019-10-29 00:43:03,900 : INFO : topic #1 (0.100): 0.062*\"rohingya\" + 0.055*\"bangladesh\" + 0.047*\"muslim\" + 0.036*\"show\" + 0.030*\"week\" + 0.030*\"persecuted\" + 0.029*\"citizen\" + 0.029*\"according\" + 0.029*\"world\" + 0.028*\"state\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:03,904 : INFO : topic diff=0.629316, rho=1.000000\n",
      "2019-10-29 00:43:04,464 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:04,481 : INFO : built Dictionary(902 unique tokens: ['located', 'dusty', 'focus', 'phonetics', 'loss']...) from 5 documents (total 8270 corpus positions)\n",
      "2019-10-29 00:43:04,495 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:04,497 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:04,502 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:04,508 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:04,512 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:04,772 : INFO : -8.562 per-word bound, 378.0 perplexity estimate based on a held-out corpus of 5 documents with 8270 words\n",
      "2019-10-29 00:43:04,774 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:04,786 : INFO : topic #8 (0.100): 0.021*\"coral\" + 0.013*\"reef\" + 0.010*\"island\" + 0.009*\"white\" + 0.009*\"hary\" + 0.008*\"lydia\" + 0.007*\"like\" + 0.007*\"water\" + 0.006*\"say\" + 0.006*\"tell\"\n",
      "2019-10-29 00:43:04,788 : INFO : topic #7 (0.100): 0.013*\"reef\" + 0.013*\"coral\" + 0.013*\"hary\" + 0.010*\"lydia\" + 0.009*\"island\" + 0.009*\"water\" + 0.009*\"like\" + 0.008*\"people\" + 0.008*\"white\" + 0.007*\"child\"\n",
      "2019-10-29 00:43:04,792 : INFO : topic #3 (0.100): 0.025*\"coral\" + 0.014*\"reef\" + 0.012*\"hary\" + 0.012*\"lydia\" + 0.010*\"water\" + 0.009*\"white\" + 0.007*\"like\" + 0.007*\"people\" + 0.007*\"child\" + 0.007*\"ocean\"\n",
      "2019-10-29 00:43:04,796 : INFO : topic #9 (0.100): 0.021*\"coral\" + 0.016*\"reef\" + 0.011*\"lydia\" + 0.010*\"people\" + 0.009*\"like\" + 0.009*\"hary\" + 0.008*\"island\" + 0.008*\"water\" + 0.006*\"say\" + 0.006*\"white\"\n",
      "2019-10-29 00:43:04,799 : INFO : topic #1 (0.100): 0.013*\"coral\" + 0.012*\"lydia\" + 0.012*\"reef\" + 0.011*\"hary\" + 0.009*\"water\" + 0.009*\"people\" + 0.008*\"white\" + 0.007*\"change\" + 0.007*\"ocean\" + 0.007*\"tell\"\n",
      "2019-10-29 00:43:04,802 : INFO : topic diff=0.939132, rho=1.000000\n",
      "2019-10-29 00:43:05,212 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:05,214 : INFO : built Dictionary(106 unique tokens: ['previously', 'previewed', 'small', 'failure', 'identified']...) from 5 documents (total 670 corpus positions)\n",
      "2019-10-29 00:43:05,216 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:05,217 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:05,219 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:05,222 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:05,223 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:05,272 : INFO : -7.137 per-word bound, 140.8 perplexity estimate based on a held-out corpus of 5 documents with 670 words\n",
      "2019-10-29 00:43:05,275 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:05,284 : INFO : topic #8 (0.100): 0.045*\"trump\" + 0.035*\"care\" + 0.025*\"state\" + 0.020*\"said\" + 0.018*\"president\" + 0.017*\"great\" + 0.016*\"buy\" + 0.015*\"insurance\" + 0.015*\"across\" + 0.015*\"week\"\n",
      "2019-10-29 00:43:05,291 : INFO : topic #1 (0.100): 0.041*\"trump\" + 0.038*\"state\" + 0.025*\"care\" + 0.022*\"great\" + 0.018*\"said\" + 0.018*\"action\" + 0.017*\"across\" + 0.016*\"take\" + 0.015*\"executive\" + 0.015*\"health\"\n",
      "2019-10-29 00:43:05,295 : INFO : topic #5 (0.100): 0.044*\"trump\" + 0.030*\"care\" + 0.027*\"state\" + 0.019*\"great\" + 0.018*\"said\" + 0.017*\"across\" + 0.017*\"health\" + 0.015*\"order\" + 0.015*\"buy\" + 0.015*\"would\"\n",
      "2019-10-29 00:43:05,297 : INFO : topic #2 (0.100): 0.034*\"trump\" + 0.027*\"care\" + 0.024*\"state\" + 0.023*\"said\" + 0.019*\"great\" + 0.018*\"would\" + 0.016*\"week\" + 0.015*\"president\" + 0.015*\"sign\" + 0.014*\"executive\"\n",
      "2019-10-29 00:43:05,300 : INFO : topic #3 (0.100): 0.033*\"trump\" + 0.028*\"state\" + 0.025*\"said\" + 0.022*\"care\" + 0.020*\"great\" + 0.017*\"would\" + 0.016*\"order\" + 0.016*\"executive\" + 0.015*\"line\" + 0.015*\"insurance\"\n",
      "2019-10-29 00:43:05,304 : INFO : topic diff=0.722542, rho=1.000000\n",
      "2019-10-29 00:43:05,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:05,712 : INFO : built Dictionary(94 unique tokens: ['abuarquob', 'end', 'marched', 'towards', 'side']...) from 5 documents (total 665 corpus positions)\n",
      "2019-10-29 00:43:05,714 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:05,715 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:05,717 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:05,719 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:05,721 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:05,763 : INFO : -6.828 per-word bound, 113.6 perplexity estimate based on a held-out corpus of 5 documents with 665 words\n",
      "2019-10-29 00:43:05,764 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:05,772 : INFO : topic #1 (0.100): 0.084*\"woman\" + 0.043*\"peace\" + 0.031*\"leader\" + 0.029*\"palestinian\" + 0.023*\"israeli\" + 0.018*\"political\" + 0.017*\"two\" + 0.017*\"march\" + 0.016*\"tent\" + 0.015*\"west\"\n",
      "2019-10-29 00:43:05,774 : INFO : topic #0 (0.100): 0.100*\"woman\" + 0.042*\"peace\" + 0.027*\"leader\" + 0.024*\"palestinian\" + 0.021*\"israeli\" + 0.017*\"political\" + 0.016*\"conflict\" + 0.016*\"felt\" + 0.016*\"bank\" + 0.016*\"two\"\n",
      "2019-10-29 00:43:05,777 : INFO : topic #5 (0.100): 0.060*\"woman\" + 0.040*\"peace\" + 0.030*\"leader\" + 0.027*\"palestinian\" + 0.022*\"israeli\" + 0.017*\"bank\" + 0.017*\"white\" + 0.017*\"arm\" + 0.017*\"two\" + 0.017*\"tent\"\n",
      "2019-10-29 00:43:05,780 : INFO : topic #9 (0.100): 0.050*\"woman\" + 0.042*\"peace\" + 0.031*\"palestinian\" + 0.022*\"leader\" + 0.021*\"israeli\" + 0.020*\"abuarquob\" + 0.017*\"felt\" + 0.016*\"agreement\" + 0.016*\"tent\" + 0.016*\"side\"\n",
      "2019-10-29 00:43:05,783 : INFO : topic #6 (0.100): 0.082*\"woman\" + 0.037*\"peace\" + 0.033*\"palestinian\" + 0.028*\"leader\" + 0.021*\"israeli\" + 0.019*\"israel\" + 0.018*\"conflict\" + 0.016*\"bank\" + 0.016*\"white\" + 0.015*\"west\"\n",
      "2019-10-29 00:43:05,788 : INFO : topic diff=0.764357, rho=1.000000\n",
      "2019-10-29 00:43:06,210 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:06,214 : INFO : built Dictionary(262 unique tokens: ['even', 'end', 'hero', 'come', 'hospice']...) from 5 documents (total 2120 corpus positions)\n",
      "2019-10-29 00:43:06,217 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:06,219 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:06,221 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:06,224 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:06,225 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:06,332 : INFO : -7.539 per-word bound, 186.0 perplexity estimate based on a held-out corpus of 5 documents with 2120 words\n",
      "2019-10-29 00:43:06,334 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:06,340 : INFO : topic #4 (0.100): 0.049*\"child\" + 0.023*\"mashale\" + 0.018*\"cnn\" + 0.012*\"care\" + 0.012*\"rosie\" + 0.011*\"aid\" + 0.011*\"program\" + 0.010*\"community\" + 0.010*\"work\" + 0.010*\"parent\"\n",
      "2019-10-29 00:43:06,342 : INFO : topic #0 (0.100): 0.036*\"child\" + 0.033*\"mashale\" + 0.017*\"cnn\" + 0.014*\"parent\" + 0.013*\"care\" + 0.012*\"rosie\" + 0.011*\"center\" + 0.010*\"aid\" + 0.010*\"program\" + 0.010*\"year\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:06,344 : INFO : topic #5 (0.100): 0.044*\"child\" + 0.034*\"mashale\" + 0.017*\"cnn\" + 0.016*\"care\" + 0.012*\"aid\" + 0.011*\"program\" + 0.011*\"parent\" + 0.011*\"rosie\" + 0.010*\"work\" + 0.010*\"center\"\n",
      "2019-10-29 00:43:06,347 : INFO : topic #3 (0.100): 0.048*\"child\" + 0.034*\"mashale\" + 0.020*\"cnn\" + 0.015*\"rosie\" + 0.014*\"care\" + 0.013*\"parent\" + 0.011*\"kid\" + 0.011*\"aid\" + 0.010*\"community\" + 0.010*\"organization\"\n",
      "2019-10-29 00:43:06,349 : INFO : topic #2 (0.100): 0.049*\"child\" + 0.027*\"mashale\" + 0.019*\"cnn\" + 0.015*\"rosie\" + 0.015*\"care\" + 0.011*\"home\" + 0.011*\"program\" + 0.010*\"aid\" + 0.010*\"organization\" + 0.009*\"africa\"\n",
      "2019-10-29 00:43:06,352 : INFO : topic diff=0.878930, rho=1.000000\n",
      "2019-10-29 00:43:06,770 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:06,776 : INFO : built Dictionary(372 unique tokens: ['valuable', 'energy', 'phase', 'revealed', 'relax']...) from 5 documents (total 3305 corpus positions)\n",
      "2019-10-29 00:43:06,781 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:06,782 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:06,784 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:06,790 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:06,793 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:06,922 : INFO : -7.743 per-word bound, 214.2 perplexity estimate based on a held-out corpus of 5 documents with 3305 words\n",
      "2019-10-29 00:43:06,923 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:06,932 : INFO : topic #8 (0.100): 0.038*\"gardner\" + 0.024*\"sketch\" + 0.024*\"say\" + 0.013*\"drawing\" + 0.012*\"plane\" + 0.011*\"flight\" + 0.010*\"board\" + 0.010*\"sketching\" + 0.009*\"really\" + 0.008*\"scene\"\n",
      "2019-10-29 00:43:06,934 : INFO : topic #0 (0.100): 0.044*\"gardner\" + 0.023*\"say\" + 0.018*\"sketch\" + 0.016*\"plane\" + 0.011*\"drawing\" + 0.011*\"really\" + 0.009*\"sketching\" + 0.009*\"board\" + 0.007*\"time\" + 0.007*\"two\"\n",
      "2019-10-29 00:43:06,936 : INFO : topic #9 (0.100): 0.049*\"gardner\" + 0.025*\"sketch\" + 0.018*\"say\" + 0.015*\"plane\" + 0.011*\"board\" + 0.009*\"really\" + 0.009*\"flight\" + 0.009*\"passenger\" + 0.009*\"drawing\" + 0.008*\"scene\"\n",
      "2019-10-29 00:43:06,939 : INFO : topic #4 (0.100): 0.045*\"gardner\" + 0.018*\"say\" + 0.017*\"sketch\" + 0.015*\"plane\" + 0.012*\"really\" + 0.011*\"board\" + 0.010*\"flight\" + 0.009*\"drawing\" + 0.009*\"painting\" + 0.008*\"two\"\n",
      "2019-10-29 00:43:06,941 : INFO : topic #1 (0.100): 0.049*\"gardner\" + 0.026*\"say\" + 0.023*\"sketch\" + 0.013*\"board\" + 0.011*\"plane\" + 0.011*\"drawing\" + 0.011*\"really\" + 0.009*\"scene\" + 0.008*\"passenger\" + 0.007*\"flight\"\n",
      "2019-10-29 00:43:06,945 : INFO : topic diff=0.894214, rho=1.000000\n",
      "2019-10-29 00:43:07,391 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:07,395 : INFO : built Dictionary(192 unique tokens: ['forward', 'deter', 'weinstein', 'victimized', 'come']...) from 5 documents (total 1450 corpus positions)\n",
      "2019-10-29 00:43:07,399 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:07,401 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:07,405 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:07,408 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:07,411 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:07,498 : INFO : -7.352 per-word bound, 163.3 perplexity estimate based on a held-out corpus of 5 documents with 1450 words\n",
      "2019-10-29 00:43:07,500 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:07,508 : INFO : topic #1 (0.100): 0.034*\"crew\" + 0.029*\"weinstein\" + 0.027*\"said\" + 0.024*\"allegation\" + 0.023*\"hollywood\" + 0.015*\"executive\" + 0.014*\"power\" + 0.012*\"forward\" + 0.011*\"woman\" + 0.011*\"many\"\n",
      "2019-10-29 00:43:07,511 : INFO : topic #2 (0.100): 0.034*\"crew\" + 0.030*\"said\" + 0.030*\"weinstein\" + 0.025*\"allegation\" + 0.018*\"hollywood\" + 0.015*\"power\" + 0.014*\"woman\" + 0.012*\"forward\" + 0.012*\"story\" + 0.012*\"sexual\"\n",
      "2019-10-29 00:43:07,514 : INFO : topic #8 (0.100): 0.029*\"crew\" + 0.028*\"said\" + 0.027*\"allegation\" + 0.026*\"weinstein\" + 0.017*\"hollywood\" + 0.016*\"power\" + 0.014*\"forward\" + 0.014*\"woman\" + 0.013*\"harassment\" + 0.013*\"executive\"\n",
      "2019-10-29 00:43:07,517 : INFO : topic #6 (0.100): 0.036*\"crew\" + 0.035*\"weinstein\" + 0.026*\"said\" + 0.020*\"hollywood\" + 0.019*\"power\" + 0.016*\"allegation\" + 0.013*\"want\" + 0.012*\"executive\" + 0.011*\"predator\" + 0.011*\"woman\"\n",
      "2019-10-29 00:43:07,519 : INFO : topic #5 (0.100): 0.036*\"crew\" + 0.032*\"weinstein\" + 0.028*\"said\" + 0.020*\"hollywood\" + 0.015*\"allegation\" + 0.015*\"executive\" + 0.014*\"power\" + 0.013*\"woman\" + 0.012*\"want\" + 0.011*\"ostracized\"\n",
      "2019-10-29 00:43:07,522 : INFO : topic diff=0.827271, rho=1.000000\n",
      "2019-10-29 00:43:08,072 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:08,081 : INFO : built Dictionary(694 unique tokens: ['earned', 'wave', 'florida', 'lamented', 'stop']...) from 5 documents (total 7435 corpus positions)\n",
      "2019-10-29 00:43:08,089 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:08,092 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:08,096 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:08,101 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:08,104 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:08,301 : INFO : -8.124 per-word bound, 278.9 perplexity estimate based on a held-out corpus of 5 documents with 7435 words\n",
      "2019-10-29 00:43:08,302 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:08,315 : INFO : topic #9 (0.100): 0.072*\"mccain\" + 0.032*\"john\" + 0.027*\"photo\" + 0.027*\"sen\" + 0.025*\"caption\" + 0.021*\"career\" + 0.021*\"hide\" + 0.019*\"life\" + 0.008*\"republican\" + 0.008*\"senate\"\n",
      "2019-10-29 00:43:08,317 : INFO : topic #2 (0.100): 0.063*\"mccain\" + 0.034*\"john\" + 0.027*\"photo\" + 0.023*\"hide\" + 0.023*\"sen\" + 0.022*\"life\" + 0.015*\"career\" + 0.014*\"caption\" + 0.010*\"senate\" + 0.010*\"republican\"\n",
      "2019-10-29 00:43:08,318 : INFO : topic #0 (0.100): 0.058*\"mccain\" + 0.036*\"john\" + 0.032*\"sen\" + 0.027*\"hide\" + 0.021*\"career\" + 0.018*\"life\" + 0.016*\"caption\" + 0.015*\"photo\" + 0.012*\"senate\" + 0.011*\"republican\"\n",
      "2019-10-29 00:43:08,322 : INFO : topic #7 (0.100): 0.069*\"mccain\" + 0.034*\"john\" + 0.031*\"sen\" + 0.027*\"caption\" + 0.022*\"photo\" + 0.022*\"life\" + 0.021*\"career\" + 0.018*\"hide\" + 0.010*\"senate\" + 0.007*\"vote\"\n",
      "2019-10-29 00:43:08,325 : INFO : topic #4 (0.100): 0.069*\"mccain\" + 0.030*\"sen\" + 0.028*\"hide\" + 0.027*\"john\" + 0.024*\"caption\" + 0.023*\"career\" + 0.021*\"photo\" + 0.021*\"life\" + 0.009*\"republican\" + 0.008*\"vote\"\n",
      "2019-10-29 00:43:08,328 : INFO : topic diff=1.022154, rho=1.000000\n",
      "2019-10-29 00:43:08,734 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:08,739 : INFO : built Dictionary(298 unique tokens: ['staying', 'school', 'watch', 'hero', 'come']...) from 5 documents (total 2250 corpus positions)\n",
      "2019-10-29 00:43:08,744 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:08,745 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:08,747 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:08,750 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:08,752 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:08,847 : INFO : -7.763 per-word bound, 217.2 perplexity estimate based on a held-out corpus of 5 documents with 2250 words\n",
      "2019-10-29 00:43:08,849 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:08,858 : INFO : topic #0 (0.100): 0.045*\"patel\" + 0.030*\"amputee\" + 0.014*\"cnn\" + 0.012*\"help\" + 0.011*\"foot\" + 0.010*\"amputation\" + 0.009*\"leg\" + 0.009*\"antonio\" + 0.009*\"work\" + 0.009*\"going\"\n",
      "2019-10-29 00:43:08,860 : INFO : topic #7 (0.100): 0.038*\"amputee\" + 0.036*\"patel\" + 0.017*\"help\" + 0.012*\"cnn\" + 0.011*\"foot\" + 0.010*\"support\" + 0.009*\"san\" + 0.009*\"work\" + 0.009*\"group\" + 0.008*\"member\"\n",
      "2019-10-29 00:43:08,863 : INFO : topic #5 (0.100): 0.040*\"amputee\" + 0.034*\"patel\" + 0.015*\"cnn\" + 0.011*\"help\" + 0.010*\"san\" + 0.010*\"foot\" + 0.009*\"said\" + 0.008*\"member\" + 0.008*\"work\" + 0.008*\"leg\"\n",
      "2019-10-29 00:43:08,866 : INFO : topic #6 (0.100): 0.033*\"amputee\" + 0.027*\"patel\" + 0.016*\"cnn\" + 0.016*\"help\" + 0.010*\"antonio\" + 0.010*\"leg\" + 0.010*\"group\" + 0.010*\"year\" + 0.009*\"support\" + 0.009*\"foot\"\n",
      "2019-10-29 00:43:08,868 : INFO : topic #9 (0.100): 0.034*\"patel\" + 0.030*\"amputee\" + 0.018*\"help\" + 0.017*\"cnn\" + 0.010*\"antonio\" + 0.010*\"foot\" + 0.009*\"year\" + 0.009*\"work\" + 0.008*\"mona\" + 0.008*\"limb\"\n",
      "2019-10-29 00:43:08,871 : INFO : topic diff=0.817070, rho=1.000000\n",
      "2019-10-29 00:43:09,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:09,299 : INFO : built Dictionary(264 unique tokens: ['concern', 'nation', 'ensuring', 'stop', 'involvement']...) from 5 documents (total 2160 corpus positions)\n",
      "2019-10-29 00:43:09,303 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:09,304 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:09,305 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:09,309 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:09,310 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:09,398 : INFO : -7.533 per-word bound, 185.2 perplexity estimate based on a held-out corpus of 5 documents with 2160 words\n",
      "2019-10-29 00:43:09,399 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:09,406 : INFO : topic #9 (0.100): 0.037*\"u\" + 0.018*\"turkish\" + 0.018*\"turkey\" + 0.018*\"member\" + 0.016*\"gulen\" + 0.016*\"state\" + 0.016*\"visa\" + 0.015*\"decision\" + 0.015*\"said\" + 0.014*\"staff\"\n",
      "2019-10-29 00:43:09,408 : INFO : topic #2 (0.100): 0.045*\"u\" + 0.026*\"turkish\" + 0.021*\"turkey\" + 0.018*\"said\" + 0.014*\"gulen\" + 0.014*\"ankara\" + 0.014*\"staff\" + 0.014*\"member\" + 0.013*\"statement\" + 0.012*\"decision\"\n",
      "2019-10-29 00:43:09,411 : INFO : topic #3 (0.100): 0.041*\"u\" + 0.020*\"turkish\" + 0.017*\"turkey\" + 0.017*\"member\" + 0.015*\"visa\" + 0.015*\"arrested\" + 0.015*\"ankara\" + 0.014*\"state\" + 0.014*\"said\" + 0.013*\"staff\"\n",
      "2019-10-29 00:43:09,413 : INFO : topic #5 (0.100): 0.039*\"u\" + 0.020*\"turkish\" + 0.019*\"staff\" + 0.017*\"said\" + 0.016*\"turkey\" + 0.015*\"member\" + 0.014*\"decision\" + 0.014*\"gulen\" + 0.012*\"arrested\" + 0.012*\"state\"\n",
      "2019-10-29 00:43:09,416 : INFO : topic #8 (0.100): 0.042*\"u\" + 0.019*\"state\" + 0.018*\"turkey\" + 0.016*\"staff\" + 0.016*\"said\" + 0.015*\"turkish\" + 0.014*\"visa\" + 0.014*\"ankara\" + 0.013*\"member\" + 0.012*\"decision\"\n",
      "2019-10-29 00:43:09,417 : INFO : topic diff=0.910535, rho=1.000000\n",
      "2019-10-29 00:43:09,821 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:09,823 : INFO : built Dictionary(86 unique tokens: ['residency', 'affected', 'financial', 'night', 'shooting']...) from 5 documents (total 645 corpus positions)\n",
      "2019-10-29 00:43:09,825 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:09,829 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:09,832 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:09,836 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:09,839 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:09,896 : INFO : -6.654 per-word bound, 100.7 perplexity estimate based on a held-out corpus of 5 documents with 645 words\n",
      "2019-10-29 00:43:09,897 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:09,905 : INFO : topic #6 (0.100): 0.037*\"show\" + 0.028*\"dion\" + 0.028*\"two\" + 0.024*\"night\" + 0.023*\"still\" + 0.023*\"vega\" + 0.023*\"said\" + 0.021*\"shooting\" + 0.021*\"day\" + 0.021*\"go\"\n",
      "2019-10-29 00:43:09,912 : INFO : topic #7 (0.100): 0.034*\"night\" + 0.033*\"two\" + 0.033*\"dion\" + 0.028*\"celine\" + 0.028*\"show\" + 0.028*\"day\" + 0.027*\"still\" + 0.025*\"vega\" + 0.024*\"shooting\" + 0.021*\"sunday\"\n",
      "2019-10-29 00:43:09,916 : INFO : topic #2 (0.100): 0.037*\"show\" + 0.035*\"dion\" + 0.032*\"still\" + 0.027*\"night\" + 0.027*\"two\" + 0.027*\"sunday\" + 0.026*\"shooting\" + 0.022*\"go\" + 0.021*\"celine\" + 0.021*\"said\"\n",
      "2019-10-29 00:43:09,921 : INFO : topic #8 (0.100): 0.040*\"show\" + 0.031*\"dion\" + 0.030*\"two\" + 0.030*\"night\" + 0.029*\"celine\" + 0.027*\"go\" + 0.026*\"still\" + 0.023*\"shooting\" + 0.022*\"tragic\" + 0.020*\"vega\"\n",
      "2019-10-29 00:43:09,923 : INFO : topic #0 (0.100): 0.036*\"still\" + 0.029*\"day\" + 0.027*\"sunday\" + 0.026*\"dion\" + 0.025*\"show\" + 0.024*\"go\" + 0.023*\"two\" + 0.022*\"shooting\" + 0.021*\"night\" + 0.020*\"vega\"\n",
      "2019-10-29 00:43:09,926 : INFO : topic diff=0.800629, rho=1.000000\n",
      "2019-10-29 00:43:10,351 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:10,353 : INFO : built Dictionary(22 unique tokens: ['ensure', 'commissioned', 'reviewed', 'provided', 'endorsed']...) from 5 documents (total 190 corpus positions)\n",
      "2019-10-29 00:43:10,356 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:10,358 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:10,359 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:10,362 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:10,363 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:10,377 : INFO : -5.403 per-word bound, 42.3 perplexity estimate based on a held-out corpus of 5 documents with 190 words\n",
      "2019-10-29 00:43:10,378 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:10,382 : INFO : topic #5 (0.100): 0.168*\"credit\" + 0.128*\"card\" + 0.068*\"issuer\" + 0.060*\"post\" + 0.052*\"top\" + 0.051*\"excellent\" + 0.049*\"response\" + 0.033*\"otherwise\" + 0.033*\"november\" + 0.032*\"ensure\"\n",
      "2019-10-29 00:43:10,384 : INFO : topic #0 (0.100): 0.179*\"credit\" + 0.127*\"card\" + 0.071*\"issuer\" + 0.053*\"top\" + 0.052*\"post\" + 0.049*\"excellent\" + 0.046*\"response\" + 0.032*\"offer\" + 0.032*\"lockyer\" + 0.031*\"ensure\"\n",
      "2019-10-29 00:43:10,387 : INFO : topic #6 (0.100): 0.150*\"card\" + 0.128*\"credit\" + 0.083*\"issuer\" + 0.061*\"response\" + 0.055*\"excellent\" + 0.051*\"top\" + 0.048*\"post\" + 0.035*\"provided\" + 0.034*\"lockyer\" + 0.032*\"answered\"\n",
      "2019-10-29 00:43:10,388 : INFO : topic #1 (0.100): 0.197*\"credit\" + 0.098*\"card\" + 0.069*\"issuer\" + 0.058*\"top\" + 0.057*\"response\" + 0.051*\"excellent\" + 0.051*\"post\" + 0.035*\"question\" + 0.035*\"tasha\" + 0.032*\"ensure\"\n",
      "2019-10-29 00:43:10,390 : INFO : topic #4 (0.100): 0.157*\"credit\" + 0.115*\"card\" + 0.070*\"issuer\" + 0.060*\"post\" + 0.053*\"response\" + 0.045*\"top\" + 0.043*\"excellent\" + 0.038*\"provided\" + 0.036*\"question\" + 0.035*\"otherwise\"\n",
      "2019-10-29 00:43:10,391 : INFO : topic diff=0.879981, rho=1.000000\n",
      "2019-10-29 00:43:10,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:10,804 : INFO : built Dictionary(96 unique tokens: ['anniversary', 'although', 'wide', 'pavement', 'military']...) from 5 documents (total 590 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:10,807 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:10,809 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:10,810 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:10,813 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:10,815 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:10,866 : INFO : -7.109 per-word bound, 138.0 perplexity estimate based on a held-out corpus of 5 documents with 590 words\n",
      "2019-10-29 00:43:10,868 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:10,876 : INFO : topic #8 (0.100): 0.034*\"walk\" + 0.033*\"president\" + 0.031*\"widodo\" + 0.024*\"traffic\" + 0.021*\"kilometer\" + 0.018*\"stuck\" + 0.018*\"indonesian\" + 0.017*\"defense\" + 0.017*\"jam\" + 0.017*\"got\"\n",
      "2019-10-29 00:43:10,879 : INFO : topic #2 (0.100): 0.036*\"widodo\" + 0.032*\"walk\" + 0.030*\"traffic\" + 0.028*\"president\" + 0.021*\"kilometer\" + 0.019*\"jam\" + 0.019*\"minute\" + 0.018*\"defense\" + 0.017*\"stuck\" + 0.017*\"car\"\n",
      "2019-10-29 00:43:10,883 : INFO : topic #1 (0.100): 0.035*\"walk\" + 0.033*\"president\" + 0.028*\"traffic\" + 0.027*\"kilometer\" + 0.023*\"widodo\" + 0.018*\"forced\" + 0.018*\"several\" + 0.017*\"indonesian\" + 0.016*\"car\" + 0.015*\"got\"\n",
      "2019-10-29 00:43:10,887 : INFO : topic #5 (0.100): 0.031*\"president\" + 0.027*\"walk\" + 0.027*\"widodo\" + 0.021*\"defense\" + 0.019*\"traffic\" + 0.016*\"kilometer\" + 0.016*\"minute\" + 0.015*\"jam\" + 0.014*\"got\" + 0.014*\"car\"\n",
      "2019-10-29 00:43:10,890 : INFO : topic #9 (0.100): 0.032*\"walk\" + 0.028*\"kilometer\" + 0.028*\"widodo\" + 0.023*\"president\" + 0.019*\"several\" + 0.019*\"forced\" + 0.019*\"traffic\" + 0.019*\"car\" + 0.018*\"got\" + 0.017*\"minute\"\n",
      "2019-10-29 00:43:10,895 : INFO : topic diff=0.707834, rho=1.000000\n",
      "2019-10-29 00:43:11,335 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:11,338 : INFO : built Dictionary(96 unique tokens: ['prime', 'disprove', 'prove', 'quizzed', 'u']...) from 5 documents (total 710 corpus positions)\n",
      "2019-10-29 00:43:11,341 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:11,342 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:11,343 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:11,346 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:11,350 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:11,406 : INFO : -6.766 per-word bound, 108.9 perplexity estimate based on a held-out corpus of 5 documents with 710 words\n",
      "2019-10-29 00:43:11,410 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:11,421 : INFO : topic #6 (0.100): 0.040*\"police\" + 0.034*\"heath\" + 0.029*\"child\" + 0.021*\"edward\" + 0.021*\"would\" + 0.020*\"rape\" + 0.019*\"report\" + 0.018*\"year\" + 0.016*\"old\" + 0.016*\"innocence\"\n",
      "2019-10-29 00:43:11,423 : INFO : topic #2 (0.100): 0.050*\"police\" + 0.043*\"child\" + 0.030*\"heath\" + 0.024*\"would\" + 0.022*\"report\" + 0.022*\"rape\" + 0.021*\"investigation\" + 0.020*\"year\" + 0.018*\"guilt\" + 0.016*\"allegation\"\n",
      "2019-10-29 00:43:11,424 : INFO : topic #8 (0.100): 0.043*\"police\" + 0.031*\"child\" + 0.029*\"heath\" + 0.025*\"rape\" + 0.025*\"year\" + 0.025*\"would\" + 0.021*\"investigation\" + 0.021*\"guilt\" + 0.021*\"report\" + 0.020*\"edward\"\n",
      "2019-10-29 00:43:11,425 : INFO : topic #7 (0.100): 0.049*\"police\" + 0.033*\"child\" + 0.031*\"would\" + 0.027*\"heath\" + 0.021*\"year\" + 0.021*\"edward\" + 0.021*\"report\" + 0.020*\"guilt\" + 0.019*\"rape\" + 0.017*\"abuse\"\n",
      "2019-10-29 00:43:11,429 : INFO : topic #9 (0.100): 0.048*\"police\" + 0.038*\"heath\" + 0.033*\"child\" + 0.029*\"would\" + 0.022*\"investigation\" + 0.021*\"year\" + 0.021*\"rape\" + 0.019*\"guilt\" + 0.018*\"edward\" + 0.016*\"report\"\n",
      "2019-10-29 00:43:11,434 : INFO : topic diff=0.773802, rho=1.000000\n",
      "2019-10-29 00:43:11,903 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:11,911 : INFO : built Dictionary(645 unique tokens: ['although', 'let', 'energy', 'deep', 'specie']...) from 5 documents (total 6740 corpus positions)\n",
      "2019-10-29 00:43:11,918 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:11,919 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:11,921 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:11,926 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:11,928 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:12,130 : INFO : -8.078 per-word bound, 270.2 perplexity estimate based on a held-out corpus of 5 documents with 6740 words\n",
      "2019-10-29 00:43:12,132 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:12,143 : INFO : topic #7 (0.100): 0.028*\"degree\" + 0.014*\"sutter\" + 0.013*\"would\" + 0.012*\"think\" + 0.011*\"lynas\" + 0.011*\"warming\" + 0.010*\"level\" + 0.010*\"world\" + 0.009*\"get\" + 0.008*\"people\"\n",
      "2019-10-29 00:43:12,145 : INFO : topic #6 (0.100): 0.027*\"degree\" + 0.013*\"lynas\" + 0.013*\"sutter\" + 0.012*\"think\" + 0.012*\"would\" + 0.010*\"world\" + 0.008*\"get\" + 0.008*\"warming\" + 0.008*\"well\" + 0.008*\"level\"\n",
      "2019-10-29 00:43:12,147 : INFO : topic #1 (0.100): 0.023*\"degree\" + 0.016*\"sutter\" + 0.013*\"think\" + 0.012*\"world\" + 0.011*\"lynas\" + 0.010*\"would\" + 0.010*\"level\" + 0.009*\"get\" + 0.008*\"climate\" + 0.008*\"people\"\n",
      "2019-10-29 00:43:12,148 : INFO : topic #9 (0.100): 0.024*\"degree\" + 0.017*\"think\" + 0.015*\"would\" + 0.013*\"lynas\" + 0.010*\"sutter\" + 0.009*\"change\" + 0.009*\"level\" + 0.008*\"get\" + 0.007*\"people\" + 0.007*\"world\"\n",
      "2019-10-29 00:43:12,149 : INFO : topic #8 (0.100): 0.018*\"think\" + 0.018*\"degree\" + 0.014*\"would\" + 0.012*\"sutter\" + 0.010*\"lynas\" + 0.009*\"level\" + 0.009*\"world\" + 0.009*\"well\" + 0.008*\"get\" + 0.008*\"change\"\n",
      "2019-10-29 00:43:12,151 : INFO : topic diff=0.943158, rho=1.000000\n",
      "2019-10-29 00:43:12,588 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:12,592 : INFO : built Dictionary(322 unique tokens: ['previously', 'let', 'filed', '1990s', 'tube']...) from 5 documents (total 2745 corpus positions)\n",
      "2019-10-29 00:43:12,597 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:12,599 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:12,600 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:12,606 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:12,609 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:12,738 : INFO : -7.661 per-word bound, 202.3 perplexity estimate based on a held-out corpus of 5 documents with 2745 words\n",
      "2019-10-29 00:43:12,740 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:12,747 : INFO : topic #8 (0.100): 0.039*\"form\" + 0.030*\"polst\" + 0.022*\"said\" + 0.020*\"health\" + 0.017*\"care\" + 0.014*\"medical\" + 0.013*\"life\" + 0.013*\"oregon\" + 0.013*\"patient\" + 0.012*\"state\"\n",
      "2019-10-29 00:43:12,749 : INFO : topic #3 (0.100): 0.027*\"polst\" + 0.022*\"form\" + 0.020*\"said\" + 0.018*\"care\" + 0.016*\"patient\" + 0.014*\"health\" + 0.013*\"state\" + 0.012*\"life\" + 0.012*\"oregon\" + 0.011*\"access\"\n",
      "2019-10-29 00:43:12,752 : INFO : topic #4 (0.100): 0.024*\"polst\" + 0.022*\"said\" + 0.022*\"form\" + 0.018*\"care\" + 0.017*\"patient\" + 0.016*\"health\" + 0.015*\"life\" + 0.014*\"state\" + 0.013*\"cutler\" + 0.012*\"ohsu\"\n",
      "2019-10-29 00:43:12,754 : INFO : topic #6 (0.100): 0.029*\"polst\" + 0.022*\"form\" + 0.020*\"health\" + 0.016*\"state\" + 0.015*\"said\" + 0.014*\"life\" + 0.014*\"oregon\" + 0.014*\"patient\" + 0.013*\"care\" + 0.012*\"cheatham\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:12,757 : INFO : topic #2 (0.100): 0.027*\"polst\" + 0.019*\"form\" + 0.018*\"said\" + 0.016*\"oregon\" + 0.015*\"patient\" + 0.015*\"access\" + 0.014*\"care\" + 0.014*\"health\" + 0.012*\"medical\" + 0.012*\"life\"\n",
      "2019-10-29 00:43:12,759 : INFO : topic diff=0.885838, rho=1.000000\n",
      "2019-10-29 00:43:13,175 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:13,181 : INFO : built Dictionary(323 unique tokens: ['thumper', 'person', 'book', 'universe', 'come']...) from 5 documents (total 2570 corpus positions)\n",
      "2019-10-29 00:43:13,186 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:13,187 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:13,188 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:13,191 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:13,194 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:13,302 : INFO : -7.752 per-word bound, 215.6 perplexity estimate based on a held-out corpus of 5 documents with 2570 words\n",
      "2019-10-29 00:43:13,304 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:13,311 : INFO : topic #2 (0.100): 0.047*\"atheist\" + 0.019*\"god\" + 0.011*\"without\" + 0.011*\"still\" + 0.010*\"many\" + 0.010*\"people\" + 0.010*\"community\" + 0.009*\"really\" + 0.009*\"religion\" + 0.009*\"faith\"\n",
      "2019-10-29 00:43:13,312 : INFO : topic #7 (0.100): 0.044*\"atheist\" + 0.017*\"without\" + 0.014*\"god\" + 0.011*\"still\" + 0.011*\"people\" + 0.010*\"u\" + 0.010*\"personal\" + 0.010*\"really\" + 0.010*\"faith\" + 0.009*\"community\"\n",
      "2019-10-29 00:43:13,314 : INFO : topic #9 (0.100): 0.040*\"atheist\" + 0.019*\"god\" + 0.013*\"without\" + 0.012*\"still\" + 0.012*\"people\" + 0.011*\"belief\" + 0.010*\"u\" + 0.009*\"replay\" + 0.009*\"faith\" + 0.009*\"really\"\n",
      "2019-10-29 00:43:13,315 : INFO : topic #8 (0.100): 0.045*\"atheist\" + 0.019*\"without\" + 0.019*\"people\" + 0.015*\"god\" + 0.012*\"community\" + 0.011*\"u\" + 0.010*\"belief\" + 0.010*\"faith\" + 0.010*\"still\" + 0.009*\"american\"\n",
      "2019-10-29 00:43:13,318 : INFO : topic #4 (0.100): 0.031*\"atheist\" + 0.020*\"god\" + 0.017*\"people\" + 0.013*\"without\" + 0.012*\"many\" + 0.011*\"still\" + 0.011*\"community\" + 0.010*\"u\" + 0.009*\"faith\" + 0.009*\"american\"\n",
      "2019-10-29 00:43:13,320 : INFO : topic diff=0.833642, rho=1.000000\n",
      "2019-10-29 00:43:13,854 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:13,863 : INFO : built Dictionary(546 unique tokens: ['josh', 'forecast', 'journey', 'crest', 'francisco']...) from 5 documents (total 6495 corpus positions)\n",
      "2019-10-29 00:43:13,872 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:13,873 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:13,875 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:13,879 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:13,881 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:14,075 : INFO : -7.780 per-word bound, 219.7 perplexity estimate based on a held-out corpus of 5 documents with 6495 words\n",
      "2019-10-29 00:43:14,077 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:14,089 : INFO : topic #3 (0.100): 0.038*\"california\" + 0.032*\"october\" + 0.029*\"wildfire\" + 0.026*\"caption\" + 0.024*\"fire\" + 0.023*\"photo\" + 0.023*\"blaze\" + 0.022*\"hide\" + 0.020*\"napa\" + 0.019*\"said\"\n",
      "2019-10-29 00:43:14,092 : INFO : topic #9 (0.100): 0.034*\"fire\" + 0.032*\"wildfire\" + 0.028*\"caption\" + 0.027*\"california\" + 0.024*\"blaze\" + 0.023*\"said\" + 0.023*\"october\" + 0.020*\"photo\" + 0.015*\"county\" + 0.015*\"hide\"\n",
      "2019-10-29 00:43:14,101 : INFO : topic #2 (0.100): 0.032*\"wildfire\" + 0.031*\"blaze\" + 0.030*\"fire\" + 0.026*\"photo\" + 0.025*\"hide\" + 0.024*\"california\" + 0.023*\"october\" + 0.021*\"said\" + 0.019*\"santa\" + 0.018*\"caption\"\n",
      "2019-10-29 00:43:14,105 : INFO : topic #4 (0.100): 0.037*\"fire\" + 0.035*\"california\" + 0.035*\"wildfire\" + 0.025*\"october\" + 0.024*\"hide\" + 0.022*\"caption\" + 0.021*\"photo\" + 0.020*\"napa\" + 0.019*\"blaze\" + 0.019*\"santa\"\n",
      "2019-10-29 00:43:14,108 : INFO : topic #6 (0.100): 0.041*\"california\" + 0.039*\"wildfire\" + 0.029*\"photo\" + 0.025*\"blaze\" + 0.024*\"fire\" + 0.023*\"october\" + 0.020*\"hide\" + 0.020*\"said\" + 0.019*\"caption\" + 0.015*\"county\"\n",
      "2019-10-29 00:43:14,111 : INFO : topic diff=1.098875, rho=1.000000\n",
      "2019-10-29 00:43:14,545 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:14,549 : INFO : built Dictionary(256 unique tokens: ['although', 'trying', 'significant', 'take', 'salt']...) from 5 documents (total 1815 corpus positions)\n",
      "2019-10-29 00:43:14,552 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:14,553 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:14,554 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:14,558 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:14,559 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:14,655 : INFO : -7.715 per-word bound, 210.2 perplexity estimate based on a held-out corpus of 5 documents with 1815 words\n",
      "2019-10-29 00:43:14,657 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:14,665 : INFO : topic #0 (0.100): 0.035*\"aquafaba\" + 0.028*\"liquid\" + 0.012*\"egg\" + 0.012*\"chickpea\" + 0.011*\"new\" + 0.010*\"use\" + 0.009*\"online\" + 0.009*\"mixer\" + 0.009*\"analysis\" + 0.009*\"used\"\n",
      "2019-10-29 00:43:14,668 : INFO : topic #4 (0.100): 0.034*\"aquafaba\" + 0.027*\"liquid\" + 0.014*\"egg\" + 0.012*\"chickpea\" + 0.012*\"mixer\" + 0.011*\"analysis\" + 0.010*\"online\" + 0.010*\"ingredient\" + 0.009*\"recipe\" + 0.009*\"option\"\n",
      "2019-10-29 00:43:14,671 : INFO : topic #3 (0.100): 0.029*\"aquafaba\" + 0.026*\"liquid\" + 0.012*\"egg\" + 0.012*\"chickpea\" + 0.011*\"online\" + 0.011*\"new\" + 0.010*\"chocolate\" + 0.010*\"used\" + 0.010*\"mixer\" + 0.010*\"vegan\"\n",
      "2019-10-29 00:43:14,675 : INFO : topic #5 (0.100): 0.045*\"aquafaba\" + 0.019*\"liquid\" + 0.014*\"egg\" + 0.012*\"chocolate\" + 0.012*\"chickpea\" + 0.010*\"made\" + 0.010*\"mixer\" + 0.010*\"recipe\" + 0.010*\"online\" + 0.009*\"trend\"\n",
      "2019-10-29 00:43:14,678 : INFO : topic #8 (0.100): 0.032*\"aquafaba\" + 0.028*\"liquid\" + 0.014*\"egg\" + 0.013*\"online\" + 0.011*\"chickpea\" + 0.010*\"chocolate\" + 0.009*\"vegan\" + 0.009*\"new\" + 0.009*\"mixer\" + 0.009*\"analysis\"\n",
      "2019-10-29 00:43:14,680 : INFO : topic diff=0.775947, rho=1.000000\n",
      "2019-10-29 00:43:15,163 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:15,170 : INFO : built Dictionary(496 unique tokens: ['dating', 'let', 'phase', 'real', 'party']...) from 5 documents (total 4985 corpus positions)\n",
      "2019-10-29 00:43:15,177 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:15,178 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:15,180 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:15,184 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:15,186 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:15,326 : INFO : -7.875 per-word bound, 234.7 perplexity estimate based on a held-out corpus of 5 documents with 4985 words\n",
      "2019-10-29 00:43:15,327 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:15,335 : INFO : topic #5 (0.100): 0.028*\"love\" + 0.022*\"said\" + 0.019*\"one\" + 0.018*\"relationship\" + 0.012*\"student\" + 0.010*\"people\" + 0.010*\"college\" + 0.010*\"film\" + 0.009*\"way\" + 0.009*\"workshop\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:15,337 : INFO : topic #1 (0.100): 0.033*\"love\" + 0.022*\"one\" + 0.020*\"said\" + 0.015*\"relationship\" + 0.011*\"think\" + 0.011*\"college\" + 0.010*\"school\" + 0.010*\"student\" + 0.009*\"way\" + 0.009*\"collier\"\n",
      "2019-10-29 00:43:15,339 : INFO : topic #6 (0.100): 0.034*\"love\" + 0.021*\"relationship\" + 0.021*\"one\" + 0.019*\"said\" + 0.014*\"student\" + 0.011*\"think\" + 0.010*\"people\" + 0.009*\"collier\" + 0.009*\"foundation\" + 0.009*\"abuse\"\n",
      "2019-10-29 00:43:15,342 : INFO : topic #8 (0.100): 0.028*\"love\" + 0.025*\"said\" + 0.024*\"relationship\" + 0.020*\"one\" + 0.010*\"college\" + 0.010*\"think\" + 0.010*\"way\" + 0.009*\"collier\" + 0.008*\"student\" + 0.008*\"people\"\n",
      "2019-10-29 00:43:15,345 : INFO : topic #7 (0.100): 0.028*\"love\" + 0.026*\"one\" + 0.022*\"relationship\" + 0.020*\"said\" + 0.011*\"student\" + 0.010*\"college\" + 0.010*\"people\" + 0.010*\"think\" + 0.010*\"school\" + 0.009*\"collier\"\n",
      "2019-10-29 00:43:15,349 : INFO : topic diff=0.949597, rho=1.000000\n",
      "2019-10-29 00:43:15,790 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:15,797 : INFO : built Dictionary(348 unique tokens: ['let', 'francisco', 'internet', 'one', 'new']...) from 5 documents (total 3135 corpus positions)\n",
      "2019-10-29 00:43:15,801 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:15,804 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:15,807 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:15,811 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:15,815 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:15,941 : INFO : -7.666 per-word bound, 203.1 perplexity estimate based on a held-out corpus of 5 documents with 3135 words\n",
      "2019-10-29 00:43:15,943 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:15,950 : INFO : topic #9 (0.100): 0.057*\"gender\" + 0.033*\"said\" + 0.015*\"masculine\" + 0.015*\"fluid\" + 0.014*\"feel\" + 0.013*\"like\" + 0.013*\"people\" + 0.012*\"fluidity\" + 0.011*\"feminine\" + 0.010*\"brauer\"\n",
      "2019-10-29 00:43:15,952 : INFO : topic #4 (0.100): 0.057*\"gender\" + 0.033*\"said\" + 0.016*\"people\" + 0.015*\"feel\" + 0.014*\"luxion\" + 0.012*\"fluid\" + 0.012*\"brauer\" + 0.012*\"feminine\" + 0.011*\"fluidity\" + 0.010*\"identifies\"\n",
      "2019-10-29 00:43:15,954 : INFO : topic #2 (0.100): 0.059*\"gender\" + 0.027*\"said\" + 0.016*\"masculine\" + 0.015*\"people\" + 0.012*\"fluid\" + 0.012*\"brauer\" + 0.011*\"fluidity\" + 0.011*\"like\" + 0.010*\"feminine\" + 0.010*\"luxion\"\n",
      "2019-10-29 00:43:15,957 : INFO : topic #1 (0.100): 0.061*\"gender\" + 0.029*\"said\" + 0.018*\"luxion\" + 0.016*\"fluid\" + 0.014*\"masculine\" + 0.013*\"people\" + 0.013*\"brauer\" + 0.012*\"feminine\" + 0.011*\"feel\" + 0.011*\"fluidity\"\n",
      "2019-10-29 00:43:15,959 : INFO : topic #6 (0.100): 0.056*\"gender\" + 0.023*\"said\" + 0.016*\"fluid\" + 0.014*\"feminine\" + 0.014*\"masculine\" + 0.013*\"luxion\" + 0.013*\"feel\" + 0.012*\"brauer\" + 0.012*\"like\" + 0.012*\"people\"\n",
      "2019-10-29 00:43:15,962 : INFO : topic diff=0.886768, rho=1.000000\n",
      "2019-10-29 00:43:16,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:16,371 : INFO : built Dictionary(35 unique tokens: ['operation', 'trying', 'weinstein', 'cnn', 'complaint']...) from 5 documents (total 220 corpus positions)\n",
      "2019-10-29 00:43:16,372 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:16,374 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:16,375 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:16,377 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:16,379 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:16,401 : INFO : -6.297 per-word bound, 78.7 perplexity estimate based on a held-out corpus of 5 documents with 220 words\n",
      "2019-10-29 00:43:16,402 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:16,410 : INFO : topic #2 (0.100): 0.064*\"tape\" + 0.059*\"weinstein\" + 0.047*\"yorker\" + 0.044*\"reportedly\" + 0.043*\"sting\" + 0.041*\"nypd\" + 0.040*\"new\" + 0.029*\"abuse\" + 0.029*\"investigated\" + 0.028*\"woman\"\n",
      "2019-10-29 00:43:16,413 : INFO : topic #0 (0.100): 0.065*\"weinstein\" + 0.060*\"reportedly\" + 0.050*\"tape\" + 0.044*\"yorker\" + 0.041*\"nypd\" + 0.041*\"new\" + 0.038*\"sting\" + 0.029*\"department\" + 0.028*\"rep\" + 0.027*\"obtains\"\n",
      "2019-10-29 00:43:16,416 : INFO : topic #4 (0.100): 0.087*\"tape\" + 0.065*\"weinstein\" + 0.045*\"sting\" + 0.043*\"reportedly\" + 0.040*\"nypd\" + 0.035*\"new\" + 0.034*\"yorker\" + 0.027*\"young\" + 0.027*\"confirms\" + 0.026*\"misdemeanor\"\n",
      "2019-10-29 00:43:16,419 : INFO : topic #3 (0.100): 0.075*\"weinstein\" + 0.068*\"tape\" + 0.045*\"new\" + 0.045*\"nypd\" + 0.044*\"reportedly\" + 0.042*\"yorker\" + 0.037*\"sting\" + 0.028*\"complaint\" + 0.028*\"audio\" + 0.027*\"trying\"\n",
      "2019-10-29 00:43:16,423 : INFO : topic #6 (0.100): 0.068*\"weinstein\" + 0.056*\"tape\" + 0.054*\"nypd\" + 0.046*\"sting\" + 0.040*\"new\" + 0.039*\"reportedly\" + 0.037*\"yorker\" + 0.030*\"misdemeanor\" + 0.028*\"young\" + 0.028*\"obtained\"\n",
      "2019-10-29 00:43:16,426 : INFO : topic diff=0.684055, rho=1.000000\n",
      "2019-10-29 00:43:16,824 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:16,826 : INFO : built Dictionary(88 unique tokens: ['forward', 'surrounding', 'help', 'travel', 'flight']...) from 5 documents (total 675 corpus positions)\n",
      "2019-10-29 00:43:16,827 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:16,829 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:16,834 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:16,838 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:16,841 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:16,887 : INFO : -6.638 per-word bound, 99.6 perplexity estimate based on a held-out corpus of 5 documents with 675 words\n",
      "2019-10-29 00:43:16,890 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:16,897 : INFO : topic #4 (0.100): 0.055*\"secretary\" + 0.041*\"hargan\" + 0.031*\"price\" + 0.029*\"hhs\" + 0.029*\"eric\" + 0.025*\"acting\" + 0.025*\"health\" + 0.024*\"trump\" + 0.020*\"deputy\" + 0.019*\"charter\"\n",
      "2019-10-29 00:43:16,899 : INFO : topic #2 (0.100): 0.056*\"secretary\" + 0.053*\"hargan\" + 0.036*\"trump\" + 0.032*\"hhs\" + 0.026*\"deputy\" + 0.023*\"health\" + 0.022*\"charter\" + 0.021*\"price\" + 0.018*\"acting\" + 0.018*\"eric\"\n",
      "2019-10-29 00:43:16,902 : INFO : topic #7 (0.100): 0.069*\"secretary\" + 0.038*\"hargan\" + 0.034*\"hhs\" + 0.031*\"trump\" + 0.028*\"price\" + 0.024*\"acting\" + 0.023*\"deputy\" + 0.022*\"health\" + 0.020*\"charter\" + 0.018*\"eric\"\n",
      "2019-10-29 00:43:16,905 : INFO : topic #8 (0.100): 0.054*\"secretary\" + 0.040*\"trump\" + 0.039*\"hargan\" + 0.033*\"hhs\" + 0.030*\"price\" + 0.024*\"health\" + 0.022*\"eric\" + 0.020*\"statement\" + 0.020*\"acting\" + 0.017*\"charter\"\n",
      "2019-10-29 00:43:16,908 : INFO : topic #6 (0.100): 0.056*\"hargan\" + 0.041*\"secretary\" + 0.036*\"hhs\" + 0.034*\"deputy\" + 0.029*\"price\" + 0.027*\"trump\" + 0.020*\"acting\" + 0.020*\"plane\" + 0.018*\"health\" + 0.017*\"eric\"\n",
      "2019-10-29 00:43:16,911 : INFO : topic diff=0.842836, rho=1.000000\n",
      "2019-10-29 00:43:17,374 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:17,379 : INFO : built Dictionary(248 unique tokens: ['exhale', 'even', 'facs', 'bone', 'reach']...) from 5 documents (total 2190 corpus positions)\n",
      "2019-10-29 00:43:17,382 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:17,384 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:17,385 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:17,388 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:17,390 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:17,502 : INFO : -7.366 per-word bound, 165.0 perplexity estimate based on a held-out corpus of 5 documents with 2190 words\n",
      "2019-10-29 00:43:17,504 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:17,512 : INFO : topic #5 (0.100): 0.037*\"attack\" + 0.036*\"may\" + 0.028*\"asthma\" + 0.023*\"severe\" + 0.020*\"trigger\" + 0.019*\"sign\" + 0.015*\"need\" + 0.014*\"even\" + 0.014*\"rescue\" + 0.013*\"symptom\"\n",
      "2019-10-29 00:43:17,515 : INFO : topic #7 (0.100): 0.038*\"asthma\" + 0.036*\"attack\" + 0.035*\"may\" + 0.020*\"severe\" + 0.017*\"sign\" + 0.017*\"trigger\" + 0.016*\"rescue\" + 0.014*\"symptom\" + 0.012*\"treatment\" + 0.011*\"inhaler\"\n",
      "2019-10-29 00:43:17,517 : INFO : topic #1 (0.100): 0.046*\"asthma\" + 0.034*\"may\" + 0.026*\"attack\" + 0.021*\"severe\" + 0.016*\"trigger\" + 0.014*\"inhaler\" + 0.013*\"even\" + 0.012*\"sign\" + 0.012*\"need\" + 0.011*\"rescue\"\n",
      "2019-10-29 00:43:17,520 : INFO : topic #9 (0.100): 0.052*\"asthma\" + 0.034*\"may\" + 0.033*\"attack\" + 0.020*\"trigger\" + 0.019*\"severe\" + 0.016*\"sign\" + 0.015*\"even\" + 0.013*\"inhaler\" + 0.013*\"warning\" + 0.012*\"symptom\"\n",
      "2019-10-29 00:43:17,522 : INFO : topic #8 (0.100): 0.037*\"may\" + 0.033*\"asthma\" + 0.031*\"attack\" + 0.026*\"trigger\" + 0.020*\"severe\" + 0.016*\"sign\" + 0.014*\"symptom\" + 0.012*\"rescue\" + 0.012*\"even\" + 0.012*\"treatment\"\n",
      "2019-10-29 00:43:17,524 : INFO : topic diff=0.916835, rho=1.000000\n",
      "2019-10-29 00:43:17,953 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:17,954 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:43:17,956 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:17,957 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:17,959 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:17,961 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:17,962 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:17,982 : INFO : -6.038 per-word bound, 65.7 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:43:17,984 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:17,989 : INFO : topic #5 (0.100): 0.163*\"transcript\" + 0.080*\"page\" + 0.055*\"october\" + 0.053*\"cnn\" + 0.051*\"back\" + 0.050*\"later\" + 0.049*\"return\" + 0.048*\"available\" + 0.048*\"main\" + 0.048*\"specific\"\n",
      "2019-10-29 00:43:17,992 : INFO : topic #6 (0.100): 0.187*\"transcript\" + 0.074*\"page\" + 0.057*\"back\" + 0.047*\"main\" + 0.046*\"find\" + 0.046*\"new\" + 0.045*\"continually\" + 0.045*\"cnn\" + 0.044*\"updated\" + 0.044*\"return\"\n",
      "2019-10-29 00:43:17,994 : INFO : topic #9 (0.100): 0.138*\"transcript\" + 0.077*\"page\" + 0.056*\"new\" + 0.054*\"october\" + 0.052*\"segment\" + 0.051*\"become\" + 0.049*\"note\" + 0.048*\"check\" + 0.047*\"updated\" + 0.047*\"later\"\n",
      "2019-10-29 00:43:17,998 : INFO : topic #3 (0.100): 0.133*\"transcript\" + 0.072*\"page\" + 0.059*\"continually\" + 0.053*\"become\" + 0.052*\"new\" + 0.052*\"find\" + 0.050*\"return\" + 0.050*\"note\" + 0.048*\"cannot\" + 0.047*\"updated\"\n",
      "2019-10-29 00:43:18,002 : INFO : topic #0 (0.100): 0.139*\"transcript\" + 0.094*\"page\" + 0.057*\"updated\" + 0.053*\"october\" + 0.051*\"segment\" + 0.049*\"find\" + 0.049*\"check\" + 0.048*\"cnn\" + 0.048*\"become\" + 0.046*\"return\"\n",
      "2019-10-29 00:43:18,004 : INFO : topic diff=0.702753, rho=1.000000\n",
      "2019-10-29 00:43:18,565 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:18,575 : INFO : built Dictionary(367 unique tokens: ['prime', 'real', 'hong', 'congratulate', 'drive']...) from 5 documents (total 3480 corpus positions)\n",
      "2019-10-29 00:43:18,583 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:18,586 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:18,590 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:18,594 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:18,597 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:18,761 : INFO : -7.652 per-word bound, 201.2 perplexity estimate based on a held-out corpus of 5 documents with 3480 words\n",
      "2019-10-29 00:43:18,762 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:18,772 : INFO : topic #2 (0.100): 0.072*\"teacher\" + 0.018*\"country\" + 0.018*\"status\" + 0.015*\"said\" + 0.013*\"education\" + 0.013*\"singapore\" + 0.011*\"salary\" + 0.011*\"report\" + 0.010*\"oecd\" + 0.010*\"school\"\n",
      "2019-10-29 00:43:18,775 : INFO : topic #3 (0.100): 0.066*\"teacher\" + 0.022*\"said\" + 0.020*\"country\" + 0.014*\"status\" + 0.014*\"singapore\" + 0.013*\"world\" + 0.013*\"salary\" + 0.011*\"schleicher\" + 0.011*\"finland\" + 0.009*\"global\"\n",
      "2019-10-29 00:43:18,778 : INFO : topic #9 (0.100): 0.054*\"teacher\" + 0.018*\"country\" + 0.017*\"said\" + 0.014*\"status\" + 0.013*\"singapore\" + 0.013*\"world\" + 0.011*\"education\" + 0.011*\"salary\" + 0.010*\"finland\" + 0.010*\"result\"\n",
      "2019-10-29 00:43:18,780 : INFO : topic #0 (0.100): 0.081*\"teacher\" + 0.018*\"said\" + 0.017*\"country\" + 0.015*\"status\" + 0.012*\"education\" + 0.011*\"singapore\" + 0.011*\"salary\" + 0.010*\"oecd\" + 0.010*\"high\" + 0.010*\"top\"\n",
      "2019-10-29 00:43:18,783 : INFO : topic #4 (0.100): 0.075*\"teacher\" + 0.017*\"said\" + 0.016*\"country\" + 0.015*\"world\" + 0.014*\"status\" + 0.014*\"singapore\" + 0.013*\"salary\" + 0.008*\"oecd\" + 0.008*\"pota\" + 0.008*\"china\"\n",
      "2019-10-29 00:43:18,785 : INFO : topic diff=0.957593, rho=1.000000\n",
      "2019-10-29 00:43:19,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:19,254 : INFO : built Dictionary(261 unique tokens: ['let', 'school', 'book', 'happy', 'freak']...) from 5 documents (total 2530 corpus positions)\n",
      "2019-10-29 00:43:19,258 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:19,260 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:19,262 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:19,265 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:19,267 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:19,382 : INFO : -7.293 per-word bound, 156.8 perplexity estimate based on a held-out corpus of 5 documents with 2530 words\n",
      "2019-10-29 00:43:19,384 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:19,392 : INFO : topic #4 (0.100): 0.036*\"said\" + 0.034*\"kid\" + 0.025*\"good\" + 0.024*\"parent\" + 0.019*\"sport\" + 0.018*\"sullivan\" + 0.017*\"child\" + 0.016*\"game\" + 0.015*\"sportsmanship\" + 0.013*\"like\"\n",
      "2019-10-29 00:43:19,395 : INFO : topic #2 (0.100): 0.035*\"parent\" + 0.032*\"said\" + 0.025*\"kid\" + 0.022*\"good\" + 0.021*\"child\" + 0.017*\"like\" + 0.016*\"every\" + 0.015*\"sport\" + 0.015*\"game\" + 0.014*\"sullivan\"\n",
      "2019-10-29 00:43:19,397 : INFO : topic #0 (0.100): 0.034*\"said\" + 0.031*\"kid\" + 0.027*\"parent\" + 0.020*\"sport\" + 0.018*\"sullivan\" + 0.017*\"good\" + 0.016*\"game\" + 0.015*\"child\" + 0.014*\"every\" + 0.012*\"sportsmanship\"\n",
      "2019-10-29 00:43:19,400 : INFO : topic #8 (0.100): 0.033*\"parent\" + 0.029*\"said\" + 0.027*\"kid\" + 0.020*\"good\" + 0.020*\"child\" + 0.020*\"game\" + 0.016*\"sullivan\" + 0.015*\"sport\" + 0.014*\"like\" + 0.014*\"sportsmanship\"\n",
      "2019-10-29 00:43:19,402 : INFO : topic #5 (0.100): 0.036*\"said\" + 0.026*\"kid\" + 0.026*\"parent\" + 0.021*\"good\" + 0.021*\"child\" + 0.018*\"sport\" + 0.015*\"game\" + 0.014*\"like\" + 0.013*\"sportsmanship\" + 0.013*\"sullivan\"\n",
      "2019-10-29 00:43:19,404 : INFO : topic diff=0.906492, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:19,883 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:19,898 : INFO : built Dictionary(314 unique tokens: ['let', 'acceptable', 'small', 'end', 'offered']...) from 5 documents (total 2795 corpus positions)\n",
      "2019-10-29 00:43:19,905 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:19,907 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:19,908 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:19,912 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:19,915 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:20,050 : INFO : -7.576 per-word bound, 190.8 perplexity estimate based on a held-out corpus of 5 documents with 2795 words\n",
      "2019-10-29 00:43:20,051 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:20,059 : INFO : topic #5 (0.100): 0.037*\"said\" + 0.018*\"say\" + 0.018*\"parent\" + 0.018*\"want\" + 0.017*\"ferrara\" + 0.014*\"kid\" + 0.012*\"going\" + 0.012*\"mom\" + 0.012*\"ponytail\" + 0.012*\"child\"\n",
      "2019-10-29 00:43:20,062 : INFO : topic #0 (0.100): 0.039*\"said\" + 0.021*\"ferrara\" + 0.017*\"want\" + 0.015*\"kid\" + 0.014*\"way\" + 0.013*\"hilborn\" + 0.013*\"go\" + 0.012*\"say\" + 0.012*\"meltdown\" + 0.012*\"get\"\n",
      "2019-10-29 00:43:20,065 : INFO : topic #3 (0.100): 0.033*\"said\" + 0.017*\"parent\" + 0.017*\"say\" + 0.017*\"ferrara\" + 0.016*\"want\" + 0.015*\"meltdown\" + 0.014*\"child\" + 0.014*\"ponytail\" + 0.014*\"go\" + 0.013*\"way\"\n",
      "2019-10-29 00:43:20,068 : INFO : topic #2 (0.100): 0.038*\"said\" + 0.017*\"ferrara\" + 0.017*\"go\" + 0.016*\"mom\" + 0.016*\"say\" + 0.016*\"kid\" + 0.015*\"parent\" + 0.014*\"help\" + 0.014*\"ponytail\" + 0.013*\"child\"\n",
      "2019-10-29 00:43:20,073 : INFO : topic #6 (0.100): 0.031*\"said\" + 0.020*\"ferrara\" + 0.017*\"say\" + 0.016*\"parent\" + 0.016*\"go\" + 0.014*\"help\" + 0.013*\"kid\" + 0.013*\"mom\" + 0.012*\"child\" + 0.012*\"want\"\n",
      "2019-10-29 00:43:20,078 : INFO : topic diff=0.903038, rho=1.000000\n",
      "2019-10-29 00:43:20,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:20,604 : INFO : built Dictionary(322 unique tokens: ['although', 'perhaps', 'unnatural', 'wanting', 'refugee']...) from 5 documents (total 2790 corpus positions)\n",
      "2019-10-29 00:43:20,609 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:20,610 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:20,612 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:20,616 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:20,617 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:20,760 : INFO : -7.638 per-word bound, 199.2 perplexity estimate based on a held-out corpus of 5 documents with 2790 words\n",
      "2019-10-29 00:43:20,763 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:20,771 : INFO : topic #5 (0.100): 0.028*\"wildlife\" + 0.020*\"tour\" + 0.018*\"big\" + 0.016*\"country\" + 0.015*\"hide\" + 0.014*\"tourism\" + 0.013*\"cashing\" + 0.012*\"photo\" + 0.011*\"lion\" + 0.011*\"caption\"\n",
      "2019-10-29 00:43:20,774 : INFO : topic #3 (0.100): 0.035*\"wildlife\" + 0.022*\"big\" + 0.018*\"country\" + 0.016*\"tourism\" + 0.014*\"tour\" + 0.012*\"world\" + 0.011*\"lion\" + 0.011*\"cecil\" + 0.011*\"industry\" + 0.011*\"photo\"\n",
      "2019-10-29 00:43:20,776 : INFO : topic #4 (0.100): 0.030*\"wildlife\" + 0.022*\"big\" + 0.021*\"tourism\" + 0.015*\"tour\" + 0.014*\"country\" + 0.013*\"cashing\" + 0.012*\"hide\" + 0.012*\"lion\" + 0.012*\"business\" + 0.012*\"world\"\n",
      "2019-10-29 00:43:20,778 : INFO : topic #9 (0.100): 0.035*\"wildlife\" + 0.021*\"tourism\" + 0.020*\"tour\" + 0.020*\"big\" + 0.014*\"cashing\" + 0.013*\"country\" + 0.013*\"photo\" + 0.012*\"beast\" + 0.012*\"hide\" + 0.012*\"cecil\"\n",
      "2019-10-29 00:43:20,780 : INFO : topic #7 (0.100): 0.027*\"wildlife\" + 0.024*\"big\" + 0.018*\"tourism\" + 0.017*\"tour\" + 0.017*\"country\" + 0.016*\"caption\" + 0.014*\"business\" + 0.012*\"hide\" + 0.011*\"photo\" + 0.011*\"cecil\"\n",
      "2019-10-29 00:43:20,783 : INFO : topic diff=0.893420, rho=1.000000\n",
      "2019-10-29 00:43:21,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:21,258 : INFO : built Dictionary(354 unique tokens: ['wanting', 'focus', 'enjoy', 'interpret', 'actually']...) from 5 documents (total 3175 corpus positions)\n",
      "2019-10-29 00:43:21,265 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:21,266 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:21,268 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:21,272 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:21,273 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:21,410 : INFO : -7.682 per-word bound, 205.4 perplexity estimate based on a held-out corpus of 5 documents with 3175 words\n",
      "2019-10-29 00:43:21,412 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:21,420 : INFO : topic #5 (0.100): 0.032*\"sex\" + 0.024*\"heart\" + 0.024*\"said\" + 0.022*\"older\" + 0.022*\"health\" + 0.021*\"men\" + 0.016*\"woman\" + 0.015*\"sexual\" + 0.013*\"cardiovascular\" + 0.011*\"risk\"\n",
      "2019-10-29 00:43:21,423 : INFO : topic #2 (0.100): 0.031*\"sex\" + 0.026*\"said\" + 0.024*\"men\" + 0.019*\"heart\" + 0.019*\"health\" + 0.018*\"sexual\" + 0.015*\"risk\" + 0.014*\"cardiovascular\" + 0.014*\"older\" + 0.011*\"woman\"\n",
      "2019-10-29 00:43:21,426 : INFO : topic #4 (0.100): 0.035*\"said\" + 0.031*\"sex\" + 0.023*\"men\" + 0.021*\"sexual\" + 0.019*\"older\" + 0.016*\"health\" + 0.016*\"heart\" + 0.014*\"risk\" + 0.013*\"cardiovascular\" + 0.013*\"may\"\n",
      "2019-10-29 00:43:21,429 : INFO : topic #9 (0.100): 0.031*\"said\" + 0.026*\"sex\" + 0.021*\"men\" + 0.020*\"older\" + 0.015*\"sexual\" + 0.015*\"health\" + 0.014*\"heart\" + 0.014*\"woman\" + 0.014*\"cardiovascular\" + 0.012*\"risk\"\n",
      "2019-10-29 00:43:21,433 : INFO : topic #8 (0.100): 0.033*\"said\" + 0.029*\"sex\" + 0.022*\"older\" + 0.020*\"woman\" + 0.019*\"men\" + 0.019*\"health\" + 0.018*\"heart\" + 0.015*\"risk\" + 0.014*\"sexual\" + 0.011*\"may\"\n",
      "2019-10-29 00:43:21,436 : INFO : topic diff=0.889738, rho=1.000000\n",
      "2019-10-29 00:43:21,897 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:21,903 : INFO : built Dictionary(184 unique tokens: ['josh', 'paradise', 'end', 'crest', 'subdivision']...) from 5 documents (total 2585 corpus positions)\n",
      "2019-10-29 00:43:21,907 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:21,909 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:21,912 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:21,915 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:21,917 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:22,016 : INFO : -6.597 per-word bound, 96.8 perplexity estimate based on a held-out corpus of 5 documents with 2585 words\n",
      "2019-10-29 00:43:22,018 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:22,025 : INFO : topic #2 (0.100): 0.080*\"blaze\" + 0.076*\"wildfire\" + 0.070*\"photo\" + 0.056*\"california\" + 0.055*\"hide\" + 0.048*\"caption\" + 0.048*\"october\" + 0.024*\"santa\" + 0.023*\"rosa\" + 0.013*\"burn\"\n",
      "2019-10-29 00:43:22,028 : INFO : topic #5 (0.100): 0.075*\"california\" + 0.074*\"october\" + 0.061*\"wildfire\" + 0.053*\"blaze\" + 0.051*\"hide\" + 0.050*\"photo\" + 0.045*\"caption\" + 0.030*\"santa\" + 0.019*\"home\" + 0.019*\"burn\"\n",
      "2019-10-29 00:43:22,031 : INFO : topic #4 (0.100): 0.066*\"photo\" + 0.063*\"hide\" + 0.060*\"caption\" + 0.057*\"wildfire\" + 0.052*\"october\" + 0.051*\"blaze\" + 0.039*\"california\" + 0.026*\"santa\" + 0.022*\"rosa\" + 0.018*\"home\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:22,033 : INFO : topic #8 (0.100): 0.099*\"wildfire\" + 0.069*\"california\" + 0.051*\"october\" + 0.051*\"photo\" + 0.050*\"blaze\" + 0.044*\"hide\" + 0.042*\"caption\" + 0.023*\"rosa\" + 0.021*\"santa\" + 0.017*\"napa\"\n",
      "2019-10-29 00:43:22,036 : INFO : topic #9 (0.100): 0.068*\"photo\" + 0.066*\"caption\" + 0.054*\"blaze\" + 0.054*\"california\" + 0.052*\"october\" + 0.049*\"wildfire\" + 0.049*\"hide\" + 0.025*\"santa\" + 0.024*\"rosa\" + 0.022*\"home\"\n",
      "2019-10-29 00:43:22,039 : INFO : topic diff=1.251619, rho=1.000000\n",
      "2019-10-29 00:43:22,424 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:22,426 : INFO : built Dictionary(12 unique tokens: ['fire', 'happening', 'facebook', 'messenger', 'find']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:43:22,427 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:22,429 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:22,430 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:22,432 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:22,433 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:22,450 : INFO : -6.144 per-word bound, 70.7 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n",
      "2019-10-29 00:43:22,452 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:22,458 : INFO : topic #1 (0.100): 0.115*\"fire\" + 0.107*\"u\" + 0.104*\"find\" + 0.090*\"world\" + 0.089*\"chat\" + 0.082*\"messenger\" + 0.074*\"outrun\" + 0.070*\"unfolds\" + 0.069*\"chief\" + 0.069*\"facebook\"\n",
      "2019-10-29 00:43:22,459 : INFO : topic #7 (0.100): 0.129*\"fire\" + 0.100*\"u\" + 0.093*\"world\" + 0.091*\"facebook\" + 0.082*\"unfolds\" + 0.078*\"chief\" + 0.077*\"happening\" + 0.075*\"find\" + 0.075*\"messenger\" + 0.071*\"outrun\"\n",
      "2019-10-29 00:43:22,462 : INFO : topic #5 (0.100): 0.142*\"fire\" + 0.089*\"find\" + 0.089*\"chief\" + 0.088*\"chat\" + 0.087*\"unfolds\" + 0.085*\"outrun\" + 0.076*\"u\" + 0.075*\"got\" + 0.074*\"messenger\" + 0.068*\"world\"\n",
      "2019-10-29 00:43:22,464 : INFO : topic #0 (0.100): 0.144*\"fire\" + 0.091*\"messenger\" + 0.083*\"chief\" + 0.081*\"happening\" + 0.080*\"outrun\" + 0.080*\"world\" + 0.078*\"unfolds\" + 0.077*\"find\" + 0.075*\"facebook\" + 0.072*\"chat\"\n",
      "2019-10-29 00:43:22,468 : INFO : topic #8 (0.100): 0.126*\"fire\" + 0.095*\"chief\" + 0.092*\"happening\" + 0.090*\"find\" + 0.082*\"outrun\" + 0.080*\"messenger\" + 0.080*\"u\" + 0.077*\"facebook\" + 0.074*\"got\" + 0.072*\"world\"\n",
      "2019-10-29 00:43:22,471 : INFO : topic diff=0.558589, rho=1.000000\n",
      "2019-10-29 00:43:22,858 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:22,859 : INFO : built Dictionary(22 unique tokens: ['matt', 'note', 'twitter', 'bors', 'life']...) from 5 documents (total 110 corpus positions)\n",
      "2019-10-29 00:43:22,860 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:22,861 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:22,863 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:22,865 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:22,866 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:22,883 : INFO : -6.607 per-word bound, 97.5 perplexity estimate based on a held-out corpus of 5 documents with 110 words\n",
      "2019-10-29 00:43:22,884 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:22,890 : INFO : topic #6 (0.100): 0.055*\"born\" + 0.055*\"tweet\" + 0.051*\"matt\" + 0.049*\"love\" + 0.048*\"life\" + 0.047*\"pulitzer\" + 0.047*\"book\" + 0.047*\"generation\" + 0.046*\"bors\" + 0.046*\"note\"\n",
      "2019-10-29 00:43:22,892 : INFO : topic #3 (0.100): 0.054*\"love\" + 0.052*\"regularly\" + 0.052*\"life\" + 0.050*\"tweet\" + 0.050*\"pulitzer\" + 0.049*\"prize\" + 0.049*\"bors\" + 0.048*\"stuff\" + 0.048*\"book\" + 0.046*\"matt\"\n",
      "2019-10-29 00:43:22,894 : INFO : topic #8 (0.100): 0.059*\"begin\" + 0.057*\"bors\" + 0.053*\"dump\" + 0.052*\"incorporation\" + 0.051*\"editor\" + 0.050*\"new\" + 0.049*\"born\" + 0.047*\"tweet\" + 0.047*\"pulitzer\" + 0.047*\"note\"\n",
      "2019-10-29 00:43:22,895 : INFO : topic #4 (0.100): 0.054*\"generation\" + 0.053*\"finalist\" + 0.053*\"cartooning\" + 0.052*\"stuff\" + 0.051*\"editorial\" + 0.049*\"note\" + 0.049*\"born\" + 0.047*\"incorporation\" + 0.047*\"twitter\" + 0.046*\"editor\"\n",
      "2019-10-29 00:43:22,897 : INFO : topic #2 (0.100): 0.056*\"finalist\" + 0.054*\"editor\" + 0.050*\"stuff\" + 0.049*\"tweet\" + 0.048*\"editorial\" + 0.048*\"new\" + 0.046*\"regularly\" + 0.046*\"dump\" + 0.046*\"begin\" + 0.046*\"prize\"\n",
      "2019-10-29 00:43:22,899 : INFO : topic diff=0.519055, rho=1.000000\n",
      "2019-10-29 00:43:23,398 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:23,412 : INFO : built Dictionary(466 unique tokens: ['extensive', 'wave', 'drinking', 'wade', 'extent']...) from 5 documents (total 7025 corpus positions)\n",
      "2019-10-29 00:43:23,423 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:23,426 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:23,429 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:23,434 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:23,436 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:23,603 : INFO : -7.416 per-word bound, 170.7 perplexity estimate based on a held-out corpus of 5 documents with 7025 words\n",
      "2019-10-29 00:43:23,604 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:23,614 : INFO : topic #8 (0.100): 0.055*\"hurricane\" + 0.044*\"tear\" + 0.042*\"caption\" + 0.040*\"irma\" + 0.037*\"caribbean\" + 0.034*\"st\" + 0.029*\"photo\" + 0.026*\"hide\" + 0.022*\"september\" + 0.019*\"island\"\n",
      "2019-10-29 00:43:23,616 : INFO : topic #4 (0.100): 0.044*\"irma\" + 0.043*\"hurricane\" + 0.039*\"photo\" + 0.037*\"caribbean\" + 0.036*\"hide\" + 0.034*\"caption\" + 0.033*\"tear\" + 0.030*\"st\" + 0.028*\"september\" + 0.021*\"island\"\n",
      "2019-10-29 00:43:23,617 : INFO : topic #7 (0.100): 0.046*\"irma\" + 0.043*\"photo\" + 0.041*\"hurricane\" + 0.037*\"caption\" + 0.035*\"tear\" + 0.035*\"caribbean\" + 0.028*\"hide\" + 0.028*\"september\" + 0.024*\"island\" + 0.023*\"st\"\n",
      "2019-10-29 00:43:23,619 : INFO : topic #2 (0.100): 0.046*\"irma\" + 0.039*\"tear\" + 0.037*\"hurricane\" + 0.036*\"photo\" + 0.035*\"caption\" + 0.032*\"caribbean\" + 0.032*\"hide\" + 0.029*\"st\" + 0.028*\"september\" + 0.021*\"island\"\n",
      "2019-10-29 00:43:23,620 : INFO : topic #9 (0.100): 0.050*\"hurricane\" + 0.049*\"irma\" + 0.045*\"tear\" + 0.042*\"hide\" + 0.037*\"caribbean\" + 0.033*\"photo\" + 0.033*\"caption\" + 0.027*\"st\" + 0.026*\"september\" + 0.019*\"island\"\n",
      "2019-10-29 00:43:23,622 : INFO : topic diff=1.205758, rho=1.000000\n",
      "2019-10-29 00:43:24,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:24,097 : INFO : built Dictionary(646 unique tokens: ['number', 'specie', 'energy', 'mitigation', 'putting']...) from 5 documents (total 6400 corpus positions)\n",
      "2019-10-29 00:43:24,106 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:24,108 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:24,110 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:24,114 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:24,116 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:24,348 : INFO : -8.146 per-word bound, 283.2 perplexity estimate based on a held-out corpus of 5 documents with 6400 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:24,350 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:24,362 : INFO : topic #9 (0.100): 0.030*\"climate\" + 0.023*\"world\" + 0.022*\"degree\" + 0.020*\"change\" + 0.009*\"affect\" + 0.009*\"caption\" + 0.008*\"like\" + 0.008*\"temperature\" + 0.008*\"photo\" + 0.007*\"expected\"\n",
      "2019-10-29 00:43:24,364 : INFO : topic #7 (0.100): 0.032*\"degree\" + 0.029*\"climate\" + 0.022*\"change\" + 0.017*\"world\" + 0.011*\"photo\" + 0.009*\"affect\" + 0.008*\"hide\" + 0.008*\"way\" + 0.008*\"caption\" + 0.007*\"temperature\"\n",
      "2019-10-29 00:43:24,367 : INFO : topic #4 (0.100): 0.025*\"climate\" + 0.025*\"degree\" + 0.022*\"change\" + 0.016*\"world\" + 0.013*\"photo\" + 0.011*\"affect\" + 0.008*\"way\" + 0.008*\"hide\" + 0.008*\"temperature\" + 0.007*\"like\"\n",
      "2019-10-29 00:43:24,370 : INFO : topic #5 (0.100): 0.033*\"climate\" + 0.022*\"degree\" + 0.021*\"change\" + 0.020*\"world\" + 0.013*\"way\" + 0.010*\"photo\" + 0.009*\"affect\" + 0.009*\"hide\" + 0.008*\"temperature\" + 0.008*\"caption\"\n",
      "2019-10-29 00:43:24,373 : INFO : topic #8 (0.100): 0.030*\"climate\" + 0.028*\"degree\" + 0.022*\"change\" + 0.016*\"world\" + 0.012*\"photo\" + 0.012*\"way\" + 0.009*\"affect\" + 0.008*\"temperature\" + 0.008*\"caption\" + 0.007*\"like\"\n",
      "2019-10-29 00:43:24,375 : INFO : topic diff=0.919158, rho=1.000000\n",
      "2019-10-29 00:43:24,786 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:24,788 : INFO : built Dictionary(112 unique tokens: ['located', 'deadly', 'small', 'deceased', 'come']...) from 5 documents (total 820 corpus positions)\n",
      "2019-10-29 00:43:24,791 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:24,792 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:24,797 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:24,800 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:24,804 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:24,854 : INFO : -6.918 per-word bound, 120.9 perplexity estimate based on a held-out corpus of 5 documents with 820 words\n",
      "2019-10-29 00:43:24,857 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:24,864 : INFO : topic #2 (0.100): 0.032*\"drug\" + 0.032*\"heroin\" + 0.031*\"said\" + 0.027*\"greensburg\" + 0.024*\"charge\" + 0.024*\"stafford\" + 0.023*\"year\" + 0.023*\"old\" + 0.023*\"room\" + 0.022*\"fatal\"\n",
      "2019-10-29 00:43:24,865 : INFO : topic #0 (0.100): 0.037*\"heroin\" + 0.036*\"drug\" + 0.027*\"greensburg\" + 0.027*\"charge\" + 0.024*\"year\" + 0.022*\"police\" + 0.022*\"said\" + 0.022*\"stafford\" + 0.022*\"overdose\" + 0.020*\"old\"\n",
      "2019-10-29 00:43:24,869 : INFO : topic #1 (0.100): 0.038*\"heroin\" + 0.026*\"drug\" + 0.025*\"year\" + 0.024*\"room\" + 0.024*\"said\" + 0.024*\"charge\" + 0.023*\"old\" + 0.022*\"greensburg\" + 0.022*\"stafford\" + 0.018*\"overdose\"\n",
      "2019-10-29 00:43:24,873 : INFO : topic #4 (0.100): 0.039*\"heroin\" + 0.038*\"drug\" + 0.028*\"greensburg\" + 0.024*\"room\" + 0.023*\"said\" + 0.022*\"stafford\" + 0.021*\"charge\" + 0.021*\"old\" + 0.020*\"year\" + 0.020*\"police\"\n",
      "2019-10-29 00:43:24,875 : INFO : topic #6 (0.100): 0.038*\"heroin\" + 0.036*\"greensburg\" + 0.029*\"drug\" + 0.025*\"old\" + 0.024*\"year\" + 0.024*\"said\" + 0.023*\"stafford\" + 0.022*\"room\" + 0.018*\"fatal\" + 0.018*\"charge\"\n",
      "2019-10-29 00:43:24,877 : INFO : topic diff=0.840044, rho=1.000000\n",
      "2019-10-29 00:43:25,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:25,274 : INFO : built Dictionary(207 unique tokens: ['even', 'deep', 'come', 'job', 'one']...) from 5 documents (total 1520 corpus positions)\n",
      "2019-10-29 00:43:25,277 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:25,278 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:25,280 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:25,283 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:25,284 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:25,375 : INFO : -7.473 per-word bound, 177.7 perplexity estimate based on a held-out corpus of 5 documents with 1520 words\n",
      "2019-10-29 00:43:25,376 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:25,384 : INFO : topic #3 (0.100): 0.028*\"city\" + 0.023*\"detroit\" + 0.019*\"copy\" + 0.018*\"gritty\" + 0.017*\"time\" + 0.015*\"way\" + 0.014*\"people\" + 0.013*\"detroiters\" + 0.012*\"far\" + 0.011*\"one\"\n",
      "2019-10-29 00:43:25,386 : INFO : topic #4 (0.100): 0.039*\"city\" + 0.029*\"detroit\" + 0.020*\"way\" + 0.016*\"gritty\" + 0.015*\"hardscrabble\" + 0.015*\"guam\" + 0.014*\"time\" + 0.014*\"people\" + 0.014*\"multiple\" + 0.013*\"detroiters\"\n",
      "2019-10-29 00:43:25,389 : INFO : topic #1 (0.100): 0.031*\"detroit\" + 0.027*\"gritty\" + 0.025*\"city\" + 0.016*\"time\" + 0.015*\"hardscrabble\" + 0.015*\"copy\" + 0.014*\"way\" + 0.013*\"people\" + 0.012*\"guam\" + 0.012*\"detroiters\"\n",
      "2019-10-29 00:43:25,391 : INFO : topic #8 (0.100): 0.032*\"city\" + 0.024*\"detroit\" + 0.020*\"gritty\" + 0.017*\"people\" + 0.016*\"guam\" + 0.015*\"copy\" + 0.014*\"way\" + 0.014*\"time\" + 0.014*\"multiple\" + 0.013*\"detroiters\"\n",
      "2019-10-29 00:43:25,393 : INFO : topic #6 (0.100): 0.026*\"city\" + 0.025*\"detroit\" + 0.018*\"gritty\" + 0.016*\"people\" + 0.016*\"way\" + 0.014*\"multiple\" + 0.013*\"guam\" + 0.013*\"hardscrabble\" + 0.012*\"time\" + 0.012*\"detroiters\"\n",
      "2019-10-29 00:43:25,395 : INFO : topic diff=0.816983, rho=1.000000\n",
      "2019-10-29 00:43:25,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:25,860 : INFO : built Dictionary(76 unique tokens: ['started', 'may', 'bonath', 'night', 'checking']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:43:25,862 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:25,864 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:25,865 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:25,868 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:25,869 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:25,904 : INFO : -6.480 per-word bound, 89.3 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:43:25,906 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:25,911 : INFO : topic #0 (0.100): 0.058*\"officer\" + 0.044*\"texas\" + 0.033*\"campus\" + 0.032*\"tech\" + 0.030*\"said\" + 0.030*\"police\" + 0.028*\"floyd\" + 0.027*\"jr\" + 0.027*\"east\" + 0.025*\"shot\"\n",
      "2019-10-29 00:43:25,915 : INFO : topic #1 (0.100): 0.053*\"officer\" + 0.037*\"tech\" + 0.036*\"texas\" + 0.033*\"police\" + 0.033*\"said\" + 0.028*\"jr\" + 0.028*\"east\" + 0.027*\"campus\" + 0.022*\"student\" + 0.021*\"shot\"\n",
      "2019-10-29 00:43:25,920 : INFO : topic #2 (0.100): 0.051*\"officer\" + 0.048*\"police\" + 0.035*\"said\" + 0.034*\"tech\" + 0.032*\"texas\" + 0.029*\"campus\" + 0.029*\"east\" + 0.027*\"floyd\" + 0.026*\"jr\" + 0.025*\"night\"\n",
      "2019-10-29 00:43:25,924 : INFO : topic #4 (0.100): 0.055*\"officer\" + 0.039*\"police\" + 0.038*\"texas\" + 0.035*\"east\" + 0.029*\"tech\" + 0.028*\"shot\" + 0.027*\"campus\" + 0.025*\"jr\" + 0.025*\"floyd\" + 0.025*\"said\"\n",
      "2019-10-29 00:43:25,927 : INFO : topic #6 (0.100): 0.048*\"officer\" + 0.042*\"police\" + 0.038*\"texas\" + 0.033*\"campus\" + 0.032*\"east\" + 0.032*\"said\" + 0.028*\"night\" + 0.027*\"floyd\" + 0.024*\"jr\" + 0.023*\"tech\"\n",
      "2019-10-29 00:43:25,929 : INFO : topic diff=0.860765, rho=1.000000\n",
      "2019-10-29 00:43:26,384 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:26,389 : INFO : built Dictionary(282 unique tokens: ['forward', 'aspiration', 'warehouse', 'collect', 'hero']...) from 5 documents (total 2250 corpus positions)\n",
      "2019-10-29 00:43:26,393 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:26,394 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:26,398 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:26,402 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:26,406 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:26,503 : INFO : -7.628 per-word bound, 197.8 perplexity estimate based on a held-out corpus of 5 documents with 2250 words\n",
      "2019-10-29 00:43:26,505 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:26,512 : INFO : topic #0 (0.100): 0.024*\"cnn\" + 0.022*\"youth\" + 0.021*\"foster\" + 0.020*\"smith\" + 0.020*\"home\" + 0.015*\"get\" + 0.012*\"community\" + 0.011*\"georgie\" + 0.010*\"system\" + 0.009*\"young\"\n",
      "2019-10-29 00:43:26,515 : INFO : topic #1 (0.100): 0.030*\"smith\" + 0.029*\"home\" + 0.018*\"cnn\" + 0.017*\"youth\" + 0.016*\"foster\" + 0.016*\"get\" + 0.011*\"community\" + 0.010*\"georgie\" + 0.010*\"system\" + 0.009*\"living\"\n",
      "2019-10-29 00:43:26,517 : INFO : topic #4 (0.100): 0.030*\"smith\" + 0.023*\"home\" + 0.020*\"youth\" + 0.019*\"foster\" + 0.018*\"get\" + 0.017*\"cnn\" + 0.014*\"space\" + 0.011*\"hero\" + 0.010*\"really\" + 0.010*\"community\"\n",
      "2019-10-29 00:43:26,519 : INFO : topic #7 (0.100): 0.031*\"smith\" + 0.024*\"home\" + 0.019*\"cnn\" + 0.019*\"youth\" + 0.015*\"foster\" + 0.014*\"get\" + 0.012*\"system\" + 0.011*\"georgie\" + 0.010*\"volunteer\" + 0.010*\"family\"\n",
      "2019-10-29 00:43:26,521 : INFO : topic #6 (0.100): 0.031*\"smith\" + 0.025*\"youth\" + 0.024*\"foster\" + 0.024*\"home\" + 0.021*\"cnn\" + 0.015*\"get\" + 0.011*\"georgie\" + 0.011*\"space\" + 0.009*\"living\" + 0.009*\"really\"\n",
      "2019-10-29 00:43:26,524 : INFO : topic diff=0.846090, rho=1.000000\n",
      "2019-10-29 00:43:26,980 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:26,983 : INFO : built Dictionary(177 unique tokens: ['including', 'end', 'bump', 'tax', 'legislation']...) from 5 documents (total 1780 corpus positions)\n",
      "2019-10-29 00:43:26,987 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:26,988 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:26,990 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:26,993 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:26,995 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:27,072 : INFO : -6.885 per-word bound, 118.2 perplexity estimate based on a held-out corpus of 5 documents with 1780 words\n",
      "2019-10-29 00:43:27,074 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:27,083 : INFO : topic #5 (0.100): 0.075*\"tax\" + 0.051*\"would\" + 0.039*\"income\" + 0.033*\"average\" + 0.017*\"year\" + 0.016*\"top\" + 0.015*\"pay\" + 0.015*\"cut\" + 0.015*\"filer\" + 0.014*\"next\"\n",
      "2019-10-29 00:43:27,085 : INFO : topic #3 (0.100): 0.071*\"tax\" + 0.040*\"would\" + 0.032*\"income\" + 0.030*\"average\" + 0.026*\"year\" + 0.018*\"get\" + 0.018*\"center\" + 0.016*\"next\" + 0.015*\"policy\" + 0.014*\"top\"\n",
      "2019-10-29 00:43:27,089 : INFO : topic #6 (0.100): 0.077*\"tax\" + 0.050*\"would\" + 0.034*\"average\" + 0.029*\"income\" + 0.019*\"policy\" + 0.016*\"center\" + 0.016*\"next\" + 0.014*\"year\" + 0.014*\"pay\" + 0.013*\"analysis\"\n",
      "2019-10-29 00:43:27,092 : INFO : topic #2 (0.100): 0.077*\"tax\" + 0.043*\"income\" + 0.037*\"would\" + 0.033*\"average\" + 0.018*\"top\" + 0.017*\"year\" + 0.017*\"center\" + 0.014*\"policy\" + 0.013*\"middle\" + 0.013*\"increase\"\n",
      "2019-10-29 00:43:27,096 : INFO : topic #9 (0.100): 0.062*\"tax\" + 0.051*\"would\" + 0.036*\"average\" + 0.032*\"income\" + 0.020*\"top\" + 0.019*\"center\" + 0.018*\"year\" + 0.017*\"pay\" + 0.016*\"policy\" + 0.016*\"filer\"\n",
      "2019-10-29 00:43:27,098 : INFO : topic diff=0.944658, rho=1.000000\n",
      "2019-10-29 00:43:27,503 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:27,505 : INFO : built Dictionary(92 unique tokens: ['let', 'rebuked', 'computer', 'annulling', 'fraudulent']...) from 5 documents (total 680 corpus positions)\n",
      "2019-10-29 00:43:27,507 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:27,509 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:27,510 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:27,512 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:27,513 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:27,554 : INFO : -6.736 per-word bound, 106.6 perplexity estimate based on a held-out corpus of 5 documents with 680 words\n",
      "2019-10-29 00:43:27,557 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:27,565 : INFO : topic #6 (0.100): 0.047*\"court\" + 0.039*\"election\" + 0.036*\"coup\" + 0.028*\"kenya\" + 0.023*\"president\" + 0.022*\"supreme\" + 0.020*\"kenyan\" + 0.020*\"kenyatta\" + 0.018*\"country\" + 0.016*\"month\"\n",
      "2019-10-29 00:43:27,567 : INFO : topic #7 (0.100): 0.049*\"court\" + 0.039*\"coup\" + 0.029*\"kenya\" + 0.027*\"election\" + 0.021*\"country\" + 0.019*\"kenyatta\" + 0.018*\"happened\" + 0.017*\"kenyan\" + 0.017*\"supreme\" + 0.016*\"president\"\n",
      "2019-10-29 00:43:27,568 : INFO : topic #1 (0.100): 0.033*\"court\" + 0.031*\"election\" + 0.029*\"coup\" + 0.025*\"kenya\" + 0.023*\"kenyatta\" + 0.022*\"kenyan\" + 0.018*\"president\" + 0.018*\"wednesday\" + 0.017*\"country\" + 0.017*\"october\"\n",
      "2019-10-29 00:43:27,569 : INFO : topic #5 (0.100): 0.047*\"court\" + 0.036*\"election\" + 0.030*\"coup\" + 0.026*\"kenya\" + 0.024*\"kenyatta\" + 0.022*\"supreme\" + 0.021*\"country\" + 0.021*\"president\" + 0.021*\"kenyan\" + 0.018*\"presidential\"\n",
      "2019-10-29 00:43:27,571 : INFO : topic #0 (0.100): 0.043*\"court\" + 0.035*\"coup\" + 0.031*\"kenya\" + 0.030*\"election\" + 0.023*\"supreme\" + 0.021*\"country\" + 0.021*\"president\" + 0.020*\"kenyan\" + 0.018*\"kenyatta\" + 0.017*\"august\"\n",
      "2019-10-29 00:43:27,573 : INFO : topic diff=0.777659, rho=1.000000\n",
      "2019-10-29 00:43:28,047 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:28,056 : INFO : built Dictionary(548 unique tokens: ['consider', 'phase', 'deep', 'reviewed', 'larger']...) from 5 documents (total 4855 corpus positions)\n",
      "2019-10-29 00:43:28,064 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:28,065 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:28,071 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:28,076 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:28,077 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:28,276 : INFO : -8.121 per-word bound, 278.4 perplexity estimate based on a held-out corpus of 5 documents with 4855 words\n",
      "2019-10-29 00:43:28,278 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:28,288 : INFO : topic #7 (0.100): 0.025*\"salmon\" + 0.019*\"bristol\" + 0.018*\"mine\" + 0.017*\"said\" + 0.014*\"bay\" + 0.014*\"would\" + 0.010*\"year\" + 0.010*\"epa\" + 0.008*\"water\" + 0.008*\"could\"\n",
      "2019-10-29 00:43:28,290 : INFO : topic #5 (0.100): 0.029*\"salmon\" + 0.023*\"bay\" + 0.019*\"mine\" + 0.016*\"bristol\" + 0.013*\"said\" + 0.011*\"would\" + 0.011*\"epa\" + 0.010*\"year\" + 0.008*\"company\" + 0.008*\"pebble\"\n",
      "2019-10-29 00:43:28,293 : INFO : topic #3 (0.100): 0.034*\"salmon\" + 0.027*\"mine\" + 0.020*\"said\" + 0.017*\"bristol\" + 0.016*\"bay\" + 0.012*\"epa\" + 0.010*\"would\" + 0.008*\"water\" + 0.008*\"mining\" + 0.008*\"year\"\n",
      "2019-10-29 00:43:28,295 : INFO : topic #9 (0.100): 0.030*\"salmon\" + 0.018*\"said\" + 0.018*\"bay\" + 0.016*\"bristol\" + 0.016*\"mine\" + 0.011*\"epa\" + 0.011*\"would\" + 0.008*\"year\" + 0.008*\"alaska\" + 0.008*\"pebble\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:28,297 : INFO : topic #4 (0.100): 0.024*\"salmon\" + 0.017*\"said\" + 0.017*\"bay\" + 0.015*\"would\" + 0.014*\"mine\" + 0.013*\"bristol\" + 0.009*\"year\" + 0.009*\"could\" + 0.009*\"epa\" + 0.009*\"water\"\n",
      "2019-10-29 00:43:28,299 : INFO : topic diff=0.914682, rho=1.000000\n",
      "2019-10-29 00:43:28,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:28,709 : INFO : built Dictionary(121 unique tokens: ['could', 'animal', 'option', 'game', 'get']...) from 5 documents (total 730 corpus positions)\n",
      "2019-10-29 00:43:28,711 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:28,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:28,714 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:28,717 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:28,718 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:28,781 : INFO : -7.339 per-word bound, 161.9 perplexity estimate based on a held-out corpus of 5 documents with 730 words\n",
      "2019-10-29 00:43:28,783 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:28,787 : INFO : topic #8 (0.100): 0.033*\"moose\" + 0.023*\"leier\" + 0.021*\"say\" + 0.018*\"wildlife\" + 0.017*\"whether\" + 0.017*\"may\" + 0.015*\"said\" + 0.015*\"typically\" + 0.015*\"fish\" + 0.013*\"several\"\n",
      "2019-10-29 00:43:28,789 : INFO : topic #7 (0.100): 0.027*\"moose\" + 0.022*\"may\" + 0.020*\"say\" + 0.019*\"whether\" + 0.018*\"leier\" + 0.016*\"try\" + 0.014*\"animal\" + 0.014*\"fish\" + 0.013*\"wildlife\" + 0.013*\"certain\"\n",
      "2019-10-29 00:43:28,791 : INFO : topic #3 (0.100): 0.031*\"moose\" + 0.023*\"say\" + 0.018*\"may\" + 0.017*\"whether\" + 0.017*\"wildlife\" + 0.015*\"leier\" + 0.014*\"year\" + 0.014*\"sighting\" + 0.013*\"certain\" + 0.013*\"typically\"\n",
      "2019-10-29 00:43:28,792 : INFO : topic #5 (0.100): 0.025*\"moose\" + 0.022*\"whether\" + 0.018*\"wildlife\" + 0.016*\"option\" + 0.016*\"may\" + 0.016*\"say\" + 0.015*\"certain\" + 0.015*\"animal\" + 0.014*\"several\" + 0.014*\"said\"\n",
      "2019-10-29 00:43:28,794 : INFO : topic #9 (0.100): 0.034*\"moose\" + 0.026*\"whether\" + 0.022*\"wildlife\" + 0.019*\"may\" + 0.019*\"leier\" + 0.017*\"game\" + 0.015*\"sighting\" + 0.014*\"typically\" + 0.014*\"option\" + 0.014*\"say\"\n",
      "2019-10-29 00:43:28,801 : INFO : topic diff=0.691267, rho=1.000000\n",
      "2019-10-29 00:43:29,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:29,234 : INFO : built Dictionary(63 unique tokens: ['strengthened', 'end', 'oversaw', 'region', 'death']...) from 5 documents (total 445 corpus positions)\n",
      "2019-10-29 00:43:29,238 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:29,240 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:29,243 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:29,246 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:29,248 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:29,289 : INFO : -6.502 per-word bound, 90.6 perplexity estimate based on a held-out corpus of 5 documents with 445 words\n",
      "2019-10-29 00:43:29,291 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:29,297 : INFO : topic #8 (0.100): 0.055*\"president\" + 0.048*\"iraqi\" + 0.046*\"talabani\" + 0.041*\"iraq\" + 0.037*\"jalal\" + 0.030*\"state\" + 0.029*\"kurdish\" + 0.022*\"first\" + 0.021*\"died\" + 0.021*\"cnn\"\n",
      "2019-10-29 00:43:29,305 : INFO : topic #6 (0.100): 0.057*\"president\" + 0.046*\"iraqi\" + 0.044*\"iraq\" + 0.038*\"kurdish\" + 0.037*\"talabani\" + 0.035*\"jalal\" + 0.029*\"state\" + 0.026*\"first\" + 0.026*\"cnn\" + 0.021*\"arab\"\n",
      "2019-10-29 00:43:29,307 : INFO : topic #3 (0.100): 0.055*\"talabani\" + 0.051*\"president\" + 0.045*\"iraq\" + 0.035*\"kurdish\" + 0.033*\"iraqi\" + 0.031*\"state\" + 0.027*\"country\" + 0.027*\"jalal\" + 0.023*\"cnn\" + 0.022*\"arab\"\n",
      "2019-10-29 00:43:29,310 : INFO : topic #5 (0.100): 0.058*\"president\" + 0.044*\"iraqi\" + 0.040*\"talabani\" + 0.038*\"jalal\" + 0.034*\"kurdish\" + 0.034*\"iraq\" + 0.033*\"state\" + 0.023*\"first\" + 0.021*\"non\" + 0.021*\"cnn\"\n",
      "2019-10-29 00:43:29,311 : INFO : topic #0 (0.100): 0.066*\"talabani\" + 0.052*\"president\" + 0.040*\"iraq\" + 0.034*\"iraqi\" + 0.030*\"state\" + 0.026*\"jalal\" + 0.026*\"kurdish\" + 0.026*\"died\" + 0.025*\"cnn\" + 0.022*\"country\"\n",
      "2019-10-29 00:43:29,315 : INFO : topic diff=0.814142, rho=1.000000\n",
      "2019-10-29 00:43:29,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:29,864 : INFO : built Dictionary(903 unique tokens: ['although', 'synchronicity', 'real', 'happy', 'diagnostic']...) from 5 documents (total 8830 corpus positions)\n",
      "2019-10-29 00:43:29,874 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:29,877 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:29,880 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:29,885 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:29,887 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:30,167 : INFO : -8.486 per-word bound, 358.4 perplexity estimate based on a held-out corpus of 5 documents with 8830 words\n",
      "2019-10-29 00:43:30,168 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:30,180 : INFO : topic #5 (0.100): 0.030*\"say\" + 0.015*\"gallagher\" + 0.014*\"possession\" + 0.013*\"exorcism\" + 0.011*\"one\" + 0.010*\"people\" + 0.008*\"woman\" + 0.007*\"like\" + 0.007*\"priest\" + 0.006*\"demonic\"\n",
      "2019-10-29 00:43:30,182 : INFO : topic #1 (0.100): 0.028*\"say\" + 0.017*\"gallagher\" + 0.016*\"possession\" + 0.013*\"one\" + 0.010*\"exorcism\" + 0.009*\"priest\" + 0.008*\"people\" + 0.008*\"woman\" + 0.006*\"exorcist\" + 0.006*\"like\"\n",
      "2019-10-29 00:43:30,183 : INFO : topic #3 (0.100): 0.024*\"say\" + 0.022*\"gallagher\" + 0.013*\"possession\" + 0.012*\"people\" + 0.011*\"exorcism\" + 0.010*\"one\" + 0.008*\"woman\" + 0.007*\"like\" + 0.006*\"demonic\" + 0.006*\"exorcist\"\n",
      "2019-10-29 00:43:30,185 : INFO : topic #7 (0.100): 0.023*\"say\" + 0.022*\"gallagher\" + 0.016*\"possession\" + 0.012*\"people\" + 0.010*\"one\" + 0.009*\"exorcism\" + 0.007*\"priest\" + 0.007*\"like\" + 0.007*\"woman\" + 0.006*\"demonic\"\n",
      "2019-10-29 00:43:30,189 : INFO : topic #4 (0.100): 0.030*\"say\" + 0.019*\"gallagher\" + 0.017*\"one\" + 0.014*\"exorcism\" + 0.012*\"possession\" + 0.009*\"people\" + 0.008*\"priest\" + 0.007*\"woman\" + 0.006*\"julia\" + 0.006*\"like\"\n",
      "2019-10-29 00:43:30,192 : INFO : topic diff=0.948114, rho=1.000000\n",
      "2019-10-29 00:43:30,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:30,643 : INFO : built Dictionary(494 unique tokens: ['consider', 'prime', 'backlash', 'similar', 'excitement']...) from 5 documents (total 4180 corpus positions)\n",
      "2019-10-29 00:43:30,650 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:30,651 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:30,652 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:30,657 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:30,659 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:30,808 : INFO : -8.077 per-word bound, 270.0 perplexity estimate based on a held-out corpus of 5 documents with 4180 words\n",
      "2019-10-29 00:43:30,809 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:30,819 : INFO : topic #6 (0.100): 0.034*\"crime\" + 0.030*\"hate\" + 0.015*\"often\" + 0.013*\"attack\" + 0.009*\"offender\" + 0.009*\"victim\" + 0.009*\"muslim\" + 0.009*\"man\" + 0.008*\"mission\" + 0.008*\"mcdevitt\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:30,822 : INFO : topic #3 (0.100): 0.032*\"crime\" + 0.024*\"hate\" + 0.013*\"often\" + 0.012*\"offender\" + 0.011*\"attack\" + 0.010*\"victim\" + 0.009*\"group\" + 0.009*\"people\" + 0.008*\"example\" + 0.008*\"mission\"\n",
      "2019-10-29 00:43:30,824 : INFO : topic #9 (0.100): 0.041*\"hate\" + 0.038*\"crime\" + 0.013*\"victim\" + 0.013*\"often\" + 0.012*\"people\" + 0.009*\"attack\" + 0.009*\"thrill\" + 0.008*\"offender\" + 0.008*\"neighborhood\" + 0.007*\"mission\"\n",
      "2019-10-29 00:43:30,825 : INFO : topic #7 (0.100): 0.030*\"hate\" + 0.023*\"crime\" + 0.014*\"often\" + 0.012*\"people\" + 0.011*\"offender\" + 0.009*\"attack\" + 0.008*\"victim\" + 0.008*\"mcdevitt\" + 0.007*\"mission\" + 0.007*\"example\"\n",
      "2019-10-29 00:43:30,827 : INFO : topic #8 (0.100): 0.033*\"hate\" + 0.028*\"crime\" + 0.010*\"mcdevitt\" + 0.010*\"victim\" + 0.010*\"attack\" + 0.010*\"group\" + 0.009*\"people\" + 0.009*\"often\" + 0.008*\"community\" + 0.008*\"say\"\n",
      "2019-10-29 00:43:30,828 : INFO : topic diff=0.900978, rho=1.000000\n",
      "2019-10-29 00:43:31,239 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:31,243 : INFO : built Dictionary(266 unique tokens: ['extensive', 'real', '1990s', 'hong', 'observing']...) from 5 documents (total 1880 corpus positions)\n",
      "2019-10-29 00:43:31,247 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:31,249 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:31,251 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:31,254 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:31,256 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:31,363 : INFO : -7.759 per-word bound, 216.7 perplexity estimate based on a held-out corpus of 5 documents with 1880 words\n",
      "2019-10-29 00:43:31,364 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:31,371 : INFO : topic #9 (0.100): 0.046*\"yu\" + 0.016*\"hong\" + 0.016*\"china\" + 0.013*\"year\" + 0.012*\"day\" + 0.012*\"artist\" + 0.012*\"art\" + 0.011*\"world\" + 0.011*\"beijing\" + 0.010*\"growth\"\n",
      "2019-10-29 00:43:31,374 : INFO : topic #7 (0.100): 0.033*\"yu\" + 0.020*\"hong\" + 0.016*\"china\" + 0.012*\"day\" + 0.012*\"year\" + 0.012*\"world\" + 0.011*\"series\" + 0.011*\"event\" + 0.010*\"artist\" + 0.010*\"art\"\n",
      "2019-10-29 00:43:31,377 : INFO : topic #5 (0.100): 0.031*\"yu\" + 0.021*\"hong\" + 0.015*\"china\" + 0.013*\"artist\" + 0.012*\"studio\" + 0.011*\"day\" + 0.011*\"year\" + 0.010*\"real\" + 0.010*\"world\" + 0.010*\"art\"\n",
      "2019-10-29 00:43:31,380 : INFO : topic #6 (0.100): 0.030*\"yu\" + 0.021*\"china\" + 0.017*\"hong\" + 0.016*\"day\" + 0.011*\"year\" + 0.010*\"guggenheim\" + 0.010*\"series\" + 0.010*\"credit\" + 0.010*\"said\" + 0.009*\"studio\"\n",
      "2019-10-29 00:43:31,382 : INFO : topic #0 (0.100): 0.041*\"yu\" + 0.019*\"china\" + 0.014*\"hong\" + 0.013*\"studio\" + 0.011*\"world\" + 0.011*\"day\" + 0.011*\"beijing\" + 0.011*\"series\" + 0.010*\"year\" + 0.010*\"real\"\n",
      "2019-10-29 00:43:31,385 : INFO : topic diff=0.803815, rho=1.000000\n",
      "2019-10-29 00:43:31,781 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:31,783 : INFO : built Dictionary(12 unique tokens: ['agreeing', 'show', 'changed', 'privacy', 'policy']...) from 5 documents (total 80 corpus positions)\n",
      "2019-10-29 00:43:31,786 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:31,788 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:31,789 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:31,792 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:31,794 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:31,806 : INFO : -5.611 per-word bound, 48.9 perplexity estimate based on a held-out corpus of 5 documents with 80 words\n",
      "2019-10-29 00:43:31,808 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:31,813 : INFO : topic #3 (0.100): 0.126*\"service\" + 0.121*\"policy\" + 0.120*\"privacy\" + 0.106*\"term\" + 0.078*\"site\" + 0.077*\"continuing\" + 0.071*\"new\" + 0.065*\"agreeing\" + 0.065*\"show\" + 0.058*\"list\"\n",
      "2019-10-29 00:43:31,815 : INFO : topic #7 (0.100): 0.120*\"service\" + 0.119*\"term\" + 0.118*\"privacy\" + 0.090*\"policy\" + 0.078*\"list\" + 0.076*\"new\" + 0.072*\"site\" + 0.070*\"agreeing\" + 0.069*\"use\" + 0.065*\"show\"\n",
      "2019-10-29 00:43:31,818 : INFO : topic #6 (0.100): 0.145*\"term\" + 0.124*\"policy\" + 0.112*\"privacy\" + 0.109*\"service\" + 0.086*\"agreeing\" + 0.075*\"show\" + 0.062*\"list\" + 0.062*\"changed\" + 0.058*\"use\" + 0.058*\"continuing\"\n",
      "2019-10-29 00:43:31,820 : INFO : topic #8 (0.100): 0.135*\"term\" + 0.119*\"policy\" + 0.110*\"service\" + 0.098*\"privacy\" + 0.078*\"list\" + 0.071*\"agreeing\" + 0.069*\"use\" + 0.067*\"show\" + 0.067*\"changed\" + 0.066*\"continuing\"\n",
      "2019-10-29 00:43:31,823 : INFO : topic #9 (0.100): 0.147*\"policy\" + 0.109*\"term\" + 0.108*\"service\" + 0.107*\"privacy\" + 0.083*\"changed\" + 0.075*\"site\" + 0.074*\"new\" + 0.067*\"continuing\" + 0.063*\"list\" + 0.059*\"use\"\n",
      "2019-10-29 00:43:31,826 : INFO : topic diff=0.606877, rho=1.000000\n",
      "2019-10-29 00:43:32,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:32,250 : INFO : built Dictionary(339 unique tokens: ['forward', 'let', 'ship', 'nation', 'directly']...) from 5 documents (total 2370 corpus positions)\n",
      "2019-10-29 00:43:32,254 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:32,256 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:32,260 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:32,265 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:32,268 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:32,395 : INFO : -8.010 per-word bound, 257.8 perplexity estimate based on a held-out corpus of 5 documents with 2370 words\n",
      "2019-10-29 00:43:32,396 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:32,404 : INFO : topic #2 (0.100): 0.017*\"military\" + 0.016*\"president\" + 0.015*\"leader\" + 0.012*\"trump\" + 0.012*\"u\" + 0.010*\"option\" + 0.010*\"like\" + 0.009*\"comment\" + 0.009*\"secretary\" + 0.009*\"irresponsible\"\n",
      "2019-10-29 00:43:32,406 : INFO : topic #7 (0.100): 0.016*\"military\" + 0.015*\"president\" + 0.011*\"trump\" + 0.010*\"like\" + 0.009*\"option\" + 0.009*\"comment\" + 0.008*\"threat\" + 0.008*\"way\" + 0.008*\"leader\" + 0.008*\"u\"\n",
      "2019-10-29 00:43:32,407 : INFO : topic #8 (0.100): 0.017*\"military\" + 0.014*\"president\" + 0.010*\"u\" + 0.009*\"option\" + 0.009*\"like\" + 0.009*\"leader\" + 0.009*\"trump\" + 0.009*\"know\" + 0.008*\"irresponsible\" + 0.008*\"dinner\"\n",
      "2019-10-29 00:43:32,409 : INFO : topic #0 (0.100): 0.019*\"military\" + 0.014*\"leader\" + 0.013*\"president\" + 0.013*\"option\" + 0.012*\"trump\" + 0.010*\"defense\" + 0.010*\"u\" + 0.009*\"like\" + 0.009*\"irresponsible\" + 0.008*\"dinner\"\n",
      "2019-10-29 00:43:32,410 : INFO : topic #3 (0.100): 0.018*\"president\" + 0.013*\"leader\" + 0.012*\"trump\" + 0.011*\"military\" + 0.010*\"like\" + 0.009*\"u\" + 0.009*\"threat\" + 0.008*\"dinner\" + 0.008*\"option\" + 0.008*\"also\"\n",
      "2019-10-29 00:43:32,413 : INFO : topic diff=0.790927, rho=1.000000\n",
      "2019-10-29 00:43:32,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:32,924 : INFO : built Dictionary(151 unique tokens: ['specie', 'square', 'end', 'sandstone', 'restriction']...) from 5 documents (total 1165 corpus positions)\n",
      "2019-10-29 00:43:32,932 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:32,940 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:32,943 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:32,946 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:32,950 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:33,115 : INFO : -7.106 per-word bound, 137.7 perplexity estimate based on a held-out corpus of 5 documents with 1165 words\n",
      "2019-10-29 00:43:33,117 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:33,124 : INFO : topic #6 (0.100): 0.048*\"park\" + 0.033*\"kakadu\" + 0.025*\"national\" + 0.023*\"territory\" + 0.021*\"australia\" + 0.019*\"northern\" + 0.019*\"tourism\" + 0.018*\"video\" + 0.016*\"drone\" + 0.016*\"land\"\n",
      "2019-10-29 00:43:33,127 : INFO : topic #3 (0.100): 0.034*\"park\" + 0.033*\"australia\" + 0.028*\"kakadu\" + 0.024*\"territory\" + 0.021*\"national\" + 0.020*\"tourism\" + 0.019*\"drone\" + 0.017*\"land\" + 0.016*\"nt\" + 0.016*\"video\"\n",
      "2019-10-29 00:43:33,130 : INFO : topic #5 (0.100): 0.035*\"park\" + 0.027*\"australia\" + 0.027*\"kakadu\" + 0.020*\"national\" + 0.019*\"northern\" + 0.019*\"nt\" + 0.018*\"tourism\" + 0.017*\"video\" + 0.016*\"drone\" + 0.015*\"territory\"\n",
      "2019-10-29 00:43:33,133 : INFO : topic #1 (0.100): 0.033*\"park\" + 0.031*\"kakadu\" + 0.025*\"territory\" + 0.023*\"national\" + 0.023*\"australia\" + 0.020*\"tourism\" + 0.018*\"land\" + 0.018*\"northern\" + 0.017*\"drone\" + 0.017*\"nt\"\n",
      "2019-10-29 00:43:33,136 : INFO : topic #0 (0.100): 0.037*\"park\" + 0.030*\"australia\" + 0.027*\"national\" + 0.026*\"kakadu\" + 0.023*\"tourism\" + 0.022*\"drone\" + 0.021*\"northern\" + 0.018*\"territory\" + 0.017*\"land\" + 0.015*\"video\"\n",
      "2019-10-29 00:43:33,138 : INFO : topic diff=0.851909, rho=1.000000\n",
      "2019-10-29 00:43:33,628 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:33,631 : INFO : built Dictionary(27 unique tokens: ['way', 'latest', 'watch', 'see', 'rift']...) from 5 documents (total 170 corpus positions)\n",
      "2019-10-29 00:43:33,633 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:33,636 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:33,639 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:33,643 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:33,646 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:33,666 : INFO : -6.137 per-word bound, 70.4 perplexity estimate based on a held-out corpus of 5 documents with 170 words\n",
      "2019-10-29 00:43:33,669 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:33,674 : INFO : topic #6 (0.100): 0.090*\"app\" + 0.058*\"vr\" + 0.057*\"headset\" + 0.050*\"cnnvr\" + 0.049*\"watch\" + 0.040*\"story\" + 0.039*\"rift\" + 0.036*\"around\" + 0.036*\"explore\" + 0.035*\"left\"\n",
      "2019-10-29 00:43:33,698 : INFO : topic #7 (0.100): 0.091*\"vr\" + 0.082*\"app\" + 0.060*\"watch\" + 0.056*\"cnnvr\" + 0.048*\"headset\" + 0.038*\"daydream\" + 0.035*\"latest\" + 0.034*\"try\" + 0.033*\"u\" + 0.032*\"oculus\"\n",
      "2019-10-29 00:43:33,701 : INFO : topic #9 (0.100): 0.089*\"vr\" + 0.087*\"app\" + 0.064*\"headset\" + 0.053*\"watch\" + 0.051*\"cnnvr\" + 0.038*\"try\" + 0.037*\"samsung\" + 0.034*\"around\" + 0.034*\"way\" + 0.033*\"need\"\n",
      "2019-10-29 00:43:33,704 : INFO : topic #5 (0.100): 0.086*\"vr\" + 0.069*\"app\" + 0.067*\"headset\" + 0.067*\"watch\" + 0.055*\"cnnvr\" + 0.041*\"oculus\" + 0.038*\"samsung\" + 0.034*\"hand\" + 0.032*\"google\" + 0.032*\"best\"\n",
      "2019-10-29 00:43:33,716 : INFO : topic #0 (0.100): 0.099*\"vr\" + 0.079*\"app\" + 0.064*\"cnnvr\" + 0.049*\"watch\" + 0.047*\"headset\" + 0.038*\"need\" + 0.037*\"believe\" + 0.034*\"hand\" + 0.033*\"see\" + 0.032*\"story\"\n",
      "2019-10-29 00:43:33,719 : INFO : topic diff=0.706681, rho=1.000000\n",
      "2019-10-29 00:43:34,269 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:34,282 : INFO : built Dictionary(488 unique tokens: ['energy', 'fossil', 'review', 'benjamin', 'expert']...) from 5 documents (total 5230 corpus positions)\n",
      "2019-10-29 00:43:34,291 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:34,294 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:34,298 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:34,302 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:34,305 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:34,506 : INFO : -7.786 per-word bound, 220.7 perplexity estimate based on a held-out corpus of 5 documents with 5230 words\n",
      "2019-10-29 00:43:34,508 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:34,519 : INFO : topic #7 (0.100): 0.028*\"climate\" + 0.023*\"said\" + 0.023*\"health\" + 0.015*\"change\" + 0.013*\"related\" + 0.011*\"disease\" + 0.010*\"air\" + 0.010*\"wildfire\" + 0.010*\"sarfaty\" + 0.010*\"according\"\n",
      "2019-10-29 00:43:34,521 : INFO : topic #0 (0.100): 0.028*\"climate\" + 0.022*\"health\" + 0.022*\"change\" + 0.021*\"said\" + 0.014*\"sarfaty\" + 0.010*\"related\" + 0.010*\"disease\" + 0.010*\"according\" + 0.009*\"report\" + 0.008*\"air\"\n",
      "2019-10-29 00:43:34,524 : INFO : topic #2 (0.100): 0.038*\"climate\" + 0.028*\"health\" + 0.024*\"said\" + 0.018*\"change\" + 0.012*\"related\" + 0.011*\"sarfaty\" + 0.010*\"disease\" + 0.009*\"people\" + 0.009*\"according\" + 0.008*\"report\"\n",
      "2019-10-29 00:43:34,527 : INFO : topic #5 (0.100): 0.033*\"health\" + 0.026*\"climate\" + 0.023*\"change\" + 0.022*\"said\" + 0.015*\"sarfaty\" + 0.010*\"related\" + 0.010*\"report\" + 0.010*\"disease\" + 0.009*\"wildfire\" + 0.009*\"according\"\n",
      "2019-10-29 00:43:34,530 : INFO : topic #1 (0.100): 0.038*\"climate\" + 0.032*\"health\" + 0.026*\"said\" + 0.015*\"change\" + 0.014*\"sarfaty\" + 0.011*\"related\" + 0.011*\"report\" + 0.010*\"wildfire\" + 0.009*\"consortium\" + 0.008*\"video\"\n",
      "2019-10-29 00:43:34,532 : INFO : topic diff=1.016441, rho=1.000000\n",
      "2019-10-29 00:43:34,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:34,995 : INFO : built Dictionary(139 unique tokens: ['cellular', 'bone', 'end', 'party', 'prove']...) from 5 documents (total 1050 corpus positions)\n",
      "2019-10-29 00:43:35,000 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:35,002 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:35,005 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:35,009 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:35,011 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:35,083 : INFO : -7.061 per-word bound, 133.5 perplexity estimate based on a held-out corpus of 5 documents with 1050 words\n",
      "2019-10-29 00:43:35,085 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:35,092 : INFO : topic #8 (0.100): 0.050*\"kindle\" + 0.038*\"amazon\" + 0.032*\"oasis\" + 0.026*\"waterproof\" + 0.023*\"reader\" + 0.022*\"version\" + 0.018*\"device\" + 0.016*\"new\" + 0.015*\"bezos\" + 0.014*\"bag\"\n",
      "2019-10-29 00:43:35,095 : INFO : topic #9 (0.100): 0.062*\"kindle\" + 0.035*\"amazon\" + 0.035*\"oasis\" + 0.028*\"device\" + 0.023*\"e\" + 0.023*\"version\" + 0.020*\"waterproof\" + 0.018*\"reader\" + 0.016*\"new\" + 0.015*\"one\"\n",
      "2019-10-29 00:43:35,098 : INFO : topic #2 (0.100): 0.051*\"kindle\" + 0.042*\"amazon\" + 0.027*\"oasis\" + 0.024*\"new\" + 0.023*\"reader\" + 0.020*\"waterproof\" + 0.019*\"version\" + 0.017*\"bezos\" + 0.015*\"device\" + 0.015*\"e\"\n",
      "2019-10-29 00:43:35,101 : INFO : topic #0 (0.100): 0.042*\"amazon\" + 0.038*\"oasis\" + 0.036*\"kindle\" + 0.028*\"new\" + 0.026*\"waterproof\" + 0.022*\"reader\" + 0.020*\"device\" + 0.019*\"e\" + 0.018*\"version\" + 0.016*\"one\"\n",
      "2019-10-29 00:43:35,104 : INFO : topic #3 (0.100): 0.044*\"amazon\" + 0.039*\"oasis\" + 0.032*\"kindle\" + 0.022*\"waterproof\" + 0.022*\"new\" + 0.022*\"version\" + 0.020*\"device\" + 0.018*\"reader\" + 0.017*\"e\" + 0.015*\"ziploc\"\n",
      "2019-10-29 00:43:35,107 : INFO : topic diff=0.863880, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:35,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:35,545 : INFO : built Dictionary(312 unique tokens: ['maternal', 'duration', 'take', 'crest', 'may']...) from 5 documents (total 2710 corpus positions)\n",
      "2019-10-29 00:43:35,550 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:35,551 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:35,552 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:35,555 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:35,557 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:35,670 : INFO : -7.604 per-word bound, 194.5 perplexity estimate based on a held-out corpus of 5 documents with 2710 words\n",
      "2019-10-29 00:43:35,672 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:35,680 : INFO : topic #3 (0.100): 0.036*\"fever\" + 0.033*\"defect\" + 0.024*\"said\" + 0.018*\"ion\" + 0.018*\"pregnancy\" + 0.015*\"channel\" + 0.015*\"heart\" + 0.014*\"temperature\" + 0.014*\"birth\" + 0.014*\"benner\"\n",
      "2019-10-29 00:43:35,683 : INFO : topic #9 (0.100): 0.035*\"fever\" + 0.032*\"defect\" + 0.027*\"said\" + 0.018*\"pregnancy\" + 0.017*\"ion\" + 0.014*\"temperature\" + 0.014*\"channel\" + 0.013*\"birth\" + 0.012*\"imler\" + 0.012*\"cell\"\n",
      "2019-10-29 00:43:35,686 : INFO : topic #5 (0.100): 0.026*\"fever\" + 0.024*\"defect\" + 0.017*\"channel\" + 0.015*\"cell\" + 0.015*\"said\" + 0.015*\"ion\" + 0.015*\"birth\" + 0.014*\"heart\" + 0.014*\"pregnancy\" + 0.012*\"temperature\"\n",
      "2019-10-29 00:43:35,689 : INFO : topic #4 (0.100): 0.036*\"fever\" + 0.026*\"defect\" + 0.019*\"pregnancy\" + 0.018*\"said\" + 0.016*\"heart\" + 0.015*\"ion\" + 0.015*\"cell\" + 0.015*\"birth\" + 0.014*\"channel\" + 0.014*\"benner\"\n",
      "2019-10-29 00:43:35,693 : INFO : topic #7 (0.100): 0.032*\"fever\" + 0.026*\"defect\" + 0.022*\"channel\" + 0.019*\"birth\" + 0.018*\"temperature\" + 0.017*\"said\" + 0.017*\"ion\" + 0.014*\"pregnancy\" + 0.013*\"imler\" + 0.013*\"benner\"\n",
      "2019-10-29 00:43:35,696 : INFO : topic diff=0.924154, rho=1.000000\n",
      "2019-10-29 00:43:36,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:36,155 : INFO : built Dictionary(211 unique tokens: ['although', 'strain', 'francisco', 'focus', 'transport']...) from 5 documents (total 1700 corpus positions)\n",
      "2019-10-29 00:43:36,158 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:36,161 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:36,164 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:36,167 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:36,170 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:36,262 : INFO : -7.342 per-word bound, 162.2 perplexity estimate based on a held-out corpus of 5 documents with 1700 words\n",
      "2019-10-29 00:43:36,264 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:36,272 : INFO : topic #3 (0.100): 0.036*\"hailing\" + 0.029*\"ride\" + 0.025*\"transportation\" + 0.023*\"service\" + 0.022*\"people\" + 0.021*\"public\" + 0.020*\"city\" + 0.017*\"uber\" + 0.013*\"lyft\" + 0.013*\"car\"\n",
      "2019-10-29 00:43:36,275 : INFO : topic #4 (0.100): 0.036*\"hailing\" + 0.026*\"ride\" + 0.026*\"city\" + 0.023*\"transportation\" + 0.021*\"service\" + 0.019*\"uber\" + 0.019*\"lyft\" + 0.018*\"people\" + 0.014*\"car\" + 0.012*\"public\"\n",
      "2019-10-29 00:43:36,278 : INFO : topic #7 (0.100): 0.042*\"ride\" + 0.026*\"city\" + 0.025*\"transportation\" + 0.025*\"hailing\" + 0.021*\"people\" + 0.019*\"service\" + 0.018*\"uber\" + 0.017*\"public\" + 0.015*\"lyft\" + 0.015*\"car\"\n",
      "2019-10-29 00:43:36,281 : INFO : topic #8 (0.100): 0.044*\"ride\" + 0.029*\"city\" + 0.029*\"hailing\" + 0.021*\"service\" + 0.021*\"people\" + 0.020*\"transportation\" + 0.018*\"lyft\" + 0.015*\"public\" + 0.014*\"car\" + 0.013*\"study\"\n",
      "2019-10-29 00:43:36,284 : INFO : topic #6 (0.100): 0.036*\"ride\" + 0.031*\"city\" + 0.029*\"transportation\" + 0.027*\"hailing\" + 0.022*\"public\" + 0.020*\"lyft\" + 0.020*\"uber\" + 0.018*\"people\" + 0.017*\"service\" + 0.016*\"study\"\n",
      "2019-10-29 00:43:36,287 : INFO : topic diff=0.854398, rho=1.000000\n",
      "2019-10-29 00:43:36,753 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:36,756 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:43:36,757 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:36,758 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:36,760 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:36,761 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:36,763 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:36,782 : INFO : -6.038 per-word bound, 65.7 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:43:36,784 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:36,790 : INFO : topic #1 (0.100): 0.131*\"transcript\" + 0.091*\"page\" + 0.055*\"cannot\" + 0.054*\"updated\" + 0.054*\"become\" + 0.054*\"continually\" + 0.050*\"specific\" + 0.050*\"available\" + 0.048*\"later\" + 0.047*\"check\"\n",
      "2019-10-29 00:43:36,792 : INFO : topic #6 (0.100): 0.183*\"transcript\" + 0.090*\"page\" + 0.057*\"find\" + 0.052*\"main\" + 0.048*\"note\" + 0.048*\"available\" + 0.048*\"specific\" + 0.048*\"check\" + 0.045*\"become\" + 0.043*\"back\"\n",
      "2019-10-29 00:43:36,795 : INFO : topic #9 (0.100): 0.179*\"transcript\" + 0.083*\"page\" + 0.053*\"segment\" + 0.053*\"find\" + 0.052*\"later\" + 0.050*\"specific\" + 0.048*\"cnn\" + 0.047*\"note\" + 0.046*\"main\" + 0.045*\"back\"\n",
      "2019-10-29 00:43:36,798 : INFO : topic #3 (0.100): 0.126*\"transcript\" + 0.065*\"page\" + 0.057*\"available\" + 0.053*\"updated\" + 0.052*\"check\" + 0.051*\"note\" + 0.051*\"become\" + 0.050*\"back\" + 0.049*\"october\" + 0.048*\"new\"\n",
      "2019-10-29 00:43:36,800 : INFO : topic #8 (0.100): 0.171*\"transcript\" + 0.097*\"page\" + 0.049*\"return\" + 0.048*\"become\" + 0.048*\"october\" + 0.047*\"cnn\" + 0.047*\"later\" + 0.047*\"check\" + 0.046*\"continually\" + 0.046*\"available\"\n",
      "2019-10-29 00:43:36,802 : INFO : topic diff=0.699902, rho=1.000000\n",
      "2019-10-29 00:43:37,244 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:37,249 : INFO : built Dictionary(369 unique tokens: ['although', 'let', 'size', 'drinking', 'advantage']...) from 5 documents (total 2735 corpus positions)\n",
      "2019-10-29 00:43:37,255 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:37,256 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:37,258 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:37,261 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:37,263 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:37,402 : INFO : -7.996 per-word bound, 255.2 perplexity estimate based on a held-out corpus of 5 documents with 2735 words\n",
      "2019-10-29 00:43:37,403 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:37,412 : INFO : topic #9 (0.100): 0.026*\"boomer\" + 0.024*\"generation\" + 0.020*\"people\" + 0.012*\"government\" + 0.011*\"problem\" + 0.010*\"care\" + 0.010*\"debt\" + 0.009*\"long\" + 0.009*\"past\" + 0.008*\"baby\"\n",
      "2019-10-29 00:43:37,414 : INFO : topic #4 (0.100): 0.035*\"boomer\" + 0.020*\"generation\" + 0.014*\"people\" + 0.009*\"care\" + 0.009*\"baby\" + 0.009*\"government\" + 0.008*\"problem\" + 0.008*\"long\" + 0.008*\"health\" + 0.007*\"company\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:37,418 : INFO : topic #8 (0.100): 0.041*\"boomer\" + 0.019*\"generation\" + 0.015*\"government\" + 0.013*\"care\" + 0.012*\"created\" + 0.011*\"people\" + 0.011*\"problem\" + 0.011*\"long\" + 0.010*\"baby\" + 0.009*\"debt\"\n",
      "2019-10-29 00:43:37,421 : INFO : topic #0 (0.100): 0.028*\"boomer\" + 0.026*\"generation\" + 0.012*\"people\" + 0.011*\"government\" + 0.011*\"long\" + 0.011*\"care\" + 0.010*\"problem\" + 0.009*\"debt\" + 0.009*\"plan\" + 0.008*\"health\"\n",
      "2019-10-29 00:43:37,424 : INFO : topic #2 (0.100): 0.033*\"boomer\" + 0.028*\"generation\" + 0.015*\"people\" + 0.011*\"government\" + 0.011*\"problem\" + 0.010*\"baby\" + 0.010*\"long\" + 0.009*\"company\" + 0.009*\"debt\" + 0.008*\"created\"\n",
      "2019-10-29 00:43:37,427 : INFO : topic diff=0.825224, rho=1.000000\n",
      "2019-10-29 00:43:37,827 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:37,830 : INFO : built Dictionary(167 unique tokens: ['bombshell', 'forward', 'story', 'shared', 'weinstein']...) from 5 documents (total 1405 corpus positions)\n",
      "2019-10-29 00:43:37,833 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:37,834 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:37,835 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:37,837 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:37,839 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:37,919 : INFO : -7.065 per-word bound, 133.9 perplexity estimate based on a held-out corpus of 5 documents with 1405 words\n",
      "2019-10-29 00:43:37,920 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:37,926 : INFO : topic #3 (0.100): 0.056*\"weinstein\" + 0.045*\"paltrow\" + 0.037*\"time\" + 0.028*\"jolie\" + 0.025*\"said\" + 0.024*\"told\" + 0.024*\"woman\" + 0.018*\"new\" + 0.017*\"cnn\" + 0.015*\"allegation\"\n",
      "2019-10-29 00:43:37,928 : INFO : topic #8 (0.100): 0.053*\"weinstein\" + 0.034*\"paltrow\" + 0.031*\"time\" + 0.027*\"told\" + 0.024*\"jolie\" + 0.022*\"cnn\" + 0.020*\"woman\" + 0.020*\"said\" + 0.015*\"new\" + 0.015*\"pitt\"\n",
      "2019-10-29 00:43:37,931 : INFO : topic #9 (0.100): 0.045*\"weinstein\" + 0.027*\"time\" + 0.026*\"paltrow\" + 0.025*\"woman\" + 0.024*\"jolie\" + 0.024*\"told\" + 0.023*\"cnn\" + 0.017*\"new\" + 0.017*\"york\" + 0.015*\"said\"\n",
      "2019-10-29 00:43:37,933 : INFO : topic #2 (0.100): 0.046*\"weinstein\" + 0.044*\"paltrow\" + 0.029*\"time\" + 0.022*\"woman\" + 0.022*\"told\" + 0.021*\"cnn\" + 0.018*\"allegation\" + 0.017*\"new\" + 0.015*\"jolie\" + 0.014*\"pitt\"\n",
      "2019-10-29 00:43:37,937 : INFO : topic #6 (0.100): 0.055*\"weinstein\" + 0.042*\"paltrow\" + 0.037*\"time\" + 0.028*\"told\" + 0.026*\"woman\" + 0.023*\"jolie\" + 0.018*\"cnn\" + 0.015*\"new\" + 0.014*\"said\" + 0.014*\"york\"\n",
      "2019-10-29 00:43:37,939 : INFO : topic diff=0.899616, rho=1.000000\n",
      "2019-10-29 00:43:38,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:38,392 : INFO : built Dictionary(163 unique tokens: ['amid', 'perhaps', 'person', 'zf', 'industry']...) from 5 documents (total 1370 corpus positions)\n",
      "2019-10-29 00:43:38,395 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:38,397 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:38,398 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:38,403 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:38,406 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:38,500 : INFO : -7.046 per-word bound, 132.2 perplexity estimate based on a held-out corpus of 5 documents with 1370 words\n",
      "2019-10-29 00:43:38,502 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:38,510 : INFO : topic #2 (0.100): 0.061*\"delivery\" + 0.043*\"self\" + 0.039*\"driving\" + 0.028*\"dhl\" + 0.027*\"technology\" + 0.026*\"truck\" + 0.020*\"company\" + 0.019*\"person\" + 0.015*\"ride\" + 0.014*\"autonomous\"\n",
      "2019-10-29 00:43:38,513 : INFO : topic #9 (0.100): 0.055*\"delivery\" + 0.040*\"driving\" + 0.033*\"truck\" + 0.032*\"self\" + 0.023*\"vehicle\" + 0.022*\"dhl\" + 0.019*\"person\" + 0.017*\"deutsche\" + 0.016*\"post\" + 0.015*\"company\"\n",
      "2019-10-29 00:43:38,516 : INFO : topic #7 (0.100): 0.043*\"delivery\" + 0.041*\"driving\" + 0.033*\"self\" + 0.032*\"dhl\" + 0.027*\"truck\" + 0.017*\"vehicle\" + 0.017*\"company\" + 0.017*\"technology\" + 0.016*\"person\" + 0.014*\"autonomous\"\n",
      "2019-10-29 00:43:38,519 : INFO : topic #6 (0.100): 0.059*\"delivery\" + 0.039*\"driving\" + 0.034*\"self\" + 0.026*\"truck\" + 0.023*\"vehicle\" + 0.022*\"technology\" + 0.022*\"dhl\" + 0.017*\"person\" + 0.017*\"follow\" + 0.017*\"company\"\n",
      "2019-10-29 00:43:38,522 : INFO : topic #8 (0.100): 0.054*\"delivery\" + 0.036*\"self\" + 0.036*\"driving\" + 0.032*\"dhl\" + 0.027*\"technology\" + 0.027*\"truck\" + 0.024*\"vehicle\" + 0.021*\"person\" + 0.020*\"company\" + 0.018*\"said\"\n",
      "2019-10-29 00:43:38,525 : INFO : topic diff=0.946892, rho=1.000000\n",
      "2019-10-29 00:43:38,972 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:38,976 : INFO : built Dictionary(132 unique tokens: ['forward', 'school', 'wave', 'refugee', 'come']...) from 5 documents (total 925 corpus positions)\n",
      "2019-10-29 00:43:38,984 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:38,987 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:38,995 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:38,998 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:39,001 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:39,100 : INFO : -7.133 per-word bound, 140.4 perplexity estimate based on a held-out corpus of 5 documents with 925 words\n",
      "2019-10-29 00:43:39,107 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:39,115 : INFO : topic #4 (0.100): 0.044*\"petty\" + 0.036*\"rock\" + 0.025*\"music\" + 0.024*\"tom\" + 0.016*\"band\" + 0.015*\"string\" + 0.015*\"album\" + 0.013*\"way\" + 0.013*\"beatles\" + 0.012*\"roll\"\n",
      "2019-10-29 00:43:39,120 : INFO : topic #5 (0.100): 0.038*\"petty\" + 0.031*\"rock\" + 0.028*\"tom\" + 0.027*\"music\" + 0.019*\"band\" + 0.016*\"string\" + 0.015*\"album\" + 0.015*\"beatles\" + 0.014*\"torpedo\" + 0.013*\"thought\"\n",
      "2019-10-29 00:43:39,122 : INFO : topic #7 (0.100): 0.045*\"petty\" + 0.033*\"rock\" + 0.027*\"tom\" + 0.020*\"music\" + 0.017*\"album\" + 0.015*\"string\" + 0.015*\"beatles\" + 0.013*\"band\" + 0.012*\"new\" + 0.012*\"guitar\"\n",
      "2019-10-29 00:43:39,125 : INFO : topic #0 (0.100): 0.046*\"rock\" + 0.043*\"petty\" + 0.024*\"tom\" + 0.019*\"music\" + 0.016*\"beatles\" + 0.016*\"string\" + 0.015*\"band\" + 0.014*\"album\" + 0.012*\"way\" + 0.012*\"guitar\"\n",
      "2019-10-29 00:43:39,128 : INFO : topic #2 (0.100): 0.036*\"petty\" + 0.032*\"rock\" + 0.030*\"music\" + 0.025*\"tom\" + 0.015*\"string\" + 0.014*\"beatles\" + 0.013*\"album\" + 0.013*\"new\" + 0.013*\"author\" + 0.012*\"wave\"\n",
      "2019-10-29 00:43:39,130 : INFO : topic diff=0.757852, rho=1.000000\n",
      "2019-10-29 00:43:39,599 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:39,603 : INFO : built Dictionary(299 unique tokens: ['although', 'concern', 'prime', 'aspiration', 'deep']...) from 5 documents (total 2420 corpus positions)\n",
      "2019-10-29 00:43:39,606 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:39,607 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:39,609 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:39,613 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:39,614 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:39,714 : INFO : -7.664 per-word bound, 202.9 perplexity estimate based on a held-out corpus of 5 documents with 2420 words\n",
      "2019-10-29 00:43:39,715 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:39,722 : INFO : topic #1 (0.100): 0.042*\"israel\" + 0.026*\"state\" + 0.024*\"support\" + 0.022*\"kurdish\" + 0.020*\"kurd\" + 0.014*\"iraqi\" + 0.013*\"iraq\" + 0.013*\"kurdistan\" + 0.012*\"independence\" + 0.011*\"referendum\"\n",
      "2019-10-29 00:43:39,724 : INFO : topic #2 (0.100): 0.046*\"israel\" + 0.030*\"support\" + 0.024*\"kurd\" + 0.018*\"kurdish\" + 0.017*\"iraq\" + 0.014*\"state\" + 0.013*\"iraqi\" + 0.013*\"kurdistan\" + 0.011*\"referendum\" + 0.011*\"independence\"\n",
      "2019-10-29 00:43:39,727 : INFO : topic #3 (0.100): 0.048*\"israel\" + 0.023*\"support\" + 0.021*\"state\" + 0.020*\"iraq\" + 0.018*\"kurdish\" + 0.017*\"referendum\" + 0.016*\"kurd\" + 0.012*\"independence\" + 0.011*\"iraqi\" + 0.011*\"israeli\"\n",
      "2019-10-29 00:43:39,729 : INFO : topic #4 (0.100): 0.048*\"israel\" + 0.026*\"kurd\" + 0.022*\"support\" + 0.022*\"state\" + 0.018*\"iraq\" + 0.016*\"kurdish\" + 0.013*\"kurdistan\" + 0.013*\"iraqi\" + 0.012*\"referendum\" + 0.010*\"independent\"\n",
      "2019-10-29 00:43:39,732 : INFO : topic #5 (0.100): 0.050*\"israel\" + 0.029*\"kurd\" + 0.022*\"support\" + 0.021*\"state\" + 0.017*\"kurdish\" + 0.016*\"iraq\" + 0.014*\"referendum\" + 0.014*\"independence\" + 0.013*\"kurdistan\" + 0.012*\"iraqi\"\n",
      "2019-10-29 00:43:39,734 : INFO : topic diff=0.905898, rho=1.000000\n",
      "2019-10-29 00:43:40,183 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:40,186 : INFO : built Dictionary(91 unique tokens: ['military', 'watch', 'remained', 'retaken', 'troop']...) from 5 documents (total 660 corpus positions)\n",
      "2019-10-29 00:43:40,188 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:40,190 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:40,192 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:40,194 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:40,196 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:40,258 : INFO : -6.758 per-word bound, 108.3 perplexity estimate based on a held-out corpus of 5 documents with 660 words\n",
      "2019-10-29 00:43:40,260 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:40,272 : INFO : topic #4 (0.100): 0.037*\"last\" + 0.035*\"isi\" + 0.031*\"militant\" + 0.026*\"hakim\" + 0.025*\"among\" + 0.022*\"kurd\" + 0.021*\"said\" + 0.021*\"troop\" + 0.021*\"iraqi\" + 0.020*\"u\"\n",
      "2019-10-29 00:43:40,275 : INFO : topic #3 (0.100): 0.029*\"militant\" + 0.028*\"iraqi\" + 0.027*\"hakim\" + 0.026*\"said\" + 0.025*\"last\" + 0.025*\"troop\" + 0.023*\"isi\" + 0.020*\"family\" + 0.019*\"u\" + 0.019*\"among\"\n",
      "2019-10-29 00:43:40,278 : INFO : topic #7 (0.100): 0.031*\"last\" + 0.031*\"isi\" + 0.025*\"militant\" + 0.024*\"hawija\" + 0.023*\"u\" + 0.022*\"hakim\" + 0.020*\"suspect\" + 0.019*\"iraqi\" + 0.019*\"kurd\" + 0.018*\"troop\"\n",
      "2019-10-29 00:43:40,281 : INFO : topic #9 (0.100): 0.031*\"militant\" + 0.027*\"isi\" + 0.027*\"said\" + 0.026*\"last\" + 0.024*\"hakim\" + 0.024*\"u\" + 0.023*\"kurd\" + 0.022*\"troop\" + 0.020*\"iraqi\" + 0.019*\"hawija\"\n",
      "2019-10-29 00:43:40,288 : INFO : topic #0 (0.100): 0.035*\"isi\" + 0.033*\"last\" + 0.027*\"among\" + 0.025*\"militant\" + 0.023*\"u\" + 0.021*\"said\" + 0.019*\"suspect\" + 0.019*\"kurd\" + 0.019*\"civilian\" + 0.019*\"iraqi\"\n",
      "2019-10-29 00:43:40,297 : INFO : topic diff=0.763114, rho=1.000000\n",
      "2019-10-29 00:43:40,712 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:40,714 : INFO : built Dictionary(75 unique tokens: ['story', 'worker', 'notice', 'business', 'evacuate']...) from 5 documents (total 580 corpus positions)\n",
      "2019-10-29 00:43:40,715 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:40,717 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:40,718 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:40,721 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:40,722 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:40,758 : INFO : -6.485 per-word bound, 89.6 perplexity estimate based on a held-out corpus of 5 documents with 580 words\n",
      "2019-10-29 00:43:40,759 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:40,767 : INFO : topic #1 (0.100): 0.038*\"irma\" + 0.036*\"home\" + 0.034*\"state\" + 0.030*\"nursing\" + 0.023*\"closed\" + 0.023*\"letter\" + 0.022*\"center\" + 0.021*\"patient\" + 0.021*\"notice\" + 0.021*\"died\"\n",
      "2019-10-29 00:43:40,772 : INFO : topic #0 (0.100): 0.039*\"nursing\" + 0.036*\"irma\" + 0.034*\"home\" + 0.032*\"state\" + 0.029*\"day\" + 0.027*\"letter\" + 0.027*\"died\" + 0.026*\"official\" + 0.024*\"closed\" + 0.021*\"plea\"\n",
      "2019-10-29 00:43:40,775 : INFO : topic #2 (0.100): 0.050*\"irma\" + 0.035*\"nursing\" + 0.033*\"home\" + 0.028*\"letter\" + 0.027*\"died\" + 0.024*\"day\" + 0.022*\"state\" + 0.022*\"closed\" + 0.021*\"patient\" + 0.020*\"said\"\n",
      "2019-10-29 00:43:40,777 : INFO : topic #9 (0.100): 0.038*\"irma\" + 0.038*\"home\" + 0.030*\"nursing\" + 0.028*\"day\" + 0.027*\"closed\" + 0.023*\"official\" + 0.021*\"died\" + 0.020*\"letter\" + 0.019*\"according\" + 0.019*\"said\"\n",
      "2019-10-29 00:43:40,779 : INFO : topic #6 (0.100): 0.041*\"irma\" + 0.035*\"nursing\" + 0.033*\"official\" + 0.030*\"closed\" + 0.024*\"day\" + 0.024*\"state\" + 0.024*\"home\" + 0.023*\"died\" + 0.023*\"letter\" + 0.021*\"said\"\n",
      "2019-10-29 00:43:40,781 : INFO : topic diff=0.732804, rho=1.000000\n",
      "2019-10-29 00:43:41,223 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:41,228 : INFO : built Dictionary(356 unique tokens: ['energy', 'portion', 'tasty', 'fiber', 'drive']...) from 5 documents (total 3550 corpus positions)\n",
      "2019-10-29 00:43:41,233 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:41,235 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:41,236 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:41,240 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:41,241 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:41,353 : INFO : -7.562 per-word bound, 189.0 perplexity estimate based on a held-out corpus of 5 documents with 3550 words\n",
      "2019-10-29 00:43:41,354 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:41,363 : INFO : topic #1 (0.100): 0.029*\"salad\" + 0.019*\"pick\" + 0.014*\"panera\" + 0.013*\"menu\" + 0.013*\"gluten\" + 0.013*\"low\" + 0.013*\"half\" + 0.013*\"protein\" + 0.013*\"sodium\" + 0.012*\"meal\"\n",
      "2019-10-29 00:43:41,365 : INFO : topic #8 (0.100): 0.025*\"salad\" + 0.017*\"pick\" + 0.014*\"half\" + 0.014*\"sodium\" + 0.013*\"menu\" + 0.013*\"panera\" + 0.013*\"meal\" + 0.013*\"low\" + 0.012*\"fat\" + 0.010*\"kid\"\n",
      "2019-10-29 00:43:41,368 : INFO : topic #6 (0.100): 0.024*\"salad\" + 0.023*\"pick\" + 0.015*\"low\" + 0.014*\"panera\" + 0.014*\"menu\" + 0.013*\"sodium\" + 0.013*\"protein\" + 0.012*\"fat\" + 0.012*\"meal\" + 0.012*\"kid\"\n",
      "2019-10-29 00:43:41,370 : INFO : topic #0 (0.100): 0.025*\"salad\" + 0.016*\"pick\" + 0.015*\"panera\" + 0.014*\"meal\" + 0.013*\"menu\" + 0.012*\"fat\" + 0.012*\"protein\" + 0.012*\"apple\" + 0.011*\"half\" + 0.011*\"gluten\"\n",
      "2019-10-29 00:43:41,373 : INFO : topic #9 (0.100): 0.029*\"salad\" + 0.017*\"half\" + 0.016*\"meal\" + 0.014*\"protein\" + 0.014*\"pick\" + 0.013*\"kid\" + 0.012*\"menu\" + 0.012*\"sandwich\" + 0.011*\"panera\" + 0.011*\"sodium\"\n",
      "2019-10-29 00:43:41,375 : INFO : topic diff=0.940262, rho=1.000000\n",
      "2019-10-29 00:43:41,789 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:41,792 : INFO : built Dictionary(159 unique tokens: ['reply', 'violence', 'school', 'security', 'refugee']...) from 5 documents (total 1160 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:41,794 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:41,796 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:41,797 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:41,799 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:41,800 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:41,866 : INFO : -7.234 per-word bound, 150.5 perplexity estimate based on a held-out corpus of 5 documents with 1160 words\n",
      "2019-10-29 00:43:41,867 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:41,874 : INFO : topic #6 (0.100): 0.032*\"security\" + 0.029*\"right\" + 0.026*\"human\" + 0.020*\"boy\" + 0.020*\"violation\" + 0.018*\"united\" + 0.017*\"nation\" + 0.016*\"nikki\" + 0.015*\"conflict\" + 0.013*\"war\"\n",
      "2019-10-29 00:43:41,878 : INFO : topic #5 (0.100): 0.029*\"security\" + 0.026*\"right\" + 0.026*\"human\" + 0.022*\"haley\" + 0.020*\"violation\" + 0.019*\"boy\" + 0.019*\"nation\" + 0.018*\"war\" + 0.014*\"nikki\" + 0.012*\"one\"\n",
      "2019-10-29 00:43:41,881 : INFO : topic #7 (0.100): 0.029*\"human\" + 0.025*\"right\" + 0.022*\"nikki\" + 0.022*\"war\" + 0.021*\"united\" + 0.019*\"violation\" + 0.019*\"security\" + 0.018*\"boy\" + 0.018*\"nation\" + 0.017*\"haley\"\n",
      "2019-10-29 00:43:41,883 : INFO : topic #8 (0.100): 0.027*\"security\" + 0.025*\"human\" + 0.023*\"united\" + 0.022*\"right\" + 0.019*\"nation\" + 0.018*\"violation\" + 0.018*\"boy\" + 0.017*\"nikki\" + 0.016*\"war\" + 0.014*\"parent\"\n",
      "2019-10-29 00:43:41,885 : INFO : topic #1 (0.100): 0.036*\"security\" + 0.032*\"right\" + 0.031*\"human\" + 0.018*\"nation\" + 0.017*\"violation\" + 0.017*\"boy\" + 0.017*\"haley\" + 0.017*\"united\" + 0.015*\"parent\" + 0.013*\"nikki\"\n",
      "2019-10-29 00:43:41,890 : INFO : topic diff=0.796433, rho=1.000000\n",
      "2019-10-29 00:43:42,300 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:42,303 : INFO : built Dictionary(210 unique tokens: ['trying', 'aspiration', 'nation', 'come', 'regime']...) from 5 documents (total 1445 corpus positions)\n",
      "2019-10-29 00:43:42,306 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:42,308 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:42,309 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:42,313 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:42,315 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:42,406 : INFO : -7.589 per-word bound, 192.5 perplexity estimate based on a held-out corpus of 5 documents with 1445 words\n",
      "2019-10-29 00:43:42,408 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:42,416 : INFO : topic #4 (0.100): 0.024*\"policy\" + 0.024*\"vietnam\" + 0.019*\"u\" + 0.018*\"afghanistan\" + 0.014*\"korea\" + 0.013*\"disaster\" + 0.013*\"often\" + 0.013*\"scheme\" + 0.011*\"act\" + 0.011*\"north\"\n",
      "2019-10-29 00:43:42,419 : INFO : topic #3 (0.100): 0.019*\"u\" + 0.018*\"policy\" + 0.018*\"disaster\" + 0.016*\"vietnam\" + 0.016*\"afghanistan\" + 0.014*\"korea\" + 0.013*\"scheme\" + 0.012*\"north\" + 0.012*\"foreign\" + 0.012*\"assumption\"\n",
      "2019-10-29 00:43:42,422 : INFO : topic #5 (0.100): 0.022*\"u\" + 0.016*\"act\" + 0.016*\"foreign\" + 0.015*\"often\" + 0.015*\"policy\" + 0.015*\"vietnam\" + 0.015*\"north\" + 0.013*\"disaster\" + 0.013*\"iraq\" + 0.013*\"afghanistan\"\n",
      "2019-10-29 00:43:42,425 : INFO : topic #8 (0.100): 0.034*\"policy\" + 0.020*\"foreign\" + 0.018*\"vietnam\" + 0.017*\"u\" + 0.013*\"scheme\" + 0.013*\"korea\" + 0.012*\"disaster\" + 0.012*\"act\" + 0.012*\"north\" + 0.011*\"afghanistan\"\n",
      "2019-10-29 00:43:42,427 : INFO : topic #2 (0.100): 0.023*\"u\" + 0.023*\"vietnam\" + 0.017*\"policy\" + 0.015*\"act\" + 0.015*\"foreign\" + 0.014*\"north\" + 0.013*\"disaster\" + 0.011*\"korea\" + 0.011*\"scheme\" + 0.011*\"often\"\n",
      "2019-10-29 00:43:42,430 : INFO : topic diff=0.780013, rho=1.000000\n",
      "2019-10-29 00:43:42,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:42,893 : INFO : built Dictionary(376 unique tokens: ['although', 'pediatrician', 'energy', 'restricting', 'revealed']...) from 5 documents (total 3580 corpus positions)\n",
      "2019-10-29 00:43:42,898 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:42,899 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:42,900 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:42,904 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:42,907 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:43,020 : INFO : -7.669 per-word bound, 203.5 perplexity estimate based on a held-out corpus of 5 documents with 3580 words\n",
      "2019-10-29 00:43:43,021 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:43,029 : INFO : topic #1 (0.100): 0.026*\"said\" + 0.026*\"child\" + 0.022*\"obesity\" + 0.018*\"country\" + 0.013*\"underweight\" + 0.012*\"obese\" + 0.012*\"health\" + 0.011*\"problem\" + 0.010*\"adolescent\" + 0.009*\"hu\"\n",
      "2019-10-29 00:43:43,030 : INFO : topic #5 (0.100): 0.028*\"obesity\" + 0.027*\"child\" + 0.018*\"said\" + 0.018*\"country\" + 0.014*\"obese\" + 0.012*\"health\" + 0.011*\"underweight\" + 0.011*\"hu\" + 0.010*\"adolescent\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:43:43,031 : INFO : topic #8 (0.100): 0.021*\"child\" + 0.019*\"said\" + 0.018*\"obesity\" + 0.017*\"country\" + 0.015*\"adolescent\" + 0.013*\"underweight\" + 0.012*\"obese\" + 0.009*\"hu\" + 0.008*\"ezzati\" + 0.008*\"food\"\n",
      "2019-10-29 00:43:43,032 : INFO : topic #3 (0.100): 0.027*\"said\" + 0.021*\"obesity\" + 0.020*\"child\" + 0.016*\"adolescent\" + 0.014*\"country\" + 0.013*\"obese\" + 0.013*\"underweight\" + 0.010*\"hu\" + 0.010*\"health\" + 0.009*\"ezzati\"\n",
      "2019-10-29 00:43:43,034 : INFO : topic #9 (0.100): 0.033*\"child\" + 0.024*\"said\" + 0.023*\"obesity\" + 0.014*\"country\" + 0.014*\"obese\" + 0.013*\"adolescent\" + 0.012*\"hu\" + 0.012*\"underweight\" + 0.011*\"health\" + 0.009*\"million\"\n",
      "2019-10-29 00:43:43,036 : INFO : topic diff=0.917019, rho=1.000000\n",
      "2019-10-29 00:43:43,456 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:43,460 : INFO : built Dictionary(286 unique tokens: ['blocked', 'juyun', 'energy', 'watch', 'oligomer']...) from 5 documents (total 2480 corpus positions)\n",
      "2019-10-29 00:43:43,463 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:43,465 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:43,466 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:43,470 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:43,471 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:43,571 : INFO : -7.527 per-word bound, 184.4 perplexity estimate based on a held-out corpus of 5 documents with 2480 words\n",
      "2019-10-29 00:43:43,573 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:43,580 : INFO : topic #9 (0.100): 0.054*\"taste\" + 0.026*\"study\" + 0.019*\"said\" + 0.014*\"sixth\" + 0.014*\"glucose\" + 0.013*\"sweet\" + 0.012*\"human\" + 0.012*\"participant\" + 0.010*\"fatty\" + 0.010*\"lim\"\n",
      "2019-10-29 00:43:43,583 : INFO : topic #8 (0.100): 0.067*\"taste\" + 0.021*\"study\" + 0.021*\"said\" + 0.015*\"glucose\" + 0.014*\"sweet\" + 0.012*\"sixth\" + 0.012*\"chemical\" + 0.012*\"participant\" + 0.011*\"human\" + 0.010*\"five\"\n",
      "2019-10-29 00:43:43,585 : INFO : topic #1 (0.100): 0.061*\"taste\" + 0.027*\"study\" + 0.020*\"said\" + 0.016*\"glucose\" + 0.014*\"sixth\" + 0.012*\"five\" + 0.011*\"fatty\" + 0.011*\"starch\" + 0.010*\"chemical\" + 0.010*\"human\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:43,588 : INFO : topic #0 (0.100): 0.063*\"taste\" + 0.027*\"study\" + 0.017*\"glucose\" + 0.016*\"sweet\" + 0.015*\"said\" + 0.012*\"participant\" + 0.012*\"human\" + 0.012*\"sixth\" + 0.012*\"detect\" + 0.010*\"starch\"\n",
      "2019-10-29 00:43:43,590 : INFO : topic #4 (0.100): 0.062*\"taste\" + 0.021*\"said\" + 0.021*\"study\" + 0.016*\"sweet\" + 0.013*\"sixth\" + 0.012*\"glucose\" + 0.012*\"participant\" + 0.011*\"five\" + 0.010*\"detect\" + 0.010*\"fatty\"\n",
      "2019-10-29 00:43:43,593 : INFO : topic diff=0.892214, rho=1.000000\n",
      "2019-10-29 00:43:44,019 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:44,024 : INFO : built Dictionary(293 unique tokens: ['anniversary', 'school', 'watch', 'nation', 'come']...) from 5 documents (total 2630 corpus positions)\n",
      "2019-10-29 00:43:44,027 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:44,030 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:44,034 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:44,039 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:44,042 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:44,174 : INFO : -7.506 per-word bound, 181.7 perplexity estimate based on a held-out corpus of 5 documents with 2630 words\n",
      "2019-10-29 00:43:44,177 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:44,184 : INFO : topic #7 (0.100): 0.035*\"kim\" + 0.034*\"jong\" + 0.029*\"un\" + 0.025*\"party\" + 0.019*\"north\" + 0.018*\"nuclear\" + 0.015*\"worker\" + 0.014*\"u\" + 0.014*\"yo\" + 0.014*\"korean\"\n",
      "2019-10-29 00:43:44,187 : INFO : topic #5 (0.100): 0.052*\"kim\" + 0.027*\"jong\" + 0.024*\"north\" + 0.023*\"party\" + 0.022*\"un\" + 0.016*\"nuclear\" + 0.015*\"korean\" + 0.015*\"korea\" + 0.014*\"country\" + 0.013*\"yo\"\n",
      "2019-10-29 00:43:44,190 : INFO : topic #6 (0.100): 0.035*\"kim\" + 0.031*\"jong\" + 0.022*\"north\" + 0.022*\"un\" + 0.020*\"party\" + 0.015*\"yo\" + 0.015*\"korean\" + 0.015*\"worker\" + 0.015*\"nuclear\" + 0.014*\"member\"\n",
      "2019-10-29 00:43:44,192 : INFO : topic #9 (0.100): 0.057*\"kim\" + 0.039*\"jong\" + 0.024*\"north\" + 0.021*\"un\" + 0.016*\"party\" + 0.016*\"korea\" + 0.014*\"korean\" + 0.012*\"nuclear\" + 0.012*\"sister\" + 0.012*\"u\"\n",
      "2019-10-29 00:43:44,195 : INFO : topic #1 (0.100): 0.048*\"kim\" + 0.039*\"jong\" + 0.022*\"north\" + 0.019*\"party\" + 0.019*\"un\" + 0.016*\"nuclear\" + 0.015*\"u\" + 0.013*\"country\" + 0.013*\"korea\" + 0.013*\"yo\"\n",
      "2019-10-29 00:43:44,198 : INFO : topic diff=0.927499, rho=1.000000\n",
      "2019-10-29 00:43:44,610 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:44,614 : INFO : built Dictionary(324 unique tokens: ['rage', 'offered', 'proceeding', 'averaged', 'de']...) from 5 documents (total 2610 corpus positions)\n",
      "2019-10-29 00:43:44,619 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:44,620 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:44,621 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:44,625 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:44,626 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:44,735 : INFO : -7.743 per-word bound, 214.2 perplexity estimate based on a held-out corpus of 5 documents with 2610 words\n",
      "2019-10-29 00:43:44,737 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:44,744 : INFO : topic #4 (0.100): 0.023*\"said\" + 0.020*\"paddock\" + 0.013*\"time\" + 0.010*\"asked\" + 0.010*\"night\" + 0.010*\"prescribed\" + 0.010*\"la\" + 0.010*\"vega\" + 0.009*\"deposition\" + 0.009*\"room\"\n",
      "2019-10-29 00:43:44,745 : INFO : topic #0 (0.100): 0.026*\"paddock\" + 0.024*\"said\" + 0.017*\"night\" + 0.016*\"time\" + 0.013*\"asked\" + 0.011*\"much\" + 0.009*\"cosmopolitan\" + 0.008*\"vega\" + 0.008*\"room\" + 0.007*\"would\"\n",
      "2019-10-29 00:43:44,747 : INFO : topic #1 (0.100): 0.028*\"said\" + 0.027*\"paddock\" + 0.013*\"night\" + 0.011*\"time\" + 0.011*\"vega\" + 0.010*\"much\" + 0.010*\"la\" + 0.009*\"prescribed\" + 0.009*\"asked\" + 0.009*\"room\"\n",
      "2019-10-29 00:43:44,750 : INFO : topic #5 (0.100): 0.032*\"paddock\" + 0.019*\"said\" + 0.013*\"night\" + 0.013*\"vega\" + 0.013*\"asked\" + 0.010*\"prescribed\" + 0.009*\"time\" + 0.008*\"la\" + 0.008*\"much\" + 0.008*\"one\"\n",
      "2019-10-29 00:43:44,752 : INFO : topic #3 (0.100): 0.025*\"said\" + 0.024*\"paddock\" + 0.012*\"time\" + 0.010*\"asked\" + 0.010*\"night\" + 0.010*\"prescribed\" + 0.010*\"vega\" + 0.009*\"la\" + 0.008*\"room\" + 0.008*\"cosmopolitan\"\n",
      "2019-10-29 00:43:44,753 : INFO : topic diff=0.834958, rho=1.000000\n",
      "2019-10-29 00:43:45,219 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:45,224 : INFO : built Dictionary(156 unique tokens: ['offered', 'sunk', 'diaz', 'saved', 'come']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:43:45,226 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:45,228 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:45,230 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:45,233 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:45,234 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:45,293 : INFO : -7.253 per-word bound, 152.6 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:43:45,295 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:45,303 : INFO : topic #8 (0.100): 0.041*\"said\" + 0.024*\"sound\" + 0.023*\"kayak\" + 0.020*\"diaz\" + 0.020*\"long\" + 0.018*\"hour\" + 0.015*\"lloyd\" + 0.014*\"saved\" + 0.014*\"life\" + 0.014*\"norwalk\"\n",
      "2019-10-29 00:43:45,305 : INFO : topic #0 (0.100): 0.027*\"sound\" + 0.026*\"said\" + 0.021*\"long\" + 0.020*\"diaz\" + 0.017*\"kayak\" + 0.017*\"hour\" + 0.016*\"harbor\" + 0.015*\"island\" + 0.015*\"spent\" + 0.013*\"lighthouse\"\n",
      "2019-10-29 00:43:45,308 : INFO : topic #1 (0.100): 0.033*\"said\" + 0.025*\"diaz\" + 0.023*\"kayak\" + 0.019*\"sound\" + 0.018*\"long\" + 0.015*\"hour\" + 0.015*\"saved\" + 0.015*\"spent\" + 0.014*\"night\" + 0.014*\"back\"\n",
      "2019-10-29 00:43:45,310 : INFO : topic #4 (0.100): 0.024*\"said\" + 0.023*\"diaz\" + 0.022*\"long\" + 0.022*\"kayak\" + 0.018*\"sound\" + 0.017*\"son\" + 0.016*\"hour\" + 0.014*\"spotted\" + 0.014*\"lighthouse\" + 0.013*\"night\"\n",
      "2019-10-29 00:43:45,312 : INFO : topic #3 (0.100): 0.040*\"said\" + 0.020*\"sound\" + 0.019*\"long\" + 0.017*\"diaz\" + 0.016*\"kayak\" + 0.016*\"sank\" + 0.015*\"spotted\" + 0.014*\"hour\" + 0.013*\"back\" + 0.013*\"harbor\"\n",
      "2019-10-29 00:43:45,314 : INFO : topic diff=0.814927, rho=1.000000\n",
      "2019-10-29 00:43:45,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:45,792 : INFO : built Dictionary(558 unique tokens: ['midfielder', 'tightly', 'real', 'antoine', 'past']...) from 5 documents (total 6320 corpus positions)\n",
      "2019-10-29 00:43:45,802 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:45,808 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:45,811 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:45,816 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:45,818 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:46,031 : INFO : -7.857 per-word bound, 231.9 perplexity estimate based on a held-out corpus of 5 documents with 6320 words\n",
      "2019-10-29 00:43:46,033 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:46,044 : INFO : topic #0 (0.100): 0.045*\"cup\" + 0.036*\"world\" + 0.035*\"russia\" + 0.024*\"hide\" + 0.023*\"photo\" + 0.022*\"qualifier\" + 0.021*\"caption\" + 0.014*\"group\" + 0.012*\"qualifying\" + 0.011*\"goal\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:46,046 : INFO : topic #5 (0.100): 0.046*\"cup\" + 0.041*\"world\" + 0.033*\"russia\" + 0.027*\"hide\" + 0.026*\"photo\" + 0.024*\"qualifier\" + 0.023*\"caption\" + 0.016*\"goal\" + 0.013*\"qualifying\" + 0.013*\"group\"\n",
      "2019-10-29 00:43:46,047 : INFO : topic #8 (0.100): 0.046*\"cup\" + 0.043*\"world\" + 0.029*\"qualifier\" + 0.028*\"caption\" + 0.028*\"russia\" + 0.024*\"hide\" + 0.018*\"photo\" + 0.016*\"goal\" + 0.012*\"qualifying\" + 0.011*\"group\"\n",
      "2019-10-29 00:43:46,051 : INFO : topic #1 (0.100): 0.044*\"cup\" + 0.039*\"world\" + 0.028*\"caption\" + 0.027*\"russia\" + 0.024*\"photo\" + 0.022*\"hide\" + 0.021*\"qualifier\" + 0.012*\"qualifying\" + 0.012*\"goal\" + 0.012*\"first\"\n",
      "2019-10-29 00:43:46,054 : INFO : topic #4 (0.100): 0.038*\"cup\" + 0.038*\"world\" + 0.036*\"russia\" + 0.029*\"hide\" + 0.026*\"photo\" + 0.023*\"qualifier\" + 0.021*\"caption\" + 0.013*\"goal\" + 0.013*\"group\" + 0.010*\"first\"\n",
      "2019-10-29 00:43:46,057 : INFO : topic diff=1.055655, rho=1.000000\n",
      "2019-10-29 00:43:46,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:46,622 : INFO : built Dictionary(1239 unique tokens: ['although', 'let', 'happy', 'backlash', 'focus']...) from 5 documents (total 12330 corpus positions)\n",
      "2019-10-29 00:43:46,635 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:46,636 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:46,638 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:46,644 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:46,646 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:46,992 : INFO : -8.775 per-word bound, 438.1 perplexity estimate based on a held-out corpus of 5 documents with 12330 words\n",
      "2019-10-29 00:43:46,993 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:47,007 : INFO : topic #2 (0.100): 0.035*\"trump\" + 0.009*\"president\" + 0.007*\"united\" + 0.006*\"state\" + 0.006*\"trade\" + 0.006*\"election\" + 0.006*\"u\" + 0.006*\"donald\" + 0.005*\"south\" + 0.005*\"policy\"\n",
      "2019-10-29 00:43:47,009 : INFO : topic #7 (0.100): 0.035*\"trump\" + 0.009*\"president\" + 0.008*\"state\" + 0.008*\"u\" + 0.006*\"south\" + 0.006*\"trade\" + 0.006*\"country\" + 0.005*\"american\" + 0.005*\"policy\" + 0.005*\"new\"\n",
      "2019-10-29 00:43:47,010 : INFO : topic #4 (0.100): 0.030*\"trump\" + 0.008*\"president\" + 0.008*\"u\" + 0.007*\"state\" + 0.006*\"united\" + 0.006*\"policy\" + 0.006*\"american\" + 0.005*\"election\" + 0.005*\"trade\" + 0.005*\"china\"\n",
      "2019-10-29 00:43:47,012 : INFO : topic #0 (0.100): 0.033*\"trump\" + 0.012*\"president\" + 0.008*\"united\" + 0.007*\"state\" + 0.007*\"election\" + 0.006*\"trade\" + 0.006*\"policy\" + 0.006*\"u\" + 0.005*\"donald\" + 0.005*\"south\"\n",
      "2019-10-29 00:43:47,014 : INFO : topic #6 (0.100): 0.038*\"trump\" + 0.014*\"president\" + 0.010*\"state\" + 0.007*\"u\" + 0.007*\"trade\" + 0.007*\"united\" + 0.006*\"donald\" + 0.006*\"south\" + 0.006*\"would\" + 0.005*\"election\"\n",
      "2019-10-29 00:43:47,016 : INFO : topic diff=0.959771, rho=1.000000\n",
      "2019-10-29 00:43:47,460 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:47,462 : INFO : built Dictionary(78 unique tokens: ['story', 'completely', 'de', 'financial', 'early']...) from 5 documents (total 600 corpus positions)\n",
      "2019-10-29 00:43:47,465 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:47,472 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:47,479 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:47,488 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:47,491 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:47,542 : INFO : -6.534 per-word bound, 92.7 perplexity estimate based on a held-out corpus of 5 documents with 600 words\n",
      "2019-10-29 00:43:47,545 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:47,552 : INFO : topic #5 (0.100): 0.059*\"nelly\" + 0.035*\"rapper\" + 0.032*\"police\" + 0.029*\"say\" + 0.024*\"report\" + 0.023*\"released\" + 0.022*\"woman\" + 0.022*\"hour\" + 0.021*\"saturday\" + 0.020*\"assault\"\n",
      "2019-10-29 00:43:47,555 : INFO : topic #9 (0.100): 0.063*\"nelly\" + 0.043*\"rapper\" + 0.036*\"police\" + 0.028*\"report\" + 0.026*\"released\" + 0.026*\"saturday\" + 0.024*\"say\" + 0.023*\"hour\" + 0.022*\"woman\" + 0.019*\"reportedly\"\n",
      "2019-10-29 00:43:47,559 : INFO : topic #6 (0.100): 0.073*\"nelly\" + 0.035*\"say\" + 0.027*\"woman\" + 0.026*\"saturday\" + 0.025*\"police\" + 0.023*\"rapper\" + 0.023*\"released\" + 0.022*\"report\" + 0.021*\"washington\" + 0.021*\"hour\"\n",
      "2019-10-29 00:43:47,562 : INFO : topic #8 (0.100): 0.070*\"nelly\" + 0.040*\"say\" + 0.031*\"police\" + 0.031*\"report\" + 0.028*\"saturday\" + 0.025*\"hour\" + 0.024*\"rapper\" + 0.022*\"woman\" + 0.021*\"released\" + 0.020*\"water\"\n",
      "2019-10-29 00:43:47,568 : INFO : topic #2 (0.100): 0.062*\"nelly\" + 0.035*\"rapper\" + 0.031*\"say\" + 0.029*\"police\" + 0.026*\"released\" + 0.026*\"hour\" + 0.025*\"saturday\" + 0.022*\"woman\" + 0.020*\"report\" + 0.019*\"washington\"\n",
      "2019-10-29 00:43:47,571 : INFO : topic diff=0.792052, rho=1.000000\n",
      "2019-10-29 00:43:48,011 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:48,017 : INFO : built Dictionary(310 unique tokens: ['although', 'restricting', 'taxpayer', 'end', 'staffer']...) from 5 documents (total 3030 corpus positions)\n",
      "2019-10-29 00:43:48,021 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:48,022 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:48,024 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:48,027 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:48,029 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:48,134 : INFO : -7.455 per-word bound, 175.4 perplexity estimate based on a held-out corpus of 5 documents with 3030 words\n",
      "2019-10-29 00:43:48,136 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:48,143 : INFO : topic #7 (0.100): 0.024*\"care\" + 0.021*\"health\" + 0.017*\"parenthood\" + 0.017*\"service\" + 0.016*\"woman\" + 0.016*\"planning\" + 0.015*\"clinic\" + 0.014*\"fund\" + 0.014*\"planned\" + 0.012*\"said\"\n",
      "2019-10-29 00:43:48,145 : INFO : topic #1 (0.100): 0.023*\"health\" + 0.021*\"care\" + 0.018*\"planned\" + 0.018*\"parenthood\" + 0.016*\"service\" + 0.015*\"planning\" + 0.015*\"family\" + 0.015*\"woman\" + 0.015*\"clinic\" + 0.014*\"law\"\n",
      "2019-10-29 00:43:48,147 : INFO : topic #0 (0.100): 0.025*\"health\" + 0.024*\"care\" + 0.020*\"parenthood\" + 0.018*\"law\" + 0.017*\"woman\" + 0.016*\"family\" + 0.016*\"planned\" + 0.015*\"said\" + 0.015*\"planning\" + 0.014*\"abortion\"\n",
      "2019-10-29 00:43:48,149 : INFO : topic #8 (0.100): 0.030*\"health\" + 0.020*\"service\" + 0.017*\"planned\" + 0.017*\"care\" + 0.016*\"clinic\" + 0.016*\"access\" + 0.015*\"parenthood\" + 0.015*\"said\" + 0.014*\"woman\" + 0.014*\"law\"\n",
      "2019-10-29 00:43:48,152 : INFO : topic #2 (0.100): 0.024*\"care\" + 0.019*\"woman\" + 0.019*\"family\" + 0.019*\"health\" + 0.018*\"service\" + 0.016*\"planning\" + 0.016*\"law\" + 0.015*\"state\" + 0.014*\"said\" + 0.014*\"parenthood\"\n",
      "2019-10-29 00:43:48,155 : INFO : topic diff=0.978411, rho=1.000000\n",
      "2019-10-29 00:43:48,640 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:48,649 : INFO : built Dictionary(383 unique tokens: ['although', 'pushed', 'happy', 'rugged', 'drive']...) from 5 documents (total 3015 corpus positions)\n",
      "2019-10-29 00:43:48,656 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:48,657 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:48,658 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:48,661 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:48,664 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:48,786 : INFO : -7.936 per-word bound, 244.9 perplexity estimate based on a held-out corpus of 5 documents with 3015 words\n",
      "2019-10-29 00:43:48,788 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:48,795 : INFO : topic #8 (0.100): 0.041*\"dubai\" + 0.022*\"runner\" + 0.018*\"race\" + 0.015*\"strider\" + 0.015*\"club\" + 0.014*\"run\" + 0.014*\"marathon\" + 0.012*\"drr\" + 0.012*\"running\" + 0.009*\"two\"\n",
      "2019-10-29 00:43:48,797 : INFO : topic #9 (0.100): 0.038*\"dubai\" + 0.023*\"runner\" + 0.018*\"club\" + 0.017*\"race\" + 0.015*\"marathon\" + 0.015*\"run\" + 0.014*\"strider\" + 0.013*\"running\" + 0.008*\"drr\" + 0.007*\"al\"\n",
      "2019-10-29 00:43:48,799 : INFO : topic #5 (0.100): 0.038*\"dubai\" + 0.018*\"race\" + 0.016*\"runner\" + 0.015*\"run\" + 0.015*\"marathon\" + 0.013*\"club\" + 0.011*\"running\" + 0.010*\"drr\" + 0.010*\"two\" + 0.009*\"one\"\n",
      "2019-10-29 00:43:48,802 : INFO : topic #7 (0.100): 0.033*\"dubai\" + 0.015*\"run\" + 0.014*\"club\" + 0.014*\"race\" + 0.013*\"strider\" + 0.013*\"runner\" + 0.012*\"marathon\" + 0.012*\"running\" + 0.012*\"drr\" + 0.009*\"three\"\n",
      "2019-10-29 00:43:48,805 : INFO : topic #4 (0.100): 0.037*\"dubai\" + 0.022*\"runner\" + 0.017*\"club\" + 0.016*\"race\" + 0.014*\"marathon\" + 0.013*\"strider\" + 0.012*\"running\" + 0.012*\"run\" + 0.009*\"two\" + 0.009*\"drr\"\n",
      "2019-10-29 00:43:48,807 : INFO : topic diff=0.862537, rho=1.000000\n",
      "2019-10-29 00:43:49,253 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:49,256 : INFO : built Dictionary(160 unique tokens: ['concern', 'locked', 'campaign', 'francisco', 'joined']...) from 5 documents (total 1245 corpus positions)\n",
      "2019-10-29 00:43:49,258 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:49,260 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:49,262 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:49,265 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:49,267 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:49,336 : INFO : -7.140 per-word bound, 141.0 perplexity estimate based on a held-out corpus of 5 documents with 1245 words\n",
      "2019-10-29 00:43:49,338 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:49,345 : INFO : topic #0 (0.100): 0.039*\"anthem\" + 0.038*\"player\" + 0.028*\"protest\" + 0.023*\"trump\" + 0.022*\"stand\" + 0.020*\"president\" + 0.017*\"nfl\" + 0.017*\"game\" + 0.016*\"controversy\" + 0.015*\"goodell\"\n",
      "2019-10-29 00:43:49,348 : INFO : topic #9 (0.100): 0.037*\"player\" + 0.032*\"nfl\" + 0.029*\"stand\" + 0.029*\"anthem\" + 0.023*\"protest\" + 0.022*\"president\" + 0.018*\"trump\" + 0.016*\"past\" + 0.015*\"national\" + 0.015*\"game\"\n",
      "2019-10-29 00:43:49,350 : INFO : topic #3 (0.100): 0.049*\"player\" + 0.031*\"anthem\" + 0.022*\"president\" + 0.021*\"game\" + 0.021*\"stand\" + 0.020*\"nfl\" + 0.020*\"protest\" + 0.019*\"trump\" + 0.015*\"past\" + 0.015*\"goodell\"\n",
      "2019-10-29 00:43:49,353 : INFO : topic #6 (0.100): 0.035*\"player\" + 0.027*\"anthem\" + 0.024*\"protest\" + 0.023*\"stand\" + 0.018*\"nfl\" + 0.018*\"trump\" + 0.018*\"president\" + 0.018*\"past\" + 0.017*\"game\" + 0.015*\"goodell\"\n",
      "2019-10-29 00:43:49,356 : INFO : topic #8 (0.100): 0.046*\"player\" + 0.026*\"anthem\" + 0.022*\"protest\" + 0.020*\"nfl\" + 0.019*\"game\" + 0.017*\"stand\" + 0.016*\"president\" + 0.015*\"controversy\" + 0.015*\"trump\" + 0.014*\"fired\"\n",
      "2019-10-29 00:43:49,359 : INFO : topic diff=0.879464, rho=1.000000\n",
      "2019-10-29 00:43:49,765 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:49,768 : INFO : built Dictionary(192 unique tokens: ['forward', 'deter', 'weinstein', 'victimized', 'come']...) from 5 documents (total 1450 corpus positions)\n",
      "2019-10-29 00:43:49,771 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:49,772 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:49,774 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:49,776 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:49,777 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:49,858 : INFO : -7.350 per-word bound, 163.2 perplexity estimate based on a held-out corpus of 5 documents with 1450 words\n",
      "2019-10-29 00:43:49,859 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:49,866 : INFO : topic #6 (0.100): 0.029*\"crew\" + 0.027*\"weinstein\" + 0.023*\"said\" + 0.021*\"allegation\" + 0.019*\"power\" + 0.018*\"hollywood\" + 0.013*\"woman\" + 0.013*\"forward\" + 0.011*\"predator\" + 0.011*\"executive\"\n",
      "2019-10-29 00:43:49,868 : INFO : topic #3 (0.100): 0.040*\"crew\" + 0.037*\"said\" + 0.031*\"weinstein\" + 0.021*\"allegation\" + 0.018*\"power\" + 0.016*\"executive\" + 0.016*\"hollywood\" + 0.012*\"many\" + 0.011*\"forward\" + 0.011*\"predator\"\n",
      "2019-10-29 00:43:49,871 : INFO : topic #4 (0.100): 0.029*\"crew\" + 0.027*\"weinstein\" + 0.027*\"said\" + 0.024*\"allegation\" + 0.018*\"hollywood\" + 0.017*\"forward\" + 0.014*\"power\" + 0.014*\"woman\" + 0.012*\"executive\" + 0.012*\"going\"\n",
      "2019-10-29 00:43:49,876 : INFO : topic #0 (0.100): 0.037*\"crew\" + 0.031*\"said\" + 0.025*\"allegation\" + 0.025*\"weinstein\" + 0.016*\"hollywood\" + 0.015*\"forward\" + 0.014*\"power\" + 0.012*\"harassment\" + 0.011*\"executive\" + 0.011*\"story\"\n",
      "2019-10-29 00:43:49,878 : INFO : topic #2 (0.100): 0.041*\"weinstein\" + 0.035*\"crew\" + 0.029*\"said\" + 0.019*\"hollywood\" + 0.018*\"allegation\" + 0.017*\"woman\" + 0.017*\"power\" + 0.014*\"executive\" + 0.013*\"forward\" + 0.013*\"predator\"\n",
      "2019-10-29 00:43:49,881 : INFO : topic diff=0.828884, rho=1.000000\n",
      "2019-10-29 00:43:50,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:50,273 : INFO : built Dictionary(12 unique tokens: ['eminem', 'happening', 'facebook', 'messenger', 'trump']...) from 5 documents (total 60 corpus positions)\n",
      "2019-10-29 00:43:50,274 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:50,275 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:50,276 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:50,278 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:50,280 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:50,289 : INFO : -6.391 per-word bound, 83.9 perplexity estimate based on a held-out corpus of 5 documents with 60 words\n",
      "2019-10-29 00:43:50,291 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:50,296 : INFO : topic #7 (0.100): 0.095*\"world\" + 0.093*\"attack\" + 0.093*\"messenger\" + 0.089*\"unfolds\" + 0.089*\"freestyle\" + 0.087*\"chat\" + 0.083*\"eminem\" + 0.080*\"happening\" + 0.079*\"facebook\" + 0.076*\"find\"\n",
      "2019-10-29 00:43:50,298 : INFO : topic #5 (0.100): 0.105*\"find\" + 0.093*\"freestyle\" + 0.092*\"eminem\" + 0.090*\"unfolds\" + 0.087*\"trump\" + 0.087*\"chat\" + 0.087*\"messenger\" + 0.084*\"happening\" + 0.075*\"attack\" + 0.073*\"world\"\n",
      "2019-10-29 00:43:50,299 : INFO : topic #9 (0.100): 0.097*\"facebook\" + 0.097*\"chat\" + 0.094*\"trump\" + 0.087*\"attack\" + 0.083*\"eminem\" + 0.081*\"unfolds\" + 0.081*\"freestyle\" + 0.080*\"messenger\" + 0.079*\"world\" + 0.077*\"happening\"\n",
      "2019-10-29 00:43:50,301 : INFO : topic #4 (0.100): 0.093*\"u\" + 0.092*\"happening\" + 0.089*\"freestyle\" + 0.088*\"eminem\" + 0.087*\"trump\" + 0.086*\"facebook\" + 0.084*\"chat\" + 0.084*\"attack\" + 0.080*\"world\" + 0.079*\"unfolds\"\n",
      "2019-10-29 00:43:50,303 : INFO : topic #1 (0.100): 0.100*\"messenger\" + 0.099*\"trump\" + 0.097*\"find\" + 0.097*\"happening\" + 0.091*\"facebook\" + 0.090*\"freestyle\" + 0.076*\"unfolds\" + 0.075*\"world\" + 0.071*\"chat\" + 0.069*\"attack\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:50,305 : INFO : topic diff=0.508238, rho=1.000000\n",
      "2019-10-29 00:43:50,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:50,705 : INFO : built Dictionary(128 unique tokens: ['aviation', 'paris', 'journey', 'aircraft', 'game']...) from 5 documents (total 920 corpus positions)\n",
      "2019-10-29 00:43:50,707 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:50,708 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:50,710 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:50,712 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:50,714 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:50,794 : INFO : -7.064 per-word bound, 133.8 perplexity estimate based on a held-out corpus of 5 documents with 920 words\n",
      "2019-10-29 00:43:50,796 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:50,802 : INFO : topic #9 (0.100): 0.078*\"electric\" + 0.035*\"easyjet\" + 0.029*\"said\" + 0.022*\"startup\" + 0.022*\"wright\" + 0.019*\"industry\" + 0.019*\"plane\" + 0.016*\"technology\" + 0.015*\"airline\" + 0.014*\"fly\"\n",
      "2019-10-29 00:43:50,805 : INFO : topic #6 (0.100): 0.044*\"electric\" + 0.037*\"easyjet\" + 0.031*\"plane\" + 0.027*\"said\" + 0.023*\"startup\" + 0.019*\"aircraft\" + 0.019*\"wright\" + 0.017*\"airline\" + 0.016*\"would\" + 0.016*\"industry\"\n",
      "2019-10-29 00:43:50,809 : INFO : topic #8 (0.100): 0.066*\"electric\" + 0.031*\"said\" + 0.024*\"easyjet\" + 0.023*\"plane\" + 0.022*\"startup\" + 0.022*\"fly\" + 0.019*\"wright\" + 0.017*\"technology\" + 0.016*\"would\" + 0.014*\"aircraft\"\n",
      "2019-10-29 00:43:50,812 : INFO : topic #4 (0.100): 0.052*\"electric\" + 0.036*\"easyjet\" + 0.031*\"said\" + 0.022*\"startup\" + 0.021*\"plane\" + 0.017*\"wright\" + 0.016*\"would\" + 0.016*\"environment\" + 0.016*\"fly\" + 0.014*\"industry\"\n",
      "2019-10-29 00:43:50,815 : INFO : topic #2 (0.100): 0.063*\"electric\" + 0.034*\"easyjet\" + 0.028*\"plane\" + 0.026*\"said\" + 0.022*\"wright\" + 0.018*\"aircraft\" + 0.018*\"startup\" + 0.016*\"technology\" + 0.016*\"airline\" + 0.016*\"fly\"\n",
      "2019-10-29 00:43:50,818 : INFO : topic diff=0.828439, rho=1.000000\n",
      "2019-10-29 00:43:51,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:51,256 : INFO : built Dictionary(164 unique tokens: ['count', 'commissioned', 'fresh', 'nation', 'may']...) from 5 documents (total 1100 corpus positions)\n",
      "2019-10-29 00:43:51,259 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:51,261 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:51,263 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:51,266 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:51,268 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:51,351 : INFO : -7.408 per-word bound, 169.8 perplexity estimate based on a held-out corpus of 5 documents with 1100 words\n",
      "2019-10-29 00:43:51,353 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:51,364 : INFO : topic #7 (0.100): 0.033*\"resident\" + 0.028*\"city\" + 0.026*\"copenhagen\" + 0.022*\"park\" + 0.018*\"help\" + 0.016*\"bike\" + 0.015*\"work\" + 0.013*\"spot\" + 0.012*\"one\" + 0.011*\"family\"\n",
      "2019-10-29 00:43:51,367 : INFO : topic #2 (0.100): 0.023*\"copenhagen\" + 0.022*\"park\" + 0.020*\"city\" + 0.019*\"bike\" + 0.018*\"work\" + 0.017*\"resident\" + 0.015*\"help\" + 0.015*\"spot\" + 0.013*\"family\" + 0.012*\"one\"\n",
      "2019-10-29 00:43:51,369 : INFO : topic #1 (0.100): 0.030*\"copenhagen\" + 0.024*\"resident\" + 0.023*\"city\" + 0.019*\"work\" + 0.019*\"park\" + 0.016*\"bike\" + 0.015*\"family\" + 0.013*\"help\" + 0.012*\"one\" + 0.012*\"hour\"\n",
      "2019-10-29 00:43:51,372 : INFO : topic #6 (0.100): 0.032*\"city\" + 0.023*\"park\" + 0.022*\"resident\" + 0.019*\"copenhagen\" + 0.018*\"work\" + 0.017*\"bike\" + 0.015*\"help\" + 0.014*\"one\" + 0.011*\"spot\" + 0.011*\"family\"\n",
      "2019-10-29 00:43:51,375 : INFO : topic #3 (0.100): 0.030*\"resident\" + 0.026*\"copenhagen\" + 0.024*\"city\" + 0.014*\"work\" + 0.014*\"bike\" + 0.013*\"spot\" + 0.013*\"one\" + 0.012*\"help\" + 0.012*\"park\" + 0.011*\"level\"\n",
      "2019-10-29 00:43:51,378 : INFO : topic diff=0.753175, rho=1.000000\n",
      "2019-10-29 00:43:51,822 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:51,825 : INFO : built Dictionary(150 unique tokens: ['although', 'decrease', 'deadly', 'come', 'function']...) from 5 documents (total 1005 corpus positions)\n",
      "2019-10-29 00:43:51,827 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:51,829 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:51,831 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:51,833 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:51,834 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:51,896 : INFO : -7.326 per-word bound, 160.5 perplexity estimate based on a held-out corpus of 5 documents with 1005 words\n",
      "2019-10-29 00:43:51,898 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:51,904 : INFO : topic #5 (0.100): 0.042*\"sitting\" + 0.022*\"exercise\" + 0.020*\"prolonged\" + 0.019*\"harmful\" + 0.018*\"effect\" + 0.018*\"may\" + 0.017*\"blood\" + 0.015*\"study\" + 0.012*\"regularly\" + 0.011*\"show\"\n",
      "2019-10-29 00:43:51,907 : INFO : topic #3 (0.100): 0.043*\"sitting\" + 0.032*\"exercise\" + 0.023*\"may\" + 0.019*\"blood\" + 0.019*\"prolonged\" + 0.018*\"study\" + 0.016*\"harmful\" + 0.012*\"especially\" + 0.012*\"due\" + 0.012*\"get\"\n",
      "2019-10-29 00:43:51,910 : INFO : topic #6 (0.100): 0.047*\"sitting\" + 0.027*\"exercise\" + 0.019*\"blood\" + 0.019*\"may\" + 0.017*\"harmful\" + 0.015*\"study\" + 0.014*\"prolonged\" + 0.014*\"activity\" + 0.012*\"minute\" + 0.012*\"concluded\"\n",
      "2019-10-29 00:43:51,912 : INFO : topic #2 (0.100): 0.037*\"sitting\" + 0.026*\"exercise\" + 0.020*\"prolonged\" + 0.018*\"harmful\" + 0.018*\"may\" + 0.015*\"minute\" + 0.014*\"effect\" + 0.014*\"blood\" + 0.014*\"smoking\" + 0.012*\"study\"\n",
      "2019-10-29 00:43:51,915 : INFO : topic #1 (0.100): 0.043*\"sitting\" + 0.031*\"exercise\" + 0.022*\"prolonged\" + 0.017*\"harmful\" + 0.017*\"minute\" + 0.017*\"may\" + 0.015*\"study\" + 0.013*\"blood\" + 0.013*\"level\" + 0.011*\"effect\"\n",
      "2019-10-29 00:43:51,918 : INFO : topic diff=0.755911, rho=1.000000\n",
      "2019-10-29 00:43:52,354 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:52,357 : INFO : built Dictionary(125 unique tokens: ['dating', 'concern', 'significant', 'end', 'entitled']...) from 5 documents (total 860 corpus positions)\n",
      "2019-10-29 00:43:52,359 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:52,361 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:52,365 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:52,369 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:52,372 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:52,434 : INFO : -7.121 per-word bound, 139.2 perplexity estimate based on a held-out corpus of 5 documents with 860 words\n",
      "2019-10-29 00:43:52,436 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:52,440 : INFO : topic #0 (0.100): 0.051*\"beer\" + 0.034*\"label\" + 0.027*\"institute\" + 0.026*\"brewer\" + 0.021*\"said\" + 0.018*\"company\" + 0.015*\"information\" + 0.013*\"calorie\" + 0.013*\"total\" + 0.013*\"already\"\n",
      "2019-10-29 00:43:52,443 : INFO : topic #7 (0.100): 0.042*\"beer\" + 0.026*\"label\" + 0.024*\"said\" + 0.021*\"brewer\" + 0.017*\"institute\" + 0.017*\"company\" + 0.016*\"calorie\" + 0.016*\"provide\" + 0.015*\"initiative\" + 0.015*\"information\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:52,448 : INFO : topic #2 (0.100): 0.072*\"beer\" + 0.033*\"label\" + 0.026*\"said\" + 0.022*\"institute\" + 0.021*\"brewer\" + 0.017*\"company\" + 0.016*\"calorie\" + 0.016*\"information\" + 0.014*\"initiative\" + 0.013*\"get\"\n",
      "2019-10-29 00:43:52,451 : INFO : topic #9 (0.100): 0.054*\"beer\" + 0.033*\"label\" + 0.024*\"brewer\" + 0.021*\"calorie\" + 0.017*\"said\" + 0.016*\"institute\" + 0.014*\"nutritional\" + 0.014*\"company\" + 0.013*\"ingredient\" + 0.013*\"volume\"\n",
      "2019-10-29 00:43:52,454 : INFO : topic #1 (0.100): 0.051*\"beer\" + 0.028*\"label\" + 0.021*\"institute\" + 0.019*\"brewer\" + 0.019*\"information\" + 0.018*\"said\" + 0.017*\"company\" + 0.015*\"calorie\" + 0.013*\"provide\" + 0.013*\"statement\"\n",
      "2019-10-29 00:43:52,456 : INFO : topic diff=0.767668, rho=1.000000\n",
      "2019-10-29 00:43:52,876 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:52,882 : INFO : built Dictionary(290 unique tokens: ['relation', 'end', 'party', 'come', 'recent']...) from 5 documents (total 1940 corpus positions)\n",
      "2019-10-29 00:43:52,885 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:52,886 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:52,888 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:52,891 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:52,892 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:53,001 : INFO : -7.933 per-word bound, 244.5 perplexity estimate based on a held-out corpus of 5 documents with 1940 words\n",
      "2019-10-29 00:43:53,002 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:53,008 : INFO : topic #8 (0.100): 0.031*\"turkey\" + 0.026*\"turkish\" + 0.023*\"state\" + 0.021*\"united\" + 0.020*\"u\" + 0.014*\"erdogan\" + 0.009*\"gulen\" + 0.009*\"policy\" + 0.009*\"syria\" + 0.009*\"friend\"\n",
      "2019-10-29 00:43:53,010 : INFO : topic #2 (0.100): 0.040*\"turkey\" + 0.024*\"u\" + 0.020*\"united\" + 0.019*\"turkish\" + 0.015*\"state\" + 0.011*\"erdogan\" + 0.010*\"syrian\" + 0.010*\"russia\" + 0.009*\"gulen\" + 0.008*\"friend\"\n",
      "2019-10-29 00:43:53,013 : INFO : topic #4 (0.100): 0.021*\"turkey\" + 0.021*\"state\" + 0.019*\"united\" + 0.018*\"u\" + 0.018*\"turkish\" + 0.016*\"erdogan\" + 0.010*\"russia\" + 0.009*\"syrian\" + 0.009*\"gulen\" + 0.008*\"fethullah\"\n",
      "2019-10-29 00:43:53,016 : INFO : topic #3 (0.100): 0.046*\"turkey\" + 0.021*\"state\" + 0.018*\"u\" + 0.018*\"turkish\" + 0.016*\"united\" + 0.012*\"erdogan\" + 0.010*\"gulen\" + 0.009*\"syrian\" + 0.008*\"russia\" + 0.008*\"fethullah\"\n",
      "2019-10-29 00:43:53,018 : INFO : topic #9 (0.100): 0.032*\"turkey\" + 0.023*\"turkish\" + 0.018*\"state\" + 0.017*\"u\" + 0.015*\"erdogan\" + 0.015*\"united\" + 0.012*\"gulen\" + 0.011*\"syrian\" + 0.010*\"russia\" + 0.008*\"extradition\"\n",
      "2019-10-29 00:43:53,020 : INFO : topic diff=0.774087, rho=1.000000\n",
      "2019-10-29 00:43:53,468 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:53,471 : INFO : built Dictionary(185 unique tokens: ['josh', 'paradise', 'end', 'crest', 'subdivision']...) from 5 documents (total 2590 corpus positions)\n",
      "2019-10-29 00:43:53,474 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:53,476 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:53,478 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:53,482 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:53,483 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:53,580 : INFO : -6.601 per-word bound, 97.1 perplexity estimate based on a held-out corpus of 5 documents with 2590 words\n",
      "2019-10-29 00:43:53,581 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:53,587 : INFO : topic #8 (0.100): 0.081*\"photo\" + 0.062*\"wildfire\" + 0.058*\"october\" + 0.057*\"california\" + 0.056*\"caption\" + 0.056*\"hide\" + 0.044*\"blaze\" + 0.025*\"rosa\" + 0.025*\"santa\" + 0.019*\"home\"\n",
      "2019-10-29 00:43:53,589 : INFO : topic #5 (0.100): 0.067*\"blaze\" + 0.063*\"october\" + 0.058*\"wildfire\" + 0.058*\"california\" + 0.054*\"caption\" + 0.044*\"photo\" + 0.044*\"hide\" + 0.027*\"rosa\" + 0.020*\"home\" + 0.020*\"santa\"\n",
      "2019-10-29 00:43:53,592 : INFO : topic #3 (0.100): 0.072*\"california\" + 0.069*\"wildfire\" + 0.061*\"hide\" + 0.060*\"caption\" + 0.058*\"blaze\" + 0.056*\"photo\" + 0.048*\"october\" + 0.027*\"rosa\" + 0.016*\"home\" + 0.016*\"santa\"\n",
      "2019-10-29 00:43:53,594 : INFO : topic #0 (0.100): 0.067*\"photo\" + 0.067*\"california\" + 0.067*\"wildfire\" + 0.058*\"hide\" + 0.056*\"blaze\" + 0.048*\"october\" + 0.046*\"caption\" + 0.025*\"santa\" + 0.017*\"burn\" + 0.016*\"napa\"\n",
      "2019-10-29 00:43:53,596 : INFO : topic #1 (0.100): 0.074*\"california\" + 0.062*\"photo\" + 0.057*\"caption\" + 0.056*\"wildfire\" + 0.054*\"blaze\" + 0.051*\"october\" + 0.048*\"hide\" + 0.029*\"santa\" + 0.023*\"rosa\" + 0.021*\"home\"\n",
      "2019-10-29 00:43:53,598 : INFO : topic diff=1.242993, rho=1.000000\n",
      "2019-10-29 00:43:54,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:54,035 : INFO : built Dictionary(452 unique tokens: ['previously', 'residency', 'refugee', 'expansion', 'asked']...) from 5 documents (total 4075 corpus positions)\n",
      "2019-10-29 00:43:54,041 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:54,041 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:54,045 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:54,050 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:54,053 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:54,220 : INFO : -7.913 per-word bound, 241.0 perplexity estimate based on a held-out corpus of 5 documents with 4075 words\n",
      "2019-10-29 00:43:54,222 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:54,232 : INFO : topic #4 (0.100): 0.032*\"immigration\" + 0.019*\"u\" + 0.018*\"administration\" + 0.013*\"dhs\" + 0.012*\"policy\" + 0.010*\"could\" + 0.010*\"also\" + 0.009*\"protection\" + 0.009*\"legal\" + 0.008*\"source\"\n",
      "2019-10-29 00:43:54,235 : INFO : topic #8 (0.100): 0.026*\"immigration\" + 0.017*\"u\" + 0.016*\"policy\" + 0.015*\"dhs\" + 0.011*\"administration\" + 0.011*\"protection\" + 0.010*\"program\" + 0.009*\"could\" + 0.008*\"said\" + 0.008*\"also\"\n",
      "2019-10-29 00:43:54,237 : INFO : topic #7 (0.100): 0.027*\"immigration\" + 0.020*\"u\" + 0.018*\"dhs\" + 0.013*\"policy\" + 0.011*\"administration\" + 0.009*\"protection\" + 0.009*\"could\" + 0.008*\"said\" + 0.008*\"legal\" + 0.008*\"exploring\"\n",
      "2019-10-29 00:43:54,239 : INFO : topic #6 (0.100): 0.038*\"immigration\" + 0.018*\"u\" + 0.015*\"could\" + 0.014*\"policy\" + 0.011*\"dhs\" + 0.009*\"administration\" + 0.009*\"source\" + 0.008*\"also\" + 0.008*\"executive\" + 0.007*\"protection\"\n",
      "2019-10-29 00:43:54,241 : INFO : topic #3 (0.100): 0.030*\"immigration\" + 0.019*\"u\" + 0.015*\"dhs\" + 0.012*\"could\" + 0.012*\"also\" + 0.012*\"administration\" + 0.010*\"policy\" + 0.009*\"protection\" + 0.008*\"change\" + 0.008*\"source\"\n",
      "2019-10-29 00:43:54,243 : INFO : topic diff=0.891790, rho=1.000000\n",
      "2019-10-29 00:43:54,663 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:54,665 : INFO : built Dictionary(72 unique tokens: ['aar', 'small', 'de', 'spread', 'led']...) from 5 documents (total 505 corpus positions)\n",
      "2019-10-29 00:43:54,667 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:54,668 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:54,670 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:54,672 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:54,674 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:54,707 : INFO : -6.619 per-word bound, 98.3 perplexity estimate based on a held-out corpus of 5 documents with 505 words\n",
      "2019-10-29 00:43:54,709 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:54,715 : INFO : topic #6 (0.100): 0.063*\"solar\" + 0.050*\"africa\" + 0.035*\"largest\" + 0.034*\"south\" + 0.031*\"plant\" + 0.029*\"power\" + 0.029*\"de\" + 0.028*\"aar\" + 0.022*\"grid\" + 0.019*\"southern\"\n",
      "2019-10-29 00:43:54,717 : INFO : topic #9 (0.100): 0.049*\"africa\" + 0.043*\"solar\" + 0.029*\"largest\" + 0.029*\"plant\" + 0.029*\"aar\" + 0.028*\"grid\" + 0.027*\"south\" + 0.022*\"power\" + 0.022*\"de\" + 0.020*\"capital\"\n",
      "2019-10-29 00:43:54,722 : INFO : topic #7 (0.100): 0.052*\"africa\" + 0.050*\"solar\" + 0.037*\"plant\" + 0.035*\"grid\" + 0.033*\"power\" + 0.031*\"largest\" + 0.031*\"aar\" + 0.027*\"south\" + 0.023*\"de\" + 0.021*\"national\"\n",
      "2019-10-29 00:43:54,725 : INFO : topic #8 (0.100): 0.055*\"solar\" + 0.041*\"plant\" + 0.039*\"africa\" + 0.034*\"de\" + 0.028*\"largest\" + 0.027*\"grid\" + 0.026*\"power\" + 0.026*\"south\" + 0.022*\"aar\" + 0.021*\"capital\"\n",
      "2019-10-29 00:43:54,729 : INFO : topic #3 (0.100): 0.055*\"solar\" + 0.047*\"africa\" + 0.043*\"plant\" + 0.032*\"grid\" + 0.031*\"aar\" + 0.028*\"de\" + 0.025*\"power\" + 0.024*\"south\" + 0.022*\"largest\" + 0.022*\"hemisphere\"\n",
      "2019-10-29 00:43:54,732 : INFO : topic diff=0.817759, rho=1.000000\n",
      "2019-10-29 00:43:55,147 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:55,151 : INFO : built Dictionary(263 unique tokens: ['school', 'small', 'party', 'drinking', 'making']...) from 5 documents (total 1990 corpus positions)\n",
      "2019-10-29 00:43:55,154 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:55,156 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:55,157 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:55,160 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:55,161 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:55,250 : INFO : -7.640 per-word bound, 199.5 perplexity estimate based on a held-out corpus of 5 documents with 1990 words\n",
      "2019-10-29 00:43:55,252 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:55,261 : INFO : topic #1 (0.100): 0.020*\"menish\" + 0.017*\"painting\" + 0.015*\"like\" + 0.012*\"year\" + 0.011*\"good\" + 0.011*\"addict\" + 0.011*\"got\" + 0.010*\"really\" + 0.010*\"hand\" + 0.010*\"talk\"\n",
      "2019-10-29 00:43:55,263 : INFO : topic #8 (0.100): 0.025*\"menish\" + 0.019*\"painting\" + 0.013*\"like\" + 0.012*\"year\" + 0.012*\"hand\" + 0.011*\"good\" + 0.011*\"life\" + 0.010*\"addict\" + 0.010*\"addiction\" + 0.010*\"going\"\n",
      "2019-10-29 00:43:55,266 : INFO : topic #5 (0.100): 0.030*\"menish\" + 0.020*\"painting\" + 0.014*\"good\" + 0.012*\"like\" + 0.012*\"art\" + 0.011*\"recovering\" + 0.010*\"year\" + 0.009*\"really\" + 0.009*\"month\" + 0.009*\"addiction\"\n",
      "2019-10-29 00:43:55,269 : INFO : topic #7 (0.100): 0.031*\"menish\" + 0.019*\"painting\" + 0.012*\"talk\" + 0.011*\"like\" + 0.011*\"year\" + 0.010*\"month\" + 0.010*\"good\" + 0.010*\"recovering\" + 0.010*\"life\" + 0.009*\"school\"\n",
      "2019-10-29 00:43:55,272 : INFO : topic #0 (0.100): 0.030*\"menish\" + 0.019*\"painting\" + 0.013*\"year\" + 0.012*\"really\" + 0.012*\"good\" + 0.012*\"art\" + 0.011*\"month\" + 0.011*\"like\" + 0.010*\"got\" + 0.009*\"recovering\"\n",
      "2019-10-29 00:43:55,274 : INFO : topic diff=0.795393, rho=1.000000\n",
      "2019-10-29 00:43:55,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:55,794 : INFO : built Dictionary(794 unique tokens: ['rage', 'portion', 'rude', 'marched', 'renamed']...) from 5 documents (total 8570 corpus positions)\n",
      "2019-10-29 00:43:55,806 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:55,809 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:55,812 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:55,818 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:55,825 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:56,055 : INFO : -8.257 per-word bound, 305.8 perplexity estimate based on a held-out corpus of 5 documents with 8570 words\n",
      "2019-10-29 00:43:56,056 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:56,068 : INFO : topic #6 (0.100): 0.030*\"people\" + 0.030*\"white\" + 0.021*\"say\" + 0.010*\"park\" + 0.010*\"nationalist\" + 0.010*\"emancipation\" + 0.008*\"racial\" + 0.008*\"family\" + 0.006*\"charlottesville\" + 0.006*\"life\"\n",
      "2019-10-29 00:43:56,069 : INFO : topic #1 (0.100): 0.033*\"white\" + 0.018*\"people\" + 0.016*\"say\" + 0.013*\"park\" + 0.012*\"trump\" + 0.010*\"nationalist\" + 0.008*\"emancipation\" + 0.007*\"black\" + 0.007*\"police\" + 0.007*\"counterprotesters\"\n",
      "2019-10-29 00:43:56,070 : INFO : topic #4 (0.100): 0.041*\"white\" + 0.027*\"people\" + 0.024*\"say\" + 0.013*\"park\" + 0.010*\"trump\" + 0.008*\"nationalist\" + 0.008*\"ordinary\" + 0.008*\"emancipation\" + 0.007*\"charlottesville\" + 0.007*\"many\"\n",
      "2019-10-29 00:43:56,072 : INFO : topic #0 (0.100): 0.026*\"white\" + 0.020*\"say\" + 0.015*\"people\" + 0.011*\"trump\" + 0.011*\"park\" + 0.009*\"nationalist\" + 0.008*\"emancipation\" + 0.008*\"many\" + 0.007*\"family\" + 0.007*\"black\"\n",
      "2019-10-29 00:43:56,074 : INFO : topic #7 (0.100): 0.038*\"white\" + 0.027*\"people\" + 0.023*\"say\" + 0.009*\"emancipation\" + 0.008*\"nationalist\" + 0.008*\"park\" + 0.007*\"million\" + 0.007*\"charlottesville\" + 0.007*\"many\" + 0.006*\"family\"\n",
      "2019-10-29 00:43:56,077 : INFO : topic diff=0.935331, rho=1.000000\n",
      "2019-10-29 00:43:56,463 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:56,464 : INFO : built Dictionary(7 unique tokens: ['help', 'cushion', 'joint', 'lubricates', 'keep']...) from 5 documents (total 35 corpus positions)\n",
      "2019-10-29 00:43:56,465 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:56,467 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:56,468 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:56,470 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:56,471 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:56,480 : INFO : -6.290 per-word bound, 78.3 perplexity estimate based on a held-out corpus of 5 documents with 35 words\n",
      "2019-10-29 00:43:56,481 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:56,486 : INFO : topic #7 (0.100): 0.176*\"joint\" + 0.146*\"help\" + 0.146*\"exercising\" + 0.140*\"cushion\" + 0.140*\"lubricates\" + 0.138*\"parallel\" + 0.114*\"keep\"\n",
      "2019-10-29 00:43:56,488 : INFO : topic #0 (0.100): 0.165*\"help\" + 0.163*\"joint\" + 0.149*\"cushion\" + 0.147*\"keep\" + 0.142*\"exercising\" + 0.133*\"parallel\" + 0.100*\"lubricates\"\n",
      "2019-10-29 00:43:56,489 : INFO : topic #3 (0.100): 0.155*\"keep\" + 0.149*\"help\" + 0.149*\"joint\" + 0.146*\"exercising\" + 0.137*\"parallel\" + 0.136*\"lubricates\" + 0.128*\"cushion\"\n",
      "2019-10-29 00:43:56,491 : INFO : topic #1 (0.100): 0.201*\"lubricates\" + 0.167*\"keep\" + 0.139*\"joint\" + 0.135*\"cushion\" + 0.128*\"parallel\" + 0.120*\"help\" + 0.110*\"exercising\"\n",
      "2019-10-29 00:43:56,493 : INFO : topic #5 (0.100): 0.162*\"keep\" + 0.152*\"lubricates\" + 0.149*\"parallel\" + 0.147*\"exercising\" + 0.132*\"joint\" + 0.129*\"cushion\" + 0.129*\"help\"\n",
      "2019-10-29 00:43:56,494 : INFO : topic diff=0.485127, rho=1.000000\n",
      "2019-10-29 00:43:56,912 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:56,913 : INFO : built Dictionary(22 unique tokens: ['night', 'snl', 'country', 'shooting', 'open']...) from 5 documents (total 135 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:56,915 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:56,917 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:56,919 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:56,920 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:56,921 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:56,934 : INFO : -6.076 per-word bound, 67.5 perplexity estimate based on a held-out corpus of 5 documents with 135 words\n",
      "2019-10-29 00:43:56,936 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:56,941 : INFO : topic #4 (0.100): 0.080*\"tribute\" + 0.076*\"jason\" + 0.065*\"vega\" + 0.061*\"open\" + 0.060*\"aldean\" + 0.050*\"singer\" + 0.045*\"performing\" + 0.043*\"began\" + 0.043*\"snl\" + 0.043*\"singing\"\n",
      "2019-10-29 00:43:56,943 : INFO : topic #3 (0.100): 0.092*\"open\" + 0.091*\"jason\" + 0.063*\"aldean\" + 0.059*\"tribute\" + 0.058*\"vega\" + 0.047*\"shooting\" + 0.044*\"tom\" + 0.043*\"saturday\" + 0.042*\"began\" + 0.040*\"petty\"\n",
      "2019-10-29 00:43:56,945 : INFO : topic #0 (0.100): 0.094*\"open\" + 0.083*\"tribute\" + 0.067*\"aldean\" + 0.064*\"vega\" + 0.057*\"jason\" + 0.042*\"victim\" + 0.042*\"back\" + 0.040*\"country\" + 0.039*\"la\" + 0.039*\"family\"\n",
      "2019-10-29 00:43:56,947 : INFO : topic #8 (0.100): 0.080*\"vega\" + 0.074*\"jason\" + 0.070*\"tribute\" + 0.068*\"aldean\" + 0.064*\"open\" + 0.054*\"cold\" + 0.051*\"la\" + 0.040*\"singer\" + 0.039*\"tom\" + 0.039*\"live\"\n",
      "2019-10-29 00:43:56,949 : INFO : topic #7 (0.100): 0.084*\"aldean\" + 0.074*\"open\" + 0.072*\"vega\" + 0.066*\"jason\" + 0.065*\"tribute\" + 0.046*\"saturday\" + 0.043*\"live\" + 0.042*\"singer\" + 0.042*\"victim\" + 0.041*\"cold\"\n",
      "2019-10-29 00:43:56,950 : INFO : topic diff=0.625418, rho=1.000000\n",
      "2019-10-29 00:43:57,366 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:57,370 : INFO : built Dictionary(226 unique tokens: ['rage', 'person', 'described', 'come', 'huff']...) from 5 documents (total 1510 corpus positions)\n",
      "2019-10-29 00:43:57,374 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:57,376 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:57,385 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:57,391 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:57,392 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:57,484 : INFO : -7.708 per-word bound, 209.1 perplexity estimate based on a held-out corpus of 5 documents with 1510 words\n",
      "2019-10-29 00:43:57,486 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:57,492 : INFO : topic #2 (0.100): 0.034*\"trump\" + 0.022*\"eminem\" + 0.018*\"lot\" + 0.014*\"rap\" + 0.013*\"say\" + 0.012*\"people\" + 0.011*\"democrat\" + 0.011*\"two\" + 0.011*\"said\" + 0.010*\"rapper\"\n",
      "2019-10-29 00:43:57,495 : INFO : topic #1 (0.100): 0.040*\"eminem\" + 0.030*\"trump\" + 0.018*\"people\" + 0.014*\"said\" + 0.014*\"say\" + 0.012*\"emotion\" + 0.012*\"rap\" + 0.011*\"lot\" + 0.011*\"angry\" + 0.010*\"democrat\"\n",
      "2019-10-29 00:43:57,499 : INFO : topic #7 (0.100): 0.053*\"trump\" + 0.024*\"eminem\" + 0.019*\"people\" + 0.012*\"lot\" + 0.011*\"said\" + 0.010*\"angry\" + 0.010*\"two\" + 0.009*\"say\" + 0.009*\"democrat\" + 0.009*\"feel\"\n",
      "2019-10-29 00:43:57,501 : INFO : topic #9 (0.100): 0.037*\"trump\" + 0.027*\"eminem\" + 0.021*\"people\" + 0.013*\"lot\" + 0.013*\"rap\" + 0.011*\"two\" + 0.010*\"angry\" + 0.010*\"feel\" + 0.010*\"said\" + 0.010*\"emotion\"\n",
      "2019-10-29 00:43:57,504 : INFO : topic #4 (0.100): 0.030*\"trump\" + 0.025*\"eminem\" + 0.019*\"people\" + 0.015*\"say\" + 0.012*\"lot\" + 0.012*\"said\" + 0.010*\"feel\" + 0.009*\"angry\" + 0.009*\"two\" + 0.009*\"emotion\"\n",
      "2019-10-29 00:43:57,507 : INFO : topic diff=0.758978, rho=1.000000\n",
      "2019-10-29 00:43:57,973 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:57,981 : INFO : built Dictionary(361 unique tokens: ['shower', 'daniel', 'ferrari', 'doused', 'new']...) from 5 documents (total 3715 corpus positions)\n",
      "2019-10-29 00:43:57,989 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:57,991 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:57,994 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:57,998 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:58,001 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:58,151 : INFO : -7.537 per-word bound, 185.8 perplexity estimate based on a held-out corpus of 5 documents with 3715 words\n",
      "2019-10-29 00:43:58,153 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:58,163 : INFO : topic #7 (0.100): 0.053*\"photo\" + 0.041*\"caption\" + 0.038*\"sport\" + 0.036*\"september\" + 0.034*\"shot\" + 0.034*\"hide\" + 0.029*\"amazing\" + 0.016*\"sunday\" + 0.013*\"game\" + 0.012*\"saturday\"\n",
      "2019-10-29 00:43:58,166 : INFO : topic #4 (0.100): 0.077*\"photo\" + 0.044*\"caption\" + 0.040*\"sport\" + 0.040*\"amazing\" + 0.031*\"shot\" + 0.029*\"hide\" + 0.027*\"september\" + 0.015*\"sunday\" + 0.009*\"game\" + 0.008*\"victory\"\n",
      "2019-10-29 00:43:58,168 : INFO : topic #8 (0.100): 0.073*\"photo\" + 0.040*\"sport\" + 0.039*\"shot\" + 0.037*\"september\" + 0.035*\"hide\" + 0.034*\"amazing\" + 0.033*\"caption\" + 0.018*\"sunday\" + 0.013*\"game\" + 0.009*\"touchdown\"\n",
      "2019-10-29 00:43:58,170 : INFO : topic #9 (0.100): 0.067*\"photo\" + 0.043*\"hide\" + 0.041*\"sport\" + 0.039*\"amazing\" + 0.036*\"shot\" + 0.029*\"september\" + 0.026*\"caption\" + 0.016*\"sunday\" + 0.012*\"game\" + 0.008*\"touchdown\"\n",
      "2019-10-29 00:43:58,172 : INFO : topic #0 (0.100): 0.055*\"photo\" + 0.042*\"shot\" + 0.038*\"amazing\" + 0.037*\"sport\" + 0.037*\"september\" + 0.035*\"caption\" + 0.026*\"hide\" + 0.016*\"sunday\" + 0.014*\"game\" + 0.012*\"saturday\"\n",
      "2019-10-29 00:43:58,174 : INFO : topic diff=0.977720, rho=1.000000\n",
      "2019-10-29 00:43:58,658 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:58,662 : INFO : built Dictionary(290 unique tokens: ['forward', 'replete', 'school', 'single', 'happy']...) from 5 documents (total 2075 corpus positions)\n",
      "2019-10-29 00:43:58,668 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:58,669 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:58,671 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:58,675 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:58,676 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:58,774 : INFO : -7.821 per-word bound, 226.1 perplexity estimate based on a held-out corpus of 5 documents with 2075 words\n",
      "2019-10-29 00:43:58,776 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:58,784 : INFO : topic #3 (0.100): 0.028*\"ross\" + 0.022*\"girl\" + 0.017*\"photo\" + 0.014*\"say\" + 0.014*\"child\" + 0.013*\"said\" + 0.011*\"story\" + 0.010*\"one\" + 0.010*\"also\" + 0.009*\"know\"\n",
      "2019-10-29 00:43:58,787 : INFO : topic #9 (0.100): 0.026*\"ross\" + 0.018*\"girl\" + 0.016*\"said\" + 0.015*\"photo\" + 0.014*\"child\" + 0.012*\"one\" + 0.012*\"say\" + 0.010*\"know\" + 0.010*\"center\" + 0.009*\"story\"\n",
      "2019-10-29 00:43:58,790 : INFO : topic #2 (0.100): 0.022*\"ross\" + 0.018*\"girl\" + 0.016*\"say\" + 0.013*\"photo\" + 0.012*\"said\" + 0.010*\"child\" + 0.010*\"story\" + 0.009*\"detention\" + 0.009*\"want\" + 0.009*\"also\"\n",
      "2019-10-29 00:43:58,794 : INFO : topic #0 (0.100): 0.024*\"girl\" + 0.023*\"ross\" + 0.015*\"say\" + 0.013*\"child\" + 0.012*\"photo\" + 0.012*\"system\" + 0.012*\"said\" + 0.011*\"know\" + 0.011*\"one\" + 0.009*\"center\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:43:58,797 : INFO : topic #1 (0.100): 0.027*\"ross\" + 0.027*\"girl\" + 0.016*\"photo\" + 0.014*\"said\" + 0.014*\"story\" + 0.012*\"one\" + 0.011*\"child\" + 0.011*\"detention\" + 0.010*\"system\" + 0.010*\"say\"\n",
      "2019-10-29 00:43:58,800 : INFO : topic diff=0.807718, rho=1.000000\n",
      "2019-10-29 00:43:59,234 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:43:59,241 : INFO : built Dictionary(520 unique tokens: ['dating', 'deep', 'entitled', 'remained', 'place']...) from 5 documents (total 4350 corpus positions)\n",
      "2019-10-29 00:43:59,246 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:43:59,247 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:43:59,248 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:43:59,253 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:43:59,255 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:43:59,405 : INFO : -8.147 per-word bound, 283.5 perplexity estimate based on a held-out corpus of 5 documents with 4350 words\n",
      "2019-10-29 00:43:59,406 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:43:59,414 : INFO : topic #2 (0.100): 0.024*\"woman\" + 0.019*\"marriage\" + 0.016*\"husband\" + 0.015*\"way\" + 0.014*\"friend\" + 0.011*\"another\" + 0.011*\"one\" + 0.010*\"infidelity\" + 0.010*\"told\" + 0.008*\"affair\"\n",
      "2019-10-29 00:43:59,417 : INFO : topic #6 (0.100): 0.031*\"woman\" + 0.016*\"husband\" + 0.015*\"marriage\" + 0.014*\"way\" + 0.011*\"friend\" + 0.010*\"one\" + 0.010*\"another\" + 0.010*\"told\" + 0.010*\"book\" + 0.009*\"like\"\n",
      "2019-10-29 00:43:59,419 : INFO : topic #0 (0.100): 0.027*\"woman\" + 0.020*\"marriage\" + 0.015*\"husband\" + 0.014*\"way\" + 0.012*\"one\" + 0.011*\"friend\" + 0.010*\"many\" + 0.010*\"infidelity\" + 0.010*\"affair\" + 0.009*\"year\"\n",
      "2019-10-29 00:43:59,421 : INFO : topic #1 (0.100): 0.026*\"woman\" + 0.019*\"marriage\" + 0.017*\"husband\" + 0.015*\"way\" + 0.012*\"friend\" + 0.011*\"one\" + 0.011*\"infidelity\" + 0.010*\"like\" + 0.010*\"year\" + 0.009*\"many\"\n",
      "2019-10-29 00:43:59,423 : INFO : topic #7 (0.100): 0.038*\"woman\" + 0.016*\"marriage\" + 0.016*\"husband\" + 0.013*\"friend\" + 0.012*\"way\" + 0.011*\"many\" + 0.010*\"told\" + 0.009*\"affair\" + 0.009*\"one\" + 0.009*\"year\"\n",
      "2019-10-29 00:43:59,426 : INFO : topic diff=0.914580, rho=1.000000\n",
      "2019-10-29 00:44:00,026 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:00,047 : INFO : built Dictionary(1415 unique tokens: ['let', 'drinking', 'wheel', 'asleep', 'blanket']...) from 5 documents (total 17415 corpus positions)\n",
      "2019-10-29 00:44:00,065 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:00,067 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:00,072 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:00,082 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:00,084 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:00,500 : INFO : -8.693 per-word bound, 413.8 perplexity estimate based on a held-out corpus of 5 documents with 17415 words\n",
      "2019-10-29 00:44:00,502 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:00,518 : INFO : topic #1 (0.100): 0.027*\"jessica\" + 0.019*\"say\" + 0.010*\"tower\" + 0.008*\"opioids\" + 0.007*\"pain\" + 0.007*\"stephanie\" + 0.007*\"one\" + 0.007*\"opioid\" + 0.006*\"katz\" + 0.006*\"baby\"\n",
      "2019-10-29 00:44:00,521 : INFO : topic #6 (0.100): 0.021*\"jessica\" + 0.018*\"say\" + 0.011*\"tower\" + 0.008*\"baby\" + 0.008*\"katz\" + 0.007*\"opioids\" + 0.007*\"stephanie\" + 0.007*\"pain\" + 0.006*\"drug\" + 0.005*\"opioid\"\n",
      "2019-10-29 00:44:00,524 : INFO : topic #2 (0.100): 0.027*\"jessica\" + 0.017*\"say\" + 0.010*\"tower\" + 0.010*\"opioids\" + 0.008*\"stephanie\" + 0.007*\"pain\" + 0.007*\"drug\" + 0.007*\"painkiller\" + 0.007*\"baby\" + 0.006*\"room\"\n",
      "2019-10-29 00:44:00,528 : INFO : topic #0 (0.100): 0.024*\"jessica\" + 0.014*\"say\" + 0.010*\"opioids\" + 0.010*\"tower\" + 0.009*\"baby\" + 0.007*\"stephanie\" + 0.007*\"painkiller\" + 0.007*\"katz\" + 0.006*\"like\" + 0.005*\"room\"\n",
      "2019-10-29 00:44:00,531 : INFO : topic #5 (0.100): 0.030*\"jessica\" + 0.020*\"say\" + 0.011*\"opioids\" + 0.009*\"tower\" + 0.009*\"baby\" + 0.008*\"stephanie\" + 0.007*\"katz\" + 0.006*\"pain\" + 0.006*\"opioid\" + 0.006*\"drug\"\n",
      "2019-10-29 00:44:00,533 : INFO : topic diff=1.068760, rho=1.000000\n",
      "2019-10-29 00:44:00,946 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:00,949 : INFO : built Dictionary(153 unique tokens: ['warrior', 'bone', 'anger', 'come', 'tax']...) from 5 documents (total 940 corpus positions)\n",
      "2019-10-29 00:44:00,951 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:00,952 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:00,953 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:00,956 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:00,957 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:01,020 : INFO : -7.505 per-word bound, 181.6 perplexity estimate based on a held-out corpus of 5 documents with 940 words\n",
      "2019-10-29 00:44:01,021 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:01,028 : INFO : topic #0 (0.100): 0.025*\"base\" + 0.023*\"say\" + 0.021*\"president\" + 0.016*\"take\" + 0.015*\"nfl\" + 0.015*\"friend\" + 0.014*\"trump\" + 0.014*\"think\" + 0.013*\"brave\" + 0.013*\"tweet\"\n",
      "2019-10-29 00:44:01,029 : INFO : topic #2 (0.100): 0.022*\"base\" + 0.020*\"president\" + 0.019*\"say\" + 0.017*\"trump\" + 0.017*\"take\" + 0.015*\"nfl\" + 0.013*\"brave\" + 0.013*\"friend\" + 0.013*\"tweet\" + 0.012*\"think\"\n",
      "2019-10-29 00:44:01,031 : INFO : topic #3 (0.100): 0.024*\"president\" + 0.021*\"say\" + 0.018*\"base\" + 0.017*\"trump\" + 0.016*\"nfl\" + 0.015*\"friend\" + 0.015*\"think\" + 0.015*\"brave\" + 0.012*\"deal\" + 0.011*\"anthem\"\n",
      "2019-10-29 00:44:01,033 : INFO : topic #4 (0.100): 0.031*\"say\" + 0.028*\"president\" + 0.020*\"trump\" + 0.019*\"take\" + 0.018*\"brave\" + 0.013*\"base\" + 0.012*\"think\" + 0.012*\"way\" + 0.011*\"tweet\" + 0.011*\"friend\"\n",
      "2019-10-29 00:44:01,035 : INFO : topic #6 (0.100): 0.023*\"president\" + 0.022*\"trump\" + 0.022*\"say\" + 0.019*\"take\" + 0.018*\"base\" + 0.016*\"think\" + 0.016*\"friend\" + 0.014*\"brave\" + 0.014*\"nfl\" + 0.012*\"care\"\n",
      "2019-10-29 00:44:01,037 : INFO : topic diff=0.712020, rho=1.000000\n",
      "2019-10-29 00:44:01,419 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:01,421 : INFO : built Dictionary(18 unique tokens: ['scope', 'aided', 'tragedy', 'number', 'cnn']...) from 5 documents (total 105 corpus positions)\n",
      "2019-10-29 00:44:01,422 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:01,424 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:01,426 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:01,428 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:01,435 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:01,449 : INFO : -6.109 per-word bound, 69.0 perplexity estimate based on a held-out corpus of 5 documents with 105 words\n",
      "2019-10-29 00:44:01,452 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:01,458 : INFO : topic #9 (0.100): 0.110*\"number\" + 0.102*\"wildfire\" + 0.073*\"california\" + 0.055*\"humidity\" + 0.055*\"eye\" + 0.053*\"popping\" + 0.052*\"low\" + 0.049*\"aided\" + 0.049*\"scorching\" + 0.049*\"tragedy\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:01,461 : INFO : topic #6 (0.100): 0.093*\"california\" + 0.092*\"number\" + 0.087*\"wildfire\" + 0.069*\"scorching\" + 0.055*\"northern\" + 0.055*\"cnn\" + 0.053*\"humidity\" + 0.053*\"wind\" + 0.052*\"dozen\" + 0.048*\"high\"\n",
      "2019-10-29 00:44:01,463 : INFO : topic #1 (0.100): 0.100*\"california\" + 0.089*\"number\" + 0.086*\"wildfire\" + 0.058*\"scope\" + 0.056*\"popping\" + 0.056*\"high\" + 0.055*\"aided\" + 0.053*\"eye\" + 0.050*\"staggering\" + 0.049*\"low\"\n",
      "2019-10-29 00:44:01,466 : INFO : topic #0 (0.100): 0.112*\"number\" + 0.081*\"california\" + 0.080*\"wildfire\" + 0.063*\"wind\" + 0.057*\"scope\" + 0.053*\"eye\" + 0.052*\"tragedy\" + 0.050*\"cnn\" + 0.049*\"staggering\" + 0.048*\"scorching\"\n",
      "2019-10-29 00:44:01,468 : INFO : topic #2 (0.100): 0.116*\"wildfire\" + 0.076*\"number\" + 0.069*\"california\" + 0.065*\"low\" + 0.057*\"tell\" + 0.055*\"dozen\" + 0.054*\"northern\" + 0.053*\"cnn\" + 0.049*\"humidity\" + 0.048*\"staggering\"\n",
      "2019-10-29 00:44:01,470 : INFO : topic diff=0.626205, rho=1.000000\n",
      "2019-10-29 00:44:01,950 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:01,952 : INFO : built Dictionary(76 unique tokens: ['story', 'party', 'victory', 'quits', 'trying']...) from 5 documents (total 540 corpus positions)\n",
      "2019-10-29 00:44:01,953 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:01,955 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:01,956 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:01,958 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:01,960 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:02,010 : INFO : -6.640 per-word bound, 99.7 perplexity estimate based on a held-out corpus of 5 documents with 540 words\n",
      "2019-10-29 00:44:02,014 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:02,024 : INFO : topic #7 (0.100): 0.051*\"odinga\" + 0.043*\"kenyatta\" + 0.038*\"election\" + 0.029*\"kenya\" + 0.027*\"rerun\" + 0.026*\"vote\" + 0.024*\"president\" + 0.021*\"nairobi\" + 0.019*\"august\" + 0.018*\"said\"\n",
      "2019-10-29 00:44:02,033 : INFO : topic #8 (0.100): 0.041*\"election\" + 0.039*\"odinga\" + 0.038*\"kenya\" + 0.037*\"kenyatta\" + 0.027*\"rerun\" + 0.025*\"vote\" + 0.023*\"announced\" + 0.022*\"president\" + 0.020*\"uhuru\" + 0.019*\"opposition\"\n",
      "2019-10-29 00:44:02,036 : INFO : topic #1 (0.100): 0.040*\"election\" + 0.039*\"odinga\" + 0.031*\"kenyatta\" + 0.030*\"kenya\" + 0.030*\"vote\" + 0.021*\"leader\" + 0.021*\"court\" + 0.020*\"incumbent\" + 0.020*\"uhuru\" + 0.019*\"opposition\"\n",
      "2019-10-29 00:44:02,039 : INFO : topic #4 (0.100): 0.047*\"odinga\" + 0.044*\"election\" + 0.041*\"kenyatta\" + 0.035*\"rerun\" + 0.025*\"kenya\" + 0.022*\"vote\" + 0.022*\"announced\" + 0.021*\"august\" + 0.021*\"opposition\" + 0.020*\"nairobi\"\n",
      "2019-10-29 00:44:02,041 : INFO : topic #6 (0.100): 0.046*\"odinga\" + 0.045*\"kenyatta\" + 0.043*\"election\" + 0.039*\"kenya\" + 0.025*\"vote\" + 0.021*\"rerun\" + 0.020*\"leader\" + 0.020*\"claimed\" + 0.019*\"said\" + 0.019*\"incumbent\"\n",
      "2019-10-29 00:44:02,044 : INFO : topic diff=0.768454, rho=1.000000\n",
      "2019-10-29 00:44:02,466 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:02,470 : INFO : built Dictionary(325 unique tokens: ['previously', 'even', 'enterprise', 'person', 'agronomist']...) from 5 documents (total 2490 corpus positions)\n",
      "2019-10-29 00:44:02,474 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:02,476 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:02,477 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:02,481 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:02,482 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:02,592 : INFO : -7.821 per-word bound, 226.1 perplexity estimate based on a held-out corpus of 5 documents with 2490 words\n",
      "2019-10-29 00:44:02,593 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:02,601 : INFO : topic #4 (0.100): 0.016*\"cost\" + 0.016*\"hand\" + 0.016*\"free\" + 0.014*\"field\" + 0.012*\"agricultural\" + 0.011*\"automated\" + 0.011*\"automation\" + 0.010*\"said\" + 0.010*\"farm\" + 0.010*\"barley\"\n",
      "2019-10-29 00:44:02,603 : INFO : topic #1 (0.100): 0.016*\"hectare\" + 0.014*\"free\" + 0.013*\"cost\" + 0.012*\"crop\" + 0.011*\"automation\" + 0.011*\"field\" + 0.011*\"farm\" + 0.011*\"hand\" + 0.010*\"automated\" + 0.010*\"researcher\"\n",
      "2019-10-29 00:44:02,604 : INFO : topic #9 (0.100): 0.017*\"free\" + 0.015*\"hand\" + 0.014*\"automation\" + 0.012*\"cost\" + 0.011*\"hectare\" + 0.011*\"automated\" + 0.010*\"barley\" + 0.010*\"project\" + 0.010*\"agricultural\" + 0.010*\"field\"\n",
      "2019-10-29 00:44:02,606 : INFO : topic #6 (0.100): 0.015*\"hectare\" + 0.013*\"free\" + 0.012*\"cost\" + 0.012*\"project\" + 0.012*\"agricultural\" + 0.011*\"said\" + 0.011*\"field\" + 0.011*\"automation\" + 0.011*\"automated\" + 0.009*\"used\"\n",
      "2019-10-29 00:44:02,607 : INFO : topic #0 (0.100): 0.014*\"hand\" + 0.013*\"hectare\" + 0.012*\"field\" + 0.012*\"agricultural\" + 0.012*\"free\" + 0.011*\"cost\" + 0.011*\"said\" + 0.011*\"automation\" + 0.010*\"automated\" + 0.010*\"project\"\n",
      "2019-10-29 00:44:02,612 : INFO : topic diff=0.831170, rho=1.000000\n",
      "2019-10-29 00:44:03,007 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:03,008 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:44:03,009 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:03,010 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:03,012 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:03,014 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:03,015 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:03,028 : INFO : -6.051 per-word bound, 66.3 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:44:03,032 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:03,038 : INFO : topic #3 (0.100): 0.148*\"transcript\" + 0.117*\"page\" + 0.055*\"specific\" + 0.053*\"find\" + 0.049*\"back\" + 0.049*\"available\" + 0.047*\"cannot\" + 0.045*\"check\" + 0.043*\"note\" + 0.043*\"cnn\"\n",
      "2019-10-29 00:44:03,041 : INFO : topic #2 (0.100): 0.136*\"transcript\" + 0.078*\"page\" + 0.055*\"continually\" + 0.054*\"new\" + 0.049*\"specific\" + 0.049*\"back\" + 0.049*\"main\" + 0.049*\"return\" + 0.048*\"check\" + 0.047*\"later\"\n",
      "2019-10-29 00:44:03,043 : INFO : topic #7 (0.100): 0.198*\"transcript\" + 0.082*\"page\" + 0.051*\"later\" + 0.049*\"segment\" + 0.049*\"main\" + 0.047*\"cnn\" + 0.047*\"cannot\" + 0.047*\"new\" + 0.045*\"become\" + 0.044*\"updated\"\n",
      "2019-10-29 00:44:03,045 : INFO : topic #4 (0.100): 0.146*\"transcript\" + 0.084*\"page\" + 0.058*\"continually\" + 0.057*\"updated\" + 0.053*\"cannot\" + 0.051*\"later\" + 0.049*\"specific\" + 0.046*\"segment\" + 0.045*\"cnn\" + 0.045*\"return\"\n",
      "2019-10-29 00:44:03,048 : INFO : topic #1 (0.100): 0.148*\"transcript\" + 0.085*\"page\" + 0.057*\"return\" + 0.057*\"october\" + 0.050*\"later\" + 0.049*\"new\" + 0.048*\"available\" + 0.045*\"cnn\" + 0.045*\"back\" + 0.045*\"segment\"\n",
      "2019-10-29 00:44:03,051 : INFO : topic diff=0.730302, rho=1.000000\n",
      "2019-10-29 00:44:03,443 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:03,445 : INFO : built Dictionary(116 unique tokens: ['aviation', 'paris', 'completely', 'portion', 'described']...) from 5 documents (total 735 corpus positions)\n",
      "2019-10-29 00:44:03,447 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:03,450 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:03,453 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:03,457 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:03,460 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:03,511 : INFO : -7.211 per-word bound, 148.2 perplexity estimate based on a held-out corpus of 5 documents with 735 words\n",
      "2019-10-29 00:44:03,516 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:03,526 : INFO : topic #4 (0.100): 0.040*\"engine\" + 0.036*\"greenland\" + 0.035*\"part\" + 0.024*\"flight\" + 0.022*\"spotted\" + 0.018*\"air\" + 0.017*\"french\" + 0.016*\"september\" + 0.014*\"emergency\" + 0.013*\"said\"\n",
      "2019-10-29 00:44:03,528 : INFO : topic #5 (0.100): 0.048*\"engine\" + 0.035*\"flight\" + 0.033*\"part\" + 0.030*\"greenland\" + 0.021*\"air\" + 0.020*\"spotted\" + 0.015*\"september\" + 0.014*\"landing\" + 0.014*\"said\" + 0.013*\"france\"\n",
      "2019-10-29 00:44:03,531 : INFO : topic #3 (0.100): 0.040*\"engine\" + 0.039*\"flight\" + 0.035*\"part\" + 0.030*\"greenland\" + 0.022*\"spotted\" + 0.020*\"air\" + 0.014*\"france\" + 0.013*\"area\" + 0.013*\"french\" + 0.012*\"september\"\n",
      "2019-10-29 00:44:03,534 : INFO : topic #8 (0.100): 0.053*\"engine\" + 0.031*\"part\" + 0.031*\"greenland\" + 0.027*\"flight\" + 0.023*\"air\" + 0.016*\"area\" + 0.016*\"spotted\" + 0.016*\"september\" + 0.016*\"landing\" + 0.015*\"france\"\n",
      "2019-10-29 00:44:03,540 : INFO : topic #7 (0.100): 0.048*\"engine\" + 0.044*\"part\" + 0.025*\"greenland\" + 0.022*\"flight\" + 0.020*\"air\" + 0.018*\"spotted\" + 0.016*\"said\" + 0.016*\"september\" + 0.013*\"french\" + 0.012*\"emergency\"\n",
      "2019-10-29 00:44:03,542 : INFO : topic diff=0.754699, rho=1.000000\n",
      "2019-10-29 00:44:03,981 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:03,985 : INFO : built Dictionary(67 unique tokens: ['unforgivable', 'time', 'request', 'break', 'harassment']...) from 5 documents (total 415 corpus positions)\n",
      "2019-10-29 00:44:03,987 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:03,988 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:03,990 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:03,992 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:03,995 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:04,038 : INFO : -6.804 per-word bound, 111.8 perplexity estimate based on a held-out corpus of 5 documents with 415 words\n",
      "2019-10-29 00:44:04,042 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:04,050 : INFO : topic #7 (0.100): 0.051*\"weinstein\" + 0.029*\"chapman\" + 0.029*\"read\" + 0.025*\"young\" + 0.025*\"woman\" + 0.024*\"harvey\" + 0.024*\"statement\" + 0.022*\"leaving\" + 0.021*\"child\" + 0.020*\"new\"\n",
      "2019-10-29 00:44:04,054 : INFO : topic #1 (0.100): 0.045*\"weinstein\" + 0.027*\"leaving\" + 0.026*\"new\" + 0.026*\"wife\" + 0.025*\"magazine\" + 0.023*\"chapman\" + 0.023*\"allegation\" + 0.023*\"read\" + 0.022*\"cnn\" + 0.021*\"statement\"\n",
      "2019-10-29 00:44:04,058 : INFO : topic #8 (0.100): 0.044*\"weinstein\" + 0.028*\"wife\" + 0.028*\"harvey\" + 0.027*\"cnn\" + 0.026*\"leaving\" + 0.024*\"woman\" + 0.024*\"child\" + 0.023*\"chapman\" + 0.022*\"magazine\" + 0.022*\"statement\"\n",
      "2019-10-29 00:44:04,060 : INFO : topic #4 (0.100): 0.035*\"weinstein\" + 0.030*\"read\" + 0.026*\"harvey\" + 0.025*\"child\" + 0.025*\"new\" + 0.024*\"magazine\" + 0.024*\"young\" + 0.023*\"cnn\" + 0.022*\"leaving\" + 0.022*\"allegation\"\n",
      "2019-10-29 00:44:04,063 : INFO : topic #0 (0.100): 0.040*\"weinstein\" + 0.029*\"wife\" + 0.027*\"woman\" + 0.026*\"read\" + 0.025*\"magazine\" + 0.024*\"chapman\" + 0.024*\"young\" + 0.023*\"new\" + 0.021*\"allegation\" + 0.021*\"statement\"\n",
      "2019-10-29 00:44:04,065 : INFO : topic diff=0.676812, rho=1.000000\n",
      "2019-10-29 00:44:04,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:04,531 : INFO : built Dictionary(239 unique tokens: ['even', 'retreat', 'across', 'campaign', 'party']...) from 5 documents (total 1855 corpus positions)\n",
      "2019-10-29 00:44:04,534 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:04,536 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:04,537 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:04,539 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:04,540 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:04,643 : INFO : -7.512 per-word bound, 182.5 perplexity estimate based on a held-out corpus of 5 documents with 1855 words\n",
      "2019-10-29 00:44:04,645 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:04,653 : INFO : topic #4 (0.100): 0.030*\"weekend\" + 0.025*\"sen\" + 0.013*\"lobbyist\" + 0.013*\"r\" + 0.012*\"trip\" + 0.012*\"golf\" + 0.012*\"retreat\" + 0.011*\"resort\" + 0.011*\"hunter\" + 0.010*\"cardin\"\n",
      "2019-10-29 00:44:04,655 : INFO : topic #1 (0.100): 0.029*\"weekend\" + 0.023*\"sen\" + 0.015*\"r\" + 0.015*\"resort\" + 0.013*\"u\" + 0.013*\"lobbyist\" + 0.011*\"trip\" + 0.010*\"cabin\" + 0.010*\"hunter\" + 0.010*\"cardin\"\n",
      "2019-10-29 00:44:04,658 : INFO : topic #2 (0.100): 0.031*\"weekend\" + 0.019*\"lobbyist\" + 0.019*\"sen\" + 0.019*\"r\" + 0.012*\"resort\" + 0.010*\"beach\" + 0.010*\"retreat\" + 0.010*\"hunter\" + 0.009*\"cardin\" + 0.009*\"trip\"\n",
      "2019-10-29 00:44:04,661 : INFO : topic #9 (0.100): 0.039*\"weekend\" + 0.019*\"sen\" + 0.017*\"r\" + 0.015*\"lobbyist\" + 0.014*\"golf\" + 0.013*\"resort\" + 0.012*\"beach\" + 0.011*\"trip\" + 0.010*\"retreat\" + 0.010*\"cardin\"\n",
      "2019-10-29 00:44:04,664 : INFO : topic #8 (0.100): 0.027*\"weekend\" + 0.022*\"r\" + 0.019*\"sen\" + 0.013*\"resort\" + 0.011*\"lobbyist\" + 0.011*\"cardin\" + 0.010*\"trip\" + 0.010*\"golf\" + 0.010*\"hosted\" + 0.010*\"senator\"\n",
      "2019-10-29 00:44:04,667 : INFO : topic diff=0.806226, rho=1.000000\n",
      "2019-10-29 00:44:05,203 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:05,217 : INFO : built Dictionary(733 unique tokens: ['let', 'wave', 'velocity', 'blanket', 'frantically']...) from 5 documents (total 7220 corpus positions)\n",
      "2019-10-29 00:44:05,229 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:05,232 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:05,236 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:05,253 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:05,256 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:05,498 : INFO : -8.276 per-word bound, 309.9 perplexity estimate based on a held-out corpus of 5 documents with 7220 words\n",
      "2019-10-29 00:44:05,499 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:05,509 : INFO : topic #8 (0.100): 0.015*\"patient\" + 0.014*\"people\" + 0.014*\"victim\" + 0.014*\"hospital\" + 0.013*\"said\" + 0.009*\"one\" + 0.009*\"room\" + 0.008*\"blood\" + 0.007*\"make\" + 0.007*\"truck\"\n",
      "2019-10-29 00:44:05,511 : INFO : topic #3 (0.100): 0.025*\"said\" + 0.014*\"hospital\" + 0.014*\"people\" + 0.013*\"victim\" + 0.012*\"patient\" + 0.009*\"blood\" + 0.008*\"one\" + 0.007*\"doctor\" + 0.007*\"like\" + 0.006*\"room\"\n",
      "2019-10-29 00:44:05,512 : INFO : topic #4 (0.100): 0.017*\"said\" + 0.015*\"people\" + 0.013*\"hospital\" + 0.013*\"victim\" + 0.009*\"one\" + 0.008*\"patient\" + 0.008*\"blood\" + 0.007*\"room\" + 0.007*\"padgett\" + 0.007*\"sunrise\"\n",
      "2019-10-29 00:44:05,515 : INFO : topic #2 (0.100): 0.019*\"said\" + 0.018*\"people\" + 0.013*\"patient\" + 0.011*\"victim\" + 0.011*\"hospital\" + 0.007*\"kole\" + 0.007*\"shot\" + 0.007*\"make\" + 0.007*\"padgett\" + 0.007*\"one\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:05,517 : INFO : topic #1 (0.100): 0.022*\"said\" + 0.015*\"hospital\" + 0.012*\"people\" + 0.012*\"victim\" + 0.012*\"patient\" + 0.009*\"one\" + 0.007*\"padgett\" + 0.006*\"truck\" + 0.006*\"blood\" + 0.006*\"trauma\"\n",
      "2019-10-29 00:44:05,519 : INFO : topic diff=0.932452, rho=1.000000\n",
      "2019-10-29 00:44:05,930 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:05,934 : INFO : built Dictionary(277 unique tokens: ['product', 'bone', 'end', 'industry', 'manually']...) from 5 documents (total 2175 corpus positions)\n",
      "2019-10-29 00:44:05,938 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:05,939 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:05,941 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:05,944 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:05,946 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:06,048 : INFO : -7.629 per-word bound, 198.0 perplexity estimate based on a held-out corpus of 5 documents with 2175 words\n",
      "2019-10-29 00:44:06,050 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:06,058 : INFO : topic #0 (0.100): 0.027*\"design\" + 0.020*\"laarman\" + 0.018*\"new\" + 0.017*\"digital\" + 0.017*\"chair\" + 0.013*\"said\" + 0.012*\"3d\" + 0.011*\"make\" + 0.011*\"bone\" + 0.010*\"computer\"\n",
      "2019-10-29 00:44:06,060 : INFO : topic #8 (0.100): 0.034*\"design\" + 0.025*\"laarman\" + 0.014*\"chair\" + 0.014*\"3d\" + 0.013*\"joris\" + 0.012*\"said\" + 0.012*\"digital\" + 0.011*\"industrial\" + 0.011*\"bone\" + 0.010*\"make\"\n",
      "2019-10-29 00:44:06,063 : INFO : topic #9 (0.100): 0.034*\"design\" + 0.028*\"laarman\" + 0.016*\"chair\" + 0.015*\"new\" + 0.014*\"said\" + 0.014*\"digital\" + 0.013*\"industrial\" + 0.013*\"bone\" + 0.012*\"computer\" + 0.011*\"make\"\n",
      "2019-10-29 00:44:06,065 : INFO : topic #5 (0.100): 0.038*\"design\" + 0.031*\"laarman\" + 0.021*\"chair\" + 0.013*\"new\" + 0.013*\"said\" + 0.012*\"digital\" + 0.012*\"3d\" + 0.012*\"industrial\" + 0.012*\"material\" + 0.011*\"make\"\n",
      "2019-10-29 00:44:06,068 : INFO : topic #4 (0.100): 0.030*\"design\" + 0.025*\"laarman\" + 0.016*\"chair\" + 0.014*\"3d\" + 0.014*\"new\" + 0.013*\"digital\" + 0.011*\"computer\" + 0.010*\"joris\" + 0.010*\"said\" + 0.010*\"bone\"\n",
      "2019-10-29 00:44:06,070 : INFO : topic diff=0.842592, rho=1.000000\n",
      "2019-10-29 00:44:06,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:06,522 : INFO : built Dictionary(335 unique tokens: ['although', 'concern', 'caution', 'come', 'shut']...) from 5 documents (total 2875 corpus positions)\n",
      "2019-10-29 00:44:06,528 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:06,531 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:06,534 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:06,539 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:06,542 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:06,674 : INFO : -7.688 per-word bound, 206.2 perplexity estimate based on a held-out corpus of 5 documents with 2875 words\n",
      "2019-10-29 00:44:06,676 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:06,683 : INFO : topic #0 (0.100): 0.027*\"said\" + 0.026*\"rhabdomyolysis\" + 0.022*\"class\" + 0.015*\"kidney\" + 0.014*\"everett\" + 0.010*\"muscle\" + 0.010*\"case\" + 0.009*\"first\" + 0.009*\"spinning\" + 0.009*\"hospital\"\n",
      "2019-10-29 00:44:06,686 : INFO : topic #1 (0.100): 0.035*\"said\" + 0.020*\"rhabdomyolysis\" + 0.019*\"class\" + 0.014*\"muscle\" + 0.013*\"everett\" + 0.013*\"condition\" + 0.012*\"spinning\" + 0.010*\"case\" + 0.010*\"kidney\" + 0.009*\"exercise\"\n",
      "2019-10-29 00:44:06,688 : INFO : topic #2 (0.100): 0.033*\"said\" + 0.020*\"rhabdomyolysis\" + 0.017*\"muscle\" + 0.015*\"class\" + 0.013*\"everett\" + 0.012*\"condition\" + 0.012*\"kidney\" + 0.010*\"exercise\" + 0.009*\"medicine\" + 0.009*\"study\"\n",
      "2019-10-29 00:44:06,691 : INFO : topic #7 (0.100): 0.032*\"said\" + 0.022*\"rhabdomyolysis\" + 0.018*\"class\" + 0.016*\"kidney\" + 0.015*\"muscle\" + 0.013*\"everett\" + 0.011*\"hospital\" + 0.009*\"new\" + 0.009*\"dialysis\" + 0.009*\"medicine\"\n",
      "2019-10-29 00:44:06,694 : INFO : topic #5 (0.100): 0.035*\"said\" + 0.024*\"rhabdomyolysis\" + 0.016*\"muscle\" + 0.016*\"class\" + 0.013*\"everett\" + 0.013*\"condition\" + 0.012*\"kidney\" + 0.011*\"case\" + 0.010*\"new\" + 0.009*\"thigh\"\n",
      "2019-10-29 00:44:06,696 : INFO : topic diff=0.881542, rho=1.000000\n",
      "2019-10-29 00:44:07,147 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:07,154 : INFO : built Dictionary(416 unique tokens: ['located', 'person', 'laboratory', 'refine', 'recommendation']...) from 5 documents (total 5350 corpus positions)\n",
      "2019-10-29 00:44:07,160 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:07,161 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:07,162 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:07,166 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:07,168 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:07,293 : INFO : -7.441 per-word bound, 173.7 perplexity estimate based on a held-out corpus of 5 documents with 5350 words\n",
      "2019-10-29 00:44:07,295 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:07,302 : INFO : topic #7 (0.100): 0.072*\"drone\" + 0.043*\"could\" + 0.028*\"life\" + 0.023*\"save\" + 0.018*\"medical\" + 0.017*\"used\" + 0.011*\"emergency\" + 0.011*\"sample\" + 0.010*\"air\" + 0.009*\"kit\"\n",
      "2019-10-29 00:44:07,304 : INFO : topic #3 (0.100): 0.067*\"drone\" + 0.050*\"could\" + 0.026*\"used\" + 0.021*\"life\" + 0.018*\"save\" + 0.012*\"medical\" + 0.011*\"emergency\" + 0.011*\"air\" + 0.010*\"sample\" + 0.010*\"said\"\n",
      "2019-10-29 00:44:07,307 : INFO : topic #0 (0.100): 0.043*\"drone\" + 0.037*\"could\" + 0.033*\"life\" + 0.026*\"save\" + 0.025*\"used\" + 0.012*\"medical\" + 0.010*\"photo\" + 0.010*\"kit\" + 0.009*\"emergency\" + 0.008*\"said\"\n",
      "2019-10-29 00:44:07,309 : INFO : topic #1 (0.100): 0.064*\"drone\" + 0.036*\"could\" + 0.030*\"save\" + 0.026*\"life\" + 0.017*\"used\" + 0.017*\"medical\" + 0.010*\"photo\" + 0.010*\"said\" + 0.008*\"mississippi\" + 0.008*\"emergency\"\n",
      "2019-10-29 00:44:07,311 : INFO : topic #5 (0.100): 0.071*\"drone\" + 0.038*\"could\" + 0.022*\"used\" + 0.019*\"life\" + 0.019*\"save\" + 0.014*\"medical\" + 0.011*\"said\" + 0.010*\"photo\" + 0.010*\"air\" + 0.008*\"sample\"\n",
      "2019-10-29 00:44:07,313 : INFO : topic diff=0.881337, rho=1.000000\n",
      "2019-10-29 00:44:07,727 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:07,732 : INFO : built Dictionary(146 unique tokens: ['fox', 'tax', 'industry', 'francisco', 'sellout']...) from 5 documents (total 1025 corpus positions)\n",
      "2019-10-29 00:44:07,735 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:07,737 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:07,740 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:07,743 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:07,746 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:07,800 : INFO : -7.224 per-word bound, 149.5 perplexity estimate based on a held-out corpus of 5 documents with 1025 words\n",
      "2019-10-29 00:44:07,802 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:07,808 : INFO : topic #2 (0.100): 0.050*\"espn\" + 0.022*\"hill\" + 0.019*\"trump\" + 0.019*\"jemele\" + 0.018*\"cable\" + 0.017*\"talk\" + 0.016*\"tanked\" + 0.013*\"rating\" + 0.013*\"bundle\" + 0.012*\"player\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:07,812 : INFO : topic #4 (0.100): 0.053*\"espn\" + 0.029*\"hill\" + 0.025*\"tanked\" + 0.024*\"jemele\" + 0.015*\"cable\" + 0.014*\"trump\" + 0.014*\"rating\" + 0.014*\"million\" + 0.014*\"streaming\" + 0.013*\"talk\"\n",
      "2019-10-29 00:44:07,815 : INFO : topic #9 (0.100): 0.051*\"espn\" + 0.029*\"hill\" + 0.026*\"jemele\" + 0.022*\"tanked\" + 0.020*\"trump\" + 0.016*\"million\" + 0.015*\"player\" + 0.015*\"streaming\" + 0.013*\"suspended\" + 0.013*\"talk\"\n",
      "2019-10-29 00:44:07,817 : INFO : topic #3 (0.100): 0.053*\"espn\" + 0.030*\"hill\" + 0.027*\"tanked\" + 0.023*\"jemele\" + 0.018*\"cable\" + 0.015*\"million\" + 0.013*\"streaming\" + 0.013*\"trump\" + 0.012*\"talk\" + 0.012*\"rating\"\n",
      "2019-10-29 00:44:07,819 : INFO : topic #7 (0.100): 0.059*\"espn\" + 0.026*\"hill\" + 0.023*\"jemele\" + 0.021*\"tanked\" + 0.020*\"trump\" + 0.015*\"streaming\" + 0.014*\"player\" + 0.014*\"rating\" + 0.013*\"talk\" + 0.013*\"million\"\n",
      "2019-10-29 00:44:07,821 : INFO : topic diff=0.787666, rho=1.000000\n",
      "2019-10-29 00:44:08,267 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:08,271 : INFO : built Dictionary(273 unique tokens: ['located', 'translated', 'deep', 'industry', 'come']...) from 5 documents (total 2140 corpus positions)\n",
      "2019-10-29 00:44:08,274 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:08,276 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:08,277 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:08,283 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:08,286 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:08,396 : INFO : -7.619 per-word bound, 196.5 perplexity estimate based on a held-out corpus of 5 documents with 2140 words\n",
      "2019-10-29 00:44:08,398 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:08,405 : INFO : topic #8 (0.100): 0.025*\"po\" + 0.022*\"tung\" + 0.019*\"cheung\" + 0.016*\"restaurant\" + 0.015*\"hong\" + 0.013*\"kong\" + 0.013*\"beer\" + 0.012*\"black\" + 0.011*\"dish\" + 0.011*\"fried\"\n",
      "2019-10-29 00:44:08,408 : INFO : topic #9 (0.100): 0.026*\"po\" + 0.026*\"tung\" + 0.019*\"hong\" + 0.019*\"kong\" + 0.018*\"cheung\" + 0.017*\"restaurant\" + 0.015*\"black\" + 0.015*\"fried\" + 0.012*\"dish\" + 0.010*\"beer\"\n",
      "2019-10-29 00:44:08,412 : INFO : topic #7 (0.100): 0.032*\"tung\" + 0.025*\"po\" + 0.017*\"restaurant\" + 0.016*\"cheung\" + 0.014*\"black\" + 0.013*\"kong\" + 0.012*\"fried\" + 0.012*\"hong\" + 0.011*\"beer\" + 0.010*\"dance\"\n",
      "2019-10-29 00:44:08,414 : INFO : topic #2 (0.100): 0.029*\"tung\" + 0.026*\"po\" + 0.023*\"restaurant\" + 0.015*\"kong\" + 0.014*\"cheung\" + 0.013*\"hong\" + 0.012*\"black\" + 0.012*\"beer\" + 0.011*\"content\" + 0.011*\"dish\"\n",
      "2019-10-29 00:44:08,416 : INFO : topic #0 (0.100): 0.028*\"tung\" + 0.026*\"restaurant\" + 0.021*\"cheung\" + 0.019*\"hong\" + 0.019*\"po\" + 0.018*\"kong\" + 0.011*\"cnn\" + 0.010*\"fried\" + 0.010*\"content\" + 0.010*\"black\"\n",
      "2019-10-29 00:44:08,418 : INFO : topic diff=0.820299, rho=1.000000\n",
      "2019-10-29 00:44:08,901 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:08,911 : INFO : built Dictionary(571 unique tokens: ['earned', 'prime', 'person', 'bo', 'minglu']...) from 5 documents (total 5065 corpus positions)\n",
      "2019-10-29 00:44:08,920 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:08,923 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:08,926 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:08,930 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:08,933 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:09,151 : INFO : -8.156 per-word bound, 285.2 perplexity estimate based on a held-out corpus of 5 documents with 5065 words\n",
      "2019-10-29 00:44:09,153 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:09,163 : INFO : topic #2 (0.100): 0.031*\"china\" + 0.016*\"power\" + 0.013*\"said\" + 0.013*\"party\" + 0.012*\"xi\" + 0.011*\"wang\" + 0.010*\"one\" + 0.009*\"li\" + 0.008*\"powerful\" + 0.008*\"chinese\"\n",
      "2019-10-29 00:44:09,166 : INFO : topic #6 (0.100): 0.028*\"china\" + 0.015*\"xi\" + 0.015*\"power\" + 0.014*\"powerful\" + 0.012*\"party\" + 0.012*\"wang\" + 0.010*\"said\" + 0.009*\"chinese\" + 0.009*\"one\" + 0.009*\"president\"\n",
      "2019-10-29 00:44:09,169 : INFO : topic #8 (0.100): 0.035*\"china\" + 0.016*\"power\" + 0.014*\"xi\" + 0.014*\"party\" + 0.012*\"chinese\" + 0.011*\"said\" + 0.010*\"people\" + 0.009*\"wang\" + 0.009*\"powerful\" + 0.008*\"one\"\n",
      "2019-10-29 00:44:09,171 : INFO : topic #4 (0.100): 0.032*\"china\" + 0.018*\"xi\" + 0.016*\"said\" + 0.015*\"party\" + 0.013*\"wang\" + 0.012*\"one\" + 0.012*\"powerful\" + 0.011*\"power\" + 0.010*\"chinese\" + 0.009*\"people\"\n",
      "2019-10-29 00:44:09,176 : INFO : topic #9 (0.100): 0.027*\"china\" + 0.018*\"xi\" + 0.016*\"said\" + 0.015*\"party\" + 0.012*\"powerful\" + 0.012*\"one\" + 0.011*\"power\" + 0.011*\"chinese\" + 0.009*\"li\" + 0.009*\"president\"\n",
      "2019-10-29 00:44:09,179 : INFO : topic diff=0.892620, rho=1.000000\n",
      "2019-10-29 00:44:09,576 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:09,578 : INFO : built Dictionary(84 unique tokens: ['sock', 'help', 'school', 'food', 'morning']...) from 5 documents (total 595 corpus positions)\n",
      "2019-10-29 00:44:09,580 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:09,582 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:09,583 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:09,586 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:09,587 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:09,623 : INFO : -6.724 per-word bound, 105.7 perplexity estimate based on a held-out corpus of 5 documents with 595 words\n",
      "2019-10-29 00:44:09,626 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:09,638 : INFO : topic #3 (0.100): 0.061*\"romero\" + 0.048*\"student\" + 0.028*\"sonya\" + 0.027*\"wallace\" + 0.026*\"new\" + 0.025*\"lew\" + 0.023*\"elementary\" + 0.022*\"teaching\" + 0.019*\"mexico\" + 0.018*\"breakfast\"\n",
      "2019-10-29 00:44:09,643 : INFO : topic #8 (0.100): 0.066*\"romero\" + 0.050*\"student\" + 0.027*\"wallace\" + 0.022*\"teaching\" + 0.021*\"lew\" + 0.021*\"elementary\" + 0.020*\"new\" + 0.020*\"teacher\" + 0.020*\"sonya\" + 0.020*\"mexico\"\n",
      "2019-10-29 00:44:09,652 : INFO : topic #4 (0.100): 0.070*\"romero\" + 0.039*\"student\" + 0.030*\"mexico\" + 0.026*\"new\" + 0.026*\"elementary\" + 0.025*\"teaching\" + 0.025*\"wallace\" + 0.025*\"sonya\" + 0.022*\"lew\" + 0.019*\"school\"\n",
      "2019-10-29 00:44:09,655 : INFO : topic #7 (0.100): 0.080*\"romero\" + 0.034*\"teaching\" + 0.034*\"student\" + 0.026*\"wallace\" + 0.026*\"sonya\" + 0.025*\"lew\" + 0.023*\"elementary\" + 0.022*\"new\" + 0.022*\"mexico\" + 0.018*\"teacher\"\n",
      "2019-10-29 00:44:09,658 : INFO : topic #1 (0.100): 0.064*\"romero\" + 0.053*\"student\" + 0.026*\"wallace\" + 0.026*\"teaching\" + 0.024*\"new\" + 0.024*\"elementary\" + 0.023*\"mexico\" + 0.020*\"year\" + 0.019*\"lew\" + 0.019*\"kindergarten\"\n",
      "2019-10-29 00:44:09,662 : INFO : topic diff=0.806621, rho=1.000000\n",
      "2019-10-29 00:44:10,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:10,082 : INFO : built Dictionary(86 unique tokens: ['franco', 'andrade', 'filed', 'florida', 'evacuate']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:44:10,084 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:10,086 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:10,087 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:10,091 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:10,094 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:10,130 : INFO : -6.664 per-word bound, 101.4 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:44:10,132 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:10,140 : INFO : topic #5 (0.100): 0.045*\"died\" + 0.031*\"nursing\" + 0.029*\"resident\" + 0.027*\"facility\" + 0.027*\"home\" + 0.023*\"following\" + 0.022*\"franco\" + 0.022*\"family\" + 0.020*\"year\" + 0.019*\"lawsuit\"\n",
      "2019-10-29 00:44:10,143 : INFO : topic #8 (0.100): 0.047*\"died\" + 0.029*\"franco\" + 0.028*\"home\" + 0.028*\"resident\" + 0.025*\"year\" + 0.024*\"facility\" + 0.024*\"nursing\" + 0.023*\"week\" + 0.022*\"family\" + 0.021*\"old\"\n",
      "2019-10-29 00:44:10,146 : INFO : topic #3 (0.100): 0.048*\"died\" + 0.033*\"nursing\" + 0.028*\"franco\" + 0.027*\"resident\" + 0.026*\"home\" + 0.026*\"week\" + 0.024*\"following\" + 0.022*\"year\" + 0.022*\"old\" + 0.019*\"facility\"\n",
      "2019-10-29 00:44:10,151 : INFO : topic #0 (0.100): 0.039*\"died\" + 0.032*\"home\" + 0.029*\"resident\" + 0.029*\"franco\" + 0.028*\"nursing\" + 0.025*\"following\" + 0.024*\"year\" + 0.021*\"family\" + 0.021*\"week\" + 0.021*\"old\"\n",
      "2019-10-29 00:44:10,156 : INFO : topic #1 (0.100): 0.037*\"died\" + 0.034*\"home\" + 0.030*\"franco\" + 0.028*\"nursing\" + 0.026*\"resident\" + 0.026*\"florida\" + 0.025*\"facility\" + 0.022*\"old\" + 0.022*\"week\" + 0.020*\"family\"\n",
      "2019-10-29 00:44:10,159 : INFO : topic diff=0.805907, rho=1.000000\n",
      "2019-10-29 00:44:10,606 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:10,610 : INFO : built Dictionary(293 unique tokens: ['concern', 'school', 'antananarivo', 'part', 'strain']...) from 5 documents (total 2425 corpus positions)\n",
      "2019-10-29 00:44:10,614 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:10,616 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:10,617 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:10,620 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:10,621 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:10,726 : INFO : -7.611 per-word bound, 195.5 perplexity estimate based on a held-out corpus of 5 documents with 2425 words\n",
      "2019-10-29 00:44:10,727 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:10,735 : INFO : topic #8 (0.100): 0.032*\"plague\" + 0.015*\"said\" + 0.015*\"outbreak\" + 0.013*\"health\" + 0.012*\"case\" + 0.012*\"public\" + 0.012*\"also\" + 0.012*\"people\" + 0.011*\"pneumonic\" + 0.011*\"area\"\n",
      "2019-10-29 00:44:10,736 : INFO : topic #4 (0.100): 0.026*\"plague\" + 0.023*\"outbreak\" + 0.016*\"health\" + 0.016*\"person\" + 0.015*\"said\" + 0.014*\"public\" + 0.014*\"pneumonic\" + 0.012*\"madagascar\" + 0.011*\"also\" + 0.011*\"unusual\"\n",
      "2019-10-29 00:44:10,738 : INFO : topic #7 (0.100): 0.031*\"plague\" + 0.019*\"outbreak\" + 0.015*\"madagascar\" + 0.014*\"health\" + 0.014*\"public\" + 0.014*\"person\" + 0.013*\"said\" + 0.012*\"case\" + 0.012*\"pneumonic\" + 0.011*\"also\"\n",
      "2019-10-29 00:44:10,739 : INFO : topic #1 (0.100): 0.034*\"plague\" + 0.017*\"outbreak\" + 0.016*\"health\" + 0.015*\"said\" + 0.015*\"public\" + 0.013*\"people\" + 0.012*\"pneumonic\" + 0.011*\"case\" + 0.011*\"person\" + 0.010*\"area\"\n",
      "2019-10-29 00:44:10,741 : INFO : topic #2 (0.100): 0.030*\"plague\" + 0.017*\"outbreak\" + 0.016*\"said\" + 0.014*\"public\" + 0.014*\"case\" + 0.013*\"person\" + 0.013*\"also\" + 0.012*\"pneumonic\" + 0.012*\"antananarivo\" + 0.010*\"madagascar\"\n",
      "2019-10-29 00:44:10,742 : INFO : topic diff=0.888139, rho=1.000000\n",
      "2019-10-29 00:44:11,213 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:11,221 : INFO : built Dictionary(410 unique tokens: ['wheelchair', 'awoke', 'crawling', 'mistake', 'one']...) from 5 documents (total 3625 corpus positions)\n",
      "2019-10-29 00:44:11,231 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:11,236 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:11,239 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:11,243 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:11,247 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:11,405 : INFO : -7.839 per-word bound, 229.0 perplexity estimate based on a held-out corpus of 5 documents with 3625 words\n",
      "2019-10-29 00:44:11,407 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:11,416 : INFO : topic #2 (0.100): 0.036*\"gomez\" + 0.025*\"said\" + 0.015*\"woman\" + 0.014*\"nursing\" + 0.014*\"victim\" + 0.010*\"brian\" + 0.010*\"home\" + 0.009*\"center\" + 0.009*\"told\" + 0.008*\"one\"\n",
      "2019-10-29 00:44:11,418 : INFO : topic #6 (0.100): 0.039*\"said\" + 0.027*\"gomez\" + 0.016*\"home\" + 0.014*\"nursing\" + 0.013*\"woman\" + 0.012*\"center\" + 0.011*\"victim\" + 0.011*\"one\" + 0.009*\"brian\" + 0.007*\"told\"\n",
      "2019-10-29 00:44:11,420 : INFO : topic #9 (0.100): 0.036*\"gomez\" + 0.024*\"said\" + 0.016*\"victim\" + 0.016*\"nursing\" + 0.012*\"woman\" + 0.012*\"home\" + 0.011*\"center\" + 0.010*\"told\" + 0.010*\"brian\" + 0.009*\"facility\"\n",
      "2019-10-29 00:44:11,422 : INFO : topic #0 (0.100): 0.031*\"gomez\" + 0.027*\"said\" + 0.016*\"nursing\" + 0.015*\"woman\" + 0.011*\"home\" + 0.011*\"victim\" + 0.010*\"one\" + 0.010*\"center\" + 0.009*\"brian\" + 0.009*\"told\"\n",
      "2019-10-29 00:44:11,424 : INFO : topic #5 (0.100): 0.038*\"said\" + 0.028*\"gomez\" + 0.014*\"woman\" + 0.014*\"home\" + 0.012*\"nursing\" + 0.011*\"brian\" + 0.011*\"center\" + 0.010*\"victim\" + 0.009*\"told\" + 0.009*\"another\"\n",
      "2019-10-29 00:44:11,426 : INFO : topic diff=0.887465, rho=1.000000\n",
      "2019-10-29 00:44:11,964 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:11,979 : INFO : built Dictionary(1074 unique tokens: ['rage', 'let', 'real', 'happy', 'focus']...) from 5 documents (total 13905 corpus positions)\n",
      "2019-10-29 00:44:11,995 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:11,996 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:11,997 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:12,002 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:12,004 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:12,329 : INFO : -8.378 per-word bound, 332.7 perplexity estimate based on a held-out corpus of 5 documents with 13905 words\n",
      "2019-10-29 00:44:12,330 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:12,345 : INFO : topic #6 (0.100): 0.049*\"say\" + 0.019*\"immigrant\" + 0.017*\"people\" + 0.013*\"albertville\" + 0.010*\"immigration\" + 0.010*\"city\" + 0.008*\"job\" + 0.007*\"year\" + 0.007*\"school\" + 0.007*\"state\"\n",
      "2019-10-29 00:44:12,347 : INFO : topic #0 (0.100): 0.039*\"say\" + 0.024*\"immigrant\" + 0.017*\"albertville\" + 0.010*\"city\" + 0.009*\"people\" + 0.008*\"immigration\" + 0.008*\"school\" + 0.008*\"state\" + 0.006*\"work\" + 0.006*\"class\"\n",
      "2019-10-29 00:44:12,350 : INFO : topic #7 (0.100): 0.034*\"say\" + 0.019*\"immigrant\" + 0.019*\"albertville\" + 0.011*\"people\" + 0.011*\"school\" + 0.010*\"immigration\" + 0.009*\"city\" + 0.007*\"job\" + 0.007*\"american\" + 0.006*\"one\"\n",
      "2019-10-29 00:44:12,354 : INFO : topic #2 (0.100): 0.035*\"say\" + 0.021*\"immigrant\" + 0.019*\"albertville\" + 0.012*\"people\" + 0.011*\"immigration\" + 0.011*\"city\" + 0.009*\"year\" + 0.008*\"school\" + 0.006*\"job\" + 0.006*\"state\"\n",
      "2019-10-29 00:44:12,357 : INFO : topic #3 (0.100): 0.053*\"say\" + 0.019*\"immigrant\" + 0.016*\"albertville\" + 0.014*\"people\" + 0.011*\"city\" + 0.010*\"immigration\" + 0.008*\"school\" + 0.007*\"year\" + 0.007*\"state\" + 0.006*\"hispanic\"\n",
      "2019-10-29 00:44:12,360 : INFO : topic diff=1.052632, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:12,823 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:12,825 : INFO : built Dictionary(57 unique tokens: ['b', 'night', 'single', 'kendrick', 'home']...) from 5 documents (total 400 corpus positions)\n",
      "2019-10-29 00:44:12,828 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:12,830 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:12,833 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:12,835 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:12,837 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:12,861 : INFO : -6.436 per-word bound, 86.6 perplexity estimate based on a held-out corpus of 5 documents with 400 words\n",
      "2019-10-29 00:44:12,863 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:12,876 : INFO : topic #6 (0.100): 0.051*\"award\" + 0.050*\"cardi\" + 0.048*\"b\" + 0.042*\"freestyle\" + 0.036*\"eminem\" + 0.033*\"trump\" + 0.026*\"video\" + 0.024*\"hop\" + 0.024*\"night\" + 0.024*\"single\"\n",
      "2019-10-29 00:44:12,880 : INFO : topic #2 (0.100): 0.043*\"award\" + 0.041*\"cardi\" + 0.040*\"b\" + 0.035*\"eminem\" + 0.031*\"trump\" + 0.031*\"freestyle\" + 0.029*\"winner\" + 0.027*\"hip\" + 0.026*\"hop\" + 0.026*\"single\"\n",
      "2019-10-29 00:44:12,883 : INFO : topic #3 (0.100): 0.049*\"b\" + 0.047*\"cardi\" + 0.042*\"eminem\" + 0.038*\"trump\" + 0.037*\"award\" + 0.036*\"freestyle\" + 0.032*\"attack\" + 0.029*\"night\" + 0.024*\"winner\" + 0.024*\"bet\"\n",
      "2019-10-29 00:44:12,891 : INFO : topic #1 (0.100): 0.049*\"award\" + 0.046*\"b\" + 0.041*\"cardi\" + 0.040*\"trump\" + 0.029*\"eminem\" + 0.028*\"hip\" + 0.028*\"winner\" + 0.027*\"freestyle\" + 0.026*\"bet\" + 0.025*\"attack\"\n",
      "2019-10-29 00:44:12,899 : INFO : topic #8 (0.100): 0.048*\"cardi\" + 0.047*\"b\" + 0.035*\"award\" + 0.035*\"trump\" + 0.034*\"freestyle\" + 0.030*\"attack\" + 0.030*\"video\" + 0.029*\"eminem\" + 0.026*\"night\" + 0.026*\"single\"\n",
      "2019-10-29 00:44:12,910 : INFO : topic diff=0.767787, rho=1.000000\n",
      "2019-10-29 00:44:13,434 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:13,446 : INFO : built Dictionary(976 unique tokens: ['let', 'treasured', 'median', 'specie', 'focus']...) from 5 documents (total 10085 corpus positions)\n",
      "2019-10-29 00:44:13,456 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:13,457 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:13,459 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:13,464 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:13,467 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:13,753 : INFO : -8.496 per-word bound, 361.0 perplexity estimate based on a held-out corpus of 5 documents with 10085 words\n",
      "2019-10-29 00:44:13,755 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:13,769 : INFO : topic #0 (0.100): 0.048*\"bee\" + 0.021*\"bumblebee\" + 0.017*\"thorp\" + 0.013*\"franklin\" + 0.011*\"specie\" + 0.010*\"one\" + 0.008*\"diversity\" + 0.008*\"year\" + 0.007*\"hide\" + 0.007*\"yellow\"\n",
      "2019-10-29 00:44:13,771 : INFO : topic #8 (0.100): 0.030*\"bee\" + 0.019*\"thorp\" + 0.016*\"bumblebee\" + 0.016*\"franklin\" + 0.012*\"one\" + 0.010*\"specie\" + 0.009*\"like\" + 0.009*\"wild\" + 0.008*\"photo\" + 0.008*\"flower\"\n",
      "2019-10-29 00:44:13,774 : INFO : topic #4 (0.100): 0.037*\"bee\" + 0.018*\"thorp\" + 0.015*\"bumblebee\" + 0.014*\"franklin\" + 0.011*\"one\" + 0.010*\"like\" + 0.009*\"diversity\" + 0.008*\"specie\" + 0.008*\"hide\" + 0.008*\"yellow\"\n",
      "2019-10-29 00:44:13,777 : INFO : topic #2 (0.100): 0.042*\"bee\" + 0.018*\"thorp\" + 0.017*\"bumblebee\" + 0.017*\"franklin\" + 0.010*\"like\" + 0.010*\"told\" + 0.010*\"one\" + 0.009*\"specie\" + 0.009*\"diversity\" + 0.009*\"photo\"\n",
      "2019-10-29 00:44:13,780 : INFO : topic #9 (0.100): 0.042*\"bee\" + 0.018*\"bumblebee\" + 0.016*\"franklin\" + 0.014*\"thorp\" + 0.010*\"like\" + 0.009*\"specie\" + 0.008*\"caption\" + 0.008*\"wild\" + 0.007*\"one\" + 0.007*\"flower\"\n",
      "2019-10-29 00:44:13,782 : INFO : topic diff=0.987589, rho=1.000000\n",
      "2019-10-29 00:44:14,240 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:14,245 : INFO : built Dictionary(346 unique tokens: ['fresh', 'color', 'drinking', 'enjoy', 'local']...) from 5 documents (total 3200 corpus positions)\n",
      "2019-10-29 00:44:14,250 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:14,252 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:14,257 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:14,261 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:14,265 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:14,405 : INFO : -7.618 per-word bound, 196.5 perplexity estimate based on a held-out corpus of 5 documents with 3200 words\n",
      "2019-10-29 00:44:14,407 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:14,416 : INFO : topic #9 (0.100): 0.025*\"bar\" + 0.022*\"tokyo\" + 0.021*\"ginza\" + 0.019*\"japan\" + 0.019*\"ueno\" + 0.015*\"sushi\" + 0.011*\"beer\" + 0.010*\"go\" + 0.010*\"called\" + 0.010*\"favorite\"\n",
      "2019-10-29 00:44:14,418 : INFO : topic #7 (0.100): 0.035*\"bar\" + 0.024*\"tokyo\" + 0.019*\"ginza\" + 0.014*\"ueno\" + 0.014*\"like\" + 0.013*\"japan\" + 0.012*\"little\" + 0.010*\"beer\" + 0.010*\"called\" + 0.009*\"sushi\"\n",
      "2019-10-29 00:44:14,420 : INFO : topic #5 (0.100): 0.035*\"bar\" + 0.021*\"tokyo\" + 0.018*\"ginza\" + 0.018*\"like\" + 0.015*\"japan\" + 0.013*\"beer\" + 0.013*\"called\" + 0.013*\"ueno\" + 0.012*\"sushi\" + 0.010*\"bartender\"\n",
      "2019-10-29 00:44:14,422 : INFO : topic #8 (0.100): 0.041*\"bar\" + 0.023*\"ginza\" + 0.018*\"japan\" + 0.017*\"tokyo\" + 0.014*\"like\" + 0.013*\"little\" + 0.012*\"sushi\" + 0.012*\"beer\" + 0.012*\"called\" + 0.011*\"ueno\"\n",
      "2019-10-29 00:44:14,423 : INFO : topic #6 (0.100): 0.037*\"bar\" + 0.028*\"tokyo\" + 0.021*\"ginza\" + 0.020*\"japan\" + 0.016*\"like\" + 0.012*\"favorite\" + 0.012*\"beer\" + 0.011*\"little\" + 0.011*\"place\" + 0.010*\"menu\"\n",
      "2019-10-29 00:44:14,425 : INFO : topic diff=0.917519, rho=1.000000\n",
      "2019-10-29 00:44:14,811 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:14,813 : INFO : built Dictionary(60 unique tokens: ['extraordinary', 'material', 'daniel', 'break', 'individuality']...) from 5 documents (total 325 corpus positions)\n",
      "2019-10-29 00:44:14,814 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:14,815 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:14,817 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:14,820 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:14,821 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:14,851 : INFO : -7.012 per-word bound, 129.1 perplexity estimate based on a held-out corpus of 5 documents with 325 words\n",
      "2019-10-29 00:44:14,852 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:14,860 : INFO : topic #1 (0.100): 0.048*\"lismore\" + 0.034*\"style\" + 0.030*\"daniel\" + 0.027*\"short\" + 0.021*\"individuality\" + 0.020*\"jewelry\" + 0.020*\"think\" + 0.019*\"day\" + 0.019*\"soft\" + 0.019*\"long\"\n",
      "2019-10-29 00:44:14,861 : INFO : topic #7 (0.100): 0.038*\"lismore\" + 0.033*\"short\" + 0.031*\"style\" + 0.029*\"daniel\" + 0.021*\"serve\" + 0.020*\"shirt\" + 0.019*\"ornament\" + 0.018*\"flamboyant\" + 0.018*\"version\" + 0.018*\"flag\"\n",
      "2019-10-29 00:44:14,868 : INFO : topic #8 (0.100): 0.035*\"lismore\" + 0.032*\"style\" + 0.028*\"daniel\" + 0.021*\"short\" + 0.020*\"blending\" + 0.020*\"sense\" + 0.020*\"singular\" + 0.019*\"flying\" + 0.019*\"see\" + 0.018*\"film\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:14,871 : INFO : topic #4 (0.100): 0.045*\"lismore\" + 0.032*\"short\" + 0.025*\"style\" + 0.025*\"daniel\" + 0.019*\"point\" + 0.019*\"armor\" + 0.018*\"day\" + 0.018*\"even\" + 0.018*\"eye\" + 0.018*\"layer\"\n",
      "2019-10-29 00:44:14,875 : INFO : topic #0 (0.100): 0.034*\"short\" + 0.033*\"lismore\" + 0.027*\"style\" + 0.023*\"daniel\" + 0.019*\"ornament\" + 0.019*\"statement\" + 0.019*\"eye\" + 0.019*\"blending\" + 0.018*\"version\" + 0.018*\"helped\"\n",
      "2019-10-29 00:44:14,879 : INFO : topic diff=0.602630, rho=1.000000\n",
      "2019-10-29 00:44:15,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:15,297 : INFO : built Dictionary(112 unique tokens: ['violence', 'concern', 'school', 'book', 'end']...) from 5 documents (total 830 corpus positions)\n",
      "2019-10-29 00:44:15,299 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:15,301 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:15,302 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:15,305 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:15,307 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:15,359 : INFO : -6.899 per-word bound, 119.3 perplexity estimate based on a held-out corpus of 5 documents with 830 words\n",
      "2019-10-29 00:44:15,360 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:15,367 : INFO : topic #8 (0.100): 0.034*\"tower\" + 0.022*\"shooting\" + 0.022*\"shooter\" + 0.022*\"lavergne\" + 0.021*\"rampage\" + 0.020*\"vega\" + 0.019*\"la\" + 0.019*\"texas\" + 0.018*\"sniper\" + 0.017*\"shot\"\n",
      "2019-10-29 00:44:15,368 : INFO : topic #7 (0.100): 0.030*\"tower\" + 0.025*\"la\" + 0.023*\"whitman\" + 0.022*\"shooter\" + 0.022*\"lavergne\" + 0.022*\"shooting\" + 0.022*\"vega\" + 0.019*\"university\" + 0.018*\"rampage\" + 0.017*\"shot\"\n",
      "2019-10-29 00:44:15,369 : INFO : topic #0 (0.100): 0.031*\"tower\" + 0.023*\"shooting\" + 0.023*\"lavergne\" + 0.021*\"shooter\" + 0.021*\"many\" + 0.021*\"la\" + 0.019*\"sniper\" + 0.019*\"vega\" + 0.018*\"gary\" + 0.017*\"whitman\"\n",
      "2019-10-29 00:44:15,373 : INFO : topic #1 (0.100): 0.041*\"tower\" + 0.024*\"shooting\" + 0.024*\"vega\" + 0.024*\"lavergne\" + 0.019*\"university\" + 0.019*\"shooter\" + 0.018*\"la\" + 0.018*\"texas\" + 0.018*\"shot\" + 0.017*\"people\"\n",
      "2019-10-29 00:44:15,374 : INFO : topic #4 (0.100): 0.030*\"tower\" + 0.026*\"vega\" + 0.024*\"shooter\" + 0.022*\"la\" + 0.021*\"shooting\" + 0.021*\"whitman\" + 0.021*\"many\" + 0.020*\"people\" + 0.020*\"lavergne\" + 0.019*\"tragedy\"\n",
      "2019-10-29 00:44:15,376 : INFO : topic diff=0.819307, rho=1.000000\n",
      "2019-10-29 00:44:15,801 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:15,807 : INFO : built Dictionary(507 unique tokens: ['paradise', 'wave', 'deep', 'party', 'drinking']...) from 5 documents (total 3730 corpus positions)\n",
      "2019-10-29 00:44:15,813 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:15,815 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:15,819 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:15,824 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:15,828 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:15,990 : INFO : -8.311 per-word bound, 317.6 perplexity estimate based on a held-out corpus of 5 documents with 3730 words\n",
      "2019-10-29 00:44:15,991 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:16,000 : INFO : topic #0 (0.100): 0.025*\"puerto\" + 0.020*\"island\" + 0.014*\"rico\" + 0.013*\"ricans\" + 0.012*\"many\" + 0.009*\"united\" + 0.009*\"state\" + 0.008*\"would\" + 0.008*\"one\" + 0.007*\"new\"\n",
      "2019-10-29 00:44:16,002 : INFO : topic #5 (0.100): 0.025*\"puerto\" + 0.022*\"island\" + 0.013*\"state\" + 0.011*\"many\" + 0.010*\"ricans\" + 0.008*\"u\" + 0.008*\"would\" + 0.008*\"rico\" + 0.007*\"maria\" + 0.007*\"united\"\n",
      "2019-10-29 00:44:16,005 : INFO : topic #3 (0.100): 0.025*\"island\" + 0.021*\"puerto\" + 0.012*\"ricans\" + 0.011*\"many\" + 0.010*\"united\" + 0.010*\"rico\" + 0.008*\"state\" + 0.008*\"would\" + 0.007*\"new\" + 0.007*\"maria\"\n",
      "2019-10-29 00:44:16,008 : INFO : topic #4 (0.100): 0.030*\"puerto\" + 0.020*\"island\" + 0.013*\"ricans\" + 0.010*\"rico\" + 0.009*\"many\" + 0.008*\"state\" + 0.008*\"would\" + 0.007*\"united\" + 0.007*\"u\" + 0.007*\"family\"\n",
      "2019-10-29 00:44:16,010 : INFO : topic #6 (0.100): 0.026*\"puerto\" + 0.023*\"island\" + 0.018*\"ricans\" + 0.012*\"many\" + 0.010*\"state\" + 0.010*\"rico\" + 0.009*\"united\" + 0.007*\"maria\" + 0.006*\"would\" + 0.006*\"time\"\n",
      "2019-10-29 00:44:16,013 : INFO : topic diff=0.821648, rho=1.000000\n",
      "2019-10-29 00:44:16,458 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:16,464 : INFO : built Dictionary(326 unique tokens: ['earned', 'significant', 'port', '1990s', 'come']...) from 5 documents (total 2230 corpus positions)\n",
      "2019-10-29 00:44:16,470 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:16,471 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:16,472 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:16,477 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:16,480 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:16,597 : INFO : -8.002 per-word bound, 256.3 perplexity estimate based on a held-out corpus of 5 documents with 2230 words\n",
      "2019-10-29 00:44:16,599 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:16,608 : INFO : topic #9 (0.100): 0.033*\"cat\" + 0.015*\"island\" + 0.014*\"houtong\" + 0.011*\"rome\" + 0.008*\"hemingway\" + 0.008*\"argentina\" + 0.008*\"feline\" + 0.007*\"kapsa\" + 0.007*\"visitor\" + 0.007*\"city\"\n",
      "2019-10-29 00:44:16,610 : INFO : topic #6 (0.100): 0.053*\"cat\" + 0.014*\"island\" + 0.011*\"rome\" + 0.009*\"houtong\" + 0.008*\"visitor\" + 0.007*\"hemingway\" + 0.007*\"feline\" + 0.007*\"city\" + 0.007*\"tashirojima\" + 0.007*\"taiwan\"\n",
      "2019-10-29 00:44:16,613 : INFO : topic #0 (0.100): 0.046*\"cat\" + 0.022*\"island\" + 0.012*\"houtong\" + 0.011*\"rome\" + 0.009*\"kalkan\" + 0.008*\"kapsa\" + 0.008*\"local\" + 0.007*\"tourist\" + 0.007*\"city\" + 0.007*\"mine\"\n",
      "2019-10-29 00:44:16,616 : INFO : topic #8 (0.100): 0.055*\"cat\" + 0.017*\"island\" + 0.014*\"houtong\" + 0.010*\"hemingway\" + 0.008*\"kalkan\" + 0.008*\"rome\" + 0.008*\"town\" + 0.007*\"ruin\" + 0.007*\"since\" + 0.007*\"local\"\n",
      "2019-10-29 00:44:16,619 : INFO : topic #5 (0.100): 0.033*\"cat\" + 0.015*\"island\" + 0.011*\"rome\" + 0.009*\"houtong\" + 0.009*\"kapsa\" + 0.008*\"hemingway\" + 0.008*\"tourist\" + 0.008*\"argentina\" + 0.008*\"key\" + 0.007*\"kalkan\"\n",
      "2019-10-29 00:44:16,621 : INFO : topic diff=0.770414, rho=1.000000\n",
      "2019-10-29 00:44:17,045 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:17,048 : INFO : built Dictionary(108 unique tokens: ['affected', 'school', 'animal', 'let', 'continuing']...) from 5 documents (total 675 corpus positions)\n",
      "2019-10-29 00:44:17,050 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:17,051 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:17,053 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:17,056 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:17,057 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:17,109 : INFO : -7.173 per-word bound, 144.3 perplexity estimate based on a held-out corpus of 5 documents with 675 words\n",
      "2019-10-29 00:44:17,111 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:17,122 : INFO : topic #2 (0.100): 0.024*\"wine\" + 0.022*\"help\" + 0.021*\"sonoma\" + 0.017*\"rosa\" + 0.016*\"country\" + 0.016*\"pet\" + 0.016*\"spca\" + 0.015*\"fire\" + 0.015*\"food\" + 0.015*\"also\"\n",
      "2019-10-29 00:44:17,124 : INFO : topic #5 (0.100): 0.028*\"country\" + 0.024*\"help\" + 0.022*\"sonoma\" + 0.020*\"wine\" + 0.018*\"fire\" + 0.017*\"shelter\" + 0.016*\"place\" + 0.016*\"school\" + 0.016*\"food\" + 0.015*\"center\"\n",
      "2019-10-29 00:44:17,127 : INFO : topic #3 (0.100): 0.036*\"help\" + 0.020*\"country\" + 0.020*\"wine\" + 0.018*\"evacuated\" + 0.017*\"drop\" + 0.016*\"shelter\" + 0.016*\"santa\" + 0.016*\"county\" + 0.015*\"wildfire\" + 0.014*\"sonoma\"\n",
      "2019-10-29 00:44:17,132 : INFO : topic #9 (0.100): 0.028*\"help\" + 0.025*\"wine\" + 0.018*\"country\" + 0.018*\"sonoma\" + 0.018*\"evacuated\" + 0.018*\"rosa\" + 0.017*\"place\" + 0.017*\"santa\" + 0.016*\"center\" + 0.015*\"food\"\n",
      "2019-10-29 00:44:17,135 : INFO : topic #0 (0.100): 0.035*\"help\" + 0.022*\"wine\" + 0.020*\"country\" + 0.019*\"sonoma\" + 0.017*\"also\" + 0.017*\"relief\" + 0.016*\"needed\" + 0.015*\"drop\" + 0.015*\"place\" + 0.015*\"rosa\"\n",
      "2019-10-29 00:44:17,137 : INFO : topic diff=0.682304, rho=1.000000\n",
      "2019-10-29 00:44:17,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:17,564 : INFO : built Dictionary(107 unique tokens: ['wave', 'couched', 'nation', 'may', 'miami']...) from 5 documents (total 635 corpus positions)\n",
      "2019-10-29 00:44:17,566 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:17,567 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:17,573 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:17,577 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:17,581 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:17,632 : INFO : -7.266 per-word bound, 153.9 perplexity estimate based on a held-out corpus of 5 documents with 635 words\n",
      "2019-10-29 00:44:17,634 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:17,639 : INFO : topic #0 (0.100): 0.032*\"climate\" + 0.027*\"island\" + 0.026*\"change\" + 0.020*\"world\" + 0.019*\"degree\" + 0.018*\"future\" + 0.017*\"cnn\" + 0.016*\"sea\" + 0.016*\"marshall\" + 0.016*\"rising\"\n",
      "2019-10-29 00:44:17,642 : INFO : topic #8 (0.100): 0.029*\"island\" + 0.023*\"change\" + 0.021*\"climate\" + 0.020*\"world\" + 0.017*\"future\" + 0.017*\"degree\" + 0.017*\"could\" + 0.016*\"cnn\" + 0.015*\"one\" + 0.015*\"marshall\"\n",
      "2019-10-29 00:44:17,645 : INFO : topic #3 (0.100): 0.037*\"climate\" + 0.028*\"degree\" + 0.027*\"future\" + 0.023*\"island\" + 0.020*\"change\" + 0.015*\"one\" + 0.015*\"rising\" + 0.015*\"cnn\" + 0.015*\"could\" + 0.013*\"marshall\"\n",
      "2019-10-29 00:44:17,648 : INFO : topic #1 (0.100): 0.032*\"island\" + 0.026*\"climate\" + 0.024*\"degree\" + 0.021*\"future\" + 0.019*\"change\" + 0.016*\"one\" + 0.015*\"could\" + 0.015*\"people\" + 0.014*\"cnn\" + 0.013*\"rising\"\n",
      "2019-10-29 00:44:17,651 : INFO : topic #2 (0.100): 0.030*\"island\" + 0.025*\"climate\" + 0.019*\"degree\" + 0.019*\"change\" + 0.018*\"one\" + 0.017*\"future\" + 0.017*\"people\" + 0.016*\"cnn\" + 0.016*\"sea\" + 0.014*\"rising\"\n",
      "2019-10-29 00:44:17,653 : INFO : topic diff=0.681219, rho=1.000000\n",
      "2019-10-29 00:44:18,032 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:18,034 : INFO : built Dictionary(11 unique tokens: ['chat', 'behind', 'unfolds', 'facebook', 'messenger']...) from 5 documents (total 55 corpus positions)\n",
      "2019-10-29 00:44:18,036 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:18,038 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:18,040 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:18,042 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:18,044 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:18,052 : INFO : -6.364 per-word bound, 82.3 perplexity estimate based on a held-out corpus of 5 documents with 55 words\n",
      "2019-10-29 00:44:18,054 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:18,058 : INFO : topic #8 (0.100): 0.110*\"chat\" + 0.109*\"unfolds\" + 0.108*\"facebook\" + 0.098*\"happening\" + 0.091*\"world\" + 0.090*\"find\" + 0.087*\"behind\" + 0.079*\"guggenheim\" + 0.078*\"u\" + 0.074*\"scene\"\n",
      "2019-10-29 00:44:18,061 : INFO : topic #1 (0.100): 0.111*\"scene\" + 0.105*\"unfolds\" + 0.103*\"behind\" + 0.102*\"find\" + 0.095*\"u\" + 0.093*\"happening\" + 0.089*\"messenger\" + 0.081*\"world\" + 0.079*\"chat\" + 0.073*\"guggenheim\"\n",
      "2019-10-29 00:44:18,063 : INFO : topic #2 (0.100): 0.112*\"find\" + 0.109*\"happening\" + 0.107*\"messenger\" + 0.103*\"guggenheim\" + 0.092*\"behind\" + 0.087*\"scene\" + 0.086*\"u\" + 0.080*\"unfolds\" + 0.079*\"world\" + 0.075*\"chat\"\n",
      "2019-10-29 00:44:18,066 : INFO : topic #9 (0.100): 0.099*\"facebook\" + 0.098*\"chat\" + 0.098*\"u\" + 0.096*\"world\" + 0.095*\"scene\" + 0.091*\"happening\" + 0.090*\"guggenheim\" + 0.088*\"unfolds\" + 0.085*\"behind\" + 0.083*\"find\"\n",
      "2019-10-29 00:44:18,069 : INFO : topic #0 (0.100): 0.102*\"scene\" + 0.097*\"messenger\" + 0.097*\"u\" + 0.095*\"facebook\" + 0.094*\"happening\" + 0.093*\"guggenheim\" + 0.093*\"behind\" + 0.089*\"find\" + 0.085*\"world\" + 0.080*\"chat\"\n",
      "2019-10-29 00:44:18,071 : INFO : topic diff=0.500654, rho=1.000000\n",
      "2019-10-29 00:44:18,492 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:18,494 : INFO : built Dictionary(63 unique tokens: ['care', 'lavished', 'ebola', 'nation', 'problem']...) from 5 documents (total 440 corpus positions)\n",
      "2019-10-29 00:44:18,496 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:18,499 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:18,502 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:18,505 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:18,508 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:18,544 : INFO : -6.520 per-word bound, 91.8 perplexity estimate based on a held-out corpus of 5 documents with 440 words\n",
      "2019-10-29 00:44:18,546 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:18,553 : INFO : topic #1 (0.100): 0.063*\"nambia\" + 0.049*\"trump\" + 0.040*\"system\" + 0.037*\"namibia\" + 0.033*\"health\" + 0.033*\"leader\" + 0.030*\"african\" + 0.023*\"nation\" + 0.023*\"increasingly\" + 0.022*\"speech\"\n",
      "2019-10-29 00:44:18,556 : INFO : topic #2 (0.100): 0.044*\"trump\" + 0.043*\"nambia\" + 0.037*\"health\" + 0.037*\"leader\" + 0.034*\"african\" + 0.030*\"namibia\" + 0.027*\"praise\" + 0.026*\"system\" + 0.025*\"country\" + 0.023*\"self\"\n",
      "2019-10-29 00:44:18,560 : INFO : topic #9 (0.100): 0.058*\"trump\" + 0.053*\"nambia\" + 0.041*\"health\" + 0.026*\"leader\" + 0.026*\"increasingly\" + 0.025*\"praise\" + 0.025*\"namibia\" + 0.025*\"nation\" + 0.025*\"speech\" + 0.024*\"african\"\n",
      "2019-10-29 00:44:18,564 : INFO : topic #0 (0.100): 0.048*\"trump\" + 0.047*\"nambia\" + 0.037*\"leader\" + 0.037*\"system\" + 0.029*\"african\" + 0.026*\"health\" + 0.025*\"namibia\" + 0.023*\"sufficient\" + 0.023*\"self\" + 0.021*\"increasingly\"\n",
      "2019-10-29 00:44:18,568 : INFO : topic #6 (0.100): 0.051*\"trump\" + 0.047*\"system\" + 0.045*\"nambia\" + 0.037*\"namibia\" + 0.035*\"health\" + 0.028*\"african\" + 0.028*\"leader\" + 0.026*\"nation\" + 0.026*\"sufficient\" + 0.024*\"country\"\n",
      "2019-10-29 00:44:18,573 : INFO : topic diff=0.786835, rho=1.000000\n",
      "2019-10-29 00:44:18,993 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:18,996 : INFO : built Dictionary(153 unique tokens: ['forward', 'previously', 'story', 'completely', 'honorary']...) from 5 documents (total 1120 corpus positions)\n",
      "2019-10-29 00:44:18,998 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:19,002 : INFO : using symmetric eta at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:19,006 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:19,010 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:19,013 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:19,088 : INFO : -7.195 per-word bound, 146.5 perplexity estimate based on a held-out corpus of 5 documents with 1120 words\n",
      "2019-10-29 00:44:19,090 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:19,098 : INFO : topic #8 (0.100): 0.060*\"weinstein\" + 0.028*\"bafta\" + 0.020*\"said\" + 0.020*\"british\" + 0.017*\"woman\" + 0.016*\"membership\" + 0.016*\"film\" + 0.015*\"academy\" + 0.015*\"harvey\" + 0.014*\"industry\"\n",
      "2019-10-29 00:44:19,104 : INFO : topic #1 (0.100): 0.040*\"weinstein\" + 0.020*\"bafta\" + 0.020*\"academy\" + 0.020*\"british\" + 0.018*\"woman\" + 0.017*\"sexual\" + 0.016*\"said\" + 0.015*\"membership\" + 0.015*\"powerful\" + 0.013*\"allegation\"\n",
      "2019-10-29 00:44:19,108 : INFO : topic #5 (0.100): 0.044*\"weinstein\" + 0.027*\"bafta\" + 0.019*\"british\" + 0.019*\"membership\" + 0.018*\"academy\" + 0.015*\"woman\" + 0.014*\"said\" + 0.014*\"film\" + 0.013*\"allegation\" + 0.013*\"hollywood\"\n",
      "2019-10-29 00:44:19,111 : INFO : topic #4 (0.100): 0.049*\"weinstein\" + 0.029*\"bafta\" + 0.026*\"woman\" + 0.019*\"british\" + 0.016*\"membership\" + 0.016*\"said\" + 0.016*\"film\" + 0.014*\"behavior\" + 0.014*\"academy\" + 0.014*\"powerful\"\n",
      "2019-10-29 00:44:19,115 : INFO : topic #3 (0.100): 0.054*\"weinstein\" + 0.024*\"bafta\" + 0.020*\"woman\" + 0.019*\"membership\" + 0.018*\"said\" + 0.017*\"british\" + 0.016*\"art\" + 0.016*\"academy\" + 0.016*\"behavior\" + 0.014*\"hollywood\"\n",
      "2019-10-29 00:44:19,120 : INFO : topic diff=0.817399, rho=1.000000\n",
      "2019-10-29 00:44:19,534 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:19,538 : INFO : built Dictionary(327 unique tokens: ['dating', 'forward', 'school', 'come', 'focus']...) from 5 documents (total 2750 corpus positions)\n",
      "2019-10-29 00:44:19,542 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:19,544 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:19,545 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:19,549 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:19,552 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:19,680 : INFO : -7.693 per-word bound, 206.9 perplexity estimate based on a held-out corpus of 5 documents with 2750 words\n",
      "2019-10-29 00:44:19,682 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:19,690 : INFO : topic #1 (0.100): 0.030*\"std\" + 0.025*\"disease\" + 0.022*\"syphilis\" + 0.018*\"said\" + 0.017*\"case\" + 0.013*\"gonorrhea\" + 0.013*\"cdc\" + 0.012*\"harvey\" + 0.012*\"chlamydia\" + 0.011*\"people\"\n",
      "2019-10-29 00:44:19,693 : INFO : topic #5 (0.100): 0.032*\"std\" + 0.024*\"disease\" + 0.020*\"syphilis\" + 0.015*\"case\" + 0.014*\"chlamydia\" + 0.013*\"said\" + 0.011*\"gonorrhea\" + 0.011*\"health\" + 0.011*\"harvey\" + 0.010*\"people\"\n",
      "2019-10-29 00:44:19,696 : INFO : topic #2 (0.100): 0.033*\"std\" + 0.027*\"disease\" + 0.022*\"syphilis\" + 0.018*\"said\" + 0.014*\"harvey\" + 0.014*\"cdc\" + 0.013*\"case\" + 0.011*\"need\" + 0.011*\"people\" + 0.010*\"health\"\n",
      "2019-10-29 00:44:19,699 : INFO : topic #8 (0.100): 0.025*\"std\" + 0.024*\"disease\" + 0.023*\"syphilis\" + 0.019*\"case\" + 0.016*\"said\" + 0.013*\"gonorrhea\" + 0.012*\"cdc\" + 0.011*\"symptom\" + 0.011*\"health\" + 0.011*\"harvey\"\n",
      "2019-10-29 00:44:19,702 : INFO : topic #3 (0.100): 0.034*\"std\" + 0.022*\"disease\" + 0.021*\"syphilis\" + 0.019*\"said\" + 0.015*\"case\" + 0.013*\"chlamydia\" + 0.012*\"harvey\" + 0.011*\"people\" + 0.011*\"cdc\" + 0.010*\"health\"\n",
      "2019-10-29 00:44:19,704 : INFO : topic diff=0.869651, rho=1.000000\n",
      "2019-10-29 00:44:20,153 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:20,158 : INFO : built Dictionary(172 unique tokens: ['pushed', 'come', 'game', 'job', 'u']...) from 5 documents (total 1280 corpus positions)\n",
      "2019-10-29 00:44:20,161 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:20,162 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:20,163 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:20,165 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:20,167 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:20,246 : INFO : -7.279 per-word bound, 155.3 perplexity estimate based on a held-out corpus of 5 documents with 1280 words\n",
      "2019-10-29 00:44:20,247 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:20,256 : INFO : topic #4 (0.100): 0.029*\"united\" + 0.024*\"state\" + 0.021*\"u\" + 0.019*\"trinidad\" + 0.018*\"goal\" + 0.017*\"back\" + 0.015*\"cup\" + 0.015*\"time\" + 0.014*\"world\" + 0.014*\"tobago\"\n",
      "2019-10-29 00:44:20,258 : INFO : topic #6 (0.100): 0.031*\"united\" + 0.027*\"state\" + 0.022*\"goal\" + 0.018*\"u\" + 0.017*\"world\" + 0.016*\"back\" + 0.016*\"win\" + 0.015*\"trinidad\" + 0.015*\"tobago\" + 0.014*\"loss\"\n",
      "2019-10-29 00:44:20,260 : INFO : topic #1 (0.100): 0.031*\"state\" + 0.029*\"goal\" + 0.026*\"united\" + 0.018*\"cup\" + 0.017*\"time\" + 0.016*\"trinidad\" + 0.016*\"tobago\" + 0.015*\"u\" + 0.014*\"world\" + 0.013*\"got\"\n",
      "2019-10-29 00:44:20,262 : INFO : topic #7 (0.100): 0.029*\"state\" + 0.025*\"united\" + 0.021*\"goal\" + 0.017*\"cup\" + 0.017*\"win\" + 0.016*\"back\" + 0.015*\"world\" + 0.015*\"u\" + 0.014*\"time\" + 0.013*\"would\"\n",
      "2019-10-29 00:44:20,264 : INFO : topic #5 (0.100): 0.036*\"united\" + 0.029*\"state\" + 0.026*\"goal\" + 0.023*\"u\" + 0.021*\"trinidad\" + 0.018*\"loss\" + 0.016*\"tobago\" + 0.015*\"win\" + 0.013*\"match\" + 0.012*\"world\"\n",
      "2019-10-29 00:44:20,267 : INFO : topic diff=0.824553, rho=1.000000\n",
      "2019-10-29 00:44:20,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:20,718 : INFO : built Dictionary(420 unique tokens: ['although', 'animal', 'drinking', 'think', 'place']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:44:20,723 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:20,727 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:20,730 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:20,734 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:20,737 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:20,876 : INFO : -8.003 per-word bound, 256.6 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:44:20,878 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:20,886 : INFO : topic #7 (0.100): 0.030*\"york\" + 0.028*\"new\" + 0.016*\"w\" + 0.014*\"ny\" + 0.013*\"time\" + 0.012*\"square\" + 0.011*\"hotel\" + 0.011*\"best\" + 0.011*\"st\" + 0.010*\"city\"\n",
      "2019-10-29 00:44:20,888 : INFO : topic #3 (0.100): 0.026*\"new\" + 0.020*\"york\" + 0.016*\"square\" + 0.014*\"time\" + 0.013*\"ny\" + 0.011*\"w\" + 0.011*\"st\" + 0.010*\"city\" + 0.009*\"hotel\" + 0.008*\"park\"\n",
      "2019-10-29 00:44:20,890 : INFO : topic #9 (0.100): 0.022*\"time\" + 0.020*\"new\" + 0.020*\"york\" + 0.019*\"square\" + 0.015*\"ny\" + 0.012*\"city\" + 0.011*\"w\" + 0.010*\"st\" + 0.010*\"hotel\" + 0.007*\"park\"\n",
      "2019-10-29 00:44:20,892 : INFO : topic #1 (0.100): 0.025*\"york\" + 0.021*\"new\" + 0.020*\"square\" + 0.018*\"time\" + 0.016*\"ny\" + 0.011*\"st\" + 0.010*\"w\" + 0.008*\"park\" + 0.008*\"city\" + 0.007*\"restaurant\"\n",
      "2019-10-29 00:44:20,894 : INFO : topic #8 (0.100): 0.027*\"new\" + 0.020*\"york\" + 0.020*\"time\" + 0.015*\"ny\" + 0.014*\"square\" + 0.012*\"w\" + 0.011*\"city\" + 0.010*\"hotel\" + 0.009*\"bar\" + 0.008*\"st\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:20,897 : INFO : topic diff=0.851085, rho=1.000000\n",
      "2019-10-29 00:44:21,314 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:21,318 : INFO : built Dictionary(350 unique tokens: ['let', 'camp', 'trying', 'one', 'self']...) from 5 documents (total 2490 corpus positions)\n",
      "2019-10-29 00:44:21,322 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:21,325 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:21,327 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:21,331 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:21,332 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:21,463 : INFO : -8.005 per-word bound, 256.8 perplexity estimate based on a held-out corpus of 5 documents with 2490 words\n",
      "2019-10-29 00:44:21,464 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:21,473 : INFO : topic #4 (0.100): 0.022*\"gun\" + 0.010*\"problem\" + 0.009*\"one\" + 0.009*\"school\" + 0.008*\"cousin\" + 0.008*\"three\" + 0.008*\"college\" + 0.008*\"mom\" + 0.007*\"shot\" + 0.007*\"deb\"\n",
      "2019-10-29 00:44:21,474 : INFO : topic #8 (0.100): 0.025*\"gun\" + 0.010*\"problem\" + 0.009*\"friend\" + 0.009*\"fun\" + 0.009*\"cousin\" + 0.008*\"school\" + 0.008*\"three\" + 0.008*\"gunman\" + 0.007*\"college\" + 0.007*\"vega\"\n",
      "2019-10-29 00:44:21,476 : INFO : topic #6 (0.100): 0.028*\"gun\" + 0.011*\"problem\" + 0.010*\"one\" + 0.009*\"three\" + 0.009*\"vega\" + 0.008*\"violence\" + 0.008*\"college\" + 0.008*\"shot\" + 0.008*\"could\" + 0.008*\"fun\"\n",
      "2019-10-29 00:44:21,477 : INFO : topic #9 (0.100): 0.022*\"gun\" + 0.012*\"problem\" + 0.010*\"vega\" + 0.008*\"violence\" + 0.008*\"mom\" + 0.008*\"cousin\" + 0.008*\"college\" + 0.008*\"three\" + 0.008*\"one\" + 0.007*\"school\"\n",
      "2019-10-29 00:44:21,480 : INFO : topic #7 (0.100): 0.025*\"gun\" + 0.011*\"problem\" + 0.008*\"school\" + 0.008*\"god\" + 0.008*\"college\" + 0.007*\"friend\" + 0.007*\"health\" + 0.007*\"mom\" + 0.007*\"three\" + 0.007*\"vega\"\n",
      "2019-10-29 00:44:21,482 : INFO : topic diff=0.771898, rho=1.000000\n",
      "2019-10-29 00:44:21,889 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:21,893 : INFO : built Dictionary(224 unique tokens: ['deep', 'party', 'come', 'victory', 'language']...) from 5 documents (total 1590 corpus positions)\n",
      "2019-10-29 00:44:21,896 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:21,898 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:21,899 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:21,903 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:21,904 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:22,007 : INFO : -7.594 per-word bound, 193.2 perplexity estimate based on a held-out corpus of 5 documents with 1590 words\n",
      "2019-10-29 00:44:22,008 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:22,016 : INFO : topic #9 (0.100): 0.025*\"trump\" + 0.018*\"class\" + 0.016*\"american\" + 0.014*\"country\" + 0.013*\"even\" + 0.013*\"america\" + 0.011*\"culture\" + 0.010*\"watch\" + 0.010*\"watched\" + 0.009*\"fear\"\n",
      "2019-10-29 00:44:22,018 : INFO : topic #5 (0.100): 0.039*\"trump\" + 0.018*\"american\" + 0.017*\"even\" + 0.016*\"class\" + 0.013*\"people\" + 0.012*\"country\" + 0.011*\"decade\" + 0.010*\"one\" + 0.010*\"zakaria\" + 0.010*\"america\"\n",
      "2019-10-29 00:44:22,020 : INFO : topic #6 (0.100): 0.045*\"trump\" + 0.018*\"even\" + 0.016*\"american\" + 0.015*\"class\" + 0.011*\"cnn\" + 0.011*\"decade\" + 0.010*\"would\" + 0.010*\"donald\" + 0.010*\"elite\" + 0.010*\"watched\"\n",
      "2019-10-29 00:44:22,024 : INFO : topic #1 (0.100): 0.037*\"trump\" + 0.019*\"class\" + 0.016*\"even\" + 0.012*\"american\" + 0.011*\"america\" + 0.011*\"watched\" + 0.011*\"country\" + 0.011*\"zakaria\" + 0.010*\"economy\" + 0.010*\"watch\"\n",
      "2019-10-29 00:44:22,027 : INFO : topic #0 (0.100): 0.039*\"trump\" + 0.017*\"even\" + 0.014*\"class\" + 0.013*\"america\" + 0.012*\"cnn\" + 0.012*\"american\" + 0.011*\"country\" + 0.011*\"watch\" + 0.010*\"must\" + 0.010*\"culture\"\n",
      "2019-10-29 00:44:22,030 : INFO : topic diff=0.779220, rho=1.000000\n",
      "2019-10-29 00:44:22,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:22,455 : INFO : built Dictionary(115 unique tokens: ['special', 'way', 'series', 'harrison', 'one']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:44:22,456 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:22,460 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:22,464 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:22,467 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:22,470 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:22,520 : INFO : -7.466 per-word bound, 176.9 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:44:22,523 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:22,531 : INFO : topic #7 (0.100): 0.031*\"blade\" + 0.025*\"runner\" + 0.019*\"westworld\" + 0.015*\"character\" + 0.015*\"even\" + 0.014*\"movie\" + 0.014*\"original\" + 0.013*\"k\" + 0.011*\"quite\" + 0.010*\"still\"\n",
      "2019-10-29 00:44:22,533 : INFO : topic #8 (0.100): 0.028*\"blade\" + 0.021*\"runner\" + 0.020*\"westworld\" + 0.017*\"original\" + 0.017*\"movie\" + 0.017*\"even\" + 0.014*\"character\" + 0.013*\"k\" + 0.011*\"harrison\" + 0.011*\"citizen\"\n",
      "2019-10-29 00:44:22,535 : INFO : topic #1 (0.100): 0.032*\"blade\" + 0.026*\"runner\" + 0.024*\"westworld\" + 0.018*\"k\" + 0.017*\"even\" + 0.017*\"character\" + 0.016*\"movie\" + 0.013*\"original\" + 0.011*\"amusement\" + 0.010*\"android\"\n",
      "2019-10-29 00:44:22,539 : INFO : topic #2 (0.100): 0.034*\"runner\" + 0.028*\"blade\" + 0.021*\"westworld\" + 0.017*\"character\" + 0.016*\"even\" + 0.016*\"k\" + 0.014*\"original\" + 0.013*\"movie\" + 0.010*\"compassion\" + 0.010*\"creation\"\n",
      "2019-10-29 00:44:22,543 : INFO : topic #6 (0.100): 0.029*\"runner\" + 0.027*\"blade\" + 0.023*\"westworld\" + 0.015*\"even\" + 0.013*\"character\" + 0.013*\"k\" + 0.013*\"original\" + 0.013*\"movie\" + 0.010*\"one\" + 0.010*\"cnn\"\n",
      "2019-10-29 00:44:22,546 : INFO : topic diff=0.642022, rho=1.000000\n",
      "2019-10-29 00:44:23,019 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:23,026 : INFO : built Dictionary(382 unique tokens: ['creak', 'deep', 'doc', 'wheel', 'drive']...) from 5 documents (total 2570 corpus positions)\n",
      "2019-10-29 00:44:23,032 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:23,033 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:23,035 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:23,039 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:23,041 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:23,223 : INFO : -8.183 per-word bound, 290.7 perplexity estimate based on a held-out corpus of 5 documents with 2570 words\n",
      "2019-10-29 00:44:23,225 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:23,234 : INFO : topic #8 (0.100): 0.012*\"one\" + 0.011*\"body\" + 0.010*\"new\" + 0.009*\"sidewalk\" + 0.008*\"people\" + 0.008*\"death\" + 0.007*\"city\" + 0.007*\"watch\" + 0.007*\"would\" + 0.007*\"foot\"\n",
      "2019-10-29 00:44:23,236 : INFO : topic #0 (0.100): 0.012*\"people\" + 0.011*\"new\" + 0.009*\"sidewalk\" + 0.009*\"one\" + 0.008*\"city\" + 0.008*\"watch\" + 0.008*\"death\" + 0.007*\"body\" + 0.007*\"foot\" + 0.007*\"turn\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:23,239 : INFO : topic #4 (0.100): 0.010*\"new\" + 0.010*\"body\" + 0.009*\"people\" + 0.008*\"turn\" + 0.008*\"would\" + 0.007*\"person\" + 0.007*\"u\" + 0.007*\"nearly\" + 0.007*\"get\" + 0.007*\"foot\"\n",
      "2019-10-29 00:44:23,242 : INFO : topic #2 (0.100): 0.010*\"one\" + 0.009*\"new\" + 0.009*\"people\" + 0.009*\"turn\" + 0.008*\"start\" + 0.008*\"city\" + 0.007*\"u\" + 0.007*\"sidewalk\" + 0.007*\"body\" + 0.007*\"dead\"\n",
      "2019-10-29 00:44:23,245 : INFO : topic #7 (0.100): 0.013*\"new\" + 0.012*\"one\" + 0.009*\"would\" + 0.009*\"death\" + 0.008*\"body\" + 0.007*\"foot\" + 0.007*\"watch\" + 0.007*\"people\" + 0.007*\"city\" + 0.007*\"way\"\n",
      "2019-10-29 00:44:23,248 : INFO : topic diff=0.736925, rho=1.000000\n",
      "2019-10-29 00:44:23,742 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:23,747 : INFO : built Dictionary(197 unique tokens: ['con', 'campaign', 'advantage', 'game', 'theft']...) from 5 documents (total 1500 corpus positions)\n",
      "2019-10-29 00:44:23,751 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:23,753 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:23,756 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:23,760 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:23,763 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:23,873 : INFO : -7.368 per-word bound, 165.2 perplexity estimate based on a held-out corpus of 5 documents with 1500 words\n",
      "2019-10-29 00:44:23,875 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:23,882 : INFO : topic #7 (0.100): 0.029*\"smith\" + 0.025*\"gofundme\" + 0.017*\"say\" + 0.017*\"said\" + 0.016*\"money\" + 0.015*\"one\" + 0.015*\"cancer\" + 0.014*\"record\" + 0.013*\"police\" + 0.013*\"find\"\n",
      "2019-10-29 00:44:23,884 : INFO : topic #9 (0.100): 0.021*\"said\" + 0.020*\"smith\" + 0.018*\"money\" + 0.017*\"say\" + 0.015*\"gofundme\" + 0.015*\"record\" + 0.015*\"county\" + 0.013*\"one\" + 0.013*\"medical\" + 0.012*\"fossum\"\n",
      "2019-10-29 00:44:23,887 : INFO : topic #1 (0.100): 0.024*\"smith\" + 0.022*\"gofundme\" + 0.020*\"say\" + 0.019*\"said\" + 0.018*\"money\" + 0.016*\"police\" + 0.015*\"medical\" + 0.014*\"county\" + 0.014*\"cancer\" + 0.013*\"find\"\n",
      "2019-10-29 00:44:23,890 : INFO : topic #3 (0.100): 0.024*\"smith\" + 0.020*\"gofundme\" + 0.017*\"money\" + 0.016*\"say\" + 0.015*\"said\" + 0.015*\"one\" + 0.014*\"cancer\" + 0.013*\"medical\" + 0.013*\"fossum\" + 0.012*\"record\"\n",
      "2019-10-29 00:44:23,893 : INFO : topic #6 (0.100): 0.023*\"smith\" + 0.021*\"gofundme\" + 0.020*\"said\" + 0.018*\"say\" + 0.015*\"one\" + 0.014*\"money\" + 0.014*\"find\" + 0.012*\"record\" + 0.012*\"county\" + 0.012*\"fossum\"\n",
      "2019-10-29 00:44:23,896 : INFO : topic diff=0.827657, rho=1.000000\n",
      "2019-10-29 00:44:24,370 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:24,378 : INFO : built Dictionary(482 unique tokens: ['although', 'closure', 'selection', 'color', 'party']...) from 5 documents (total 3375 corpus positions)\n",
      "2019-10-29 00:44:24,384 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:24,385 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:24,386 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:24,390 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:24,392 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:24,586 : INFO : -8.340 per-word bound, 324.1 perplexity estimate based on a held-out corpus of 5 documents with 3375 words\n",
      "2019-10-29 00:44:24,588 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:24,598 : INFO : topic #6 (0.100): 0.028*\"schrager\" + 0.016*\"studio\" + 0.013*\"club\" + 0.012*\"say\" + 0.010*\"people\" + 0.009*\"party\" + 0.008*\"year\" + 0.008*\"rubell\" + 0.007*\"celebrity\" + 0.006*\"book\"\n",
      "2019-10-29 00:44:24,600 : INFO : topic #8 (0.100): 0.023*\"schrager\" + 0.014*\"studio\" + 0.012*\"say\" + 0.011*\"still\" + 0.011*\"celebrity\" + 0.011*\"people\" + 0.010*\"club\" + 0.008*\"new\" + 0.007*\"even\" + 0.006*\"rubell\"\n",
      "2019-10-29 00:44:24,603 : INFO : topic #9 (0.100): 0.023*\"schrager\" + 0.016*\"say\" + 0.016*\"studio\" + 0.013*\"people\" + 0.012*\"club\" + 0.009*\"party\" + 0.009*\"still\" + 0.009*\"rubell\" + 0.007*\"book\" + 0.007*\"celebrity\"\n",
      "2019-10-29 00:44:24,606 : INFO : topic #2 (0.100): 0.026*\"schrager\" + 0.019*\"studio\" + 0.016*\"say\" + 0.011*\"people\" + 0.010*\"club\" + 0.010*\"party\" + 0.008*\"celebrity\" + 0.008*\"still\" + 0.008*\"new\" + 0.006*\"year\"\n",
      "2019-10-29 00:44:24,609 : INFO : topic #7 (0.100): 0.027*\"schrager\" + 0.018*\"studio\" + 0.014*\"people\" + 0.013*\"say\" + 0.011*\"club\" + 0.010*\"new\" + 0.009*\"party\" + 0.009*\"rubell\" + 0.008*\"celebrity\" + 0.007*\"still\"\n",
      "2019-10-29 00:44:24,611 : INFO : topic diff=0.798754, rho=1.000000\n",
      "2019-10-29 00:44:25,106 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:25,114 : INFO : built Dictionary(289 unique tokens: ['trying', 'single', 'end', 'spun', 'come']...) from 5 documents (total 3105 corpus positions)\n",
      "2019-10-29 00:44:25,120 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:25,123 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:25,127 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:25,131 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:25,134 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:25,293 : INFO : -7.276 per-word bound, 155.0 perplexity estimate based on a held-out corpus of 5 documents with 3105 words\n",
      "2019-10-29 00:44:25,295 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:25,304 : INFO : topic #7 (0.100): 0.042*\"hamilton\" + 0.035*\"win\" + 0.030*\"ferrari\" + 0.028*\"vettel\" + 0.024*\"race\" + 0.024*\"start\" + 0.019*\"dream\" + 0.019*\"gift\" + 0.019*\"nightmare\" + 0.018*\"hide\"\n",
      "2019-10-29 00:44:25,307 : INFO : topic #0 (0.100): 0.049*\"ferrari\" + 0.040*\"hamilton\" + 0.028*\"vettel\" + 0.024*\"win\" + 0.023*\"start\" + 0.021*\"photo\" + 0.019*\"caption\" + 0.019*\"dream\" + 0.017*\"hide\" + 0.017*\"nightmare\"\n",
      "2019-10-29 00:44:25,310 : INFO : topic #1 (0.100): 0.046*\"hamilton\" + 0.036*\"ferrari\" + 0.030*\"vettel\" + 0.025*\"start\" + 0.024*\"win\" + 0.020*\"caption\" + 0.018*\"hide\" + 0.017*\"race\" + 0.017*\"dream\" + 0.016*\"photo\"\n",
      "2019-10-29 00:44:25,312 : INFO : topic #4 (0.100): 0.034*\"ferrari\" + 0.031*\"vettel\" + 0.029*\"hamilton\" + 0.026*\"win\" + 0.021*\"race\" + 0.021*\"caption\" + 0.020*\"start\" + 0.020*\"gift\" + 0.019*\"photo\" + 0.017*\"hide\"\n",
      "2019-10-29 00:44:25,315 : INFO : topic #6 (0.100): 0.037*\"win\" + 0.030*\"hamilton\" + 0.029*\"start\" + 0.027*\"vettel\" + 0.023*\"ferrari\" + 0.021*\"photo\" + 0.021*\"race\" + 0.019*\"gift\" + 0.018*\"caption\" + 0.017*\"nightmare\"\n",
      "2019-10-29 00:44:25,318 : INFO : topic diff=1.067984, rho=1.000000\n",
      "2019-10-29 00:44:25,753 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:25,756 : INFO : built Dictionary(69 unique tokens: ['evident', 'deadly', 'loss', 'visible', 'home']...) from 5 documents (total 495 corpus positions)\n",
      "2019-10-29 00:44:25,758 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:25,760 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:25,765 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:25,768 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:25,771 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:25,802 : INFO : -6.550 per-word bound, 93.7 perplexity estimate based on a held-out corpus of 5 documents with 495 words\n",
      "2019-10-29 00:44:25,805 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:25,811 : INFO : topic #4 (0.100): 0.066*\"officer\" + 0.050*\"u\" + 0.037*\"ship\" + 0.024*\"said\" + 0.022*\"statement\" + 0.021*\"collision\" + 0.021*\"accident\" + 0.021*\"commanding\" + 0.021*\"exercised\" + 0.020*\"duty\"\n",
      "2019-10-29 00:44:25,813 : INFO : topic #1 (0.100): 0.064*\"officer\" + 0.051*\"u\" + 0.030*\"ship\" + 0.027*\"statement\" + 0.024*\"mccain\" + 0.023*\"poor\" + 0.023*\"duty\" + 0.023*\"destroyer\" + 0.023*\"relieved\" + 0.021*\"accident\"\n",
      "2019-10-29 00:44:25,816 : INFO : topic #5 (0.100): 0.077*\"officer\" + 0.067*\"u\" + 0.036*\"ship\" + 0.034*\"statement\" + 0.021*\"duty\" + 0.021*\"said\" + 0.020*\"accident\" + 0.019*\"mccain\" + 0.018*\"navy\" + 0.018*\"japan\"\n",
      "2019-10-29 00:44:25,819 : INFO : topic #9 (0.100): 0.063*\"officer\" + 0.033*\"u\" + 0.031*\"ship\" + 0.025*\"accident\" + 0.024*\"collision\" + 0.023*\"statement\" + 0.023*\"cmdr\" + 0.022*\"poor\" + 0.022*\"commanding\" + 0.022*\"relieved\"\n",
      "2019-10-29 00:44:25,823 : INFO : topic #2 (0.100): 0.058*\"officer\" + 0.046*\"ship\" + 0.044*\"u\" + 0.038*\"statement\" + 0.025*\"executive\" + 0.024*\"destroyer\" + 0.023*\"exercised\" + 0.023*\"duty\" + 0.021*\"navy\" + 0.021*\"cmdr\"\n",
      "2019-10-29 00:44:25,826 : INFO : topic diff=0.759075, rho=1.000000\n",
      "2019-10-29 00:44:26,293 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:26,298 : INFO : built Dictionary(325 unique tokens: ['liability', 'let', 'filed', 'prove', 'success']...) from 5 documents (total 2845 corpus positions)\n",
      "2019-10-29 00:44:26,302 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:26,304 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:26,305 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:26,309 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:26,310 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:26,418 : INFO : -7.634 per-word bound, 198.7 perplexity estimate based on a held-out corpus of 5 documents with 2845 words\n",
      "2019-10-29 00:44:26,419 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:26,427 : INFO : topic #1 (0.100): 0.024*\"trump\" + 0.020*\"law\" + 0.013*\"public\" + 0.011*\"slapp\" + 0.010*\"anti\" + 0.010*\"new\" + 0.009*\"could\" + 0.009*\"case\" + 0.009*\"sullivan\" + 0.009*\"plaintiff\"\n",
      "2019-10-29 00:44:26,429 : INFO : topic #8 (0.100): 0.024*\"trump\" + 0.015*\"law\" + 0.014*\"slapp\" + 0.012*\"public\" + 0.012*\"case\" + 0.012*\"sullivan\" + 0.010*\"amendment\" + 0.010*\"first\" + 0.010*\"open\" + 0.009*\"defamation\"\n",
      "2019-10-29 00:44:26,433 : INFO : topic #2 (0.100): 0.021*\"trump\" + 0.017*\"law\" + 0.014*\"first\" + 0.014*\"slapp\" + 0.013*\"case\" + 0.012*\"defamation\" + 0.011*\"could\" + 0.011*\"sullivan\" + 0.010*\"public\" + 0.010*\"free\"\n",
      "2019-10-29 00:44:26,436 : INFO : topic #6 (0.100): 0.022*\"trump\" + 0.018*\"law\" + 0.013*\"slapp\" + 0.012*\"case\" + 0.011*\"sullivan\" + 0.011*\"defamation\" + 0.011*\"public\" + 0.011*\"could\" + 0.010*\"first\" + 0.010*\"free\"\n",
      "2019-10-29 00:44:26,439 : INFO : topic #9 (0.100): 0.018*\"trump\" + 0.016*\"case\" + 0.016*\"law\" + 0.013*\"defamation\" + 0.013*\"open\" + 0.012*\"first\" + 0.011*\"public\" + 0.011*\"slapp\" + 0.010*\"free\" + 0.010*\"justice\"\n",
      "2019-10-29 00:44:26,441 : INFO : topic diff=0.895383, rho=1.000000\n",
      "2019-10-29 00:44:26,944 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:26,955 : INFO : built Dictionary(420 unique tokens: ['previously', 'theft', 'method', 'party', 'advantage']...) from 5 documents (total 3655 corpus positions)\n",
      "2019-10-29 00:44:26,964 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:26,966 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:26,969 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:26,973 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:26,976 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:27,190 : INFO : -7.885 per-word bound, 236.3 perplexity estimate based on a held-out corpus of 5 documents with 3655 words\n",
      "2019-10-29 00:44:27,191 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:27,201 : INFO : topic #8 (0.100): 0.054*\"korea\" + 0.047*\"north\" + 0.021*\"korean\" + 0.021*\"cyber\" + 0.019*\"south\" + 0.012*\"said\" + 0.012*\"hacker\" + 0.011*\"attack\" + 0.009*\"cnn\" + 0.009*\"pyongyang\"\n",
      "2019-10-29 00:44:27,204 : INFO : topic #3 (0.100): 0.053*\"korea\" + 0.043*\"north\" + 0.019*\"cyber\" + 0.018*\"korean\" + 0.018*\"said\" + 0.014*\"south\" + 0.013*\"hacker\" + 0.010*\"attack\" + 0.009*\"boland\" + 0.009*\"cnn\"\n",
      "2019-10-29 00:44:27,207 : INFO : topic #2 (0.100): 0.045*\"korea\" + 0.044*\"north\" + 0.021*\"cyber\" + 0.020*\"korean\" + 0.016*\"south\" + 0.016*\"hacker\" + 0.012*\"said\" + 0.011*\"attack\" + 0.008*\"boland\" + 0.008*\"computer\"\n",
      "2019-10-29 00:44:27,209 : INFO : topic #6 (0.100): 0.047*\"north\" + 0.045*\"korea\" + 0.018*\"korean\" + 0.017*\"cyber\" + 0.015*\"hacker\" + 0.015*\"said\" + 0.014*\"south\" + 0.010*\"attack\" + 0.010*\"computer\" + 0.008*\"cnn\"\n",
      "2019-10-29 00:44:27,212 : INFO : topic #9 (0.100): 0.050*\"korea\" + 0.048*\"north\" + 0.020*\"cyber\" + 0.016*\"said\" + 0.015*\"korean\" + 0.015*\"south\" + 0.014*\"hacker\" + 0.010*\"attack\" + 0.009*\"boland\" + 0.008*\"weapon\"\n",
      "2019-10-29 00:44:27,215 : INFO : topic diff=0.894845, rho=1.000000\n",
      "2019-10-29 00:44:27,651 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:27,655 : INFO : built Dictionary(78 unique tokens: ['earned', 'school', 'negotiating', 'nigeria', 'nation']...) from 5 documents (total 530 corpus positions)\n",
      "2019-10-29 00:44:27,658 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:27,660 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:27,661 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:27,664 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:27,666 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:27,707 : INFO : -6.744 per-word bound, 107.2 perplexity estimate based on a held-out corpus of 5 documents with 530 words\n",
      "2019-10-29 00:44:27,710 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:27,718 : INFO : topic #4 (0.100): 0.041*\"nigerian\" + 0.033*\"school\" + 0.032*\"orphan\" + 0.031*\"boko\" + 0.030*\"mustapha\" + 0.029*\"haram\" + 0.021*\"northeast\" + 0.020*\"honor\" + 0.020*\"united\" + 0.019*\"nation\"\n",
      "2019-10-29 00:44:27,721 : INFO : topic #3 (0.100): 0.035*\"orphan\" + 0.033*\"haram\" + 0.033*\"boko\" + 0.033*\"school\" + 0.029*\"mustapha\" + 0.029*\"nigerian\" + 0.027*\"nigeria\" + 0.021*\"zannah\" + 0.020*\"award\" + 0.020*\"educate\"\n",
      "2019-10-29 00:44:27,726 : INFO : topic #5 (0.100): 0.039*\"school\" + 0.038*\"haram\" + 0.037*\"orphan\" + 0.033*\"boko\" + 0.028*\"mustapha\" + 0.026*\"nigerian\" + 0.022*\"northeast\" + 0.022*\"nation\" + 0.021*\"refugee\" + 0.021*\"honor\"\n",
      "2019-10-29 00:44:27,731 : INFO : topic #6 (0.100): 0.042*\"boko\" + 0.036*\"orphan\" + 0.035*\"school\" + 0.035*\"nigerian\" + 0.032*\"haram\" + 0.026*\"mustapha\" + 0.026*\"educate\" + 0.022*\"zannah\" + 0.021*\"united\" + 0.019*\"northeast\"\n",
      "2019-10-29 00:44:27,734 : INFO : topic #0 (0.100): 0.043*\"nigerian\" + 0.039*\"school\" + 0.036*\"haram\" + 0.029*\"boko\" + 0.028*\"orphan\" + 0.024*\"mustapha\" + 0.022*\"refugee\" + 0.022*\"educate\" + 0.021*\"displaced\" + 0.020*\"united\"\n",
      "2019-10-29 00:44:27,736 : INFO : topic diff=0.755398, rho=1.000000\n",
      "2019-10-29 00:44:28,200 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:28,214 : INFO : built Dictionary(490 unique tokens: ['dating', 'let', 'tasty', 'francisco', 'raise']...) from 5 documents (total 4695 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:28,225 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:28,227 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:28,231 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:28,235 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:28,238 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:28,413 : INFO : -7.914 per-word bound, 241.1 perplexity estimate based on a held-out corpus of 5 documents with 4695 words\n",
      "2019-10-29 00:44:28,414 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:28,423 : INFO : topic #6 (0.100): 0.042*\"sugar\" + 0.030*\"heart\" + 0.022*\"research\" + 0.022*\"disease\" + 0.018*\"said\" + 0.015*\"industry\" + 0.010*\"new\" + 0.009*\"health\" + 0.009*\"risk\" + 0.009*\"fat\"\n",
      "2019-10-29 00:44:28,425 : INFO : topic #2 (0.100): 0.052*\"sugar\" + 0.026*\"disease\" + 0.025*\"heart\" + 0.019*\"research\" + 0.014*\"industry\" + 0.014*\"said\" + 0.012*\"health\" + 0.010*\"new\" + 0.009*\"american\" + 0.009*\"fat\"\n",
      "2019-10-29 00:44:28,426 : INFO : topic #3 (0.100): 0.036*\"sugar\" + 0.034*\"heart\" + 0.023*\"disease\" + 0.015*\"said\" + 0.015*\"research\" + 0.014*\"risk\" + 0.013*\"industry\" + 0.012*\"fat\" + 0.009*\"health\" + 0.008*\"american\"\n",
      "2019-10-29 00:44:28,428 : INFO : topic #8 (0.100): 0.040*\"sugar\" + 0.038*\"disease\" + 0.025*\"heart\" + 0.021*\"research\" + 0.015*\"said\" + 0.013*\"health\" + 0.012*\"industry\" + 0.011*\"fat\" + 0.008*\"new\" + 0.008*\"would\"\n",
      "2019-10-29 00:44:28,430 : INFO : topic #1 (0.100): 0.044*\"sugar\" + 0.025*\"heart\" + 0.025*\"disease\" + 0.021*\"research\" + 0.017*\"industry\" + 0.014*\"said\" + 0.014*\"fat\" + 0.011*\"risk\" + 0.010*\"health\" + 0.009*\"new\"\n",
      "2019-10-29 00:44:28,431 : INFO : topic diff=0.941739, rho=1.000000\n",
      "2019-10-29 00:44:28,863 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:28,873 : INFO : built Dictionary(453 unique tokens: ['dating', 'extensive', 'energy', 'focus', 'drive']...) from 5 documents (total 3305 corpus positions)\n",
      "2019-10-29 00:44:28,879 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:28,881 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:28,883 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:28,887 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:28,889 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:29,046 : INFO : -8.217 per-word bound, 297.6 perplexity estimate based on a held-out corpus of 5 documents with 3305 words\n",
      "2019-10-29 00:44:29,048 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:29,057 : INFO : topic #9 (0.100): 0.020*\"city\" + 0.015*\"town\" + 0.014*\"new\" + 0.014*\"restaurant\" + 0.014*\"johannesburg\" + 0.012*\"cape\" + 0.010*\"old\" + 0.007*\"art\" + 0.007*\"south\" + 0.007*\"building\"\n",
      "2019-10-29 00:44:29,060 : INFO : topic #5 (0.100): 0.016*\"city\" + 0.014*\"johannesburg\" + 0.013*\"cape\" + 0.011*\"restaurant\" + 0.010*\"town\" + 0.010*\"new\" + 0.008*\"old\" + 0.008*\"africa\" + 0.007*\"art\" + 0.007*\"building\"\n",
      "2019-10-29 00:44:29,061 : INFO : topic #2 (0.100): 0.019*\"johannesburg\" + 0.018*\"city\" + 0.012*\"town\" + 0.012*\"new\" + 0.010*\"restaurant\" + 0.010*\"cape\" + 0.009*\"old\" + 0.008*\"south\" + 0.008*\"building\" + 0.007*\"africa\"\n",
      "2019-10-29 00:44:29,063 : INFO : topic #7 (0.100): 0.015*\"johannesburg\" + 0.015*\"new\" + 0.015*\"town\" + 0.015*\"city\" + 0.012*\"cape\" + 0.010*\"restaurant\" + 0.010*\"old\" + 0.008*\"art\" + 0.008*\"south\" + 0.008*\"best\"\n",
      "2019-10-29 00:44:29,065 : INFO : topic #0 (0.100): 0.020*\"city\" + 0.015*\"johannesburg\" + 0.015*\"town\" + 0.012*\"new\" + 0.012*\"restaurant\" + 0.011*\"old\" + 0.009*\"cape\" + 0.008*\"africa\" + 0.007*\"art\" + 0.007*\"museum\"\n",
      "2019-10-29 00:44:29,067 : INFO : topic diff=0.786614, rho=1.000000\n",
      "2019-10-29 00:44:29,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:29,515 : INFO : built Dictionary(15 unique tokens: ['unfolds', 'happening', 'housewife', 'facebook', 'cohen']...) from 5 documents (total 75 corpus positions)\n",
      "2019-10-29 00:44:29,517 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:29,522 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:29,525 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:29,529 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:29,532 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:29,546 : INFO : -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 5 documents with 75 words\n",
      "2019-10-29 00:44:29,549 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:29,556 : INFO : topic #3 (0.100): 0.082*\"world\" + 0.078*\"like\" + 0.072*\"messenger\" + 0.072*\"find\" + 0.072*\"unfolds\" + 0.070*\"facebook\" + 0.068*\"real\" + 0.067*\"housewife\" + 0.066*\"chat\" + 0.066*\"trump\"\n",
      "2019-10-29 00:44:29,559 : INFO : topic #9 (0.100): 0.085*\"cohen\" + 0.075*\"world\" + 0.073*\"u\" + 0.071*\"like\" + 0.069*\"happening\" + 0.067*\"find\" + 0.066*\"facebook\" + 0.065*\"trump\" + 0.063*\"housewife\" + 0.063*\"say\"\n",
      "2019-10-29 00:44:29,562 : INFO : topic #7 (0.100): 0.073*\"unfolds\" + 0.073*\"chat\" + 0.072*\"tweet\" + 0.071*\"say\" + 0.071*\"u\" + 0.070*\"real\" + 0.068*\"trump\" + 0.066*\"messenger\" + 0.065*\"happening\" + 0.065*\"like\"\n",
      "2019-10-29 00:44:29,565 : INFO : topic #5 (0.100): 0.082*\"find\" + 0.076*\"say\" + 0.071*\"u\" + 0.069*\"chat\" + 0.068*\"real\" + 0.068*\"housewife\" + 0.067*\"like\" + 0.066*\"trump\" + 0.066*\"happening\" + 0.065*\"facebook\"\n",
      "2019-10-29 00:44:29,568 : INFO : topic #2 (0.100): 0.085*\"unfolds\" + 0.085*\"happening\" + 0.083*\"u\" + 0.068*\"real\" + 0.066*\"housewife\" + 0.066*\"find\" + 0.066*\"messenger\" + 0.065*\"cohen\" + 0.064*\"world\" + 0.063*\"say\"\n",
      "2019-10-29 00:44:29,571 : INFO : topic diff=0.508178, rho=1.000000\n",
      "2019-10-29 00:44:30,080 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:30,088 : INFO : built Dictionary(563 unique tokens: ['impotent', 'let', 'selection', 'tremor', 'party']...) from 5 documents (total 5385 corpus positions)\n",
      "2019-10-29 00:44:30,096 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:30,098 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:30,102 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:30,107 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:30,109 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:30,292 : INFO : -8.052 per-word bound, 265.3 perplexity estimate based on a held-out corpus of 5 documents with 5385 words\n",
      "2019-10-29 00:44:30,294 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:30,302 : INFO : topic #6 (0.100): 0.051*\"coffee\" + 0.019*\"study\" + 0.018*\"found\" + 0.017*\"cup\" + 0.017*\"risk\" + 0.014*\"headline\" + 0.012*\"analysis\" + 0.011*\"meta\" + 0.010*\"heart\" + 0.010*\"day\"\n",
      "2019-10-29 00:44:30,304 : INFO : topic #2 (0.100): 0.064*\"coffee\" + 0.023*\"study\" + 0.019*\"risk\" + 0.015*\"found\" + 0.013*\"cup\" + 0.013*\"headline\" + 0.010*\"meta\" + 0.010*\"heart\" + 0.010*\"analysis\" + 0.009*\"cancer\"\n",
      "2019-10-29 00:44:30,307 : INFO : topic #3 (0.100): 0.073*\"coffee\" + 0.020*\"study\" + 0.018*\"cup\" + 0.015*\"found\" + 0.014*\"risk\" + 0.012*\"heart\" + 0.011*\"headline\" + 0.010*\"one\" + 0.009*\"analysis\" + 0.009*\"day\"\n",
      "2019-10-29 00:44:30,309 : INFO : topic #7 (0.100): 0.049*\"coffee\" + 0.022*\"study\" + 0.018*\"risk\" + 0.017*\"found\" + 0.017*\"cup\" + 0.013*\"headline\" + 0.012*\"analysis\" + 0.011*\"day\" + 0.010*\"heart\" + 0.008*\"one\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:30,312 : INFO : topic #4 (0.100): 0.065*\"coffee\" + 0.026*\"study\" + 0.018*\"risk\" + 0.018*\"headline\" + 0.013*\"cup\" + 0.012*\"found\" + 0.011*\"day\" + 0.010*\"heart\" + 0.009*\"meta\" + 0.008*\"analysis\"\n",
      "2019-10-29 00:44:30,315 : INFO : topic diff=0.929709, rho=1.000000\n",
      "2019-10-29 00:44:30,724 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:30,727 : INFO : built Dictionary(199 unique tokens: ['deep', 'drinking', 'soul', 'might', 'west']...) from 5 documents (total 1355 corpus positions)\n",
      "2019-10-29 00:44:30,730 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:30,732 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:30,734 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:30,737 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:30,739 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:30,820 : INFO : -7.556 per-word bound, 188.2 perplexity estimate based on a held-out corpus of 5 documents with 1355 words\n",
      "2019-10-29 00:44:30,822 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:30,828 : INFO : topic #7 (0.100): 0.024*\"wonder\" + 0.024*\"colorado\" + 0.024*\"river\" + 0.016*\"one\" + 0.015*\"growth\" + 0.015*\"weir\" + 0.014*\"water\" + 0.013*\"bill\" + 0.013*\"denver\" + 0.012*\"million\"\n",
      "2019-10-29 00:44:30,831 : INFO : topic #0 (0.100): 0.025*\"river\" + 0.021*\"wonder\" + 0.020*\"colorado\" + 0.015*\"weir\" + 0.014*\"water\" + 0.014*\"denver\" + 0.014*\"list\" + 0.014*\"bill\" + 0.014*\"one\" + 0.012*\"dad\"\n",
      "2019-10-29 00:44:30,834 : INFO : topic #4 (0.100): 0.032*\"wonder\" + 0.023*\"river\" + 0.022*\"colorado\" + 0.014*\"weir\" + 0.014*\"one\" + 0.014*\"bill\" + 0.012*\"water\" + 0.011*\"denver\" + 0.011*\"lake\" + 0.011*\"list\"\n",
      "2019-10-29 00:44:30,837 : INFO : topic #2 (0.100): 0.028*\"colorado\" + 0.020*\"river\" + 0.016*\"wonder\" + 0.015*\"million\" + 0.014*\"bill\" + 0.013*\"list\" + 0.013*\"one\" + 0.012*\"weir\" + 0.012*\"lake\" + 0.011*\"water\"\n",
      "2019-10-29 00:44:30,841 : INFO : topic #8 (0.100): 0.024*\"colorado\" + 0.022*\"wonder\" + 0.021*\"river\" + 0.016*\"list\" + 0.015*\"bill\" + 0.015*\"one\" + 0.015*\"weir\" + 0.014*\"lake\" + 0.012*\"water\" + 0.011*\"old\"\n",
      "2019-10-29 00:44:30,845 : INFO : topic diff=0.772179, rho=1.000000\n",
      "2019-10-29 00:44:31,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:31,263 : INFO : built Dictionary(53 unique tokens: ['help', 'hero', 'concert', 'friend', 'shooting']...) from 5 documents (total 335 corpus positions)\n",
      "2019-10-29 00:44:31,265 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:31,266 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:31,267 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:31,270 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:31,271 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:31,304 : INFO : -6.581 per-word bound, 95.7 perplexity estimate based on a held-out corpus of 5 documents with 335 words\n",
      "2019-10-29 00:44:31,305 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:31,313 : INFO : topic #2 (0.100): 0.046*\"phippen\" + 0.044*\"son\" + 0.037*\"nagiyvanyi\" + 0.032*\"shooting\" + 0.030*\"said\" + 0.026*\"stopped\" + 0.026*\"john\" + 0.026*\"travis\" + 0.026*\"help\" + 0.026*\"someone\"\n",
      "2019-10-29 00:44:31,317 : INFO : topic #4 (0.100): 0.054*\"nagiyvanyi\" + 0.036*\"phippen\" + 0.034*\"son\" + 0.030*\"someone\" + 0.028*\"travis\" + 0.027*\"year\" + 0.026*\"said\" + 0.026*\"help\" + 0.025*\"stopped\" + 0.023*\"john\"\n",
      "2019-10-29 00:44:31,320 : INFO : topic #3 (0.100): 0.047*\"nagiyvanyi\" + 0.042*\"son\" + 0.033*\"phippen\" + 0.033*\"travis\" + 0.032*\"help\" + 0.031*\"someone\" + 0.031*\"shooting\" + 0.028*\"year\" + 0.027*\"stopped\" + 0.027*\"john\"\n",
      "2019-10-29 00:44:31,326 : INFO : topic #0 (0.100): 0.047*\"son\" + 0.039*\"phippen\" + 0.038*\"nagiyvanyi\" + 0.036*\"john\" + 0.035*\"stopped\" + 0.030*\"help\" + 0.030*\"said\" + 0.028*\"shooting\" + 0.028*\"year\" + 0.028*\"someone\"\n",
      "2019-10-29 00:44:31,331 : INFO : topic #6 (0.100): 0.056*\"phippen\" + 0.041*\"son\" + 0.041*\"nagiyvanyi\" + 0.034*\"year\" + 0.031*\"travis\" + 0.031*\"help\" + 0.031*\"stopped\" + 0.029*\"shooting\" + 0.027*\"said\" + 0.024*\"john\"\n",
      "2019-10-29 00:44:31,334 : INFO : topic diff=0.691369, rho=1.000000\n",
      "2019-10-29 00:44:31,756 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:31,758 : INFO : built Dictionary(129 unique tokens: ['trying', 'praised', 'sit', 'making', 'u']...) from 5 documents (total 1115 corpus positions)\n",
      "2019-10-29 00:44:31,761 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:31,762 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:31,764 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:31,766 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:31,768 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:31,824 : INFO : -6.787 per-word bound, 110.4 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:44:31,826 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:31,833 : INFO : topic #8 (0.100): 0.047*\"player\" + 0.044*\"nfl\" + 0.041*\"anthem\" + 0.030*\"trump\" + 0.027*\"national\" + 0.026*\"said\" + 0.025*\"protest\" + 0.025*\"goodell\" + 0.020*\"stand\" + 0.017*\"commissioner\"\n",
      "2019-10-29 00:44:31,835 : INFO : topic #5 (0.100): 0.045*\"anthem\" + 0.041*\"player\" + 0.035*\"nfl\" + 0.033*\"national\" + 0.029*\"said\" + 0.028*\"goodell\" + 0.026*\"trump\" + 0.024*\"protest\" + 0.024*\"stand\" + 0.021*\"commissioner\"\n",
      "2019-10-29 00:44:31,836 : INFO : topic #0 (0.100): 0.055*\"nfl\" + 0.048*\"player\" + 0.034*\"anthem\" + 0.031*\"protest\" + 0.030*\"national\" + 0.025*\"said\" + 0.025*\"goodell\" + 0.024*\"trump\" + 0.021*\"stand\" + 0.016*\"commissioner\"\n",
      "2019-10-29 00:44:31,840 : INFO : topic #4 (0.100): 0.047*\"player\" + 0.039*\"nfl\" + 0.036*\"trump\" + 0.032*\"anthem\" + 0.029*\"protest\" + 0.024*\"goodell\" + 0.023*\"said\" + 0.022*\"stand\" + 0.021*\"national\" + 0.020*\"league\"\n",
      "2019-10-29 00:44:31,842 : INFO : topic #6 (0.100): 0.058*\"player\" + 0.038*\"anthem\" + 0.034*\"goodell\" + 0.032*\"nfl\" + 0.028*\"national\" + 0.023*\"trump\" + 0.021*\"protest\" + 0.020*\"league\" + 0.019*\"said\" + 0.019*\"commissioner\"\n",
      "2019-10-29 00:44:31,843 : INFO : topic diff=0.909605, rho=1.000000\n",
      "2019-10-29 00:44:32,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:32,266 : INFO : built Dictionary(218 unique tokens: ['consent', 'acceptable', 'weinstein', 'described', 'come']...) from 5 documents (total 1780 corpus positions)\n",
      "2019-10-29 00:44:32,269 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:32,271 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:32,272 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:32,275 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:32,277 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:32,358 : INFO : -7.361 per-word bound, 164.3 perplexity estimate based on a held-out corpus of 5 documents with 1780 words\n",
      "2019-10-29 00:44:32,360 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:32,366 : INFO : topic #4 (0.100): 0.047*\"karan\" + 0.025*\"woman\" + 0.021*\"donna\" + 0.020*\"weinstein\" + 0.016*\"said\" + 0.016*\"statement\" + 0.015*\"comment\" + 0.014*\"asking\" + 0.012*\"harassment\" + 0.011*\"time\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:32,369 : INFO : topic #5 (0.100): 0.039*\"karan\" + 0.034*\"woman\" + 0.021*\"weinstein\" + 0.020*\"said\" + 0.018*\"donna\" + 0.016*\"asking\" + 0.013*\"comment\" + 0.013*\"statement\" + 0.012*\"sexual\" + 0.010*\"harassment\"\n",
      "2019-10-29 00:44:32,372 : INFO : topic #1 (0.100): 0.049*\"karan\" + 0.025*\"woman\" + 0.018*\"said\" + 0.018*\"donna\" + 0.017*\"weinstein\" + 0.017*\"comment\" + 0.013*\"asking\" + 0.012*\"statement\" + 0.012*\"time\" + 0.011*\"october\"\n",
      "2019-10-29 00:44:32,375 : INFO : topic #7 (0.100): 0.058*\"karan\" + 0.022*\"woman\" + 0.020*\"donna\" + 0.020*\"said\" + 0.019*\"weinstein\" + 0.017*\"comment\" + 0.014*\"harvey\" + 0.013*\"october\" + 0.012*\"statement\" + 0.010*\"asking\"\n",
      "2019-10-29 00:44:32,377 : INFO : topic #3 (0.100): 0.047*\"karan\" + 0.022*\"weinstein\" + 0.021*\"woman\" + 0.021*\"said\" + 0.020*\"comment\" + 0.020*\"donna\" + 0.015*\"statement\" + 0.012*\"asking\" + 0.012*\"harassment\" + 0.010*\"october\"\n",
      "2019-10-29 00:44:32,379 : INFO : topic diff=0.829552, rho=1.000000\n",
      "2019-10-29 00:44:32,819 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:32,826 : INFO : built Dictionary(488 unique tokens: ['although', 'previously', 'phase', 'deep', 'advantage']...) from 5 documents (total 4265 corpus positions)\n",
      "2019-10-29 00:44:32,831 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:32,832 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:32,835 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:32,841 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:32,844 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:32,997 : INFO : -8.024 per-word bound, 260.3 perplexity estimate based on a held-out corpus of 5 documents with 4265 words\n",
      "2019-10-29 00:44:32,999 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:33,008 : INFO : topic #7 (0.100): 0.035*\"china\" + 0.024*\"architect\" + 0.013*\"project\" + 0.013*\"said\" + 0.013*\"valcarce\" + 0.012*\"market\" + 0.012*\"firm\" + 0.011*\"year\" + 0.011*\"europe\" + 0.009*\"architecture\"\n",
      "2019-10-29 00:44:33,012 : INFO : topic #9 (0.100): 0.022*\"architect\" + 0.021*\"china\" + 0.015*\"said\" + 0.012*\"valcarce\" + 0.012*\"europe\" + 0.011*\"firm\" + 0.011*\"architecture\" + 0.010*\"market\" + 0.010*\"european\" + 0.010*\"year\"\n",
      "2019-10-29 00:44:33,015 : INFO : topic #8 (0.100): 0.024*\"china\" + 0.020*\"architect\" + 0.018*\"said\" + 0.012*\"europe\" + 0.012*\"market\" + 0.011*\"valcarce\" + 0.011*\"project\" + 0.011*\"year\" + 0.010*\"building\" + 0.010*\"architecture\"\n",
      "2019-10-29 00:44:33,017 : INFO : topic #0 (0.100): 0.031*\"china\" + 0.025*\"architect\" + 0.016*\"said\" + 0.012*\"project\" + 0.012*\"valcarce\" + 0.011*\"firm\" + 0.011*\"also\" + 0.011*\"europe\" + 0.010*\"architecture\" + 0.010*\"design\"\n",
      "2019-10-29 00:44:33,020 : INFO : topic #3 (0.100): 0.024*\"china\" + 0.022*\"architect\" + 0.015*\"valcarce\" + 0.014*\"project\" + 0.013*\"said\" + 0.011*\"europe\" + 0.010*\"architecture\" + 0.010*\"design\" + 0.010*\"year\" + 0.009*\"market\"\n",
      "2019-10-29 00:44:33,023 : INFO : topic diff=0.899998, rho=1.000000\n",
      "2019-10-29 00:44:33,446 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:33,448 : INFO : built Dictionary(35 unique tokens: ['story', 'business', 'see', 'cnn', 'get']...) from 5 documents (total 220 corpus positions)\n",
      "2019-10-29 00:44:33,449 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:33,450 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:33,452 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:33,454 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:33,455 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:33,475 : INFO : -6.306 per-word bound, 79.1 perplexity estimate based on a held-out corpus of 5 documents with 220 words\n",
      "2019-10-29 00:44:33,476 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:33,482 : INFO : topic #0 (0.100): 0.070*\"bachelor\" + 0.064*\"kraus\" + 0.051*\"coming\" + 0.051*\"franchise\" + 0.051*\"peter\" + 0.039*\"favorite\" + 0.028*\"read\" + 0.027*\"jr\" + 0.027*\"owner\" + 0.026*\"rose\"\n",
      "2019-10-29 00:44:33,483 : INFO : topic #8 (0.100): 0.083*\"bachelor\" + 0.063*\"kraus\" + 0.050*\"peter\" + 0.047*\"franchise\" + 0.044*\"coming\" + 0.039*\"favorite\" + 0.030*\"another\" + 0.029*\"chance\" + 0.027*\"get\" + 0.027*\"love\"\n",
      "2019-10-29 00:44:33,485 : INFO : topic #5 (0.100): 0.098*\"bachelor\" + 0.051*\"kraus\" + 0.048*\"coming\" + 0.046*\"franchise\" + 0.042*\"peter\" + 0.039*\"favorite\" + 0.031*\"fan\" + 0.028*\"honor\" + 0.027*\"last\" + 0.027*\"spinoff\"\n",
      "2019-10-29 00:44:33,487 : INFO : topic #6 (0.100): 0.081*\"bachelor\" + 0.063*\"kraus\" + 0.050*\"peter\" + 0.046*\"favorite\" + 0.043*\"franchise\" + 0.039*\"coming\" + 0.029*\"give\" + 0.027*\"story\" + 0.027*\"rose\" + 0.027*\"luyendyk\"\n",
      "2019-10-29 00:44:33,489 : INFO : topic #3 (0.100): 0.080*\"bachelor\" + 0.076*\"kraus\" + 0.042*\"favorite\" + 0.038*\"coming\" + 0.036*\"franchise\" + 0.034*\"peter\" + 0.029*\"jr\" + 0.029*\"went\" + 0.028*\"instead\" + 0.027*\"fan\"\n",
      "2019-10-29 00:44:33,497 : INFO : topic diff=0.719784, rho=1.000000\n",
      "2019-10-29 00:44:33,886 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:33,888 : INFO : built Dictionary(14 unique tokens: ['happening', 'unfolds', 'facebook', 'last', 'audience']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:44:33,889 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:33,890 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:33,892 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:33,894 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:33,895 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:33,908 : INFO : -6.436 per-word bound, 86.6 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:44:33,909 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:33,915 : INFO : topic #4 (0.100): 0.080*\"u\" + 0.078*\"week\" + 0.077*\"chat\" + 0.077*\"colbert\" + 0.075*\"surprise\" + 0.075*\"find\" + 0.074*\"messenger\" + 0.071*\"audience\" + 0.071*\"world\" + 0.070*\"tonight\"\n",
      "2019-10-29 00:44:33,917 : INFO : topic #6 (0.100): 0.092*\"happening\" + 0.085*\"messenger\" + 0.085*\"surprise\" + 0.075*\"last\" + 0.073*\"chat\" + 0.073*\"audience\" + 0.070*\"facebook\" + 0.069*\"week\" + 0.066*\"u\" + 0.065*\"world\"\n",
      "2019-10-29 00:44:33,919 : INFO : topic #3 (0.100): 0.092*\"unfolds\" + 0.078*\"audience\" + 0.076*\"colbert\" + 0.075*\"find\" + 0.075*\"week\" + 0.074*\"messenger\" + 0.073*\"facebook\" + 0.073*\"chat\" + 0.069*\"last\" + 0.069*\"happening\"\n",
      "2019-10-29 00:44:33,922 : INFO : topic #2 (0.100): 0.085*\"find\" + 0.085*\"colbert\" + 0.082*\"audience\" + 0.079*\"tonight\" + 0.075*\"u\" + 0.074*\"world\" + 0.073*\"happening\" + 0.072*\"messenger\" + 0.069*\"week\" + 0.066*\"last\"\n",
      "2019-10-29 00:44:33,923 : INFO : topic #1 (0.100): 0.095*\"surprise\" + 0.086*\"u\" + 0.077*\"chat\" + 0.076*\"last\" + 0.071*\"messenger\" + 0.071*\"colbert\" + 0.071*\"unfolds\" + 0.070*\"tonight\" + 0.070*\"happening\" + 0.068*\"week\"\n",
      "2019-10-29 00:44:33,926 : INFO : topic diff=0.513425, rho=1.000000\n",
      "2019-10-29 00:44:34,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:34,378 : INFO : built Dictionary(87 unique tokens: ['block', 'alexander', 'anti', 'pushkin', 'petersburg']...) from 5 documents (total 575 corpus positions)\n",
      "2019-10-29 00:44:34,384 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:34,387 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:34,390 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:34,393 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:34,397 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:34,452 : INFO : -6.883 per-word bound, 118.0 perplexity estimate based on a held-out corpus of 5 documents with 575 words\n",
      "2019-10-29 00:44:34,454 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:34,461 : INFO : topic #5 (0.100): 0.038*\"putin\" + 0.028*\"navalny\" + 0.024*\"russian\" + 0.022*\"march\" + 0.020*\"time\" + 0.019*\"presidential\" + 0.019*\"public\" + 0.019*\"birthday\" + 0.019*\"anti\" + 0.018*\"rally\"\n",
      "2019-10-29 00:44:34,464 : INFO : topic #0 (0.100): 0.045*\"putin\" + 0.033*\"navalny\" + 0.026*\"march\" + 0.023*\"russian\" + 0.022*\"russia\" + 0.020*\"conviction\" + 0.019*\"term\" + 0.019*\"presidential\" + 0.018*\"saturday\" + 0.018*\"unauthorized\"\n",
      "2019-10-29 00:44:34,468 : INFO : topic #3 (0.100): 0.041*\"putin\" + 0.032*\"russian\" + 0.029*\"navalny\" + 0.026*\"march\" + 0.021*\"organizing\" + 0.020*\"rally\" + 0.020*\"alexei\" + 0.018*\"presidential\" + 0.018*\"leader\" + 0.016*\"moscow\"\n",
      "2019-10-29 00:44:34,471 : INFO : topic #4 (0.100): 0.043*\"putin\" + 0.029*\"navalny\" + 0.027*\"russian\" + 0.026*\"march\" + 0.021*\"organizing\" + 0.019*\"saturday\" + 0.019*\"conviction\" + 0.019*\"time\" + 0.017*\"leader\" + 0.017*\"unauthorized\"\n",
      "2019-10-29 00:44:34,474 : INFO : topic #7 (0.100): 0.035*\"navalny\" + 0.034*\"putin\" + 0.024*\"russian\" + 0.022*\"march\" + 0.019*\"rally\" + 0.019*\"unauthorized\" + 0.019*\"saturday\" + 0.019*\"russia\" + 0.018*\"moscow\" + 0.017*\"conviction\"\n",
      "2019-10-29 00:44:34,476 : INFO : topic diff=0.706544, rho=1.000000\n",
      "2019-10-29 00:44:34,907 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:34,908 : INFO : built Dictionary(12 unique tokens: ['happening', 'facebook', 'messenger', 'find', 'u']...) from 5 documents (total 60 corpus positions)\n",
      "2019-10-29 00:44:34,909 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:34,910 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:34,912 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:34,914 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:34,915 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:34,927 : INFO : -6.392 per-word bound, 84.0 perplexity estimate based on a held-out corpus of 5 documents with 60 words\n",
      "2019-10-29 00:44:34,929 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:34,935 : INFO : topic #9 (0.100): 0.098*\"messenger\" + 0.095*\"outcry\" + 0.092*\"find\" + 0.088*\"world\" + 0.086*\"u\" + 0.084*\"ad\" + 0.084*\"chat\" + 0.082*\"controversial\" + 0.079*\"unfolds\" + 0.079*\"dove\"\n",
      "2019-10-29 00:44:34,936 : INFO : topic #1 (0.100): 0.096*\"chat\" + 0.095*\"controversial\" + 0.089*\"unfolds\" + 0.088*\"find\" + 0.088*\"happening\" + 0.087*\"facebook\" + 0.082*\"u\" + 0.081*\"ad\" + 0.080*\"outcry\" + 0.076*\"messenger\"\n",
      "2019-10-29 00:44:34,938 : INFO : topic #2 (0.100): 0.101*\"find\" + 0.096*\"u\" + 0.089*\"outcry\" + 0.088*\"dove\" + 0.085*\"world\" + 0.084*\"facebook\" + 0.081*\"chat\" + 0.081*\"ad\" + 0.080*\"unfolds\" + 0.078*\"messenger\"\n",
      "2019-10-29 00:44:34,940 : INFO : topic #7 (0.100): 0.100*\"outcry\" + 0.095*\"facebook\" + 0.091*\"unfolds\" + 0.090*\"find\" + 0.084*\"world\" + 0.082*\"happening\" + 0.080*\"u\" + 0.080*\"ad\" + 0.080*\"messenger\" + 0.075*\"controversial\"\n",
      "2019-10-29 00:44:34,941 : INFO : topic #3 (0.100): 0.111*\"ad\" + 0.093*\"controversial\" + 0.089*\"facebook\" + 0.087*\"messenger\" + 0.083*\"happening\" + 0.082*\"world\" + 0.079*\"unfolds\" + 0.079*\"dove\" + 0.078*\"chat\" + 0.078*\"outcry\"\n",
      "2019-10-29 00:44:34,949 : INFO : topic diff=0.506486, rho=1.000000\n",
      "2019-10-29 00:44:35,352 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:35,355 : INFO : built Dictionary(166 unique tokens: ['canon', 'term', 'funeral', 'duration', 'u']...) from 5 documents (total 1250 corpus positions)\n",
      "2019-10-29 00:44:35,357 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:35,359 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:35,362 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:35,365 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:35,366 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:35,461 : INFO : -7.219 per-word bound, 149.0 perplexity estimate based on a held-out corpus of 5 documents with 1250 words\n",
      "2019-10-29 00:44:35,463 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:35,472 : INFO : topic #3 (0.100): 0.041*\"cathedral\" + 0.029*\"national\" + 0.028*\"said\" + 0.025*\"window\" + 0.021*\"confederate\" + 0.018*\"two\" + 0.018*\"hall\" + 0.017*\"symbol\" + 0.015*\"washington\" + 0.012*\"general\"\n",
      "2019-10-29 00:44:35,475 : INFO : topic #1 (0.100): 0.037*\"cathedral\" + 0.032*\"national\" + 0.021*\"said\" + 0.020*\"two\" + 0.020*\"confederate\" + 0.019*\"window\" + 0.017*\"washington\" + 0.014*\"hall\" + 0.013*\"symbol\" + 0.013*\"glass\"\n",
      "2019-10-29 00:44:35,478 : INFO : topic #2 (0.100): 0.043*\"cathedral\" + 0.035*\"said\" + 0.026*\"national\" + 0.020*\"confederate\" + 0.019*\"window\" + 0.019*\"two\" + 0.014*\"symbol\" + 0.013*\"washington\" + 0.013*\"general\" + 0.012*\"hall\"\n",
      "2019-10-29 00:44:35,480 : INFO : topic #9 (0.100): 0.034*\"national\" + 0.032*\"said\" + 0.032*\"cathedral\" + 0.023*\"window\" + 0.021*\"confederate\" + 0.021*\"two\" + 0.016*\"washington\" + 0.016*\"symbol\" + 0.015*\"racial\" + 0.013*\"lee\"\n",
      "2019-10-29 00:44:35,481 : INFO : topic #8 (0.100): 0.044*\"cathedral\" + 0.034*\"said\" + 0.030*\"national\" + 0.024*\"window\" + 0.020*\"confederate\" + 0.018*\"symbol\" + 0.017*\"official\" + 0.015*\"two\" + 0.015*\"hall\" + 0.014*\"south\"\n",
      "2019-10-29 00:44:35,485 : INFO : topic diff=0.824798, rho=1.000000\n",
      "2019-10-29 00:44:35,954 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:35,961 : INFO : built Dictionary(369 unique tokens: ['let', 'happy', 'party', 'biblical', 'spare']...) from 5 documents (total 2745 corpus positions)\n",
      "2019-10-29 00:44:35,964 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:35,967 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:35,971 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:35,975 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:35,978 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:36,104 : INFO : -7.987 per-word bound, 253.8 perplexity estimate based on a held-out corpus of 5 documents with 2745 words\n",
      "2019-10-29 00:44:36,105 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:36,114 : INFO : topic #1 (0.100): 0.015*\"kid\" + 0.015*\"social\" + 0.015*\"medium\" + 0.013*\"better\" + 0.012*\"parent\" + 0.010*\"new\" + 0.010*\"time\" + 0.009*\"popular\" + 0.009*\"year\" + 0.009*\"tell\"\n",
      "2019-10-29 00:44:36,116 : INFO : topic #4 (0.100): 0.016*\"kid\" + 0.015*\"better\" + 0.015*\"social\" + 0.011*\"year\" + 0.011*\"medium\" + 0.010*\"new\" + 0.010*\"parent\" + 0.010*\"popular\" + 0.009*\"raise\" + 0.009*\"could\"\n",
      "2019-10-29 00:44:36,119 : INFO : topic #0 (0.100): 0.016*\"social\" + 0.016*\"kid\" + 0.015*\"better\" + 0.012*\"year\" + 0.012*\"medium\" + 0.010*\"parent\" + 0.010*\"one\" + 0.010*\"old\" + 0.009*\"think\" + 0.008*\"popular\"\n",
      "2019-10-29 00:44:36,122 : INFO : topic #2 (0.100): 0.017*\"social\" + 0.015*\"parent\" + 0.014*\"medium\" + 0.014*\"year\" + 0.013*\"kid\" + 0.010*\"better\" + 0.010*\"popular\" + 0.009*\"bullying\" + 0.009*\"fit\" + 0.009*\"one\"\n",
      "2019-10-29 00:44:36,125 : INFO : topic #6 (0.100): 0.016*\"kid\" + 0.015*\"better\" + 0.014*\"social\" + 0.013*\"medium\" + 0.011*\"parent\" + 0.011*\"old\" + 0.011*\"year\" + 0.009*\"time\" + 0.009*\"school\" + 0.009*\"fit\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:36,127 : INFO : topic diff=0.823865, rho=1.000000\n",
      "2019-10-29 00:44:36,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:36,551 : INFO : built Dictionary(147 unique tokens: ['let', 'sorry', 'tax', 'end', 'nation']...) from 5 documents (total 1590 corpus positions)\n",
      "2019-10-29 00:44:36,554 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:36,555 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:36,557 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:36,560 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:36,562 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:36,627 : INFO : -6.627 per-word bound, 98.9 perplexity estimate based on a held-out corpus of 5 documents with 1590 words\n",
      "2019-10-29 00:44:36,629 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:36,638 : INFO : topic #0 (0.100): 0.046*\"sander\" + 0.045*\"taxed\" + 0.045*\"highest\" + 0.042*\"nation\" + 0.033*\"said\" + 0.027*\"world\" + 0.026*\"yingst\" + 0.025*\"president\" + 0.020*\"u\" + 0.019*\"corporate\"\n",
      "2019-10-29 00:44:36,640 : INFO : topic #8 (0.100): 0.042*\"highest\" + 0.041*\"taxed\" + 0.039*\"nation\" + 0.035*\"sander\" + 0.034*\"said\" + 0.027*\"world\" + 0.024*\"corporate\" + 0.022*\"saying\" + 0.021*\"yingst\" + 0.021*\"president\"\n",
      "2019-10-29 00:44:36,642 : INFO : topic #5 (0.100): 0.049*\"sander\" + 0.042*\"highest\" + 0.035*\"taxed\" + 0.031*\"trump\" + 0.030*\"said\" + 0.030*\"nation\" + 0.027*\"yingst\" + 0.025*\"corporate\" + 0.023*\"president\" + 0.021*\"tax\"\n",
      "2019-10-29 00:44:36,644 : INFO : topic #2 (0.100): 0.057*\"taxed\" + 0.048*\"highest\" + 0.038*\"said\" + 0.037*\"corporate\" + 0.032*\"sander\" + 0.030*\"nation\" + 0.025*\"yingst\" + 0.024*\"world\" + 0.023*\"trump\" + 0.022*\"president\"\n",
      "2019-10-29 00:44:36,645 : INFO : topic #9 (0.100): 0.051*\"highest\" + 0.039*\"taxed\" + 0.030*\"sander\" + 0.029*\"president\" + 0.028*\"trump\" + 0.027*\"world\" + 0.026*\"nation\" + 0.024*\"said\" + 0.022*\"yingst\" + 0.021*\"saying\"\n",
      "2019-10-29 00:44:36,646 : INFO : topic diff=1.048335, rho=1.000000\n",
      "2019-10-29 00:44:37,081 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:37,084 : INFO : built Dictionary(110 unique tokens: ['tjeerd', 'presidency', 'life', 'burkina', 'graphic']...) from 5 documents (total 1010 corpus positions)\n",
      "2019-10-29 00:44:37,087 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:37,090 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:37,093 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:37,097 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:37,100 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:37,144 : INFO : -6.566 per-word bound, 94.8 perplexity estimate based on a held-out corpus of 5 documents with 1010 words\n",
      "2019-10-29 00:44:37,145 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:37,153 : INFO : topic #2 (0.100): 0.055*\"hide\" + 0.054*\"trump\" + 0.054*\"caption\" + 0.053*\"presidency\" + 0.051*\"day\" + 0.046*\"photo\" + 0.040*\"first\" + 0.029*\"cartoonist\" + 0.013*\"newspaper\" + 0.013*\"year\"\n",
      "2019-10-29 00:44:37,157 : INFO : topic #3 (0.100): 0.059*\"trump\" + 0.056*\"photo\" + 0.049*\"first\" + 0.044*\"caption\" + 0.043*\"presidency\" + 0.041*\"hide\" + 0.038*\"day\" + 0.034*\"cartoonist\" + 0.014*\"year\" + 0.014*\"editorial\"\n",
      "2019-10-29 00:44:37,160 : INFO : topic #1 (0.100): 0.061*\"caption\" + 0.057*\"day\" + 0.056*\"photo\" + 0.052*\"first\" + 0.048*\"trump\" + 0.045*\"presidency\" + 0.044*\"hide\" + 0.041*\"cartoonist\" + 0.016*\"editorial\" + 0.013*\"cartoon\"\n",
      "2019-10-29 00:44:37,162 : INFO : topic #5 (0.100): 0.059*\"hide\" + 0.058*\"day\" + 0.057*\"trump\" + 0.056*\"first\" + 0.054*\"photo\" + 0.037*\"caption\" + 0.035*\"presidency\" + 0.031*\"cartoonist\" + 0.015*\"year\" + 0.015*\"editorial\"\n",
      "2019-10-29 00:44:37,165 : INFO : topic #7 (0.100): 0.058*\"first\" + 0.058*\"trump\" + 0.057*\"day\" + 0.054*\"caption\" + 0.053*\"presidency\" + 0.044*\"hide\" + 0.040*\"photo\" + 0.038*\"cartoonist\" + 0.015*\"year\" + 0.013*\"editorial\"\n",
      "2019-10-29 00:44:37,168 : INFO : topic diff=1.042947, rho=1.000000\n",
      "2019-10-29 00:44:37,609 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:37,616 : INFO : built Dictionary(456 unique tokens: ['deep', 'reluctant', 'one', 'self', 'new']...) from 5 documents (total 3155 corpus positions)\n",
      "2019-10-29 00:44:37,622 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:37,623 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:37,628 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:37,633 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:37,636 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:37,788 : INFO : -8.304 per-word bound, 316.0 perplexity estimate based on a held-out corpus of 5 documents with 3155 words\n",
      "2019-10-29 00:44:37,789 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:37,798 : INFO : topic #2 (0.100): 0.028*\"trump\" + 0.016*\"sander\" + 0.014*\"people\" + 0.014*\"would\" + 0.009*\"make\" + 0.008*\"america\" + 0.008*\"1930s\" + 0.007*\"know\" + 0.007*\"power\" + 0.006*\"world\"\n",
      "2019-10-29 00:44:37,801 : INFO : topic #6 (0.100): 0.027*\"trump\" + 0.024*\"would\" + 0.013*\"sander\" + 0.012*\"people\" + 0.009*\"1930s\" + 0.008*\"make\" + 0.006*\"world\" + 0.006*\"power\" + 0.006*\"america\" + 0.006*\"know\"\n",
      "2019-10-29 00:44:37,803 : INFO : topic #5 (0.100): 0.026*\"trump\" + 0.024*\"would\" + 0.019*\"sander\" + 0.013*\"people\" + 0.010*\"america\" + 0.009*\"make\" + 0.009*\"1930s\" + 0.007*\"know\" + 0.006*\"way\" + 0.006*\"power\"\n",
      "2019-10-29 00:44:37,806 : INFO : topic #9 (0.100): 0.022*\"trump\" + 0.021*\"would\" + 0.018*\"sander\" + 0.010*\"america\" + 0.010*\"people\" + 0.009*\"make\" + 0.009*\"know\" + 0.008*\"power\" + 0.007*\"1930s\" + 0.006*\"offering\"\n",
      "2019-10-29 00:44:37,808 : INFO : topic #7 (0.100): 0.029*\"trump\" + 0.018*\"would\" + 0.015*\"sander\" + 0.010*\"1930s\" + 0.009*\"make\" + 0.009*\"people\" + 0.008*\"america\" + 0.007*\"fascist\" + 0.006*\"see\" + 0.006*\"world\"\n",
      "2019-10-29 00:44:37,811 : INFO : topic diff=0.780660, rho=1.000000\n",
      "2019-10-29 00:44:38,217 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:38,221 : INFO : built Dictionary(138 unique tokens: ['concern', 'perhaps', 'completely', 'cerebral', 'cinematic']...) from 5 documents (total 775 corpus positions)\n",
      "2019-10-29 00:44:38,224 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:38,227 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:38,229 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:38,232 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:38,234 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:38,291 : INFO : -7.599 per-word bound, 193.9 perplexity estimate based on a held-out corpus of 5 documents with 775 words\n",
      "2019-10-29 00:44:38,293 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:38,298 : INFO : topic #6 (0.100): 0.025*\"blade\" + 0.019*\"runner\" + 0.016*\"movie\" + 0.016*\"much\" + 0.014*\"glitch\" + 0.014*\"year\" + 0.013*\"possible\" + 0.011*\"ford\" + 0.011*\"feeling\" + 0.011*\"gosling\"\n",
      "2019-10-29 00:44:38,300 : INFO : topic #1 (0.100): 0.021*\"blade\" + 0.019*\"much\" + 0.017*\"year\" + 0.016*\"runner\" + 0.016*\"movie\" + 0.013*\"ford\" + 0.011*\"feeling\" + 0.011*\"possible\" + 0.011*\"gosling\" + 0.009*\"drawn\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:38,304 : INFO : topic #5 (0.100): 0.027*\"blade\" + 0.024*\"runner\" + 0.021*\"movie\" + 0.016*\"ford\" + 0.015*\"much\" + 0.014*\"possible\" + 0.013*\"glitch\" + 0.013*\"drawn\" + 0.013*\"gosling\" + 0.011*\"year\"\n",
      "2019-10-29 00:44:38,308 : INFO : topic #8 (0.100): 0.025*\"blade\" + 0.024*\"runner\" + 0.016*\"movie\" + 0.015*\"drawn\" + 0.015*\"much\" + 0.014*\"gosling\" + 0.012*\"feeling\" + 0.012*\"possible\" + 0.012*\"ford\" + 0.009*\"glitch\"\n",
      "2019-10-29 00:44:38,311 : INFO : topic #0 (0.100): 0.026*\"runner\" + 0.022*\"blade\" + 0.020*\"much\" + 0.018*\"movie\" + 0.016*\"year\" + 0.016*\"ford\" + 0.015*\"glitch\" + 0.013*\"possible\" + 0.013*\"drawn\" + 0.011*\"gosling\"\n",
      "2019-10-29 00:44:38,313 : INFO : topic diff=0.643833, rho=1.000000\n",
      "2019-10-29 00:44:38,711 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:38,713 : INFO : built Dictionary(88 unique tokens: ['concern', 'nation', 'josh', 'something', 'option']...) from 5 documents (total 535 corpus positions)\n",
      "2019-10-29 00:44:38,716 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:38,717 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:38,718 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:38,720 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:38,721 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:38,765 : INFO : -7.056 per-word bound, 133.1 perplexity estimate based on a held-out corpus of 5 documents with 535 words\n",
      "2019-10-29 00:44:38,769 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:38,777 : INFO : topic #7 (0.100): 0.042*\"hope\" + 0.040*\"people\" + 0.024*\"help\" + 0.021*\"political\" + 0.020*\"message\" + 0.020*\"new\" + 0.019*\"actually\" + 0.018*\"trump\" + 0.018*\"offer\" + 0.018*\"technology\"\n",
      "2019-10-29 00:44:38,780 : INFO : topic #5 (0.100): 0.043*\"people\" + 0.029*\"hope\" + 0.021*\"technology\" + 0.020*\"provide\" + 0.019*\"member\" + 0.019*\"new\" + 0.018*\"political\" + 0.018*\"bot\" + 0.018*\"offer\" + 0.018*\"trump\"\n",
      "2019-10-29 00:44:38,783 : INFO : topic #2 (0.100): 0.034*\"people\" + 0.032*\"hope\" + 0.020*\"actually\" + 0.020*\"technology\" + 0.019*\"built\" + 0.019*\"bot\" + 0.018*\"message\" + 0.017*\"provide\" + 0.017*\"action\" + 0.017*\"political\"\n",
      "2019-10-29 00:44:38,785 : INFO : topic #4 (0.100): 0.032*\"hope\" + 0.032*\"people\" + 0.025*\"action\" + 0.023*\"bot\" + 0.019*\"built\" + 0.019*\"help\" + 0.018*\"new\" + 0.018*\"technology\" + 0.018*\"member\" + 0.017*\"provide\"\n",
      "2019-10-29 00:44:38,788 : INFO : topic #3 (0.100): 0.038*\"people\" + 0.034*\"hope\" + 0.022*\"political\" + 0.021*\"member\" + 0.021*\"technology\" + 0.020*\"built\" + 0.019*\"actually\" + 0.019*\"message\" + 0.018*\"bot\" + 0.017*\"provide\"\n",
      "2019-10-29 00:44:38,790 : INFO : topic diff=0.677607, rho=1.000000\n",
      "2019-10-29 00:44:39,230 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:39,233 : INFO : built Dictionary(78 unique tokens: ['story', 'completely', 'de', 'financial', 'early']...) from 5 documents (total 600 corpus positions)\n",
      "2019-10-29 00:44:39,235 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:39,237 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:39,241 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:39,244 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:39,247 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:39,290 : INFO : -6.534 per-word bound, 92.6 perplexity estimate based on a held-out corpus of 5 documents with 600 words\n",
      "2019-10-29 00:44:39,294 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:39,299 : INFO : topic #3 (0.100): 0.075*\"nelly\" + 0.031*\"woman\" + 0.031*\"say\" + 0.029*\"rapper\" + 0.027*\"hour\" + 0.025*\"police\" + 0.024*\"released\" + 0.024*\"report\" + 0.023*\"saturday\" + 0.022*\"alleged\"\n",
      "2019-10-29 00:44:39,302 : INFO : topic #2 (0.100): 0.057*\"nelly\" + 0.037*\"rapper\" + 0.037*\"say\" + 0.031*\"police\" + 0.027*\"released\" + 0.022*\"report\" + 0.022*\"woman\" + 0.021*\"custody\" + 0.021*\"hour\" + 0.021*\"saturday\"\n",
      "2019-10-29 00:44:39,308 : INFO : topic #1 (0.100): 0.057*\"nelly\" + 0.033*\"say\" + 0.032*\"rapper\" + 0.030*\"hour\" + 0.028*\"report\" + 0.027*\"released\" + 0.026*\"police\" + 0.026*\"woman\" + 0.025*\"saturday\" + 0.020*\"washington\"\n",
      "2019-10-29 00:44:39,312 : INFO : topic #0 (0.100): 0.068*\"nelly\" + 0.029*\"saturday\" + 0.028*\"police\" + 0.028*\"say\" + 0.026*\"report\" + 0.026*\"rapper\" + 0.024*\"released\" + 0.020*\"hour\" + 0.019*\"woman\" + 0.018*\"washington\"\n",
      "2019-10-29 00:44:39,314 : INFO : topic #8 (0.100): 0.057*\"nelly\" + 0.035*\"police\" + 0.030*\"hour\" + 0.030*\"rapper\" + 0.025*\"report\" + 0.024*\"woman\" + 0.023*\"say\" + 0.023*\"released\" + 0.021*\"charge\" + 0.020*\"water\"\n",
      "2019-10-29 00:44:39,317 : INFO : topic diff=0.795674, rho=1.000000\n",
      "2019-10-29 00:44:39,749 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:39,754 : INFO : built Dictionary(302 unique tokens: ['although', 'deter', 'product', 'significant', 'taxpayer']...) from 5 documents (total 2430 corpus positions)\n",
      "2019-10-29 00:44:39,758 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:39,759 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:39,761 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:39,766 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:39,767 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:39,860 : INFO : -7.676 per-word bound, 204.5 perplexity estimate based on a held-out corpus of 5 documents with 2430 words\n",
      "2019-10-29 00:44:39,861 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:39,870 : INFO : topic #9 (0.100): 0.032*\"study\" + 0.032*\"program\" + 0.025*\"baby\" + 0.022*\"girl\" + 0.016*\"said\" + 0.013*\"educational\" + 0.013*\"simulator\" + 0.011*\"brinkman\" + 0.011*\"pregnancy\" + 0.010*\"realityworks\"\n",
      "2019-10-29 00:44:39,871 : INFO : topic #2 (0.100): 0.034*\"study\" + 0.031*\"baby\" + 0.030*\"program\" + 0.021*\"girl\" + 0.015*\"said\" + 0.013*\"brinkman\" + 0.012*\"simulator\" + 0.012*\"pregnancy\" + 0.010*\"educational\" + 0.009*\"researcher\"\n",
      "2019-10-29 00:44:39,873 : INFO : topic #0 (0.100): 0.030*\"study\" + 0.026*\"program\" + 0.022*\"baby\" + 0.020*\"said\" + 0.015*\"girl\" + 0.014*\"educational\" + 0.013*\"brinkman\" + 0.011*\"pregnancy\" + 0.011*\"realityworks\" + 0.010*\"researcher\"\n",
      "2019-10-29 00:44:39,874 : INFO : topic #8 (0.100): 0.038*\"program\" + 0.030*\"baby\" + 0.024*\"study\" + 0.020*\"said\" + 0.015*\"educational\" + 0.015*\"girl\" + 0.014*\"simulator\" + 0.011*\"researcher\" + 0.011*\"pregnancy\" + 0.011*\"brinkman\"\n",
      "2019-10-29 00:44:39,876 : INFO : topic #7 (0.100): 0.037*\"program\" + 0.032*\"study\" + 0.027*\"baby\" + 0.023*\"girl\" + 0.018*\"simulator\" + 0.013*\"educational\" + 0.012*\"said\" + 0.012*\"brinkman\" + 0.011*\"realityworks\" + 0.011*\"pregnancy\"\n",
      "2019-10-29 00:44:39,878 : INFO : topic diff=0.843931, rho=1.000000\n",
      "2019-10-29 00:44:40,332 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:40,337 : INFO : built Dictionary(372 unique tokens: ['let', 'filed', 'deep', 'party', 'francisco']...) from 5 documents (total 3060 corpus positions)\n",
      "2019-10-29 00:44:40,344 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:40,345 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:40,350 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:40,354 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:40,357 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:40,517 : INFO : -7.846 per-word bound, 230.1 perplexity estimate based on a held-out corpus of 5 documents with 3060 words\n",
      "2019-10-29 00:44:40,518 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:40,527 : INFO : topic #1 (0.100): 0.024*\"feinstein\" + 0.019*\"california\" + 0.009*\"race\" + 0.008*\"term\" + 0.008*\"liberal\" + 0.007*\"one\" + 0.007*\"democrat\" + 0.007*\"senate\" + 0.007*\"long\" + 0.007*\"challenge\"\n",
      "2019-10-29 00:44:40,530 : INFO : topic #0 (0.100): 0.026*\"feinstein\" + 0.015*\"california\" + 0.010*\"race\" + 0.009*\"term\" + 0.008*\"one\" + 0.008*\"senate\" + 0.008*\"state\" + 0.007*\"challenge\" + 0.007*\"liberal\" + 0.007*\"run\"\n",
      "2019-10-29 00:44:40,534 : INFO : topic #9 (0.100): 0.024*\"feinstein\" + 0.017*\"california\" + 0.011*\"would\" + 0.010*\"race\" + 0.010*\"term\" + 0.008*\"liberal\" + 0.007*\"run\" + 0.007*\"challenge\" + 0.007*\"gun\" + 0.007*\"reston\"\n",
      "2019-10-29 00:44:40,538 : INFO : topic #3 (0.100): 0.021*\"feinstein\" + 0.019*\"california\" + 0.010*\"term\" + 0.008*\"would\" + 0.008*\"challenge\" + 0.008*\"race\" + 0.008*\"liberal\" + 0.008*\"senate\" + 0.007*\"trump\" + 0.007*\"reston\"\n",
      "2019-10-29 00:44:40,541 : INFO : topic #6 (0.100): 0.028*\"feinstein\" + 0.021*\"california\" + 0.010*\"term\" + 0.010*\"challenge\" + 0.009*\"race\" + 0.009*\"liberal\" + 0.008*\"senate\" + 0.008*\"would\" + 0.007*\"always\" + 0.007*\"democrat\"\n",
      "2019-10-29 00:44:40,553 : INFO : topic diff=0.818975, rho=1.000000\n",
      "2019-10-29 00:44:40,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:40,985 : INFO : built Dictionary(53 unique tokens: ['beat', 'rico', 'friend', 'loud', 'clock']...) from 5 documents (total 335 corpus positions)\n",
      "2019-10-29 00:44:40,986 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:40,987 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:40,989 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:40,991 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:40,996 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:41,018 : INFO : -6.580 per-word bound, 95.6 perplexity estimate based on a held-out corpus of 5 documents with 335 words\n",
      "2019-10-29 00:44:41,019 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:41,026 : INFO : topic #9 (0.100): 0.051*\"puerto\" + 0.046*\"song\" + 0.043*\"rico\" + 0.039*\"miranda\" + 0.032*\"praying\" + 0.031*\"like\" + 0.028*\"almost\" + 0.027*\"manuel\" + 0.025*\"lin\" + 0.024*\"say\"\n",
      "2019-10-29 00:44:41,030 : INFO : topic #4 (0.100): 0.049*\"puerto\" + 0.047*\"miranda\" + 0.038*\"song\" + 0.037*\"rico\" + 0.032*\"almost\" + 0.031*\"praying\" + 0.030*\"like\" + 0.028*\"say\" + 0.028*\"lin\" + 0.025*\"manuel\"\n",
      "2019-10-29 00:44:41,033 : INFO : topic #1 (0.100): 0.044*\"song\" + 0.041*\"puerto\" + 0.039*\"rico\" + 0.034*\"manuel\" + 0.033*\"praying\" + 0.033*\"miranda\" + 0.030*\"like\" + 0.027*\"say\" + 0.026*\"lin\" + 0.022*\"almost\"\n",
      "2019-10-29 00:44:41,037 : INFO : topic #0 (0.100): 0.049*\"miranda\" + 0.038*\"song\" + 0.036*\"rico\" + 0.034*\"like\" + 0.033*\"manuel\" + 0.030*\"almost\" + 0.029*\"praying\" + 0.029*\"puerto\" + 0.028*\"lin\" + 0.022*\"say\"\n",
      "2019-10-29 00:44:41,041 : INFO : topic #8 (0.100): 0.045*\"song\" + 0.043*\"miranda\" + 0.041*\"rico\" + 0.041*\"puerto\" + 0.035*\"almost\" + 0.030*\"lin\" + 0.029*\"manuel\" + 0.026*\"say\" + 0.025*\"like\" + 0.023*\"praying\"\n",
      "2019-10-29 00:44:41,046 : INFO : topic diff=0.711351, rho=1.000000\n",
      "2019-10-29 00:44:41,604 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:41,624 : INFO : built Dictionary(1311 unique tokens: ['reunion', 'earned', 'incremental', 'wanting', 'described']...) from 5 documents (total 14645 corpus positions)\n",
      "2019-10-29 00:44:41,639 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:41,641 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:41,647 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:41,656 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:41,659 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:42,056 : INFO : -8.708 per-word bound, 418.3 perplexity estimate based on a held-out corpus of 5 documents with 14645 words\n",
      "2019-10-29 00:44:42,057 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:42,072 : INFO : topic #0 (0.100): 0.020*\"gun\" + 0.013*\"say\" + 0.009*\"mother\" + 0.007*\"dougherty\" + 0.006*\"shooting\" + 0.006*\"rodriguez\" + 0.006*\"violence\" + 0.006*\"killed\" + 0.006*\"one\" + 0.006*\"sullivan\"\n",
      "2019-10-29 00:44:42,073 : INFO : topic #5 (0.100): 0.020*\"gun\" + 0.015*\"say\" + 0.009*\"mother\" + 0.009*\"dougherty\" + 0.008*\"rodriguez\" + 0.008*\"violence\" + 0.007*\"killed\" + 0.007*\"daughter\" + 0.007*\"one\" + 0.007*\"day\"\n",
      "2019-10-29 00:44:42,075 : INFO : topic #8 (0.100): 0.018*\"gun\" + 0.015*\"say\" + 0.008*\"rodriguez\" + 0.008*\"dougherty\" + 0.007*\"mother\" + 0.007*\"sullivan\" + 0.007*\"killed\" + 0.006*\"violence\" + 0.006*\"son\" + 0.006*\"one\"\n",
      "2019-10-29 00:44:42,077 : INFO : topic #2 (0.100): 0.020*\"gun\" + 0.011*\"mother\" + 0.011*\"say\" + 0.009*\"rodriguez\" + 0.008*\"violence\" + 0.008*\"killed\" + 0.008*\"shooting\" + 0.007*\"dougherty\" + 0.006*\"day\" + 0.006*\"family\"\n",
      "2019-10-29 00:44:42,078 : INFO : topic #7 (0.100): 0.020*\"gun\" + 0.015*\"say\" + 0.008*\"rodriguez\" + 0.008*\"dougherty\" + 0.007*\"killed\" + 0.007*\"mother\" + 0.006*\"two\" + 0.006*\"violence\" + 0.006*\"smegielski\" + 0.006*\"son\"\n",
      "2019-10-29 00:44:42,080 : INFO : topic diff=0.994474, rho=1.000000\n",
      "2019-10-29 00:44:42,496 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:42,498 : INFO : built Dictionary(39 unique tokens: ['caption', 'school', 'prepare', 'collect', 'rico']...) from 5 documents (total 615 corpus positions)\n",
      "2019-10-29 00:44:42,499 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:42,500 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:42,505 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:42,509 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:42,512 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:42,538 : INFO : -5.075 per-word bound, 33.7 perplexity estimate based on a held-out corpus of 5 documents with 615 words\n",
      "2019-10-29 00:44:42,540 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:42,547 : INFO : topic #6 (0.100): 0.102*\"puerto\" + 0.085*\"rico\" + 0.066*\"grassroots\" + 0.060*\"collect\" + 0.058*\"supply\" + 0.054*\"caption\" + 0.053*\"atlanta\" + 0.044*\"photo\" + 0.044*\"organzation\" + 0.040*\"hide\"\n",
      "2019-10-29 00:44:42,549 : INFO : topic #1 (0.100): 0.115*\"supply\" + 0.092*\"puerto\" + 0.062*\"rico\" + 0.061*\"grassroots\" + 0.060*\"organzation\" + 0.053*\"hide\" + 0.053*\"collect\" + 0.047*\"atlanta\" + 0.046*\"photo\" + 0.045*\"caption\"\n",
      "2019-10-29 00:44:42,552 : INFO : topic #0 (0.100): 0.107*\"puerto\" + 0.092*\"supply\" + 0.077*\"rico\" + 0.055*\"hide\" + 0.054*\"grassroots\" + 0.054*\"photo\" + 0.052*\"caption\" + 0.050*\"organzation\" + 0.050*\"collect\" + 0.039*\"donation\"\n",
      "2019-10-29 00:44:42,555 : INFO : topic #9 (0.100): 0.135*\"puerto\" + 0.082*\"supply\" + 0.075*\"rico\" + 0.059*\"grassroots\" + 0.059*\"organzation\" + 0.056*\"atlanta\" + 0.056*\"caption\" + 0.050*\"collect\" + 0.047*\"hide\" + 0.039*\"photo\"\n",
      "2019-10-29 00:44:42,559 : INFO : topic #5 (0.100): 0.092*\"puerto\" + 0.082*\"rico\" + 0.081*\"supply\" + 0.060*\"atlanta\" + 0.056*\"grassroots\" + 0.055*\"organzation\" + 0.052*\"collect\" + 0.051*\"photo\" + 0.046*\"caption\" + 0.046*\"hide\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:42,562 : INFO : topic diff=1.239763, rho=1.000000\n",
      "2019-10-29 00:44:42,983 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:42,987 : INFO : built Dictionary(106 unique tokens: ['anniversary', 'directly', 'thoughtful', 'special', 'hero']...) from 5 documents (total 950 corpus positions)\n",
      "2019-10-29 00:44:42,991 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:42,994 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:42,997 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:43,000 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:43,003 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:43,064 : INFO : -6.565 per-word bound, 94.7 perplexity estimate based on a held-out corpus of 5 documents with 950 words\n",
      "2019-10-29 00:44:43,067 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:43,074 : INFO : topic #9 (0.100): 0.040*\"hero\" + 0.031*\"nomination\" + 0.031*\"cnn\" + 0.022*\"work\" + 0.021*\"word\" + 0.019*\"write\" + 0.018*\"answer\" + 0.018*\"take\" + 0.017*\"help\" + 0.017*\"information\"\n",
      "2019-10-29 00:44:43,077 : INFO : topic #2 (0.100): 0.032*\"nomination\" + 0.031*\"cnn\" + 0.027*\"hero\" + 0.021*\"answer\" + 0.020*\"write\" + 0.019*\"share\" + 0.019*\"word\" + 0.017*\"form\" + 0.017*\"information\" + 0.015*\"take\"\n",
      "2019-10-29 00:44:43,080 : INFO : topic #1 (0.100): 0.037*\"nomination\" + 0.033*\"hero\" + 0.029*\"cnn\" + 0.026*\"information\" + 0.023*\"work\" + 0.021*\"write\" + 0.017*\"word\" + 0.017*\"nominee\" + 0.017*\"take\" + 0.015*\"help\"\n",
      "2019-10-29 00:44:43,084 : INFO : topic #8 (0.100): 0.036*\"nomination\" + 0.031*\"hero\" + 0.028*\"cnn\" + 0.027*\"answer\" + 0.025*\"word\" + 0.023*\"write\" + 0.021*\"information\" + 0.021*\"work\" + 0.019*\"form\" + 0.018*\"u\"\n",
      "2019-10-29 00:44:43,089 : INFO : topic #7 (0.100): 0.040*\"cnn\" + 0.039*\"nomination\" + 0.030*\"hero\" + 0.024*\"write\" + 0.021*\"information\" + 0.021*\"answer\" + 0.020*\"help\" + 0.018*\"u\" + 0.018*\"word\" + 0.017*\"share\"\n",
      "2019-10-29 00:44:43,091 : INFO : topic diff=0.704282, rho=1.000000\n",
      "2019-10-29 00:44:43,500 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:43,502 : INFO : built Dictionary(135 unique tokens: ['extensive', 'sorry', 'weinstein', 'consensual', 'interview']...) from 5 documents (total 1000 corpus positions)\n",
      "2019-10-29 00:44:43,504 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:43,506 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:43,508 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:43,511 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:43,512 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:43,577 : INFO : -7.068 per-word bound, 134.2 perplexity estimate based on a held-out corpus of 5 documents with 1000 words\n",
      "2019-10-29 00:44:43,578 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:43,587 : INFO : topic #5 (0.100): 0.046*\"weinstein\" + 0.028*\"damon\" + 0.026*\"cnn\" + 0.019*\"allegation\" + 0.019*\"harvey\" + 0.016*\"tuesday\" + 0.016*\"interview\" + 0.015*\"story\" + 0.015*\"report\" + 0.014*\"time\"\n",
      "2019-10-29 00:44:43,589 : INFO : topic #0 (0.100): 0.051*\"weinstein\" + 0.031*\"damon\" + 0.023*\"cnn\" + 0.021*\"story\" + 0.018*\"tuesday\" + 0.017*\"allegation\" + 0.016*\"interview\" + 0.016*\"woman\" + 0.013*\"harvey\" + 0.013*\"new\"\n",
      "2019-10-29 00:44:43,592 : INFO : topic #9 (0.100): 0.039*\"damon\" + 0.035*\"weinstein\" + 0.025*\"cnn\" + 0.024*\"allegation\" + 0.022*\"story\" + 0.020*\"tuesday\" + 0.019*\"interview\" + 0.016*\"new\" + 0.014*\"report\" + 0.014*\"harvey\"\n",
      "2019-10-29 00:44:43,594 : INFO : topic #8 (0.100): 0.047*\"weinstein\" + 0.025*\"damon\" + 0.023*\"cnn\" + 0.020*\"tuesday\" + 0.019*\"interview\" + 0.018*\"story\" + 0.017*\"allegation\" + 0.015*\"woman\" + 0.015*\"time\" + 0.014*\"report\"\n",
      "2019-10-29 00:44:43,597 : INFO : topic #3 (0.100): 0.052*\"weinstein\" + 0.028*\"damon\" + 0.021*\"cnn\" + 0.017*\"tuesday\" + 0.017*\"story\" + 0.016*\"new\" + 0.016*\"allegation\" + 0.016*\"interview\" + 0.015*\"time\" + 0.014*\"woman\"\n",
      "2019-10-29 00:44:43,600 : INFO : topic diff=0.794591, rho=1.000000\n",
      "2019-10-29 00:44:43,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:43,994 : INFO : built Dictionary(73 unique tokens: ['creating', 'help', 'energy', 'nation', 'drinking']...) from 5 documents (total 400 corpus positions)\n",
      "2019-10-29 00:44:43,995 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:43,997 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:44,002 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:44,006 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:44,009 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:44,046 : INFO : -7.132 per-word bound, 140.2 perplexity estimate based on a held-out corpus of 5 documents with 400 words\n",
      "2019-10-29 00:44:44,048 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:44,058 : INFO : topic #3 (0.100): 0.030*\"water\" + 0.025*\"innovation\" + 0.024*\"city\" + 0.022*\"cnn\" + 0.022*\"tomorrow\" + 0.021*\"energy\" + 0.017*\"21st\" + 0.017*\"solve\" + 0.016*\"air\" + 0.016*\"along\"\n",
      "2019-10-29 00:44:44,060 : INFO : topic #5 (0.100): 0.041*\"city\" + 0.031*\"tomorrow\" + 0.027*\"cnn\" + 0.026*\"water\" + 0.025*\"energy\" + 0.019*\"innovation\" + 0.017*\"via\" + 0.016*\"amazing\" + 0.016*\"along\" + 0.015*\"emerging\"\n",
      "2019-10-29 00:44:44,063 : INFO : topic #9 (0.100): 0.041*\"city\" + 0.025*\"cnn\" + 0.023*\"energy\" + 0.022*\"tomorrow\" + 0.021*\"innovation\" + 0.020*\"water\" + 0.016*\"http\" + 0.016*\"footprint\" + 0.016*\"imagine\" + 0.015*\"happening\"\n",
      "2019-10-29 00:44:44,067 : INFO : topic #6 (0.100): 0.037*\"city\" + 0.030*\"energy\" + 0.029*\"water\" + 0.025*\"innovation\" + 0.024*\"tomorrow\" + 0.019*\"cnn\" + 0.018*\"high\" + 0.016*\"pace\" + 0.015*\"creating\" + 0.015*\"increased\"\n",
      "2019-10-29 00:44:44,071 : INFO : topic #4 (0.100): 0.037*\"city\" + 0.026*\"cnn\" + 0.022*\"energy\" + 0.020*\"tomorrow\" + 0.020*\"innovation\" + 0.020*\"water\" + 0.016*\"skyrocket\" + 0.016*\"pace\" + 0.016*\"www\" + 0.015*\"conversation\"\n",
      "2019-10-29 00:44:44,073 : INFO : topic diff=0.610720, rho=1.000000\n",
      "2019-10-29 00:44:44,474 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:44,475 : INFO : built Dictionary(1 unique tokens: ['nan']) from 5 documents (total 5 corpus positions)\n",
      "2019-10-29 00:44:44,476 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:44,477 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:44,479 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:44,481 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:44,482 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:44,488 : INFO : -4.931 per-word bound, 30.5 perplexity estimate based on a held-out corpus of 5 documents with 5 words\n",
      "2019-10-29 00:44:44,490 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:44,495 : INFO : topic #7 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:44:44,497 : INFO : topic #3 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:44:44,499 : INFO : topic #9 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:44:44,501 : INFO : topic #5 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:44:44,502 : INFO : topic #4 (0.100): 1.000*\"nan\"\n",
      "2019-10-29 00:44:44,504 : INFO : topic diff=0.000000, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:44,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:44,904 : INFO : built Dictionary(111 unique tokens: ['decide', 'take', 'fate', 'required', 'stop']...) from 5 documents (total 765 corpus positions)\n",
      "2019-10-29 00:44:44,907 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:44,910 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:44,916 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:44,920 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:44,921 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:44,991 : INFO : -7.014 per-word bound, 129.3 perplexity estimate based on a held-out corpus of 5 documents with 765 words\n",
      "2019-10-29 00:44:44,992 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:44,998 : INFO : topic #9 (0.100): 0.041*\"trump\" + 0.027*\"judge\" + 0.024*\"called\" + 0.023*\"rule\" + 0.020*\"washington\" + 0.019*\"administration\" + 0.019*\"suit\" + 0.018*\"new\" + 0.018*\"state\" + 0.017*\"contraceptive\"\n",
      "2019-10-29 00:44:45,002 : INFO : topic #8 (0.100): 0.040*\"trump\" + 0.027*\"rule\" + 0.025*\"called\" + 0.024*\"washington\" + 0.023*\"new\" + 0.023*\"judge\" + 0.021*\"administration\" + 0.020*\"health\" + 0.018*\"state\" + 0.015*\"suit\"\n",
      "2019-10-29 00:44:45,006 : INFO : topic #1 (0.100): 0.052*\"trump\" + 0.035*\"judge\" + 0.029*\"administration\" + 0.029*\"rule\" + 0.027*\"washington\" + 0.024*\"new\" + 0.019*\"suit\" + 0.019*\"called\" + 0.019*\"health\" + 0.016*\"travel\"\n",
      "2019-10-29 00:44:45,009 : INFO : topic #0 (0.100): 0.029*\"judge\" + 0.028*\"trump\" + 0.026*\"washington\" + 0.025*\"administration\" + 0.023*\"rule\" + 0.022*\"called\" + 0.022*\"health\" + 0.020*\"state\" + 0.020*\"suit\" + 0.017*\"ban\"\n",
      "2019-10-29 00:44:45,012 : INFO : topic #7 (0.100): 0.049*\"trump\" + 0.033*\"judge\" + 0.029*\"called\" + 0.025*\"rule\" + 0.022*\"health\" + 0.022*\"administration\" + 0.021*\"new\" + 0.019*\"washington\" + 0.016*\"suit\" + 0.014*\"state\"\n",
      "2019-10-29 00:44:45,016 : INFO : topic diff=0.787911, rho=1.000000\n",
      "2019-10-29 00:44:45,475 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:45,477 : INFO : built Dictionary(92 unique tokens: ['forecast', 'nation', 'come', 'southwest', 'boost']...) from 5 documents (total 710 corpus positions)\n",
      "2019-10-29 00:44:45,479 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:45,481 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:45,482 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:45,488 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:45,491 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:45,539 : INFO : -6.664 per-word bound, 101.4 perplexity estimate based on a held-out corpus of 5 documents with 710 words\n",
      "2019-10-29 00:44:45,542 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:45,549 : INFO : topic #3 (0.100): 0.041*\"airline\" + 0.031*\"quarter\" + 0.028*\"fare\" + 0.026*\"delta\" + 0.023*\"guidance\" + 0.023*\"hurricane\" + 0.022*\"passenger\" + 0.022*\"earlier\" + 0.021*\"better\" + 0.021*\"million\"\n",
      "2019-10-29 00:44:45,552 : INFO : topic #6 (0.100): 0.040*\"airline\" + 0.036*\"quarter\" + 0.032*\"delta\" + 0.023*\"million\" + 0.023*\"fare\" + 0.022*\"better\" + 0.021*\"said\" + 0.020*\"guidance\" + 0.019*\"measure\" + 0.019*\"hurricane\"\n",
      "2019-10-29 00:44:45,558 : INFO : topic #4 (0.100): 0.041*\"airline\" + 0.032*\"fare\" + 0.030*\"quarter\" + 0.030*\"delta\" + 0.027*\"guidance\" + 0.024*\"earlier\" + 0.024*\"better\" + 0.022*\"passenger\" + 0.021*\"million\" + 0.020*\"hurricane\"\n",
      "2019-10-29 00:44:45,561 : INFO : topic #1 (0.100): 0.051*\"airline\" + 0.036*\"fare\" + 0.031*\"quarter\" + 0.029*\"delta\" + 0.024*\"said\" + 0.021*\"guidance\" + 0.020*\"hurricane\" + 0.019*\"third\" + 0.017*\"even\" + 0.017*\"passenger\"\n",
      "2019-10-29 00:44:45,568 : INFO : topic #0 (0.100): 0.040*\"quarter\" + 0.038*\"airline\" + 0.036*\"fare\" + 0.031*\"guidance\" + 0.023*\"earlier\" + 0.023*\"third\" + 0.023*\"delta\" + 0.020*\"better\" + 0.020*\"passenger\" + 0.019*\"million\"\n",
      "2019-10-29 00:44:45,573 : INFO : topic diff=0.797735, rho=1.000000\n",
      "2019-10-29 00:44:45,986 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:45,989 : INFO : built Dictionary(121 unique tokens: ['school', 'campaign', 'leader', 'home', 'get']...) from 5 documents (total 920 corpus positions)\n",
      "2019-10-29 00:44:45,992 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:45,993 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:45,994 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:45,996 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:45,997 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:46,053 : INFO : -6.921 per-word bound, 121.1 perplexity estimate based on a held-out corpus of 5 documents with 920 words\n",
      "2019-10-29 00:44:46,056 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:46,065 : INFO : topic #7 (0.100): 0.069*\"girl\" + 0.022*\"million\" + 0.022*\"world\" + 0.022*\"africa\" + 0.022*\"get\" + 0.021*\"country\" + 0.019*\"day\" + 0.017*\"school\" + 0.017*\"gayle\" + 0.016*\"education\"\n",
      "2019-10-29 00:44:46,066 : INFO : topic #4 (0.100): 0.071*\"girl\" + 0.026*\"million\" + 0.026*\"day\" + 0.023*\"world\" + 0.022*\"country\" + 0.021*\"education\" + 0.018*\"get\" + 0.017*\"africa\" + 0.017*\"smith\" + 0.015*\"school\"\n",
      "2019-10-29 00:44:46,070 : INFO : topic #0 (0.100): 0.069*\"girl\" + 0.028*\"education\" + 0.021*\"day\" + 0.021*\"year\" + 0.020*\"africa\" + 0.020*\"million\" + 0.019*\"world\" + 0.018*\"get\" + 0.018*\"country\" + 0.017*\"smith\"\n",
      "2019-10-29 00:44:46,076 : INFO : topic #8 (0.100): 0.077*\"girl\" + 0.021*\"day\" + 0.020*\"million\" + 0.019*\"education\" + 0.019*\"get\" + 0.019*\"country\" + 0.019*\"world\" + 0.017*\"long\" + 0.016*\"gayle\" + 0.015*\"school\"\n",
      "2019-10-29 00:44:46,080 : INFO : topic #9 (0.100): 0.063*\"girl\" + 0.023*\"country\" + 0.022*\"get\" + 0.021*\"africa\" + 0.021*\"world\" + 0.021*\"year\" + 0.021*\"day\" + 0.020*\"million\" + 0.018*\"education\" + 0.016*\"smith\"\n",
      "2019-10-29 00:44:46,083 : INFO : topic diff=0.812651, rho=1.000000\n",
      "2019-10-29 00:44:46,540 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:46,546 : INFO : built Dictionary(442 unique tokens: ['although', 'deep', 'focus', 'expert', 'one']...) from 5 documents (total 4010 corpus positions)\n",
      "2019-10-29 00:44:46,551 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:46,553 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:46,554 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:46,558 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:46,560 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:46,694 : INFO : -7.879 per-word bound, 235.4 perplexity estimate based on a held-out corpus of 5 documents with 4010 words\n",
      "2019-10-29 00:44:46,696 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:46,706 : INFO : topic #6 (0.100): 0.025*\"budget\" + 0.018*\"health\" + 0.018*\"would\" + 0.015*\"said\" + 0.015*\"research\" + 0.012*\"medical\" + 0.011*\"american\" + 0.009*\"program\" + 0.009*\"also\" + 0.008*\"proposal\"\n",
      "2019-10-29 00:44:46,707 : INFO : topic #9 (0.100): 0.025*\"budget\" + 0.018*\"health\" + 0.017*\"said\" + 0.017*\"would\" + 0.011*\"american\" + 0.010*\"science\" + 0.010*\"funding\" + 0.009*\"million\" + 0.009*\"medical\" + 0.009*\"research\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:46,709 : INFO : topic #1 (0.100): 0.037*\"budget\" + 0.020*\"would\" + 0.019*\"health\" + 0.016*\"said\" + 0.013*\"medical\" + 0.013*\"science\" + 0.012*\"american\" + 0.012*\"research\" + 0.011*\"also\" + 0.009*\"funding\"\n",
      "2019-10-29 00:44:46,710 : INFO : topic #0 (0.100): 0.036*\"budget\" + 0.021*\"would\" + 0.017*\"health\" + 0.016*\"research\" + 0.014*\"said\" + 0.013*\"american\" + 0.011*\"medical\" + 0.011*\"science\" + 0.011*\"program\" + 0.010*\"state\"\n",
      "2019-10-29 00:44:46,712 : INFO : topic #3 (0.100): 0.020*\"health\" + 0.020*\"budget\" + 0.018*\"would\" + 0.015*\"research\" + 0.012*\"medical\" + 0.012*\"proposal\" + 0.012*\"said\" + 0.011*\"american\" + 0.010*\"effort\" + 0.010*\"science\"\n",
      "2019-10-29 00:44:46,714 : INFO : topic diff=0.926987, rho=1.000000\n",
      "2019-10-29 00:44:47,124 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:47,129 : INFO : built Dictionary(313 unique tokens: ['previously', 'shell', 'perhaps', 'tax', 'campaign']...) from 5 documents (total 2445 corpus positions)\n",
      "2019-10-29 00:44:47,134 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:47,137 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:47,142 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:47,146 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:47,149 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:47,291 : INFO : -7.756 per-word bound, 216.1 perplexity estimate based on a held-out corpus of 5 documents with 2445 words\n",
      "2019-10-29 00:44:47,293 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:47,301 : INFO : topic #6 (0.100): 0.029*\"trump\" + 0.024*\"cause\" + 0.019*\"eminem\" + 0.013*\"president\" + 0.012*\"like\" + 0.010*\"come\" + 0.009*\"rapper\" + 0.009*\"tax\" + 0.009*\"war\" + 0.009*\"verse\"\n",
      "2019-10-29 00:44:47,304 : INFO : topic #3 (0.100): 0.030*\"trump\" + 0.022*\"eminem\" + 0.020*\"cause\" + 0.013*\"president\" + 0.011*\"like\" + 0.010*\"come\" + 0.009*\"war\" + 0.008*\"attack\" + 0.008*\"freestyle\" + 0.008*\"verse\"\n",
      "2019-10-29 00:44:47,307 : INFO : topic #0 (0.100): 0.033*\"trump\" + 0.020*\"cause\" + 0.019*\"eminem\" + 0.014*\"president\" + 0.013*\"come\" + 0.011*\"like\" + 0.009*\"kaepernick\" + 0.009*\"freestyle\" + 0.009*\"full\" + 0.009*\"war\"\n",
      "2019-10-29 00:44:47,310 : INFO : topic #2 (0.100): 0.026*\"trump\" + 0.025*\"eminem\" + 0.025*\"cause\" + 0.015*\"come\" + 0.014*\"like\" + 0.013*\"president\" + 0.010*\"war\" + 0.009*\"full\" + 0.008*\"kaepernick\" + 0.008*\"verse\"\n",
      "2019-10-29 00:44:47,312 : INFO : topic #5 (0.100): 0.026*\"cause\" + 0.026*\"trump\" + 0.022*\"eminem\" + 0.012*\"president\" + 0.012*\"like\" + 0.011*\"war\" + 0.010*\"rapper\" + 0.009*\"come\" + 0.009*\"verse\" + 0.008*\"freestyle\"\n",
      "2019-10-29 00:44:47,314 : INFO : topic diff=0.795731, rho=1.000000\n",
      "2019-10-29 00:44:47,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:47,734 : INFO : built Dictionary(21 unique tokens: ['film', 'night', 'harassment', 'weinstein', 'host']...) from 5 documents (total 110 corpus positions)\n",
      "2019-10-29 00:44:47,735 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:47,736 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:47,738 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:47,740 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:47,741 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:47,758 : INFO : -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 5 documents with 110 words\n",
      "2019-10-29 00:44:47,759 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:47,764 : INFO : topic #7 (0.100): 0.070*\"weinstein\" + 0.061*\"night\" + 0.058*\"harassment\" + 0.056*\"dinosaur\" + 0.053*\"late\" + 0.052*\"accusation\" + 0.051*\"television\" + 0.050*\"sexual\" + 0.047*\"fired\" + 0.046*\"back\"\n",
      "2019-10-29 00:44:47,765 : INFO : topic #8 (0.100): 0.067*\"weinstein\" + 0.052*\"sexual\" + 0.052*\"television\" + 0.051*\"light\" + 0.051*\"mogul\" + 0.050*\"hollywood\" + 0.049*\"film\" + 0.049*\"harassment\" + 0.049*\"late\" + 0.049*\"fired\"\n",
      "2019-10-29 00:44:47,767 : INFO : topic #4 (0.100): 0.103*\"weinstein\" + 0.056*\"harvey\" + 0.055*\"hold\" + 0.053*\"hollywood\" + 0.051*\"back\" + 0.051*\"colbert\" + 0.047*\"film\" + 0.045*\"fired\" + 0.045*\"mogul\" + 0.044*\"dinosaur\"\n",
      "2019-10-29 00:44:47,768 : INFO : topic #3 (0.100): 0.093*\"weinstein\" + 0.056*\"harvey\" + 0.053*\"sexual\" + 0.053*\"mogul\" + 0.051*\"colbert\" + 0.050*\"better\" + 0.049*\"late\" + 0.049*\"accusation\" + 0.048*\"company\" + 0.047*\"fired\"\n",
      "2019-10-29 00:44:47,769 : INFO : topic #1 (0.100): 0.082*\"weinstein\" + 0.054*\"colbert\" + 0.051*\"hold\" + 0.050*\"light\" + 0.049*\"night\" + 0.049*\"mogul\" + 0.048*\"knew\" + 0.048*\"film\" + 0.048*\"company\" + 0.047*\"better\"\n",
      "2019-10-29 00:44:47,770 : INFO : topic diff=0.562875, rho=1.000000\n",
      "2019-10-29 00:44:48,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:48,223 : INFO : built Dictionary(286 unique tokens: ['blocked', 'juyun', 'energy', 'watch', 'oligomer']...) from 5 documents (total 2480 corpus positions)\n",
      "2019-10-29 00:44:48,228 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:48,229 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:48,230 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:48,234 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:48,235 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:48,354 : INFO : -7.522 per-word bound, 183.7 perplexity estimate based on a held-out corpus of 5 documents with 2480 words\n",
      "2019-10-29 00:44:48,355 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:48,365 : INFO : topic #8 (0.100): 0.064*\"taste\" + 0.026*\"study\" + 0.025*\"said\" + 0.016*\"sweet\" + 0.013*\"glucose\" + 0.012*\"participant\" + 0.011*\"human\" + 0.010*\"sixth\" + 0.010*\"fatty\" + 0.010*\"detect\"\n",
      "2019-10-29 00:44:48,367 : INFO : topic #4 (0.100): 0.061*\"taste\" + 0.024*\"study\" + 0.024*\"said\" + 0.016*\"sweet\" + 0.014*\"sixth\" + 0.013*\"human\" + 0.012*\"glucose\" + 0.011*\"lim\" + 0.011*\"chemical\" + 0.010*\"participant\"\n",
      "2019-10-29 00:44:48,369 : INFO : topic #2 (0.100): 0.058*\"taste\" + 0.029*\"study\" + 0.019*\"said\" + 0.015*\"glucose\" + 0.013*\"sixth\" + 0.012*\"sweet\" + 0.012*\"lim\" + 0.011*\"participant\" + 0.011*\"five\" + 0.010*\"starch\"\n",
      "2019-10-29 00:44:48,373 : INFO : topic #6 (0.100): 0.054*\"taste\" + 0.022*\"said\" + 0.021*\"study\" + 0.014*\"sweet\" + 0.013*\"glucose\" + 0.011*\"human\" + 0.011*\"fatty\" + 0.010*\"sixth\" + 0.009*\"participant\" + 0.009*\"lim\"\n",
      "2019-10-29 00:44:48,375 : INFO : topic #3 (0.100): 0.057*\"taste\" + 0.029*\"study\" + 0.016*\"said\" + 0.015*\"glucose\" + 0.014*\"sweet\" + 0.013*\"sixth\" + 0.011*\"detect\" + 0.010*\"receptor\" + 0.010*\"participant\" + 0.010*\"researcher\"\n",
      "2019-10-29 00:44:48,378 : INFO : topic diff=0.892465, rho=1.000000\n",
      "2019-10-29 00:44:48,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:48,791 : INFO : built Dictionary(207 unique tokens: ['let', 'significant', 'happy', 'focus', 'firsthand']...) from 5 documents (total 1455 corpus positions)\n",
      "2019-10-29 00:44:48,794 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:48,797 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:48,800 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:48,804 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:48,808 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:48,884 : INFO : -7.534 per-word bound, 185.4 perplexity estimate based on a held-out corpus of 5 documents with 1455 words\n",
      "2019-10-29 00:44:48,885 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:48,893 : INFO : topic #4 (0.100): 0.050*\"pandya\" + 0.043*\"huaorani\" + 0.021*\"said\" + 0.015*\"think\" + 0.012*\"change\" + 0.012*\"community\" + 0.010*\"native\" + 0.010*\"portrait\" + 0.010*\"decision\" + 0.008*\"human\"\n",
      "2019-10-29 00:44:48,895 : INFO : topic #9 (0.100): 0.040*\"huaorani\" + 0.030*\"pandya\" + 0.022*\"said\" + 0.016*\"change\" + 0.013*\"portrait\" + 0.012*\"think\" + 0.011*\"year\" + 0.011*\"human\" + 0.010*\"community\" + 0.010*\"language\"\n",
      "2019-10-29 00:44:48,897 : INFO : topic #2 (0.100): 0.044*\"huaorani\" + 0.032*\"pandya\" + 0.026*\"said\" + 0.015*\"change\" + 0.012*\"native\" + 0.011*\"year\" + 0.011*\"think\" + 0.010*\"portrait\" + 0.010*\"community\" + 0.009*\"language\"\n",
      "2019-10-29 00:44:48,899 : INFO : topic #1 (0.100): 0.038*\"pandya\" + 0.033*\"huaorani\" + 0.023*\"said\" + 0.015*\"portrait\" + 0.012*\"think\" + 0.011*\"language\" + 0.010*\"community\" + 0.009*\"native\" + 0.009*\"human\" + 0.009*\"year\"\n",
      "2019-10-29 00:44:48,901 : INFO : topic #0 (0.100): 0.041*\"pandya\" + 0.037*\"huaorani\" + 0.020*\"said\" + 0.016*\"think\" + 0.013*\"change\" + 0.012*\"portrait\" + 0.012*\"year\" + 0.011*\"community\" + 0.011*\"native\" + 0.009*\"language\"\n",
      "2019-10-29 00:44:48,906 : INFO : topic diff=0.757380, rho=1.000000\n",
      "2019-10-29 00:44:49,399 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:49,408 : INFO : built Dictionary(629 unique tokens: ['reunion', 'rumor', 'bone', 'jamie', 'drinking']...) from 5 documents (total 5980 corpus positions)\n",
      "2019-10-29 00:44:49,415 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:49,416 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:49,417 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:49,421 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:49,423 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:49,598 : INFO : -8.166 per-word bound, 287.1 perplexity estimate based on a held-out corpus of 5 documents with 5980 words\n",
      "2019-10-29 00:44:49,599 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:49,608 : INFO : topic #3 (0.100): 0.016*\"people\" + 0.009*\"gunfire\" + 0.009*\"festival\" + 0.008*\"one\" + 0.008*\"get\" + 0.008*\"vega\" + 0.007*\"say\" + 0.007*\"inside\" + 0.007*\"la\" + 0.006*\"police\"\n",
      "2019-10-29 00:44:49,611 : INFO : topic #0 (0.100): 0.019*\"people\" + 0.012*\"get\" + 0.008*\"vega\" + 0.007*\"say\" + 0.007*\"festival\" + 0.007*\"go\" + 0.007*\"floor\" + 0.007*\"la\" + 0.006*\"inside\" + 0.006*\"gunfire\"\n",
      "2019-10-29 00:44:49,612 : INFO : topic #2 (0.100): 0.016*\"people\" + 0.009*\"inside\" + 0.009*\"get\" + 0.007*\"go\" + 0.007*\"festival\" + 0.007*\"gunfire\" + 0.007*\"hopkins\" + 0.006*\"police\" + 0.006*\"la\" + 0.006*\"stage\"\n",
      "2019-10-29 00:44:49,614 : INFO : topic #9 (0.100): 0.012*\"people\" + 0.009*\"inside\" + 0.008*\"say\" + 0.008*\"one\" + 0.008*\"get\" + 0.007*\"go\" + 0.007*\"floor\" + 0.007*\"festival\" + 0.006*\"police\" + 0.006*\"video\"\n",
      "2019-10-29 00:44:49,616 : INFO : topic #5 (0.100): 0.012*\"people\" + 0.011*\"get\" + 0.009*\"gunfire\" + 0.009*\"vega\" + 0.009*\"go\" + 0.008*\"inside\" + 0.008*\"police\" + 0.008*\"say\" + 0.007*\"festival\" + 0.007*\"la\"\n",
      "2019-10-29 00:44:49,617 : INFO : topic diff=0.892833, rho=1.000000\n",
      "2019-10-29 00:44:50,031 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:50,033 : INFO : built Dictionary(124 unique tokens: ['extensive', 'energy', 'gillie', 'crazier', 'sniping']...) from 5 documents (total 725 corpus positions)\n",
      "2019-10-29 00:44:50,036 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:50,037 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:50,038 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:50,041 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:50,042 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:50,101 : INFO : -7.425 per-word bound, 171.8 perplexity estimate based on a held-out corpus of 5 documents with 725 words\n",
      "2019-10-29 00:44:50,103 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:50,109 : INFO : topic #9 (0.100): 0.028*\"blake\" + 0.020*\"girl\" + 0.018*\"fallon\" + 0.018*\"original\" + 0.017*\"dynasty\" + 0.016*\"character\" + 0.015*\"rich\" + 0.014*\"buck\" + 0.014*\"cristal\" + 0.013*\"revival\"\n",
      "2019-10-29 00:44:50,112 : INFO : topic #0 (0.100): 0.027*\"blake\" + 0.020*\"girl\" + 0.019*\"fallon\" + 0.017*\"original\" + 0.015*\"gossip\" + 0.015*\"buck\" + 0.014*\"revival\" + 0.014*\"dynasty\" + 0.014*\"producer\" + 0.013*\"rich\"\n",
      "2019-10-29 00:44:50,116 : INFO : topic #1 (0.100): 0.023*\"blake\" + 0.022*\"dynasty\" + 0.019*\"original\" + 0.018*\"girl\" + 0.015*\"fallon\" + 0.015*\"character\" + 0.013*\"banging\" + 0.013*\"rich\" + 0.013*\"producer\" + 0.012*\"super\"\n",
      "2019-10-29 00:44:50,125 : INFO : topic #7 (0.100): 0.023*\"girl\" + 0.020*\"dynasty\" + 0.018*\"original\" + 0.017*\"blake\" + 0.016*\"revival\" + 0.016*\"producer\" + 0.015*\"buck\" + 0.014*\"super\" + 0.014*\"fallon\" + 0.014*\"banging\"\n",
      "2019-10-29 00:44:50,129 : INFO : topic #4 (0.100): 0.021*\"fallon\" + 0.020*\"dynasty\" + 0.019*\"blake\" + 0.017*\"revival\" + 0.017*\"original\" + 0.015*\"show\" + 0.014*\"rich\" + 0.014*\"buck\" + 0.014*\"super\" + 0.014*\"character\"\n",
      "2019-10-29 00:44:50,132 : INFO : topic diff=0.666464, rho=1.000000\n",
      "2019-10-29 00:44:50,575 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:50,581 : INFO : built Dictionary(387 unique tokens: ['although', 'dating', 'innovation', 'daniel', 'expert']...) from 5 documents (total 4045 corpus positions)\n",
      "2019-10-29 00:44:50,586 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:50,587 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:50,588 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:50,592 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:50,593 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:50,717 : INFO : -7.585 per-word bound, 192.1 perplexity estimate based on a held-out corpus of 5 documents with 4045 words\n",
      "2019-10-29 00:44:50,718 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:50,725 : INFO : topic #4 (0.100): 0.037*\"hiv\" + 0.021*\"said\" + 0.018*\"dating\" + 0.016*\"user\" + 0.016*\"status\" + 0.014*\"apps\" + 0.014*\"std\" + 0.013*\"people\" + 0.012*\"could\" + 0.012*\"app\"\n",
      "2019-10-29 00:44:50,728 : INFO : topic #8 (0.100): 0.055*\"hiv\" + 0.022*\"said\" + 0.018*\"dating\" + 0.017*\"people\" + 0.015*\"user\" + 0.015*\"status\" + 0.012*\"app\" + 0.011*\"filter\" + 0.011*\"std\" + 0.011*\"could\"\n",
      "2019-10-29 00:44:50,730 : INFO : topic #1 (0.100): 0.057*\"hiv\" + 0.018*\"said\" + 0.017*\"dating\" + 0.017*\"people\" + 0.017*\"user\" + 0.015*\"status\" + 0.015*\"positive\" + 0.014*\"apps\" + 0.013*\"app\" + 0.011*\"std\"\n",
      "2019-10-29 00:44:50,733 : INFO : topic #0 (0.100): 0.051*\"hiv\" + 0.020*\"dating\" + 0.018*\"said\" + 0.015*\"user\" + 0.015*\"status\" + 0.014*\"people\" + 0.013*\"std\" + 0.013*\"app\" + 0.012*\"filter\" + 0.012*\"apps\"\n",
      "2019-10-29 00:44:50,735 : INFO : topic #9 (0.100): 0.044*\"hiv\" + 0.022*\"dating\" + 0.021*\"user\" + 0.018*\"people\" + 0.016*\"said\" + 0.015*\"apps\" + 0.015*\"status\" + 0.012*\"could\" + 0.011*\"filter\" + 0.011*\"health\"\n",
      "2019-10-29 00:44:50,738 : INFO : topic diff=1.004247, rho=1.000000\n",
      "2019-10-29 00:44:51,231 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:51,242 : INFO : built Dictionary(548 unique tokens: ['phase', 'grew', 'allergic', 'recommendation', 'orphan']...) from 5 documents (total 4910 corpus positions)\n",
      "2019-10-29 00:44:51,251 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:51,254 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:51,257 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:51,262 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:51,263 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:51,503 : INFO : -8.099 per-word bound, 274.2 perplexity estimate based on a held-out corpus of 5 documents with 4910 words\n",
      "2019-10-29 00:44:51,504 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:51,515 : INFO : topic #0 (0.100): 0.027*\"gene\" + 0.024*\"said\" + 0.016*\"christian\" + 0.015*\"therapy\" + 0.014*\"would\" + 0.012*\"mahajan\" + 0.010*\"patient\" + 0.009*\"cell\" + 0.009*\"virus\" + 0.008*\"vision\"\n",
      "2019-10-29 00:44:51,518 : INFO : topic #3 (0.100): 0.023*\"gene\" + 0.021*\"said\" + 0.013*\"would\" + 0.013*\"therapy\" + 0.012*\"virus\" + 0.012*\"christian\" + 0.011*\"mahajan\" + 0.010*\"eye\" + 0.010*\"cell\" + 0.009*\"disease\"\n",
      "2019-10-29 00:44:51,522 : INFO : topic #6 (0.100): 0.023*\"said\" + 0.018*\"gene\" + 0.017*\"christian\" + 0.014*\"therapy\" + 0.011*\"eye\" + 0.011*\"cell\" + 0.011*\"vision\" + 0.011*\"patient\" + 0.010*\"would\" + 0.009*\"mahajan\"\n",
      "2019-10-29 00:44:51,526 : INFO : topic #9 (0.100): 0.021*\"said\" + 0.018*\"gene\" + 0.014*\"therapy\" + 0.014*\"christian\" + 0.014*\"cell\" + 0.012*\"would\" + 0.011*\"disease\" + 0.010*\"patient\" + 0.010*\"eye\" + 0.009*\"vision\"\n",
      "2019-10-29 00:44:51,529 : INFO : topic #4 (0.100): 0.030*\"said\" + 0.022*\"gene\" + 0.015*\"christian\" + 0.013*\"mahajan\" + 0.012*\"patient\" + 0.012*\"would\" + 0.012*\"therapy\" + 0.012*\"eye\" + 0.011*\"cell\" + 0.010*\"virus\"\n",
      "2019-10-29 00:44:51,532 : INFO : topic diff=0.905964, rho=1.000000\n",
      "2019-10-29 00:44:51,964 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:51,968 : INFO : built Dictionary(305 unique tokens: ['forward', 'roper', 'school', 'significant', 'campaign']...) from 5 documents (total 2825 corpus positions)\n",
      "2019-10-29 00:44:51,973 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:51,974 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:51,976 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:51,979 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:51,980 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:52,076 : INFO : -7.499 per-word bound, 180.9 perplexity estimate based on a held-out corpus of 5 documents with 2825 words\n",
      "2019-10-29 00:44:52,078 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:52,086 : INFO : topic #2 (0.100): 0.035*\"alcohol\" + 0.029*\"advertising\" + 0.027*\"drink\" + 0.020*\"study\" + 0.015*\"said\" + 0.013*\"kid\" + 0.012*\"drinking\" + 0.012*\"parent\" + 0.012*\"underage\" + 0.011*\"much\"\n",
      "2019-10-29 00:44:52,087 : INFO : topic #1 (0.100): 0.043*\"alcohol\" + 0.024*\"advertising\" + 0.024*\"drink\" + 0.021*\"said\" + 0.014*\"underage\" + 0.013*\"much\" + 0.013*\"drinking\" + 0.013*\"kid\" + 0.012*\"study\" + 0.012*\"parent\"\n",
      "2019-10-29 00:44:52,090 : INFO : topic #9 (0.100): 0.029*\"alcohol\" + 0.024*\"advertising\" + 0.022*\"said\" + 0.019*\"drink\" + 0.015*\"study\" + 0.015*\"parent\" + 0.014*\"much\" + 0.013*\"kid\" + 0.013*\"drinking\" + 0.011*\"ad\"\n",
      "2019-10-29 00:44:52,093 : INFO : topic #7 (0.100): 0.034*\"alcohol\" + 0.027*\"advertising\" + 0.023*\"drink\" + 0.021*\"said\" + 0.019*\"study\" + 0.018*\"kid\" + 0.016*\"much\" + 0.012*\"time\" + 0.012*\"underage\" + 0.011*\"brand\"\n",
      "2019-10-29 00:44:52,096 : INFO : topic #5 (0.100): 0.043*\"alcohol\" + 0.023*\"drink\" + 0.019*\"advertising\" + 0.019*\"said\" + 0.015*\"study\" + 0.015*\"kid\" + 0.014*\"much\" + 0.013*\"brand\" + 0.013*\"drinking\" + 0.013*\"parent\"\n",
      "2019-10-29 00:44:52,098 : INFO : topic diff=0.929900, rho=1.000000\n",
      "2019-10-29 00:44:52,514 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:52,515 : INFO : built Dictionary(9 unique tokens: ['chat', 'world', 'unfolds', 'facebook', 'messenger']...) from 5 documents (total 50 corpus positions)\n",
      "2019-10-29 00:44:52,517 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:52,518 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:52,519 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:52,521 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:52,522 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:52,530 : INFO : -6.018 per-word bound, 64.8 perplexity estimate based on a held-out corpus of 5 documents with 50 words\n",
      "2019-10-29 00:44:52,531 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:52,536 : INFO : topic #0 (0.100): 0.193*\"world\" + 0.119*\"chat\" + 0.117*\"messenger\" + 0.109*\"facebook\" + 0.101*\"unfolds\" + 0.099*\"u\" + 0.096*\"happening\" + 0.093*\"find\" + 0.074*\"convenes\"\n",
      "2019-10-29 00:44:52,538 : INFO : topic #9 (0.100): 0.185*\"world\" + 0.114*\"convenes\" + 0.113*\"find\" + 0.104*\"facebook\" + 0.103*\"messenger\" + 0.099*\"happening\" + 0.099*\"u\" + 0.096*\"chat\" + 0.088*\"unfolds\"\n",
      "2019-10-29 00:44:52,539 : INFO : topic #8 (0.100): 0.180*\"world\" + 0.123*\"happening\" + 0.121*\"convenes\" + 0.110*\"facebook\" + 0.100*\"unfolds\" + 0.098*\"u\" + 0.096*\"chat\" + 0.091*\"messenger\" + 0.080*\"find\"\n",
      "2019-10-29 00:44:52,540 : INFO : topic #1 (0.100): 0.173*\"world\" + 0.142*\"messenger\" + 0.119*\"find\" + 0.106*\"convenes\" + 0.104*\"u\" + 0.096*\"unfolds\" + 0.093*\"happening\" + 0.086*\"chat\" + 0.080*\"facebook\"\n",
      "2019-10-29 00:44:52,542 : INFO : topic #5 (0.100): 0.150*\"world\" + 0.116*\"chat\" + 0.114*\"u\" + 0.113*\"happening\" + 0.109*\"facebook\" + 0.109*\"find\" + 0.097*\"unfolds\" + 0.096*\"convenes\" + 0.096*\"messenger\"\n",
      "2019-10-29 00:44:52,543 : INFO : topic diff=0.603855, rho=1.000000\n",
      "2019-10-29 00:44:52,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:52,977 : INFO : built Dictionary(501 unique tokens: ['yu', 'protestors', 'one', 'beijing', 'new']...) from 5 documents (total 4090 corpus positions)\n",
      "2019-10-29 00:44:52,986 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:52,997 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:53,000 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:53,006 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:53,008 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:53,175 : INFO : -8.146 per-word bound, 283.2 perplexity estimate based on a held-out corpus of 5 documents with 4090 words\n",
      "2019-10-29 00:44:53,176 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:53,187 : INFO : topic #0 (0.100): 0.018*\"art\" + 0.018*\"guggenheim\" + 0.017*\"work\" + 0.016*\"animal\" + 0.012*\"artist\" + 0.010*\"museum\" + 0.009*\"artwork\" + 0.008*\"right\" + 0.007*\"chinese\" + 0.007*\"credit\"\n",
      "2019-10-29 00:44:53,190 : INFO : topic #8 (0.100): 0.023*\"art\" + 0.023*\"animal\" + 0.020*\"work\" + 0.012*\"artist\" + 0.011*\"guggenheim\" + 0.011*\"museum\" + 0.008*\"right\" + 0.008*\"chinese\" + 0.007*\"critic\" + 0.007*\"matter\"\n",
      "2019-10-29 00:44:53,193 : INFO : topic #5 (0.100): 0.020*\"animal\" + 0.020*\"art\" + 0.016*\"work\" + 0.012*\"guggenheim\" + 0.012*\"museum\" + 0.012*\"artist\" + 0.011*\"critic\" + 0.010*\"right\" + 0.008*\"credit\" + 0.008*\"dog\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:53,196 : INFO : topic #6 (0.100): 0.019*\"animal\" + 0.017*\"work\" + 0.016*\"art\" + 0.014*\"artist\" + 0.012*\"guggenheim\" + 0.011*\"artwork\" + 0.009*\"museum\" + 0.009*\"right\" + 0.008*\"credit\" + 0.008*\"chinese\"\n",
      "2019-10-29 00:44:53,200 : INFO : topic #7 (0.100): 0.020*\"animal\" + 0.018*\"art\" + 0.016*\"work\" + 0.015*\"guggenheim\" + 0.012*\"artist\" + 0.011*\"museum\" + 0.010*\"artwork\" + 0.009*\"right\" + 0.007*\"dog\" + 0.007*\"critic\"\n",
      "2019-10-29 00:44:53,203 : INFO : topic diff=0.867838, rho=1.000000\n",
      "2019-10-29 00:44:53,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:53,674 : INFO : built Dictionary(696 unique tokens: ['let', 'wave', 'happy', 'younger', 'hatred']...) from 5 documents (total 5805 corpus positions)\n",
      "2019-10-29 00:44:53,683 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:53,684 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:53,685 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:53,690 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:53,692 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:53,907 : INFO : -8.433 per-word bound, 345.7 perplexity estimate based on a held-out corpus of 5 documents with 5805 words\n",
      "2019-10-29 00:44:53,908 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:53,918 : INFO : topic #9 (0.100): 0.017*\"frampton\" + 0.012*\"door\" + 0.009*\"time\" + 0.009*\"gnomist\" + 0.008*\"say\" + 0.008*\"one\" + 0.007*\"trail\" + 0.007*\"tree\" + 0.006*\"still\" + 0.006*\"come\"\n",
      "2019-10-29 00:44:53,920 : INFO : topic #1 (0.100): 0.016*\"door\" + 0.016*\"frampton\" + 0.010*\"say\" + 0.010*\"one\" + 0.009*\"time\" + 0.007*\"tree\" + 0.007*\"trail\" + 0.007*\"park\" + 0.007*\"fairy\" + 0.007*\"come\"\n",
      "2019-10-29 00:44:53,922 : INFO : topic #7 (0.100): 0.013*\"frampton\" + 0.012*\"say\" + 0.010*\"door\" + 0.009*\"trail\" + 0.009*\"park\" + 0.008*\"time\" + 0.008*\"tree\" + 0.008*\"one\" + 0.007*\"fairy\" + 0.007*\"still\"\n",
      "2019-10-29 00:44:53,923 : INFO : topic #2 (0.100): 0.015*\"frampton\" + 0.011*\"door\" + 0.010*\"say\" + 0.008*\"tree\" + 0.007*\"park\" + 0.007*\"fairy\" + 0.007*\"time\" + 0.007*\"one\" + 0.007*\"still\" + 0.006*\"film\"\n",
      "2019-10-29 00:44:53,925 : INFO : topic #3 (0.100): 0.015*\"frampton\" + 0.012*\"door\" + 0.011*\"say\" + 0.008*\"fairy\" + 0.008*\"time\" + 0.008*\"tree\" + 0.007*\"come\" + 0.007*\"little\" + 0.006*\"trail\" + 0.006*\"park\"\n",
      "2019-10-29 00:44:53,928 : INFO : topic diff=0.854886, rho=1.000000\n",
      "2019-10-29 00:44:54,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:54,426 : INFO : built Dictionary(400 unique tokens: ['franco', 'violence', 'retrieve', 'mayor', 'clash']...) from 5 documents (total 7090 corpus positions)\n",
      "2019-10-29 00:44:54,436 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:54,439 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:54,442 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:54,446 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:54,448 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:54,641 : INFO : -7.162 per-word bound, 143.2 perplexity estimate based on a held-out corpus of 5 documents with 7090 words\n",
      "2019-10-29 00:44:54,643 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:54,652 : INFO : topic #2 (0.100): 0.032*\"catalan\" + 0.028*\"spain\" + 0.027*\"october\" + 0.026*\"police\" + 0.025*\"referendum\" + 0.024*\"barcelona\" + 0.023*\"independence\" + 0.021*\"people\" + 0.017*\"station\" + 0.016*\"polling\"\n",
      "2019-10-29 00:44:54,656 : INFO : topic #9 (0.100): 0.038*\"spain\" + 0.029*\"catalan\" + 0.029*\"october\" + 0.026*\"people\" + 0.022*\"police\" + 0.021*\"said\" + 0.021*\"barcelona\" + 0.018*\"independence\" + 0.015*\"spanish\" + 0.014*\"station\"\n",
      "2019-10-29 00:44:54,659 : INFO : topic #4 (0.100): 0.033*\"referendum\" + 0.030*\"catalan\" + 0.029*\"october\" + 0.029*\"spain\" + 0.028*\"police\" + 0.026*\"people\" + 0.021*\"barcelona\" + 0.020*\"independence\" + 0.016*\"said\" + 0.016*\"madrid\"\n",
      "2019-10-29 00:44:54,661 : INFO : topic #3 (0.100): 0.034*\"october\" + 0.032*\"catalan\" + 0.029*\"people\" + 0.028*\"police\" + 0.027*\"spain\" + 0.023*\"independence\" + 0.023*\"barcelona\" + 0.022*\"referendum\" + 0.019*\"station\" + 0.017*\"polling\"\n",
      "2019-10-29 00:44:54,664 : INFO : topic #0 (0.100): 0.034*\"barcelona\" + 0.029*\"october\" + 0.029*\"people\" + 0.029*\"catalan\" + 0.029*\"independence\" + 0.026*\"referendum\" + 0.024*\"police\" + 0.022*\"spain\" + 0.018*\"polling\" + 0.016*\"station\"\n",
      "2019-10-29 00:44:54,667 : INFO : topic diff=0.981375, rho=1.000000\n",
      "2019-10-29 00:44:55,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:55,079 : INFO : built Dictionary(183 unique tokens: ['prime', 'industry', 'come', 'tax', 'ensure']...) from 5 documents (total 1330 corpus positions)\n",
      "2019-10-29 00:44:55,081 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:55,082 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:55,083 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:55,085 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:55,086 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:55,162 : INFO : -7.367 per-word bound, 165.1 perplexity estimate based on a held-out corpus of 5 documents with 1330 words\n",
      "2019-10-29 00:44:55,163 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:55,170 : INFO : topic #5 (0.100): 0.024*\"said\" + 0.023*\"facebook\" + 0.020*\"government\" + 0.017*\"britain\" + 0.017*\"twitter\" + 0.016*\"hate\" + 0.016*\"would\" + 0.014*\"company\" + 0.014*\"much\" + 0.013*\"medium\"\n",
      "2019-10-29 00:44:55,172 : INFO : topic #9 (0.100): 0.022*\"said\" + 0.021*\"would\" + 0.021*\"company\" + 0.018*\"facebook\" + 0.017*\"medium\" + 0.015*\"law\" + 0.015*\"britain\" + 0.014*\"hate\" + 0.014*\"social\" + 0.014*\"government\"\n",
      "2019-10-29 00:44:55,174 : INFO : topic #3 (0.100): 0.025*\"company\" + 0.023*\"would\" + 0.019*\"said\" + 0.018*\"government\" + 0.017*\"law\" + 0.016*\"facebook\" + 0.016*\"medium\" + 0.015*\"social\" + 0.014*\"twitter\" + 0.014*\"much\"\n",
      "2019-10-29 00:44:55,176 : INFO : topic #6 (0.100): 0.024*\"said\" + 0.022*\"would\" + 0.022*\"government\" + 0.019*\"company\" + 0.015*\"speech\" + 0.014*\"law\" + 0.014*\"britain\" + 0.014*\"facebook\" + 0.012*\"social\" + 0.012*\"europe\"\n",
      "2019-10-29 00:44:55,178 : INFO : topic #0 (0.100): 0.025*\"said\" + 0.022*\"would\" + 0.020*\"facebook\" + 0.019*\"company\" + 0.019*\"medium\" + 0.016*\"hate\" + 0.016*\"speech\" + 0.014*\"government\" + 0.014*\"twitter\" + 0.014*\"britain\"\n",
      "2019-10-29 00:44:55,179 : INFO : topic diff=0.808238, rho=1.000000\n",
      "2019-10-29 00:44:55,629 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:55,631 : INFO : built Dictionary(13 unique tokens: ['happening', 'unfolds', 'facebook', 'messenger', 'trump']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:44:55,633 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:55,634 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:55,634 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:55,636 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:55,637 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:55,644 : INFO : -6.408 per-word bound, 84.9 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:55,646 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:55,649 : INFO : topic #9 (0.100): 0.093*\"find\" + 0.086*\"chat\" + 0.085*\"midshipman\" + 0.084*\"world\" + 0.082*\"ban\" + 0.081*\"messenger\" + 0.076*\"transgender\" + 0.076*\"unfolds\" + 0.072*\"happening\" + 0.071*\"facebook\"\n",
      "2019-10-29 00:44:55,650 : INFO : topic #0 (0.100): 0.092*\"u\" + 0.091*\"world\" + 0.090*\"trump\" + 0.089*\"happening\" + 0.079*\"chat\" + 0.076*\"ban\" + 0.075*\"facebook\" + 0.075*\"transgender\" + 0.074*\"midshipman\" + 0.070*\"find\"\n",
      "2019-10-29 00:44:55,652 : INFO : topic #2 (0.100): 0.088*\"u\" + 0.087*\"transgender\" + 0.086*\"fight\" + 0.084*\"facebook\" + 0.082*\"messenger\" + 0.082*\"trump\" + 0.080*\"unfolds\" + 0.078*\"chat\" + 0.073*\"world\" + 0.071*\"midshipman\"\n",
      "2019-10-29 00:44:55,653 : INFO : topic #3 (0.100): 0.101*\"happening\" + 0.088*\"transgender\" + 0.087*\"messenger\" + 0.087*\"facebook\" + 0.080*\"ban\" + 0.079*\"chat\" + 0.075*\"world\" + 0.074*\"fight\" + 0.074*\"u\" + 0.070*\"trump\"\n",
      "2019-10-29 00:44:55,654 : INFO : topic #7 (0.100): 0.093*\"fight\" + 0.086*\"u\" + 0.085*\"find\" + 0.084*\"happening\" + 0.083*\"unfolds\" + 0.079*\"midshipman\" + 0.079*\"ban\" + 0.074*\"transgender\" + 0.072*\"facebook\" + 0.071*\"chat\"\n",
      "2019-10-29 00:44:55,655 : INFO : topic diff=0.517848, rho=1.000000\n",
      "2019-10-29 00:44:56,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:56,264 : INFO : built Dictionary(420 unique tokens: ['although', 'animal', 'drinking', 'think', 'place']...) from 5 documents (total 3370 corpus positions)\n",
      "2019-10-29 00:44:56,271 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:56,275 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:56,282 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:56,286 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:56,296 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:56,449 : INFO : -7.998 per-word bound, 255.6 perplexity estimate based on a held-out corpus of 5 documents with 3370 words\n",
      "2019-10-29 00:44:56,451 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:56,459 : INFO : topic #7 (0.100): 0.024*\"new\" + 0.018*\"york\" + 0.018*\"time\" + 0.013*\"ny\" + 0.011*\"square\" + 0.010*\"w\" + 0.010*\"st\" + 0.009*\"park\" + 0.009*\"hotel\" + 0.009*\"city\"\n",
      "2019-10-29 00:44:56,461 : INFO : topic #9 (0.100): 0.034*\"new\" + 0.021*\"york\" + 0.017*\"square\" + 0.015*\"ny\" + 0.015*\"time\" + 0.012*\"w\" + 0.010*\"city\" + 0.009*\"st\" + 0.009*\"one\" + 0.008*\"like\"\n",
      "2019-10-29 00:44:56,463 : INFO : topic #6 (0.100): 0.030*\"york\" + 0.028*\"time\" + 0.023*\"new\" + 0.015*\"square\" + 0.013*\"ny\" + 0.012*\"w\" + 0.009*\"hotel\" + 0.008*\"city\" + 0.008*\"restaurant\" + 0.008*\"best\"\n",
      "2019-10-29 00:44:56,464 : INFO : topic #8 (0.100): 0.031*\"new\" + 0.022*\"york\" + 0.019*\"square\" + 0.017*\"time\" + 0.015*\"w\" + 0.014*\"ny\" + 0.013*\"st\" + 0.011*\"city\" + 0.010*\"room\" + 0.009*\"hotel\"\n",
      "2019-10-29 00:44:56,466 : INFO : topic #0 (0.100): 0.023*\"new\" + 0.020*\"york\" + 0.018*\"ny\" + 0.017*\"square\" + 0.015*\"time\" + 0.011*\"hotel\" + 0.011*\"st\" + 0.010*\"w\" + 0.009*\"city\" + 0.008*\"bar\"\n",
      "2019-10-29 00:44:56,468 : INFO : topic diff=0.852234, rho=1.000000\n",
      "2019-10-29 00:44:56,856 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:56,858 : INFO : built Dictionary(74 unique tokens: ['friend', 'popular', 'embraced', 'death', 'get']...) from 5 documents (total 465 corpus positions)\n",
      "2019-10-29 00:44:56,859 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:56,861 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:56,862 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:56,864 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:56,865 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:56,901 : INFO : -6.853 per-word bound, 115.6 perplexity estimate based on a held-out corpus of 5 documents with 465 words\n",
      "2019-10-29 00:44:56,904 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:56,910 : INFO : topic #5 (0.100): 0.035*\"radio\" + 0.035*\"rene\" + 0.033*\"son\" + 0.028*\"show\" + 0.023*\"host\" + 0.022*\"family\" + 0.021*\"time\" + 0.020*\"cnn\" + 0.020*\"statement\" + 0.020*\"delilah\"\n",
      "2019-10-29 00:44:56,913 : INFO : topic #1 (0.100): 0.038*\"son\" + 0.035*\"rene\" + 0.031*\"show\" + 0.026*\"radio\" + 0.025*\"family\" + 0.024*\"host\" + 0.023*\"delilah\" + 0.020*\"friend\" + 0.020*\"statement\" + 0.018*\"suicide\"\n",
      "2019-10-29 00:44:56,917 : INFO : topic #3 (0.100): 0.045*\"son\" + 0.045*\"rene\" + 0.030*\"show\" + 0.030*\"radio\" + 0.024*\"statement\" + 0.023*\"suicide\" + 0.021*\"host\" + 0.019*\"friend\" + 0.018*\"family\" + 0.018*\"time\"\n",
      "2019-10-29 00:44:56,921 : INFO : topic #2 (0.100): 0.052*\"son\" + 0.042*\"rene\" + 0.030*\"show\" + 0.027*\"radio\" + 0.025*\"friend\" + 0.021*\"family\" + 0.021*\"time\" + 0.019*\"cnn\" + 0.018*\"suicide\" + 0.018*\"delilah\"\n",
      "2019-10-29 00:44:56,925 : INFO : topic #6 (0.100): 0.048*\"son\" + 0.043*\"rene\" + 0.031*\"show\" + 0.024*\"delilah\" + 0.023*\"cnn\" + 0.023*\"time\" + 0.022*\"radio\" + 0.021*\"family\" + 0.019*\"suicide\" + 0.018*\"statement\"\n",
      "2019-10-29 00:44:56,929 : INFO : topic diff=0.718922, rho=1.000000\n",
      "2019-10-29 00:44:57,702 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:57,743 : INFO : built Dictionary(2038 unique tokens: ['let', 'upworthy', 'real', 'grew', 'advantage']...) from 5 documents (total 30875 corpus positions)\n",
      "2019-10-29 00:44:57,785 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:57,789 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:57,793 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:57,804 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:57,806 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:58,374 : INFO : -8.884 per-word bound, 472.4 perplexity estimate based on a held-out corpus of 5 documents with 30875 words\n",
      "2019-10-29 00:44:58,375 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:58,394 : INFO : topic #2 (0.100): 0.040*\"paulette\" + 0.021*\"said\" + 0.013*\"cancer\" + 0.010*\"woman\" + 0.009*\"told\" + 0.008*\"day\" + 0.007*\"story\" + 0.007*\"walk\" + 0.006*\"facebook\" + 0.006*\"breast\"\n",
      "2019-10-29 00:44:58,397 : INFO : topic #7 (0.100): 0.048*\"paulette\" + 0.030*\"said\" + 0.013*\"cancer\" + 0.010*\"story\" + 0.010*\"woman\" + 0.009*\"walk\" + 0.009*\"breast\" + 0.008*\"told\" + 0.007*\"day\" + 0.005*\"one\"\n",
      "2019-10-29 00:44:58,399 : INFO : topic #5 (0.100): 0.038*\"paulette\" + 0.025*\"said\" + 0.013*\"cancer\" + 0.009*\"breast\" + 0.009*\"woman\" + 0.008*\"story\" + 0.007*\"told\" + 0.007*\"one\" + 0.006*\"day\" + 0.005*\"walk\"\n",
      "2019-10-29 00:44:58,401 : INFO : topic #4 (0.100): 0.033*\"paulette\" + 0.024*\"said\" + 0.012*\"cancer\" + 0.010*\"walk\" + 0.009*\"day\" + 0.008*\"told\" + 0.007*\"one\" + 0.007*\"woman\" + 0.007*\"breast\" + 0.007*\"story\"\n",
      "2019-10-29 00:44:58,403 : INFO : topic #1 (0.100): 0.063*\"paulette\" + 0.023*\"said\" + 0.015*\"cancer\" + 0.010*\"told\" + 0.008*\"woman\" + 0.008*\"one\" + 0.008*\"day\" + 0.008*\"walk\" + 0.008*\"story\" + 0.007*\"facebook\"\n",
      "2019-10-29 00:44:58,406 : INFO : topic diff=1.153689, rho=1.000000\n",
      "2019-10-29 00:44:58,874 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:58,879 : INFO : built Dictionary(387 unique tokens: ['netanyahu', 'previously', 'prime', 'party', 'offered']...) from 5 documents (total 3125 corpus positions)\n",
      "2019-10-29 00:44:58,883 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:58,885 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:58,886 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:44:58,890 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:58,892 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:59,008 : INFO : -7.911 per-word bound, 240.7 perplexity estimate based on a held-out corpus of 5 documents with 3125 words\n",
      "2019-10-29 00:44:59,009 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:59,018 : INFO : topic #6 (0.100): 0.026*\"palestinian\" + 0.019*\"hamas\" + 0.017*\"reconciliation\" + 0.015*\"gaza\" + 0.010*\"israel\" + 0.010*\"step\" + 0.009*\"fatah\" + 0.009*\"people\" + 0.009*\"said\" + 0.009*\"faction\"\n",
      "2019-10-29 00:44:59,019 : INFO : topic #4 (0.100): 0.024*\"hamas\" + 0.020*\"palestinian\" + 0.014*\"gaza\" + 0.014*\"israel\" + 0.012*\"reconciliation\" + 0.010*\"step\" + 0.010*\"faction\" + 0.010*\"said\" + 0.009*\"people\" + 0.009*\"first\"\n",
      "2019-10-29 00:44:59,020 : INFO : topic #1 (0.100): 0.025*\"palestinian\" + 0.020*\"gaza\" + 0.016*\"reconciliation\" + 0.013*\"israel\" + 0.013*\"hamas\" + 0.011*\"fatah\" + 0.010*\"egyptian\" + 0.010*\"people\" + 0.010*\"faction\" + 0.010*\"step\"\n",
      "2019-10-29 00:44:59,022 : INFO : topic #5 (0.100): 0.023*\"palestinian\" + 0.021*\"hamas\" + 0.017*\"reconciliation\" + 0.014*\"gaza\" + 0.014*\"israel\" + 0.010*\"people\" + 0.009*\"year\" + 0.009*\"first\" + 0.009*\"step\" + 0.008*\"faction\"\n",
      "2019-10-29 00:44:59,024 : INFO : topic #9 (0.100): 0.027*\"hamas\" + 0.025*\"palestinian\" + 0.021*\"gaza\" + 0.015*\"reconciliation\" + 0.012*\"egyptian\" + 0.012*\"israel\" + 0.010*\"come\" + 0.010*\"year\" + 0.009*\"step\" + 0.009*\"people\"\n",
      "2019-10-29 00:44:59,026 : INFO : topic diff=0.856642, rho=1.000000\n",
      "2019-10-29 00:44:59,452 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:59,455 : INFO : built Dictionary(158 unique tokens: ['located', 'paradise', 'part', 'financial', 'come']...) from 5 documents (total 1150 corpus positions)\n",
      "2019-10-29 00:44:59,457 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:44:59,459 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:44:59,460 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:44:59,463 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:44:59,465 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:44:59,532 : INFO : -7.238 per-word bound, 150.9 perplexity estimate based on a held-out corpus of 5 documents with 1150 words\n",
      "2019-10-29 00:44:59,534 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:44:59,541 : INFO : topic #5 (0.100): 0.052*\"island\" + 0.026*\"dubai\" + 0.022*\"al\" + 0.018*\"arab\" + 0.018*\"jumeirah\" + 0.015*\"burj\" + 0.015*\"hotel\" + 0.013*\"marsa\" + 0.013*\"constructed\" + 0.013*\"square\"\n",
      "2019-10-29 00:44:59,543 : INFO : topic #9 (0.100): 0.041*\"dubai\" + 0.037*\"island\" + 0.025*\"arab\" + 0.019*\"hotel\" + 0.018*\"al\" + 0.016*\"jumeirah\" + 0.013*\"burj\" + 0.012*\"group\" + 0.012*\"square\" + 0.012*\"mile\"\n",
      "2019-10-29 00:44:59,544 : INFO : topic #4 (0.100): 0.042*\"island\" + 0.038*\"dubai\" + 0.028*\"al\" + 0.021*\"jumeirah\" + 0.018*\"arab\" + 0.017*\"hotel\" + 0.016*\"mile\" + 0.014*\"holding\" + 0.014*\"artificial\" + 0.013*\"burj\"\n",
      "2019-10-29 00:44:59,547 : INFO : topic #6 (0.100): 0.057*\"island\" + 0.031*\"dubai\" + 0.022*\"arab\" + 0.022*\"al\" + 0.019*\"jumeirah\" + 0.016*\"palm\" + 0.015*\"artificial\" + 0.014*\"group\" + 0.013*\"mile\" + 0.013*\"hotel\"\n",
      "2019-10-29 00:44:59,548 : INFO : topic #2 (0.100): 0.047*\"dubai\" + 0.037*\"island\" + 0.032*\"al\" + 0.022*\"arab\" + 0.020*\"jumeirah\" + 0.017*\"constructed\" + 0.016*\"group\" + 0.015*\"marsa\" + 0.014*\"square\" + 0.014*\"artificial\"\n",
      "2019-10-29 00:44:59,550 : INFO : topic diff=0.820279, rho=1.000000\n",
      "2019-10-29 00:44:59,990 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:44:59,996 : INFO : built Dictionary(314 unique tokens: ['let', 'acceptable', 'small', 'end', 'offered']...) from 5 documents (total 2795 corpus positions)\n",
      "2019-10-29 00:45:00,000 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:00,001 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:00,004 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:00,010 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:00,013 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:00,157 : INFO : -7.575 per-word bound, 190.7 perplexity estimate based on a held-out corpus of 5 documents with 2795 words\n",
      "2019-10-29 00:45:00,159 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:00,165 : INFO : topic #5 (0.100): 0.041*\"said\" + 0.020*\"ferrara\" + 0.018*\"child\" + 0.016*\"say\" + 0.016*\"parent\" + 0.015*\"meltdown\" + 0.014*\"go\" + 0.012*\"want\" + 0.012*\"mom\" + 0.011*\"kid\"\n",
      "2019-10-29 00:45:00,167 : INFO : topic #3 (0.100): 0.028*\"said\" + 0.025*\"ferrara\" + 0.020*\"go\" + 0.019*\"want\" + 0.019*\"parent\" + 0.018*\"say\" + 0.015*\"kid\" + 0.013*\"child\" + 0.013*\"know\" + 0.012*\"help\"\n",
      "2019-10-29 00:45:00,169 : INFO : topic #1 (0.100): 0.044*\"said\" + 0.022*\"say\" + 0.016*\"child\" + 0.015*\"parent\" + 0.014*\"want\" + 0.014*\"go\" + 0.013*\"ponytail\" + 0.013*\"kid\" + 0.013*\"ferrara\" + 0.012*\"way\"\n",
      "2019-10-29 00:45:00,171 : INFO : topic #7 (0.100): 0.042*\"said\" + 0.017*\"ferrara\" + 0.017*\"go\" + 0.016*\"parent\" + 0.015*\"want\" + 0.015*\"say\" + 0.014*\"way\" + 0.013*\"help\" + 0.013*\"hilborn\" + 0.012*\"child\"\n",
      "2019-10-29 00:45:00,172 : INFO : topic #9 (0.100): 0.027*\"said\" + 0.020*\"parent\" + 0.019*\"go\" + 0.016*\"ferrara\" + 0.015*\"say\" + 0.014*\"child\" + 0.014*\"want\" + 0.012*\"meltdown\" + 0.012*\"kid\" + 0.011*\"ponytail\"\n",
      "2019-10-29 00:45:00,174 : INFO : topic diff=0.902931, rho=1.000000\n",
      "2019-10-29 00:45:00,567 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:00,570 : INFO : built Dictionary(183 unique tokens: ['prime', 'industry', 'come', 'tax', 'ensure']...) from 5 documents (total 1330 corpus positions)\n",
      "2019-10-29 00:45:00,572 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:00,574 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:00,576 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:00,578 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:00,580 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:00,648 : INFO : -7.372 per-word bound, 165.7 perplexity estimate based on a held-out corpus of 5 documents with 1330 words\n",
      "2019-10-29 00:45:00,651 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:00,658 : INFO : topic #0 (0.100): 0.025*\"said\" + 0.021*\"government\" + 0.018*\"company\" + 0.018*\"would\" + 0.017*\"facebook\" + 0.015*\"social\" + 0.015*\"twitter\" + 0.014*\"medium\" + 0.013*\"speech\" + 0.013*\"law\"\n",
      "2019-10-29 00:45:00,666 : INFO : topic #3 (0.100): 0.025*\"would\" + 0.020*\"said\" + 0.019*\"company\" + 0.017*\"government\" + 0.015*\"britain\" + 0.013*\"law\" + 0.013*\"twitter\" + 0.013*\"tax\" + 0.013*\"bradley\" + 0.013*\"speech\"\n",
      "2019-10-29 00:45:00,669 : INFO : topic #6 (0.100): 0.027*\"said\" + 0.025*\"would\" + 0.017*\"britain\" + 0.016*\"facebook\" + 0.016*\"government\" + 0.015*\"twitter\" + 0.015*\"hate\" + 0.015*\"social\" + 0.014*\"medium\" + 0.014*\"law\"\n",
      "2019-10-29 00:45:00,674 : INFO : topic #1 (0.100): 0.022*\"company\" + 0.021*\"said\" + 0.019*\"government\" + 0.018*\"facebook\" + 0.017*\"law\" + 0.016*\"would\" + 0.016*\"social\" + 0.015*\"medium\" + 0.014*\"twitter\" + 0.014*\"speech\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:00,677 : INFO : topic #9 (0.100): 0.026*\"said\" + 0.021*\"facebook\" + 0.019*\"twitter\" + 0.017*\"would\" + 0.016*\"company\" + 0.016*\"speech\" + 0.015*\"hate\" + 0.015*\"law\" + 0.015*\"britain\" + 0.013*\"social\"\n",
      "2019-10-29 00:45:00,680 : INFO : topic diff=0.814873, rho=1.000000\n",
      "2019-10-29 00:45:01,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:01,204 : INFO : built Dictionary(354 unique tokens: ['acceptable', 'portion', 'doc', 'cycle', 'stop']...) from 5 documents (total 2925 corpus positions)\n",
      "2019-10-29 00:45:01,210 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:01,212 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:01,214 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:01,218 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:01,221 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:01,372 : INFO : -7.792 per-word bound, 221.6 perplexity estimate based on a held-out corpus of 5 documents with 2925 words\n",
      "2019-10-29 00:45:01,374 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:01,384 : INFO : topic #4 (0.100): 0.031*\"control\" + 0.025*\"birth\" + 0.017*\"said\" + 0.016*\"woman\" + 0.010*\"know\" + 0.010*\"condition\" + 0.009*\"phipps\" + 0.009*\"ovary\" + 0.009*\"health\" + 0.008*\"davis\"\n",
      "2019-10-29 00:45:01,386 : INFO : topic #2 (0.100): 0.023*\"control\" + 0.022*\"birth\" + 0.022*\"woman\" + 0.018*\"said\" + 0.010*\"davis\" + 0.010*\"phipps\" + 0.010*\"health\" + 0.009*\"condition\" + 0.008*\"ovary\" + 0.008*\"endometriosis\"\n",
      "2019-10-29 00:45:01,388 : INFO : topic #3 (0.100): 0.025*\"birth\" + 0.023*\"control\" + 0.018*\"woman\" + 0.014*\"said\" + 0.012*\"phipps\" + 0.010*\"jarnagin\" + 0.009*\"health\" + 0.009*\"davis\" + 0.008*\"ovary\" + 0.008*\"endometriosis\"\n",
      "2019-10-29 00:45:01,390 : INFO : topic #7 (0.100): 0.038*\"control\" + 0.035*\"birth\" + 0.018*\"said\" + 0.015*\"woman\" + 0.012*\"davis\" + 0.010*\"condition\" + 0.010*\"phipps\" + 0.008*\"health\" + 0.008*\"ovary\" + 0.007*\"jarnagin\"\n",
      "2019-10-29 00:45:01,392 : INFO : topic #5 (0.100): 0.029*\"birth\" + 0.027*\"control\" + 0.024*\"woman\" + 0.018*\"said\" + 0.011*\"phipps\" + 0.010*\"condition\" + 0.009*\"jarnagin\" + 0.009*\"health\" + 0.009*\"pill\" + 0.009*\"davis\"\n",
      "2019-10-29 00:45:01,396 : INFO : topic diff=0.837801, rho=1.000000\n",
      "2019-10-29 00:45:01,847 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:01,848 : INFO : built Dictionary(15 unique tokens: ['genius', 'go', 'ibrahimovic', 'zlatan', 'generation']...) from 5 documents (total 95 corpus positions)\n",
      "2019-10-29 00:45:01,849 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:01,850 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:01,852 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:01,854 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:01,855 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:01,869 : INFO : -5.833 per-word bound, 57.0 perplexity estimate based on a held-out corpus of 5 documents with 95 words\n",
      "2019-10-29 00:45:01,870 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:01,876 : INFO : topic #1 (0.100): 0.126*\"copa90\" + 0.106*\"zlatan\" + 0.100*\"football\" + 0.069*\"ibrahimovic\" + 0.064*\"baddest\" + 0.063*\"footballer\" + 0.061*\"man\" + 0.058*\"generation\" + 0.054*\"animation\" + 0.053*\"source\"\n",
      "2019-10-29 00:45:01,878 : INFO : topic #9 (0.100): 0.168*\"copa90\" + 0.109*\"zlatan\" + 0.083*\"football\" + 0.064*\"look\" + 0.062*\"man\" + 0.056*\"intriguing\" + 0.056*\"generation\" + 0.055*\"go\" + 0.053*\"footballer\" + 0.052*\"genius\"\n",
      "2019-10-29 00:45:01,879 : INFO : topic #0 (0.100): 0.155*\"copa90\" + 0.118*\"football\" + 0.090*\"zlatan\" + 0.063*\"intriguing\" + 0.059*\"baddest\" + 0.058*\"animation\" + 0.057*\"man\" + 0.055*\"ibrahimovic\" + 0.053*\"making\" + 0.051*\"look\"\n",
      "2019-10-29 00:45:01,880 : INFO : topic #4 (0.100): 0.116*\"zlatan\" + 0.108*\"football\" + 0.100*\"copa90\" + 0.071*\"look\" + 0.060*\"baddest\" + 0.060*\"footballer\" + 0.058*\"source\" + 0.057*\"making\" + 0.056*\"genius\" + 0.056*\"man\"\n",
      "2019-10-29 00:45:01,881 : INFO : topic #7 (0.100): 0.155*\"copa90\" + 0.136*\"zlatan\" + 0.087*\"football\" + 0.060*\"generation\" + 0.057*\"making\" + 0.056*\"genius\" + 0.055*\"animation\" + 0.055*\"look\" + 0.053*\"intriguing\" + 0.052*\"man\"\n",
      "2019-10-29 00:45:01,882 : INFO : topic diff=0.700081, rho=1.000000\n",
      "2019-10-29 00:45:02,311 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:02,313 : INFO : built Dictionary(87 unique tokens: ['speaker', 'part', 'responder', 'situation', 'new']...) from 5 documents (total 680 corpus positions)\n",
      "2019-10-29 00:45:02,315 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:02,317 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:02,318 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:02,321 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:02,322 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:02,361 : INFO : -6.595 per-word bound, 96.6 perplexity estimate based on a held-out corpus of 5 documents with 680 words\n",
      "2019-10-29 00:45:02,363 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:02,369 : INFO : topic #2 (0.100): 0.038*\"house\" + 0.031*\"rico\" + 0.030*\"ryan\" + 0.029*\"expected\" + 0.029*\"delegation\" + 0.026*\"puerto\" + 0.024*\"speaker\" + 0.021*\"week\" + 0.020*\"island\" + 0.019*\"approve\"\n",
      "2019-10-29 00:45:02,371 : INFO : topic #5 (0.100): 0.036*\"house\" + 0.034*\"rico\" + 0.034*\"delegation\" + 0.031*\"puerto\" + 0.027*\"ryan\" + 0.024*\"according\" + 0.024*\"expected\" + 0.023*\"week\" + 0.022*\"island\" + 0.017*\"conference\"\n",
      "2019-10-29 00:45:02,382 : INFO : topic #6 (0.100): 0.041*\"house\" + 0.039*\"ryan\" + 0.031*\"delegation\" + 0.028*\"rico\" + 0.025*\"puerto\" + 0.023*\"island\" + 0.022*\"according\" + 0.021*\"expected\" + 0.018*\"official\" + 0.018*\"week\"\n",
      "2019-10-29 00:45:02,384 : INFO : topic #7 (0.100): 0.046*\"house\" + 0.036*\"delegation\" + 0.029*\"expected\" + 0.027*\"speaker\" + 0.025*\"puerto\" + 0.025*\"rico\" + 0.024*\"ryan\" + 0.023*\"island\" + 0.022*\"week\" + 0.020*\"gop\"\n",
      "2019-10-29 00:45:02,389 : INFO : topic #0 (0.100): 0.037*\"house\" + 0.033*\"ryan\" + 0.029*\"puerto\" + 0.027*\"delegation\" + 0.027*\"expected\" + 0.026*\"rico\" + 0.025*\"speaker\" + 0.020*\"according\" + 0.020*\"week\" + 0.019*\"island\"\n",
      "2019-10-29 00:45:02,391 : INFO : topic diff=0.768669, rho=1.000000\n",
      "2019-10-29 00:45:02,797 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:02,800 : INFO : built Dictionary(143 unique tokens: ['anniversary', 'even', 'fewer', 'disquiet', 'book']...) from 5 documents (total 825 corpus positions)\n",
      "2019-10-29 00:45:02,802 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:02,803 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:02,805 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:02,808 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:02,809 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:02,873 : INFO : -7.575 per-word bound, 190.7 perplexity estimate based on a held-out corpus of 5 documents with 825 words\n",
      "2019-10-29 00:45:02,874 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:02,887 : INFO : topic #3 (0.100): 0.045*\"trump\" + 0.022*\"time\" + 0.014*\"hill\" + 0.014*\"mike\" + 0.014*\"minute\" + 0.013*\"first\" + 0.013*\"espn\" + 0.012*\"early\" + 0.011*\"began\" + 0.011*\"donald\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:02,888 : INFO : topic #8 (0.100): 0.036*\"trump\" + 0.020*\"began\" + 0.016*\"time\" + 0.012*\"espn\" + 0.012*\"first\" + 0.012*\"le\" + 0.012*\"mike\" + 0.012*\"morning\" + 0.011*\"night\" + 0.011*\"minute\"\n",
      "2019-10-29 00:45:02,893 : INFO : topic #5 (0.100): 0.038*\"trump\" + 0.018*\"began\" + 0.016*\"tweet\" + 0.016*\"mike\" + 0.014*\"time\" + 0.014*\"minute\" + 0.013*\"le\" + 0.011*\"donald\" + 0.011*\"espn\" + 0.011*\"night\"\n",
      "2019-10-29 00:45:02,899 : INFO : topic #4 (0.100): 0.037*\"trump\" + 0.015*\"time\" + 0.014*\"night\" + 0.014*\"began\" + 0.013*\"good\" + 0.013*\"mike\" + 0.013*\"hill\" + 0.012*\"espn\" + 0.012*\"morning\" + 0.012*\"tweet\"\n",
      "2019-10-29 00:45:02,901 : INFO : topic #7 (0.100): 0.031*\"trump\" + 0.019*\"time\" + 0.018*\"began\" + 0.012*\"first\" + 0.012*\"good\" + 0.012*\"le\" + 0.012*\"morning\" + 0.012*\"donald\" + 0.011*\"hill\" + 0.010*\"mike\"\n",
      "2019-10-29 00:45:02,906 : INFO : topic diff=0.655444, rho=1.000000\n",
      "2019-10-29 00:45:03,299 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:03,300 : INFO : built Dictionary(11 unique tokens: ['agreeing', 'new', 'changed', 'privacy', 'cnnmoney']...) from 5 documents (total 75 corpus positions)\n",
      "2019-10-29 00:45:03,301 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:03,302 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:03,304 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:03,305 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:03,306 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:03,319 : INFO : -5.539 per-word bound, 46.5 perplexity estimate based on a held-out corpus of 5 documents with 75 words\n",
      "2019-10-29 00:45:03,321 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:03,327 : INFO : topic #9 (0.100): 0.143*\"privacy\" + 0.141*\"policy\" + 0.132*\"term\" + 0.118*\"service\" + 0.075*\"continuing\" + 0.071*\"agreeing\" + 0.069*\"new\" + 0.068*\"changed\" + 0.067*\"cnnmoney\" + 0.065*\"use\"\n",
      "2019-10-29 00:45:03,328 : INFO : topic #2 (0.100): 0.153*\"term\" + 0.123*\"privacy\" + 0.121*\"service\" + 0.111*\"policy\" + 0.081*\"use\" + 0.078*\"cnnmoney\" + 0.076*\"new\" + 0.069*\"changed\" + 0.064*\"continuing\" + 0.063*\"site\"\n",
      "2019-10-29 00:45:03,330 : INFO : topic #7 (0.100): 0.173*\"policy\" + 0.156*\"privacy\" + 0.126*\"term\" + 0.084*\"service\" + 0.076*\"continuing\" + 0.071*\"agreeing\" + 0.070*\"use\" + 0.064*\"cnnmoney\" + 0.063*\"site\" + 0.059*\"changed\"\n",
      "2019-10-29 00:45:03,331 : INFO : topic #3 (0.100): 0.148*\"service\" + 0.126*\"term\" + 0.112*\"privacy\" + 0.102*\"policy\" + 0.083*\"site\" + 0.076*\"changed\" + 0.074*\"continuing\" + 0.073*\"new\" + 0.071*\"use\" + 0.070*\"agreeing\"\n",
      "2019-10-29 00:45:03,333 : INFO : topic #8 (0.100): 0.132*\"policy\" + 0.129*\"privacy\" + 0.128*\"service\" + 0.098*\"term\" + 0.097*\"cnnmoney\" + 0.081*\"site\" + 0.076*\"continuing\" + 0.071*\"agreeing\" + 0.069*\"use\" + 0.065*\"new\"\n",
      "2019-10-29 00:45:03,334 : INFO : topic diff=0.635652, rho=1.000000\n",
      "2019-10-29 00:45:03,785 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:03,791 : INFO : built Dictionary(319 unique tokens: ['located', 'story', 'reach', 'deep', 'come']...) from 5 documents (total 2725 corpus positions)\n",
      "2019-10-29 00:45:03,797 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:03,805 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:03,808 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:03,811 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:03,823 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:03,944 : INFO : -7.653 per-word bound, 201.3 perplexity estimate based on a held-out corpus of 5 documents with 2725 words\n",
      "2019-10-29 00:45:03,946 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:03,954 : INFO : topic #1 (0.100): 0.028*\"wreck\" + 0.025*\"dive\" + 0.019*\"time\" + 0.018*\"brunei\" + 0.017*\"abdullah\" + 0.012*\"water\" + 0.012*\"ship\" + 0.012*\"wong\" + 0.012*\"diver\" + 0.012*\"underwater\"\n",
      "2019-10-29 00:45:03,956 : INFO : topic #3 (0.100): 0.029*\"wreck\" + 0.027*\"brunei\" + 0.024*\"dive\" + 0.016*\"foot\" + 0.016*\"diver\" + 0.014*\"time\" + 0.013*\"diving\" + 0.012*\"take\" + 0.011*\"water\" + 0.010*\"wong\"\n",
      "2019-10-29 00:45:03,959 : INFO : topic #6 (0.100): 0.024*\"brunei\" + 0.022*\"wreck\" + 0.017*\"dive\" + 0.015*\"diver\" + 0.015*\"foot\" + 0.014*\"time\" + 0.012*\"diving\" + 0.012*\"wong\" + 0.012*\"abdullah\" + 0.011*\"underwater\"\n",
      "2019-10-29 00:45:03,962 : INFO : topic #2 (0.100): 0.028*\"brunei\" + 0.024*\"wreck\" + 0.023*\"dive\" + 0.015*\"diver\" + 0.013*\"foot\" + 0.013*\"underwater\" + 0.012*\"ship\" + 0.012*\"abdullah\" + 0.011*\"diving\" + 0.011*\"water\"\n",
      "2019-10-29 00:45:03,964 : INFO : topic #9 (0.100): 0.026*\"brunei\" + 0.026*\"wreck\" + 0.024*\"dive\" + 0.017*\"abdullah\" + 0.015*\"time\" + 0.015*\"diver\" + 0.015*\"foot\" + 0.013*\"world\" + 0.012*\"underwater\" + 0.010*\"ship\"\n",
      "2019-10-29 00:45:03,966 : INFO : topic diff=0.876530, rho=1.000000\n",
      "2019-10-29 00:45:04,507 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:04,520 : INFO : built Dictionary(879 unique tokens: ['phase', 'real', 'younger', 'nicole', 'way']...) from 5 documents (total 12220 corpus positions)\n",
      "2019-10-29 00:45:04,531 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:04,533 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:04,534 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:04,539 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:04,542 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:04,787 : INFO : -8.119 per-word bound, 277.9 perplexity estimate based on a held-out corpus of 5 documents with 12220 words\n",
      "2019-10-29 00:45:04,789 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:04,804 : INFO : topic #1 (0.100): 0.024*\"twin\" + 0.022*\"conjoined\" + 0.019*\"boy\" + 0.018*\"caption\" + 0.015*\"separated\" + 0.014*\"surgery\" + 0.013*\"nicole\" + 0.013*\"photo\" + 0.013*\"new\" + 0.012*\"goodrich\"\n",
      "2019-10-29 00:45:04,806 : INFO : topic #0 (0.100): 0.025*\"twin\" + 0.022*\"boy\" + 0.019*\"separated\" + 0.017*\"photo\" + 0.016*\"conjoined\" + 0.016*\"hide\" + 0.015*\"goodrich\" + 0.015*\"surgery\" + 0.013*\"say\" + 0.013*\"anias\"\n",
      "2019-10-29 00:45:04,809 : INFO : topic #4 (0.100): 0.023*\"conjoined\" + 0.019*\"twin\" + 0.017*\"surgery\" + 0.017*\"boy\" + 0.016*\"caption\" + 0.015*\"goodrich\" + 0.015*\"nicole\" + 0.015*\"photo\" + 0.015*\"say\" + 0.015*\"hide\"\n",
      "2019-10-29 00:45:04,812 : INFO : topic #2 (0.100): 0.021*\"separated\" + 0.021*\"twin\" + 0.020*\"conjoined\" + 0.015*\"nicole\" + 0.015*\"head\" + 0.015*\"photo\" + 0.014*\"new\" + 0.013*\"hide\" + 0.013*\"goodrich\" + 0.012*\"life\"\n",
      "2019-10-29 00:45:04,815 : INFO : topic #6 (0.100): 0.025*\"twin\" + 0.020*\"separated\" + 0.018*\"boy\" + 0.018*\"conjoined\" + 0.015*\"new\" + 0.014*\"say\" + 0.014*\"caption\" + 0.014*\"nicole\" + 0.014*\"photo\" + 0.012*\"hide\"\n",
      "2019-10-29 00:45:04,818 : INFO : topic diff=1.137300, rho=1.000000\n",
      "2019-10-29 00:45:05,273 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:05,279 : INFO : built Dictionary(346 unique tokens: ['fresh', 'color', 'drinking', 'enjoy', 'local']...) from 5 documents (total 3200 corpus positions)\n",
      "2019-10-29 00:45:05,284 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:05,286 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:05,289 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:05,294 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:05,297 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:05,424 : INFO : -7.621 per-word bound, 196.9 perplexity estimate based on a held-out corpus of 5 documents with 3200 words\n",
      "2019-10-29 00:45:05,426 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:05,433 : INFO : topic #1 (0.100): 0.035*\"bar\" + 0.021*\"ginza\" + 0.020*\"tokyo\" + 0.015*\"beer\" + 0.015*\"ueno\" + 0.013*\"japan\" + 0.012*\"like\" + 0.011*\"little\" + 0.010*\"called\" + 0.010*\"place\"\n",
      "2019-10-29 00:45:05,436 : INFO : topic #8 (0.100): 0.034*\"bar\" + 0.025*\"ginza\" + 0.023*\"tokyo\" + 0.016*\"like\" + 0.016*\"japan\" + 0.011*\"ueno\" + 0.011*\"place\" + 0.011*\"sushi\" + 0.011*\"beer\" + 0.010*\"called\"\n",
      "2019-10-29 00:45:05,438 : INFO : topic #3 (0.100): 0.039*\"bar\" + 0.024*\"ginza\" + 0.021*\"tokyo\" + 0.018*\"japan\" + 0.016*\"like\" + 0.014*\"ueno\" + 0.011*\"sushi\" + 0.011*\"called\" + 0.011*\"little\" + 0.010*\"beer\"\n",
      "2019-10-29 00:45:05,440 : INFO : topic #0 (0.100): 0.037*\"bar\" + 0.023*\"tokyo\" + 0.019*\"japan\" + 0.016*\"ginza\" + 0.014*\"like\" + 0.013*\"ueno\" + 0.013*\"sushi\" + 0.011*\"called\" + 0.011*\"little\" + 0.010*\"bartender\"\n",
      "2019-10-29 00:45:05,443 : INFO : topic #5 (0.100): 0.031*\"bar\" + 0.021*\"tokyo\" + 0.017*\"ueno\" + 0.016*\"ginza\" + 0.016*\"japan\" + 0.015*\"little\" + 0.013*\"like\" + 0.013*\"sushi\" + 0.011*\"beer\" + 0.011*\"place\"\n",
      "2019-10-29 00:45:05,446 : INFO : topic diff=0.924410, rho=1.000000\n",
      "2019-10-29 00:45:05,884 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:05,889 : INFO : built Dictionary(312 unique tokens: ['scope', 'concern', 'perhaps', 'nature', 'book']...) from 5 documents (total 2225 corpus positions)\n",
      "2019-10-29 00:45:05,892 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:05,894 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:05,895 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:05,899 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:05,901 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:05,999 : INFO : -7.900 per-word bound, 238.9 perplexity estimate based on a held-out corpus of 5 documents with 2225 words\n",
      "2019-10-29 00:45:06,001 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:06,009 : INFO : topic #5 (0.100): 0.020*\"giraffe\" + 0.016*\"human\" + 0.015*\"extinction\" + 0.012*\"world\" + 0.012*\"earth\" + 0.011*\"u\" + 0.010*\"change\" + 0.010*\"elephant\" + 0.009*\"life\" + 0.009*\"without\"\n",
      "2019-10-29 00:45:06,012 : INFO : topic #8 (0.100): 0.019*\"giraffe\" + 0.013*\"human\" + 0.013*\"earth\" + 0.012*\"change\" + 0.012*\"world\" + 0.011*\"extinction\" + 0.011*\"life\" + 0.011*\"u\" + 0.010*\"one\" + 0.009*\"cnn\"\n",
      "2019-10-29 00:45:06,014 : INFO : topic #6 (0.100): 0.018*\"human\" + 0.017*\"giraffe\" + 0.015*\"extinction\" + 0.011*\"earth\" + 0.011*\"world\" + 0.011*\"u\" + 0.010*\"life\" + 0.009*\"one\" + 0.009*\"sixth\" + 0.009*\"nature\"\n",
      "2019-10-29 00:45:06,017 : INFO : topic #4 (0.100): 0.017*\"giraffe\" + 0.017*\"human\" + 0.014*\"world\" + 0.013*\"extinction\" + 0.012*\"life\" + 0.011*\"nature\" + 0.011*\"one\" + 0.010*\"elephant\" + 0.009*\"change\" + 0.009*\"earth\"\n",
      "2019-10-29 00:45:06,020 : INFO : topic #7 (0.100): 0.020*\"giraffe\" + 0.017*\"extinction\" + 0.012*\"life\" + 0.012*\"world\" + 0.012*\"human\" + 0.011*\"change\" + 0.010*\"sixth\" + 0.010*\"u\" + 0.009*\"earth\" + 0.009*\"without\"\n",
      "2019-10-29 00:45:06,022 : INFO : topic diff=0.789517, rho=1.000000\n",
      "2019-10-29 00:45:06,415 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:06,418 : INFO : built Dictionary(159 unique tokens: ['rode', 'small', 'recently', 'allergic', 'golden']...) from 5 documents (total 1060 corpus positions)\n",
      "2019-10-29 00:45:06,421 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:06,423 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:06,424 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:06,427 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:06,429 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:06,489 : INFO : -7.391 per-word bound, 167.8 perplexity estimate based on a held-out corpus of 5 documents with 1060 words\n",
      "2019-10-29 00:45:06,490 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:06,499 : INFO : topic #2 (0.100): 0.043*\"hohs\" + 0.025*\"life\" + 0.019*\"cbs4\" + 0.018*\"friend\" + 0.015*\"told\" + 0.015*\"wrong\" + 0.015*\"time\" + 0.014*\"mountain\" + 0.013*\"full\" + 0.013*\"steamboat\"\n",
      "2019-10-29 00:45:06,502 : INFO : topic #5 (0.100): 0.042*\"hohs\" + 0.019*\"rattlesnake\" + 0.017*\"life\" + 0.016*\"cbs4\" + 0.015*\"mountain\" + 0.015*\"time\" + 0.014*\"friend\" + 0.013*\"wrong\" + 0.013*\"told\" + 0.013*\"steamboat\"\n",
      "2019-10-29 00:45:06,504 : INFO : topic #4 (0.100): 0.047*\"hohs\" + 0.021*\"life\" + 0.019*\"friend\" + 0.018*\"full\" + 0.018*\"cbs4\" + 0.016*\"rattlesnake\" + 0.015*\"gollnick\" + 0.014*\"said\" + 0.014*\"steamboat\" + 0.014*\"say\"\n",
      "2019-10-29 00:45:06,507 : INFO : topic #9 (0.100): 0.043*\"hohs\" + 0.020*\"friend\" + 0.018*\"cbs4\" + 0.016*\"said\" + 0.015*\"rattlesnake\" + 0.014*\"time\" + 0.014*\"told\" + 0.014*\"full\" + 0.014*\"say\" + 0.014*\"wrong\"\n",
      "2019-10-29 00:45:06,510 : INFO : topic #3 (0.100): 0.045*\"hohs\" + 0.016*\"steamboat\" + 0.016*\"friend\" + 0.016*\"mountain\" + 0.015*\"life\" + 0.015*\"gollnick\" + 0.015*\"time\" + 0.014*\"full\" + 0.013*\"say\" + 0.013*\"cbs4\"\n",
      "2019-10-29 00:45:06,512 : INFO : topic diff=0.767772, rho=1.000000\n",
      "2019-10-29 00:45:06,926 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:06,930 : INFO : built Dictionary(86 unique tokens: ['zaghari', 'paralyzed', 'set', 'new', 'sick']...) from 5 documents (total 615 corpus positions)\n",
      "2019-10-29 00:45:06,935 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:06,938 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:06,942 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:06,945 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:06,948 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:07,003 : INFO : -6.734 per-word bound, 106.5 perplexity estimate based on a held-out corpus of 5 documents with 615 words\n",
      "2019-10-29 00:45:07,006 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:07,012 : INFO : topic #2 (0.100): 0.042*\"iranian\" + 0.036*\"ratcliffe\" + 0.028*\"zaghari\" + 0.027*\"year\" + 0.023*\"nazanin\" + 0.021*\"charge\" + 0.020*\"government\" + 0.020*\"plotting\" + 0.019*\"trial\" + 0.019*\"daughter\"\n",
      "2019-10-29 00:45:07,014 : INFO : topic #4 (0.100): 0.050*\"ratcliffe\" + 0.037*\"iranian\" + 0.033*\"year\" + 0.033*\"zaghari\" + 0.022*\"charge\" + 0.021*\"trial\" + 0.019*\"government\" + 0.018*\"nazanin\" + 0.018*\"awaiting\" + 0.018*\"cnn\"\n",
      "2019-10-29 00:45:07,017 : INFO : topic #8 (0.100): 0.056*\"ratcliffe\" + 0.042*\"iranian\" + 0.034*\"zaghari\" + 0.032*\"year\" + 0.032*\"charge\" + 0.025*\"nazanin\" + 0.024*\"trial\" + 0.018*\"prison\" + 0.018*\"family\" + 0.017*\"confinement\"\n",
      "2019-10-29 00:45:07,020 : INFO : topic #3 (0.100): 0.042*\"ratcliffe\" + 0.035*\"iranian\" + 0.028*\"zaghari\" + 0.027*\"year\" + 0.025*\"nazanin\" + 0.023*\"trial\" + 0.022*\"worker\" + 0.020*\"plotting\" + 0.019*\"tehran\" + 0.018*\"mother\"\n",
      "2019-10-29 00:45:07,023 : INFO : topic #7 (0.100): 0.039*\"ratcliffe\" + 0.036*\"iranian\" + 0.032*\"year\" + 0.028*\"zaghari\" + 0.027*\"trial\" + 0.024*\"nazanin\" + 0.020*\"new\" + 0.020*\"charge\" + 0.019*\"detained\" + 0.017*\"charity\"\n",
      "2019-10-29 00:45:07,025 : INFO : topic diff=0.763079, rho=1.000000\n",
      "2019-10-29 00:45:07,493 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:07,495 : INFO : built Dictionary(18 unique tokens: ['scope', 'aided', 'tragedy', 'number', 'cnn']...) from 5 documents (total 105 corpus positions)\n",
      "2019-10-29 00:45:07,496 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:07,498 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:07,499 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:07,501 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:07,502 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:07,514 : INFO : -6.108 per-word bound, 69.0 perplexity estimate based on a held-out corpus of 5 documents with 105 words\n",
      "2019-10-29 00:45:07,516 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:07,522 : INFO : topic #5 (0.100): 0.112*\"wildfire\" + 0.087*\"california\" + 0.080*\"number\" + 0.057*\"aided\" + 0.054*\"tell\" + 0.054*\"dozen\" + 0.052*\"scope\" + 0.050*\"eye\" + 0.050*\"staggering\" + 0.050*\"popping\"\n",
      "2019-10-29 00:45:07,523 : INFO : topic #7 (0.100): 0.106*\"number\" + 0.105*\"california\" + 0.070*\"wildfire\" + 0.056*\"low\" + 0.054*\"dozen\" + 0.053*\"high\" + 0.052*\"wind\" + 0.051*\"northern\" + 0.050*\"scorching\" + 0.049*\"aided\"\n",
      "2019-10-29 00:45:07,525 : INFO : topic #2 (0.100): 0.096*\"number\" + 0.095*\"wildfire\" + 0.085*\"california\" + 0.057*\"wind\" + 0.057*\"humidity\" + 0.057*\"scorching\" + 0.055*\"tragedy\" + 0.053*\"scope\" + 0.052*\"popping\" + 0.048*\"low\"\n",
      "2019-10-29 00:45:07,527 : INFO : topic #3 (0.100): 0.087*\"wildfire\" + 0.082*\"california\" + 0.078*\"number\" + 0.059*\"eye\" + 0.057*\"humidity\" + 0.054*\"staggering\" + 0.052*\"popping\" + 0.052*\"scope\" + 0.050*\"scorching\" + 0.050*\"cnn\"\n",
      "2019-10-29 00:45:07,528 : INFO : topic #9 (0.100): 0.111*\"number\" + 0.092*\"wildfire\" + 0.062*\"california\" + 0.058*\"humidity\" + 0.057*\"staggering\" + 0.056*\"high\" + 0.055*\"aided\" + 0.055*\"scorching\" + 0.054*\"tragedy\" + 0.052*\"scope\"\n",
      "2019-10-29 00:45:07,530 : INFO : topic diff=0.620555, rho=1.000000\n",
      "2019-10-29 00:45:07,946 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:07,950 : INFO : built Dictionary(63 unique tokens: ['enrolled', 'overseas', 'fewer', 'phase', 'special']...) from 5 documents (total 465 corpus positions)\n",
      "2019-10-29 00:45:07,952 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:07,954 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:07,955 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:07,958 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:07,959 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:08,007 : INFO : -6.421 per-word bound, 85.7 perplexity estimate based on a held-out corpus of 5 documents with 465 words\n",
      "2019-10-29 00:45:08,010 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:08,020 : INFO : topic #4 (0.100): 0.054*\"result\" + 0.038*\"vote\" + 0.036*\"seat\" + 0.033*\"party\" + 0.031*\"final\" + 0.026*\"new\" + 0.024*\"english\" + 0.024*\"election\" + 0.024*\"saturday\" + 0.023*\"minister\"\n",
      "2019-10-29 00:45:08,024 : INFO : topic #6 (0.100): 0.045*\"result\" + 0.042*\"seat\" + 0.037*\"party\" + 0.034*\"final\" + 0.031*\"new\" + 0.030*\"vote\" + 0.024*\"cast\" + 0.023*\"prime\" + 0.022*\"saturday\" + 0.021*\"coalition\"\n",
      "2019-10-29 00:45:08,027 : INFO : topic #8 (0.100): 0.053*\"result\" + 0.041*\"vote\" + 0.035*\"seat\" + 0.030*\"final\" + 0.024*\"new\" + 0.024*\"take\" + 0.024*\"september\" + 0.023*\"english\" + 0.023*\"zealand\" + 0.023*\"coalition\"\n",
      "2019-10-29 00:45:08,031 : INFO : topic #3 (0.100): 0.053*\"result\" + 0.040*\"seat\" + 0.038*\"final\" + 0.034*\"new\" + 0.032*\"vote\" + 0.031*\"party\" + 0.024*\"election\" + 0.023*\"led\" + 0.022*\"september\" + 0.021*\"two\"\n",
      "2019-10-29 00:45:08,036 : INFO : topic #7 (0.100): 0.042*\"result\" + 0.042*\"seat\" + 0.037*\"vote\" + 0.033*\"party\" + 0.033*\"new\" + 0.027*\"cast\" + 0.025*\"prime\" + 0.024*\"saturday\" + 0.024*\"final\" + 0.023*\"minister\"\n",
      "2019-10-29 00:45:08,040 : INFO : topic diff=0.744515, rho=1.000000\n",
      "2019-10-29 00:45:08,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:08,506 : INFO : built Dictionary(300 unique tokens: ['portable', 'even', 'end', 'hero', 'come']...) from 5 documents (total 2405 corpus positions)\n",
      "2019-10-29 00:45:08,509 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:08,511 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:08,512 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:08,517 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:08,521 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:08,648 : INFO : -7.679 per-word bound, 205.0 perplexity estimate based on a held-out corpus of 5 documents with 2405 words\n",
      "2019-10-29 00:45:08,649 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:08,656 : INFO : topic #7 (0.100): 0.023*\"meal\" + 0.021*\"disaster\" + 0.021*\"hay\" + 0.017*\"day\" + 0.017*\"volunteer\" + 0.016*\"cnn\" + 0.013*\"people\" + 0.011*\"get\" + 0.011*\"many\" + 0.010*\"hurricane\"\n",
      "2019-10-29 00:45:08,659 : INFO : topic #8 (0.100): 0.031*\"hay\" + 0.019*\"volunteer\" + 0.017*\"meal\" + 0.015*\"disaster\" + 0.014*\"day\" + 0.012*\"cnn\" + 0.011*\"many\" + 0.011*\"help\" + 0.011*\"people\" + 0.010*\"barbecue\"\n",
      "2019-10-29 00:45:08,661 : INFO : topic #2 (0.100): 0.032*\"hay\" + 0.021*\"volunteer\" + 0.020*\"meal\" + 0.018*\"day\" + 0.015*\"cnn\" + 0.014*\"disaster\" + 0.012*\"people\" + 0.011*\"barbecue\" + 0.011*\"many\" + 0.009*\"get\"\n",
      "2019-10-29 00:45:08,664 : INFO : topic #6 (0.100): 0.035*\"hay\" + 0.026*\"meal\" + 0.022*\"volunteer\" + 0.022*\"disaster\" + 0.018*\"cnn\" + 0.013*\"people\" + 0.013*\"day\" + 0.011*\"harvey\" + 0.011*\"barbecue\" + 0.009*\"going\"\n",
      "2019-10-29 00:45:08,667 : INFO : topic #3 (0.100): 0.031*\"hay\" + 0.020*\"meal\" + 0.017*\"volunteer\" + 0.016*\"cnn\" + 0.015*\"disaster\" + 0.014*\"day\" + 0.012*\"people\" + 0.011*\"help\" + 0.010*\"bbq\" + 0.010*\"many\"\n",
      "2019-10-29 00:45:08,669 : INFO : topic diff=0.840878, rho=1.000000\n",
      "2019-10-29 00:45:09,057 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:09,059 : INFO : built Dictionary(100 unique tokens: ['beat', 'recognizing', 'golden', 'life', 'game']...) from 5 documents (total 700 corpus positions)\n",
      "2019-10-29 00:45:09,061 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:09,063 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:09,065 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:09,067 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:09,068 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:09,119 : INFO : -6.902 per-word bound, 119.6 perplexity estimate based on a held-out corpus of 5 documents with 700 words\n",
      "2019-10-29 00:45:09,123 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:09,131 : INFO : topic #2 (0.100): 0.044*\"vega\" + 0.029*\"knight\" + 0.024*\"golden\" + 0.023*\"victim\" + 0.023*\"opener\" + 0.020*\"honor\" + 0.018*\"team\" + 0.016*\"responder\" + 0.015*\"image\" + 0.015*\"coyote\"\n",
      "2019-10-29 00:45:09,136 : INFO : topic #9 (0.100): 0.045*\"vega\" + 0.032*\"knight\" + 0.025*\"victim\" + 0.022*\"golden\" + 0.019*\"la\" + 0.018*\"opener\" + 0.018*\"responder\" + 0.017*\"honor\" + 0.017*\"ceremony\" + 0.017*\"puck\"\n",
      "2019-10-29 00:45:09,138 : INFO : topic #6 (0.100): 0.031*\"vega\" + 0.030*\"golden\" + 0.026*\"knight\" + 0.023*\"team\" + 0.023*\"victim\" + 0.023*\"honor\" + 0.021*\"responder\" + 0.017*\"opener\" + 0.017*\"com\" + 0.016*\"noted\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:09,142 : INFO : topic #4 (0.100): 0.031*\"vega\" + 0.029*\"victim\" + 0.027*\"knight\" + 0.027*\"golden\" + 0.023*\"honor\" + 0.023*\"team\" + 0.021*\"responder\" + 0.018*\"opener\" + 0.017*\"markazi\" + 0.016*\"puck\"\n",
      "2019-10-29 00:45:09,146 : INFO : topic #3 (0.100): 0.038*\"vega\" + 0.028*\"golden\" + 0.027*\"knight\" + 0.026*\"victim\" + 0.026*\"opener\" + 0.022*\"team\" + 0.019*\"responder\" + 0.018*\"honor\" + 0.018*\"sharing\" + 0.017*\"arena\"\n",
      "2019-10-29 00:45:09,149 : INFO : topic diff=0.756656, rho=1.000000\n",
      "2019-10-29 00:45:09,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:09,600 : INFO : built Dictionary(167 unique tokens: ['op', 'clientele', 'downsized', 'hong', 'life']...) from 5 documents (total 1300 corpus positions)\n",
      "2019-10-29 00:45:09,603 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:09,605 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:09,606 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:09,609 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:09,611 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:09,694 : INFO : -7.176 per-word bound, 144.6 perplexity estimate based on a held-out corpus of 5 documents with 1300 words\n",
      "2019-10-29 00:45:09,695 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:09,702 : INFO : topic #3 (0.100): 0.039*\"price\" + 0.027*\"home\" + 0.024*\"quarter\" + 0.023*\"sale\" + 0.023*\"manhattan\" + 0.018*\"bedroom\" + 0.015*\"median\" + 0.015*\"elliman\" + 0.015*\"said\" + 0.014*\"new\"\n",
      "2019-10-29 00:45:09,704 : INFO : topic #7 (0.100): 0.040*\"manhattan\" + 0.035*\"price\" + 0.028*\"home\" + 0.019*\"quarter\" + 0.017*\"sale\" + 0.017*\"three\" + 0.016*\"said\" + 0.016*\"housing\" + 0.014*\"bedroom\" + 0.012*\"demand\"\n",
      "2019-10-29 00:45:09,706 : INFO : topic #5 (0.100): 0.032*\"home\" + 0.028*\"price\" + 0.027*\"manhattan\" + 0.020*\"three\" + 0.019*\"quarter\" + 0.019*\"sale\" + 0.018*\"median\" + 0.015*\"said\" + 0.014*\"luxury\" + 0.014*\"elliman\"\n",
      "2019-10-29 00:45:09,709 : INFO : topic #8 (0.100): 0.035*\"manhattan\" + 0.034*\"home\" + 0.033*\"price\" + 0.023*\"quarter\" + 0.017*\"sale\" + 0.017*\"three\" + 0.016*\"bedroom\" + 0.015*\"buyer\" + 0.015*\"housing\" + 0.015*\"median\"\n",
      "2019-10-29 00:45:09,711 : INFO : topic #6 (0.100): 0.038*\"manhattan\" + 0.033*\"price\" + 0.032*\"home\" + 0.019*\"quarter\" + 0.017*\"housing\" + 0.017*\"sale\" + 0.015*\"elliman\" + 0.015*\"median\" + 0.014*\"said\" + 0.013*\"first\"\n",
      "2019-10-29 00:45:09,713 : INFO : topic diff=0.845677, rho=1.000000\n",
      "2019-10-29 00:45:10,132 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:10,136 : INFO : built Dictionary(237 unique tokens: ['earned', 'single', 'shower', 'nation', 'mounting']...) from 5 documents (total 1660 corpus positions)\n",
      "2019-10-29 00:45:10,140 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:10,143 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:10,147 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:10,151 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:10,153 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:10,242 : INFO : -7.672 per-word bound, 204.0 perplexity estimate based on a held-out corpus of 5 documents with 1660 words\n",
      "2019-10-29 00:45:10,243 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:10,252 : INFO : topic #1 (0.100): 0.023*\"sky\" + 0.021*\"lebanon\" + 0.016*\"astrophotography\" + 0.014*\"azar\" + 0.013*\"say\" + 0.012*\"take\" + 0.011*\"star\" + 0.011*\"photo\" + 0.010*\"night\" + 0.010*\"camera\"\n",
      "2019-10-29 00:45:10,255 : INFO : topic #5 (0.100): 0.024*\"azar\" + 0.023*\"astrophotography\" + 0.020*\"lebanon\" + 0.014*\"sky\" + 0.013*\"say\" + 0.011*\"photo\" + 0.011*\"image\" + 0.011*\"take\" + 0.010*\"star\" + 0.010*\"beirut\"\n",
      "2019-10-29 00:45:10,257 : INFO : topic #3 (0.100): 0.020*\"astrophotography\" + 0.019*\"lebanon\" + 0.018*\"sky\" + 0.017*\"say\" + 0.016*\"azar\" + 0.011*\"photo\" + 0.011*\"beirut\" + 0.010*\"star\" + 0.010*\"take\" + 0.010*\"capture\"\n",
      "2019-10-29 00:45:10,259 : INFO : topic #7 (0.100): 0.022*\"sky\" + 0.020*\"lebanon\" + 0.017*\"azar\" + 0.015*\"astrophotography\" + 0.013*\"star\" + 0.013*\"say\" + 0.012*\"camera\" + 0.011*\"hajjar\" + 0.010*\"take\" + 0.010*\"night\"\n",
      "2019-10-29 00:45:10,261 : INFO : topic #9 (0.100): 0.026*\"lebanon\" + 0.023*\"sky\" + 0.020*\"astrophotography\" + 0.019*\"azar\" + 0.012*\"say\" + 0.012*\"take\" + 0.011*\"camera\" + 0.010*\"process\" + 0.009*\"aim\" + 0.009*\"image\"\n",
      "2019-10-29 00:45:10,263 : INFO : topic diff=0.769907, rho=1.000000\n",
      "2019-10-29 00:45:10,703 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:10,707 : INFO : built Dictionary(299 unique tokens: ['hotline', 'trying', 'person', 'duration', 'part']...) from 5 documents (total 2565 corpus positions)\n",
      "2019-10-29 00:45:10,711 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:10,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:10,714 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:10,718 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:10,719 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:10,817 : INFO : -7.581 per-word bound, 191.4 perplexity estimate based on a held-out corpus of 5 documents with 2565 words\n",
      "2019-10-29 00:45:10,819 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:10,826 : INFO : topic #3 (0.100): 0.036*\"treatment\" + 0.028*\"abuse\" + 0.025*\"drug\" + 0.014*\"substance\" + 0.013*\"individual\" + 0.013*\"option\" + 0.013*\"also\" + 0.012*\"one\" + 0.012*\"help\" + 0.012*\"health\"\n",
      "2019-10-29 00:45:10,828 : INFO : topic #7 (0.100): 0.032*\"treatment\" + 0.024*\"abuse\" + 0.023*\"drug\" + 0.022*\"one\" + 0.017*\"need\" + 0.015*\"help\" + 0.013*\"also\" + 0.013*\"substance\" + 0.013*\"institute\" + 0.013*\"veteran\"\n",
      "2019-10-29 00:45:10,829 : INFO : topic #0 (0.100): 0.033*\"treatment\" + 0.027*\"abuse\" + 0.020*\"drug\" + 0.014*\"need\" + 0.014*\"also\" + 0.013*\"individual\" + 0.012*\"health\" + 0.011*\"substance\" + 0.011*\"support\" + 0.011*\"addiction\"\n",
      "2019-10-29 00:45:10,831 : INFO : topic #5 (0.100): 0.035*\"treatment\" + 0.027*\"abuse\" + 0.024*\"drug\" + 0.016*\"help\" + 0.016*\"one\" + 0.013*\"national\" + 0.013*\"substance\" + 0.013*\"health\" + 0.013*\"need\" + 0.012*\"individual\"\n",
      "2019-10-29 00:45:10,833 : INFO : topic #6 (0.100): 0.038*\"treatment\" + 0.033*\"drug\" + 0.024*\"abuse\" + 0.015*\"need\" + 0.014*\"one\" + 0.013*\"help\" + 0.013*\"option\" + 0.012*\"health\" + 0.011*\"substance\" + 0.011*\"program\"\n",
      "2019-10-29 00:45:10,836 : INFO : topic diff=0.910445, rho=1.000000\n",
      "2019-10-29 00:45:11,262 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:11,268 : INFO : built Dictionary(454 unique tokens: ['although', 'dating', 'bone', 'archaeologist', 'indicating']...) from 5 documents (total 3325 corpus positions)\n",
      "2019-10-29 00:45:11,274 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:11,276 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:11,278 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:11,282 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:11,283 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:11,430 : INFO : -8.212 per-word bound, 296.5 perplexity estimate based on a held-out corpus of 5 documents with 3325 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:11,432 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:11,441 : INFO : topic #7 (0.100): 0.017*\"tomb\" + 0.013*\"ancient\" + 0.011*\"al\" + 0.011*\"egyptian\" + 0.010*\"coffin\" + 0.009*\"egypt\" + 0.009*\"gaftawi\" + 0.008*\"time\" + 0.007*\"bce\" + 0.006*\"lived\"\n",
      "2019-10-29 00:45:11,443 : INFO : topic #3 (0.100): 0.015*\"tomb\" + 0.015*\"ancient\" + 0.015*\"egyptian\" + 0.012*\"al\" + 0.012*\"coffin\" + 0.010*\"egypt\" + 0.010*\"time\" + 0.007*\"woman\" + 0.007*\"back\" + 0.007*\"gaftawi\"\n",
      "2019-10-29 00:45:11,444 : INFO : topic #6 (0.100): 0.018*\"ancient\" + 0.016*\"tomb\" + 0.014*\"egyptian\" + 0.010*\"al\" + 0.010*\"gaftawi\" + 0.009*\"time\" + 0.009*\"coffin\" + 0.008*\"found\" + 0.008*\"egypt\" + 0.006*\"shirt\"\n",
      "2019-10-29 00:45:11,446 : INFO : topic #9 (0.100): 0.019*\"tomb\" + 0.014*\"egyptian\" + 0.013*\"ancient\" + 0.013*\"al\" + 0.012*\"time\" + 0.010*\"coffin\" + 0.008*\"egypt\" + 0.008*\"gaftawi\" + 0.008*\"found\" + 0.008*\"woman\"\n",
      "2019-10-29 00:45:11,448 : INFO : topic #4 (0.100): 0.014*\"tomb\" + 0.013*\"al\" + 0.013*\"ancient\" + 0.012*\"egypt\" + 0.011*\"egyptian\" + 0.010*\"gaftawi\" + 0.008*\"woman\" + 0.007*\"amenemhat\" + 0.007*\"wife\" + 0.006*\"known\"\n",
      "2019-10-29 00:45:11,451 : INFO : topic diff=0.802521, rho=1.000000\n",
      "2019-10-29 00:45:11,913 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:11,915 : INFO : built Dictionary(62 unique tokens: ['interview', 'meeting', 'yes', 'since', 'clearly']...) from 5 documents (total 440 corpus positions)\n",
      "2019-10-29 00:45:11,917 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:11,919 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:11,921 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:11,923 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:11,928 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:11,966 : INFO : -6.480 per-word bound, 89.3 perplexity estimate based on a held-out corpus of 5 documents with 440 words\n",
      "2019-10-29 00:45:11,969 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:11,976 : INFO : topic #6 (0.100): 0.079*\"trump\" + 0.053*\"tillerson\" + 0.043*\"tuesday\" + 0.039*\"secretary\" + 0.033*\"said\" + 0.031*\"state\" + 0.026*\"confidence\" + 0.024*\"tell\" + 0.023*\"president\" + 0.021*\"meeting\"\n",
      "2019-10-29 00:45:11,982 : INFO : topic #2 (0.100): 0.062*\"tillerson\" + 0.046*\"trump\" + 0.040*\"secretary\" + 0.039*\"said\" + 0.033*\"confidence\" + 0.030*\"meeting\" + 0.027*\"tuesday\" + 0.027*\"state\" + 0.024*\"report\" + 0.023*\"iq\"\n",
      "2019-10-29 00:45:11,985 : INFO : topic #5 (0.100): 0.074*\"trump\" + 0.051*\"tillerson\" + 0.039*\"state\" + 0.036*\"confidence\" + 0.031*\"said\" + 0.031*\"secretary\" + 0.030*\"tuesday\" + 0.027*\"cnn\" + 0.026*\"iq\" + 0.021*\"tell\"\n",
      "2019-10-29 00:45:11,990 : INFO : topic #0 (0.100): 0.090*\"trump\" + 0.043*\"secretary\" + 0.041*\"tillerson\" + 0.036*\"state\" + 0.033*\"confidence\" + 0.032*\"tuesday\" + 0.027*\"said\" + 0.026*\"meeting\" + 0.025*\"iq\" + 0.023*\"cnn\"\n",
      "2019-10-29 00:45:11,994 : INFO : topic #1 (0.100): 0.070*\"trump\" + 0.044*\"tillerson\" + 0.036*\"state\" + 0.030*\"said\" + 0.030*\"secretary\" + 0.029*\"confidence\" + 0.029*\"tuesday\" + 0.025*\"report\" + 0.024*\"tell\" + 0.023*\"president\"\n",
      "2019-10-29 00:45:11,997 : INFO : topic diff=0.811392, rho=1.000000\n",
      "2019-10-29 00:45:12,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:12,494 : INFO : built Dictionary(314 unique tokens: ['concern', 'acceptable', 'small', 'crawl', 'game']...) from 5 documents (total 2685 corpus positions)\n",
      "2019-10-29 00:45:12,498 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:12,499 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:12,501 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:12,505 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:12,508 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:12,619 : INFO : -7.636 per-word bound, 198.9 perplexity estimate based on a held-out corpus of 5 documents with 2685 words\n",
      "2019-10-29 00:45:12,620 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:12,629 : INFO : topic #1 (0.100): 0.039*\"chemical\" + 0.026*\"dust\" + 0.017*\"found\" + 0.017*\"zota\" + 0.016*\"exposure\" + 0.015*\"said\" + 0.014*\"home\" + 0.014*\"child\" + 0.012*\"product\" + 0.012*\"phthalates\"\n",
      "2019-10-29 00:45:12,632 : INFO : topic #6 (0.100): 0.049*\"chemical\" + 0.022*\"exposure\" + 0.017*\"found\" + 0.016*\"zota\" + 0.016*\"home\" + 0.016*\"study\" + 0.013*\"dust\" + 0.011*\"said\" + 0.011*\"child\" + 0.010*\"bradman\"\n",
      "2019-10-29 00:45:12,635 : INFO : topic #0 (0.100): 0.040*\"chemical\" + 0.019*\"found\" + 0.018*\"exposure\" + 0.016*\"said\" + 0.016*\"dust\" + 0.015*\"study\" + 0.013*\"house\" + 0.013*\"zota\" + 0.012*\"home\" + 0.012*\"flame\"\n",
      "2019-10-29 00:45:12,638 : INFO : topic #7 (0.100): 0.029*\"chemical\" + 0.021*\"home\" + 0.018*\"found\" + 0.017*\"exposure\" + 0.017*\"dust\" + 0.015*\"study\" + 0.015*\"child\" + 0.014*\"said\" + 0.013*\"retardant\" + 0.012*\"zota\"\n",
      "2019-10-29 00:45:12,641 : INFO : topic #3 (0.100): 0.046*\"chemical\" + 0.023*\"exposure\" + 0.018*\"study\" + 0.018*\"found\" + 0.017*\"dust\" + 0.017*\"home\" + 0.015*\"child\" + 0.013*\"zota\" + 0.013*\"said\" + 0.011*\"product\"\n",
      "2019-10-29 00:45:12,644 : INFO : topic diff=0.918181, rho=1.000000\n",
      "2019-10-29 00:45:13,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:13,084 : INFO : built Dictionary(296 unique tokens: ['forward', 'phase', 'across', 'de', 'af66']...) from 5 documents (total 2285 corpus positions)\n",
      "2019-10-29 00:45:13,088 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:13,089 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:13,093 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:13,097 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:13,101 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:13,237 : INFO : -7.721 per-word bound, 211.0 perplexity estimate based on a held-out corpus of 5 documents with 2285 words\n",
      "2019-10-29 00:45:13,240 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:13,247 : INFO : topic #6 (0.100): 0.039*\"engine\" + 0.019*\"flight\" + 0.016*\"said\" + 0.016*\"air\" + 0.015*\"france\" + 0.013*\"passenger\" + 0.012*\"one\" + 0.010*\"failure\" + 0.009*\"airport\" + 0.009*\"airline\"\n",
      "2019-10-29 00:45:13,249 : INFO : topic #0 (0.100): 0.042*\"engine\" + 0.026*\"flight\" + 0.016*\"air\" + 0.016*\"passenger\" + 0.013*\"said\" + 0.013*\"france\" + 0.010*\"take\" + 0.010*\"one\" + 0.009*\"plane\" + 0.008*\"a380\"\n",
      "2019-10-29 00:45:13,252 : INFO : topic #2 (0.100): 0.045*\"engine\" + 0.024*\"flight\" + 0.022*\"air\" + 0.016*\"passenger\" + 0.016*\"said\" + 0.011*\"france\" + 0.011*\"one\" + 0.009*\"take\" + 0.008*\"airline\" + 0.008*\"a380\"\n",
      "2019-10-29 00:45:13,255 : INFO : topic #5 (0.100): 0.036*\"engine\" + 0.019*\"flight\" + 0.018*\"passenger\" + 0.017*\"air\" + 0.016*\"france\" + 0.015*\"said\" + 0.010*\"airport\" + 0.009*\"take\" + 0.009*\"one\" + 0.009*\"saturday\"\n",
      "2019-10-29 00:45:13,258 : INFO : topic #7 (0.100): 0.041*\"engine\" + 0.027*\"flight\" + 0.025*\"passenger\" + 0.017*\"france\" + 0.017*\"air\" + 0.017*\"said\" + 0.011*\"take\" + 0.010*\"aircraft\" + 0.010*\"airline\" + 0.009*\"airport\"\n",
      "2019-10-29 00:45:13,261 : INFO : topic diff=0.836362, rho=1.000000\n",
      "2019-10-29 00:45:13,695 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:13,700 : INFO : built Dictionary(371 unique tokens: ['transport', 'drive', 'u', 'new', 'airline']...) from 5 documents (total 2765 corpus positions)\n",
      "2019-10-29 00:45:13,707 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:13,708 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:13,714 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:13,718 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:13,721 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:13,838 : INFO : -7.992 per-word bound, 254.6 perplexity estimate based on a held-out corpus of 5 documents with 2765 words\n",
      "2019-10-29 00:45:13,839 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:13,847 : INFO : topic #7 (0.100): 0.024*\"fragrance\" + 0.021*\"scent\" + 0.013*\"five\" + 0.013*\"experience\" + 0.012*\"jorgensen\" + 0.010*\"zodiac\" + 0.010*\"airline\" + 0.008*\"aroma\" + 0.008*\"smell\" + 0.008*\"cabin\"\n",
      "2019-10-29 00:45:13,849 : INFO : topic #3 (0.100): 0.030*\"fragrance\" + 0.021*\"scent\" + 0.013*\"five\" + 0.011*\"experience\" + 0.011*\"smell\" + 0.010*\"zodiac\" + 0.010*\"jorgensen\" + 0.009*\"say\" + 0.009*\"brand\" + 0.008*\"burke\"\n",
      "2019-10-29 00:45:13,851 : INFO : topic #0 (0.100): 0.033*\"fragrance\" + 0.033*\"scent\" + 0.015*\"zodiac\" + 0.012*\"experience\" + 0.011*\"airline\" + 0.011*\"say\" + 0.010*\"smell\" + 0.010*\"jorgensen\" + 0.010*\"brand\" + 0.008*\"cabin\"\n",
      "2019-10-29 00:45:13,854 : INFO : topic #2 (0.100): 0.034*\"fragrance\" + 0.029*\"scent\" + 0.012*\"experience\" + 0.011*\"jorgensen\" + 0.011*\"five\" + 0.010*\"brand\" + 0.010*\"customer\" + 0.010*\"zodiac\" + 0.009*\"say\" + 0.009*\"aroma\"\n",
      "2019-10-29 00:45:13,855 : INFO : topic #5 (0.100): 0.030*\"fragrance\" + 0.024*\"scent\" + 0.014*\"experience\" + 0.013*\"jorgensen\" + 0.012*\"zodiac\" + 0.011*\"smell\" + 0.010*\"airline\" + 0.010*\"five\" + 0.009*\"customer\" + 0.009*\"brand\"\n",
      "2019-10-29 00:45:13,857 : INFO : topic diff=0.828705, rho=1.000000\n",
      "2019-10-29 00:45:14,339 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:14,354 : INFO : built Dictionary(736 unique tokens: ['let', 'happy', 'entitled', 'focus', 'troll']...) from 5 documents (total 6675 corpus positions)\n",
      "2019-10-29 00:45:14,364 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:14,366 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:14,368 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:14,372 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:14,375 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:14,628 : INFO : -8.378 per-word bound, 332.8 perplexity estimate based on a held-out corpus of 5 documents with 6675 words\n",
      "2019-10-29 00:45:14,629 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:14,642 : INFO : topic #1 (0.100): 0.014*\"photo\" + 0.012*\"retouching\" + 0.012*\"look\" + 0.012*\"take\" + 0.012*\"fat\" + 0.011*\"stand\" + 0.010*\"celebs\" + 0.009*\"people\" + 0.009*\"said\" + 0.009*\"caption\"\n",
      "2019-10-29 00:45:14,644 : INFO : topic #6 (0.100): 0.016*\"photo\" + 0.013*\"hide\" + 0.013*\"caption\" + 0.013*\"retouching\" + 0.012*\"stand\" + 0.011*\"look\" + 0.010*\"take\" + 0.010*\"celebs\" + 0.010*\"people\" + 0.009*\"fat\"\n",
      "2019-10-29 00:45:14,645 : INFO : topic #0 (0.100): 0.017*\"look\" + 0.014*\"retouching\" + 0.013*\"stand\" + 0.012*\"photo\" + 0.011*\"hide\" + 0.010*\"people\" + 0.010*\"take\" + 0.010*\"celebs\" + 0.009*\"said\" + 0.008*\"body\"\n",
      "2019-10-29 00:45:14,649 : INFO : topic #8 (0.100): 0.015*\"retouching\" + 0.014*\"photo\" + 0.013*\"celebs\" + 0.013*\"take\" + 0.013*\"fat\" + 0.013*\"look\" + 0.011*\"hide\" + 0.010*\"said\" + 0.009*\"stand\" + 0.008*\"woman\"\n",
      "2019-10-29 00:45:14,653 : INFO : topic #4 (0.100): 0.014*\"photo\" + 0.014*\"retouching\" + 0.012*\"look\" + 0.011*\"fat\" + 0.011*\"celebs\" + 0.010*\"body\" + 0.010*\"said\" + 0.010*\"stand\" + 0.009*\"take\" + 0.009*\"magazine\"\n",
      "2019-10-29 00:45:14,656 : INFO : topic diff=0.931756, rho=1.000000\n",
      "2019-10-29 00:45:15,100 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:15,106 : INFO : built Dictionary(534 unique tokens: ['reclaim', 'residency', 'translated', 'filed', 'reach']...) from 5 documents (total 4775 corpus positions)\n",
      "2019-10-29 00:45:15,112 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:15,113 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:15,115 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:15,119 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:15,121 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:15,274 : INFO : -8.076 per-word bound, 269.9 perplexity estimate based on a held-out corpus of 5 documents with 4775 words\n",
      "2019-10-29 00:45:15,276 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:15,286 : INFO : topic #3 (0.100): 0.032*\"allami\" + 0.027*\"hrebid\" + 0.015*\"say\" + 0.013*\"day\" + 0.011*\"refugee\" + 0.010*\"u\" + 0.009*\"new\" + 0.009*\"would\" + 0.009*\"home\" + 0.009*\"one\"\n",
      "2019-10-29 00:45:15,289 : INFO : topic #8 (0.100): 0.039*\"hrebid\" + 0.029*\"allami\" + 0.017*\"say\" + 0.010*\"u\" + 0.010*\"home\" + 0.009*\"night\" + 0.009*\"would\" + 0.009*\"one\" + 0.008*\"day\" + 0.008*\"two\"\n",
      "2019-10-29 00:45:15,291 : INFO : topic #5 (0.100): 0.031*\"allami\" + 0.030*\"hrebid\" + 0.020*\"say\" + 0.010*\"u\" + 0.010*\"refugee\" + 0.009*\"would\" + 0.009*\"one\" + 0.009*\"new\" + 0.008*\"home\" + 0.008*\"seattle\"\n",
      "2019-10-29 00:45:15,293 : INFO : topic #7 (0.100): 0.043*\"hrebid\" + 0.031*\"allami\" + 0.015*\"say\" + 0.011*\"day\" + 0.011*\"one\" + 0.010*\"seattle\" + 0.009*\"two\" + 0.009*\"refugee\" + 0.009*\"year\" + 0.009*\"iraq\"\n",
      "2019-10-29 00:45:15,296 : INFO : topic #4 (0.100): 0.037*\"allami\" + 0.033*\"hrebid\" + 0.012*\"say\" + 0.012*\"one\" + 0.012*\"new\" + 0.010*\"night\" + 0.010*\"day\" + 0.009*\"would\" + 0.009*\"seattle\" + 0.009*\"refugee\"\n",
      "2019-10-29 00:45:15,298 : INFO : topic diff=0.892494, rho=1.000000\n",
      "2019-10-29 00:45:15,698 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:15,700 : INFO : built Dictionary(63 unique tokens: ['faced', 'birfday', 'life', 'grocery', 'strike']...) from 5 documents (total 395 corpus positions)\n",
      "2019-10-29 00:45:15,701 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:15,702 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:15,704 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:15,707 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:15,708 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:15,740 : INFO : -6.720 per-word bound, 105.4 perplexity estimate based on a held-out corpus of 5 documents with 395 words\n",
      "2019-10-29 00:45:15,742 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:15,747 : INFO : topic #6 (0.100): 0.041*\"old\" + 0.034*\"norah\" + 0.031*\"month\" + 0.031*\"man\" + 0.030*\"year\" + 0.028*\"lonely\" + 0.027*\"today\" + 0.027*\"mother\" + 0.026*\"girl\" + 0.025*\"cnn\"\n",
      "2019-10-29 00:45:15,750 : INFO : topic #2 (0.100): 0.064*\"old\" + 0.035*\"norah\" + 0.028*\"year\" + 0.028*\"girl\" + 0.027*\"today\" + 0.024*\"lonely\" + 0.023*\"man\" + 0.023*\"wood\" + 0.022*\"cnn\" + 0.020*\"mother\"\n",
      "2019-10-29 00:45:15,754 : INFO : topic #3 (0.100): 0.072*\"old\" + 0.035*\"norah\" + 0.034*\"year\" + 0.028*\"man\" + 0.027*\"cnn\" + 0.026*\"today\" + 0.022*\"month\" + 0.021*\"mother\" + 0.020*\"wood\" + 0.019*\"aisle\"\n",
      "2019-10-29 00:45:15,758 : INFO : topic #4 (0.100): 0.073*\"old\" + 0.038*\"norah\" + 0.036*\"year\" + 0.026*\"lonely\" + 0.025*\"wood\" + 0.025*\"cnn\" + 0.025*\"girl\" + 0.024*\"today\" + 0.023*\"man\" + 0.023*\"mother\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:15,761 : INFO : topic #0 (0.100): 0.047*\"old\" + 0.042*\"year\" + 0.038*\"norah\" + 0.032*\"wood\" + 0.028*\"month\" + 0.025*\"man\" + 0.025*\"cnn\" + 0.024*\"mother\" + 0.021*\"lonely\" + 0.021*\"girl\"\n",
      "2019-10-29 00:45:15,764 : INFO : topic diff=0.694386, rho=1.000000\n",
      "2019-10-29 00:45:16,176 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:16,180 : INFO : built Dictionary(65 unique tokens: ['way', 'punish', 'rozier', 'know', 'trainer']...) from 5 documents (total 415 corpus positions)\n",
      "2019-10-29 00:45:16,183 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:16,186 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:16,187 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:16,190 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:16,193 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:16,238 : INFO : -6.720 per-word bound, 105.4 perplexity estimate based on a held-out corpus of 5 documents with 415 words\n",
      "2019-10-29 00:45:16,240 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:16,258 : INFO : topic #6 (0.100): 0.036*\"new\" + 0.035*\"brooklyn\" + 0.034*\"boxer\" + 0.032*\"rozier\" + 0.025*\"york\" + 0.025*\"lose\" + 0.024*\"champion\" + 0.023*\"fighter\" + 0.022*\"boxing\" + 0.021*\"way\"\n",
      "2019-10-29 00:45:16,261 : INFO : topic #1 (0.100): 0.040*\"rozier\" + 0.040*\"new\" + 0.034*\"boxer\" + 0.034*\"brooklyn\" + 0.026*\"fighter\" + 0.025*\"champion\" + 0.025*\"york\" + 0.024*\"know\" + 0.024*\"boxing\" + 0.023*\"like\"\n",
      "2019-10-29 00:45:16,264 : INFO : topic #5 (0.100): 0.050*\"new\" + 0.037*\"rozier\" + 0.033*\"brooklyn\" + 0.029*\"boxer\" + 0.028*\"boxing\" + 0.027*\"fighter\" + 0.026*\"know\" + 0.026*\"way\" + 0.022*\"champion\" + 0.021*\"like\"\n",
      "2019-10-29 00:45:16,270 : INFO : topic #4 (0.100): 0.046*\"new\" + 0.035*\"rozier\" + 0.034*\"boxer\" + 0.029*\"brooklyn\" + 0.028*\"way\" + 0.026*\"lose\" + 0.024*\"champion\" + 0.024*\"fighter\" + 0.022*\"andre\" + 0.022*\"like\"\n",
      "2019-10-29 00:45:16,274 : INFO : topic #2 (0.100): 0.049*\"new\" + 0.043*\"boxer\" + 0.027*\"rozier\" + 0.026*\"lose\" + 0.026*\"brooklyn\" + 0.026*\"way\" + 0.025*\"like\" + 0.024*\"andre\" + 0.024*\"boxing\" + 0.023*\"fighter\"\n",
      "2019-10-29 00:45:16,277 : INFO : topic diff=0.713208, rho=1.000000\n",
      "2019-10-29 00:45:16,735 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:16,742 : INFO : built Dictionary(531 unique tokens: ['previously', 'let', 'size', 'restriction', 'railroad']...) from 5 documents (total 4705 corpus positions)\n",
      "2019-10-29 00:45:16,748 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:16,750 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:16,751 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:16,755 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:16,758 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:16,909 : INFO : -8.084 per-word bound, 271.4 perplexity estimate based on a held-out corpus of 5 documents with 4705 words\n",
      "2019-10-29 00:45:16,911 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:16,919 : INFO : topic #2 (0.100): 0.046*\"circus\" + 0.030*\"bros\" + 0.027*\"ringling\" + 0.023*\"elephant\" + 0.022*\"photo\" + 0.016*\"hide\" + 0.010*\"caption\" + 0.010*\"back\" + 0.008*\"mann\" + 0.007*\"show\"\n",
      "2019-10-29 00:45:16,921 : INFO : topic #3 (0.100): 0.040*\"circus\" + 0.030*\"elephant\" + 0.028*\"ringling\" + 0.027*\"bros\" + 0.016*\"caption\" + 0.015*\"photo\" + 0.012*\"hide\" + 0.007*\"back\" + 0.007*\"mann\" + 0.007*\"performance\"\n",
      "2019-10-29 00:45:16,922 : INFO : topic #4 (0.100): 0.050*\"circus\" + 0.038*\"elephant\" + 0.028*\"ringling\" + 0.022*\"bros\" + 0.019*\"hide\" + 0.017*\"photo\" + 0.014*\"caption\" + 0.010*\"mann\" + 0.008*\"back\" + 0.007*\"lion\"\n",
      "2019-10-29 00:45:16,924 : INFO : topic #9 (0.100): 0.047*\"circus\" + 0.038*\"elephant\" + 0.020*\"ringling\" + 0.019*\"bros\" + 0.015*\"photo\" + 0.013*\"caption\" + 0.013*\"hide\" + 0.007*\"mann\" + 0.006*\"grandma\" + 0.006*\"train\"\n",
      "2019-10-29 00:45:16,926 : INFO : topic #0 (0.100): 0.042*\"circus\" + 0.031*\"elephant\" + 0.022*\"ringling\" + 0.022*\"bros\" + 0.016*\"caption\" + 0.014*\"hide\" + 0.014*\"photo\" + 0.008*\"tiger\" + 0.007*\"one\" + 0.007*\"mann\"\n",
      "2019-10-29 00:45:16,927 : INFO : topic diff=0.913394, rho=1.000000\n",
      "2019-10-29 00:45:17,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:17,314 : INFO : built Dictionary(56 unique tokens: ['story', 'issue', 'time', 'life', 'joe']...) from 5 documents (total 360 corpus positions)\n",
      "2019-10-29 00:45:17,315 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:17,317 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:17,318 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:17,322 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:17,323 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:17,351 : INFO : -6.584 per-word bound, 95.9 perplexity estimate based on a held-out corpus of 5 documents with 360 words\n",
      "2019-10-29 00:45:17,352 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:17,361 : INFO : topic #3 (0.100): 0.063*\"heart\" + 0.053*\"tyler\" + 0.046*\"tour\" + 0.031*\"attack\" + 0.029*\"said\" + 0.027*\"seizure\" + 0.023*\"steven\" + 0.021*\"issue\" + 0.020*\"frontman\" + 0.018*\"south\"\n",
      "2019-10-29 00:45:17,363 : INFO : topic #5 (0.100): 0.079*\"heart\" + 0.056*\"tyler\" + 0.040*\"tour\" + 0.038*\"attack\" + 0.035*\"issue\" + 0.024*\"seizure\" + 0.023*\"steven\" + 0.023*\"said\" + 0.019*\"condition\" + 0.018*\"wrote\"\n",
      "2019-10-29 00:45:17,367 : INFO : topic #6 (0.100): 0.068*\"tyler\" + 0.050*\"heart\" + 0.045*\"attack\" + 0.040*\"tour\" + 0.024*\"issue\" + 0.023*\"said\" + 0.021*\"health\" + 0.018*\"seizure\" + 0.018*\"steven\" + 0.017*\"announced\"\n",
      "2019-10-29 00:45:17,371 : INFO : topic #1 (0.100): 0.076*\"tyler\" + 0.056*\"heart\" + 0.038*\"attack\" + 0.038*\"tour\" + 0.028*\"steven\" + 0.025*\"seizure\" + 0.024*\"said\" + 0.024*\"issue\" + 0.019*\"aero\" + 0.018*\"life\"\n",
      "2019-10-29 00:45:17,376 : INFO : topic #7 (0.100): 0.055*\"heart\" + 0.042*\"tyler\" + 0.034*\"attack\" + 0.034*\"said\" + 0.028*\"issue\" + 0.028*\"tour\" + 0.027*\"seizure\" + 0.024*\"steven\" + 0.019*\"cnn\" + 0.018*\"health\"\n",
      "2019-10-29 00:45:17,380 : INFO : topic diff=0.749560, rho=1.000000\n",
      "2019-10-29 00:45:17,902 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:17,913 : INFO : built Dictionary(498 unique tokens: ['catholic', 'filed', 'real', 'happy', 'relax']...) from 5 documents (total 4155 corpus positions)\n",
      "2019-10-29 00:45:17,922 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:17,925 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:17,929 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:17,934 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:17,937 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:18,122 : INFO : -8.105 per-word bound, 275.3 perplexity estimate based on a held-out corpus of 5 documents with 4155 words\n",
      "2019-10-29 00:45:18,123 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:18,130 : INFO : topic #0 (0.100): 0.019*\"ranch\" + 0.019*\"say\" + 0.014*\"one\" + 0.013*\"luiz\" + 0.012*\"brazil\" + 0.011*\"labor\" + 0.010*\"slavery\" + 0.010*\"unit\" + 0.010*\"family\" + 0.010*\"seu\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:18,133 : INFO : topic #5 (0.100): 0.018*\"ranch\" + 0.017*\"say\" + 0.015*\"labor\" + 0.013*\"cattle\" + 0.013*\"brazil\" + 0.012*\"luiz\" + 0.011*\"one\" + 0.009*\"year\" + 0.009*\"seu\" + 0.008*\"slavery\"\n",
      "2019-10-29 00:45:18,135 : INFO : topic #1 (0.100): 0.025*\"ranch\" + 0.017*\"say\" + 0.011*\"brazil\" + 0.011*\"slavery\" + 0.011*\"worker\" + 0.010*\"luiz\" + 0.009*\"cattle\" + 0.008*\"mobile\" + 0.008*\"family\" + 0.008*\"year\"\n",
      "2019-10-29 00:45:18,137 : INFO : topic #3 (0.100): 0.017*\"say\" + 0.016*\"ranch\" + 0.013*\"luiz\" + 0.013*\"brazil\" + 0.011*\"worker\" + 0.011*\"mobile\" + 0.010*\"cattle\" + 0.010*\"labor\" + 0.009*\"slavery\" + 0.009*\"one\"\n",
      "2019-10-29 00:45:18,139 : INFO : topic #2 (0.100): 0.023*\"say\" + 0.017*\"ranch\" + 0.011*\"slavery\" + 0.011*\"one\" + 0.011*\"brazil\" + 0.011*\"labor\" + 0.010*\"worker\" + 0.009*\"luiz\" + 0.009*\"family\" + 0.009*\"seu\"\n",
      "2019-10-29 00:45:18,141 : INFO : topic diff=0.866998, rho=1.000000\n",
      "2019-10-29 00:45:18,570 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:18,576 : INFO : built Dictionary(420 unique tokens: ['let', 'mistreatment', 'weinstein', 'expense', 'party']...) from 5 documents (total 3205 corpus positions)\n",
      "2019-10-29 00:45:18,582 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:18,583 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:18,584 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:18,588 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:18,589 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:18,730 : INFO : -8.068 per-word bound, 268.3 perplexity estimate based on a held-out corpus of 5 documents with 3205 words\n",
      "2019-10-29 00:45:18,731 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:18,740 : INFO : topic #9 (0.100): 0.038*\"weinstein\" + 0.020*\"sexual\" + 0.013*\"new\" + 0.012*\"woman\" + 0.010*\"trump\" + 0.010*\"predator\" + 0.008*\"alleged\" + 0.007*\"democratic\" + 0.007*\"men\" + 0.007*\"u\"\n",
      "2019-10-29 00:45:18,742 : INFO : topic #7 (0.100): 0.033*\"weinstein\" + 0.026*\"sexual\" + 0.016*\"woman\" + 0.012*\"trump\" + 0.008*\"alleged\" + 0.008*\"jr\" + 0.008*\"new\" + 0.008*\"u\" + 0.008*\"men\" + 0.007*\"money\"\n",
      "2019-10-29 00:45:18,745 : INFO : topic #3 (0.100): 0.037*\"weinstein\" + 0.026*\"sexual\" + 0.013*\"woman\" + 0.013*\"new\" + 0.010*\"u\" + 0.010*\"trump\" + 0.007*\"jr\" + 0.006*\"alleged\" + 0.006*\"predator\" + 0.006*\"snl\"\n",
      "2019-10-29 00:45:18,747 : INFO : topic #2 (0.100): 0.033*\"weinstein\" + 0.020*\"sexual\" + 0.014*\"new\" + 0.013*\"woman\" + 0.010*\"trump\" + 0.009*\"u\" + 0.009*\"men\" + 0.008*\"alleged\" + 0.007*\"democratic\" + 0.007*\"money\"\n",
      "2019-10-29 00:45:18,749 : INFO : topic #5 (0.100): 0.035*\"weinstein\" + 0.021*\"sexual\" + 0.018*\"woman\" + 0.012*\"new\" + 0.011*\"trump\" + 0.010*\"u\" + 0.008*\"also\" + 0.008*\"men\" + 0.007*\"week\" + 0.007*\"alleged\"\n",
      "2019-10-29 00:45:18,751 : INFO : topic diff=0.825954, rho=1.000000\n",
      "2019-10-29 00:45:19,150 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:19,153 : INFO : built Dictionary(143 unique tokens: ['anniversary', 'even', 'fewer', 'disquiet', 'book']...) from 5 documents (total 825 corpus positions)\n",
      "2019-10-29 00:45:19,155 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:19,157 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:19,159 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:19,161 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:19,162 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:19,228 : INFO : -7.572 per-word bound, 190.3 perplexity estimate based on a held-out corpus of 5 documents with 825 words\n",
      "2019-10-29 00:45:19,229 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:19,236 : INFO : topic #2 (0.100): 0.045*\"trump\" + 0.016*\"time\" + 0.015*\"began\" + 0.014*\"night\" + 0.012*\"morning\" + 0.012*\"donald\" + 0.012*\"minute\" + 0.012*\"tweet\" + 0.011*\"early\" + 0.011*\"mike\"\n",
      "2019-10-29 00:45:19,238 : INFO : topic #5 (0.100): 0.033*\"trump\" + 0.016*\"began\" + 0.016*\"time\" + 0.016*\"mike\" + 0.014*\"espn\" + 0.014*\"minute\" + 0.014*\"first\" + 0.012*\"good\" + 0.011*\"le\" + 0.011*\"morning\"\n",
      "2019-10-29 00:45:19,241 : INFO : topic #4 (0.100): 0.032*\"trump\" + 0.016*\"espn\" + 0.016*\"time\" + 0.015*\"began\" + 0.014*\"tweet\" + 0.014*\"night\" + 0.013*\"early\" + 0.012*\"le\" + 0.012*\"donald\" + 0.012*\"morning\"\n",
      "2019-10-29 00:45:19,244 : INFO : topic #6 (0.100): 0.041*\"trump\" + 0.019*\"time\" + 0.015*\"tweet\" + 0.015*\"began\" + 0.014*\"night\" + 0.014*\"first\" + 0.013*\"mike\" + 0.013*\"donald\" + 0.012*\"hill\" + 0.012*\"espn\"\n",
      "2019-10-29 00:45:19,246 : INFO : topic #1 (0.100): 0.036*\"trump\" + 0.019*\"time\" + 0.017*\"began\" + 0.013*\"le\" + 0.013*\"good\" + 0.013*\"mike\" + 0.012*\"first\" + 0.012*\"morning\" + 0.012*\"hill\" + 0.011*\"night\"\n",
      "2019-10-29 00:45:19,249 : INFO : topic diff=0.654052, rho=1.000000\n",
      "2019-10-29 00:45:19,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:19,641 : INFO : built Dictionary(75 unique tokens: ['affected', 'story', 'briefing', 'night', 'know']...) from 5 documents (total 500 corpus positions)\n",
      "2019-10-29 00:45:19,642 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:19,644 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:19,645 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:19,647 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:19,648 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:19,681 : INFO : -6.751 per-word bound, 107.7 perplexity estimate based on a held-out corpus of 5 documents with 500 words\n",
      "2019-10-29 00:45:19,682 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:19,691 : INFO : topic #0 (0.100): 0.060*\"california\" + 0.041*\"trump\" + 0.030*\"wildfire\" + 0.026*\"addressed\" + 0.024*\"country\" + 0.024*\"stand\" + 0.022*\"white\" + 0.021*\"president\" + 0.019*\"gov\" + 0.019*\"tuesday\"\n",
      "2019-10-29 00:45:19,694 : INFO : topic #6 (0.100): 0.047*\"california\" + 0.042*\"wildfire\" + 0.040*\"trump\" + 0.026*\"stand\" + 0.023*\"white\" + 0.022*\"house\" + 0.020*\"president\" + 0.020*\"gov\" + 0.019*\"night\" + 0.019*\"government\"\n",
      "2019-10-29 00:45:19,697 : INFO : topic #5 (0.100): 0.041*\"california\" + 0.039*\"wildfire\" + 0.035*\"trump\" + 0.031*\"stand\" + 0.023*\"brown\" + 0.022*\"night\" + 0.022*\"president\" + 0.022*\"spoke\" + 0.020*\"country\" + 0.019*\"government\"\n",
      "2019-10-29 00:45:19,701 : INFO : topic #1 (0.100): 0.046*\"wildfire\" + 0.040*\"california\" + 0.025*\"stand\" + 0.024*\"trump\" + 0.022*\"house\" + 0.022*\"government\" + 0.021*\"brown\" + 0.021*\"president\" + 0.020*\"spoke\" + 0.020*\"night\"\n",
      "2019-10-29 00:45:19,707 : INFO : topic #8 (0.100): 0.052*\"wildfire\" + 0.031*\"trump\" + 0.030*\"california\" + 0.026*\"stand\" + 0.022*\"house\" + 0.022*\"spoke\" + 0.021*\"night\" + 0.021*\"country\" + 0.021*\"brown\" + 0.020*\"president\"\n",
      "2019-10-29 00:45:19,710 : INFO : topic diff=0.742921, rho=1.000000\n",
      "2019-10-29 00:45:20,190 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:20,197 : INFO : built Dictionary(254 unique tokens: ['violence', 'located', 'myanmar', 'reach', 'collect']...) from 5 documents (total 3635 corpus positions)\n",
      "2019-10-29 00:45:20,202 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:20,203 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:20,205 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:20,209 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:20,212 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:20,312 : INFO : -6.888 per-word bound, 118.5 perplexity estimate based on a held-out corpus of 5 documents with 3635 words\n",
      "2019-10-29 00:45:20,314 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:20,320 : INFO : topic #5 (0.100): 0.090*\"rohingya\" + 0.084*\"refugee\" + 0.054*\"flee\" + 0.048*\"myanmar\" + 0.045*\"caption\" + 0.039*\"hide\" + 0.032*\"photo\" + 0.028*\"september\" + 0.023*\"bangladesh\" + 0.012*\"camp\"\n",
      "2019-10-29 00:45:20,322 : INFO : topic #7 (0.100): 0.079*\"rohingya\" + 0.077*\"refugee\" + 0.074*\"myanmar\" + 0.047*\"photo\" + 0.039*\"hide\" + 0.034*\"flee\" + 0.028*\"caption\" + 0.027*\"september\" + 0.024*\"bangladesh\" + 0.014*\"camp\"\n",
      "2019-10-29 00:45:20,325 : INFO : topic #8 (0.100): 0.085*\"refugee\" + 0.072*\"rohingya\" + 0.062*\"myanmar\" + 0.041*\"hide\" + 0.037*\"photo\" + 0.032*\"september\" + 0.031*\"bangladesh\" + 0.027*\"flee\" + 0.022*\"caption\" + 0.017*\"camp\"\n",
      "2019-10-29 00:45:20,328 : INFO : topic #3 (0.100): 0.073*\"rohingya\" + 0.061*\"refugee\" + 0.055*\"myanmar\" + 0.046*\"flee\" + 0.043*\"caption\" + 0.043*\"hide\" + 0.042*\"september\" + 0.035*\"photo\" + 0.035*\"bangladesh\" + 0.014*\"camp\"\n",
      "2019-10-29 00:45:20,330 : INFO : topic #0 (0.100): 0.074*\"rohingya\" + 0.064*\"refugee\" + 0.062*\"myanmar\" + 0.047*\"flee\" + 0.039*\"caption\" + 0.039*\"hide\" + 0.032*\"bangladesh\" + 0.029*\"september\" + 0.027*\"photo\" + 0.012*\"boat\"\n",
      "2019-10-29 00:45:20,333 : INFO : topic diff=1.220040, rho=1.000000\n",
      "2019-10-29 00:45:20,845 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:20,856 : INFO : built Dictionary(804 unique tokens: ['happy', 'strain', 'expert', 'way', 'cnn']...) from 5 documents (total 9805 corpus positions)\n",
      "2019-10-29 00:45:20,868 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:20,869 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:20,874 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:20,880 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:20,883 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:21,126 : INFO : -8.143 per-word bound, 282.7 perplexity estimate based on a held-out corpus of 5 documents with 9805 words\n",
      "2019-10-29 00:45:21,127 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:21,138 : INFO : topic #4 (0.100): 0.030*\"twin\" + 0.022*\"new\" + 0.020*\"separated\" + 0.020*\"anias\" + 0.016*\"life\" + 0.014*\"boy\" + 0.013*\"jadon\" + 0.012*\"photo\" + 0.012*\"room\" + 0.011*\"hospital\"\n",
      "2019-10-29 00:45:21,140 : INFO : topic #3 (0.100): 0.025*\"twin\" + 0.020*\"anias\" + 0.020*\"new\" + 0.018*\"separated\" + 0.016*\"boy\" + 0.016*\"life\" + 0.016*\"conjoined\" + 0.014*\"photo\" + 0.012*\"room\" + 0.012*\"hide\"\n",
      "2019-10-29 00:45:21,142 : INFO : topic #2 (0.100): 0.024*\"twin\" + 0.023*\"anias\" + 0.021*\"separated\" + 0.018*\"photo\" + 0.018*\"jadon\" + 0.018*\"new\" + 0.013*\"conjoined\" + 0.013*\"life\" + 0.013*\"boy\" + 0.012*\"apart\"\n",
      "2019-10-29 00:45:21,144 : INFO : topic #8 (0.100): 0.024*\"twin\" + 0.016*\"new\" + 0.016*\"boy\" + 0.015*\"conjoined\" + 0.014*\"separated\" + 0.014*\"life\" + 0.013*\"hide\" + 0.013*\"jadon\" + 0.012*\"anias\" + 0.012*\"apart\"\n",
      "2019-10-29 00:45:21,147 : INFO : topic #5 (0.100): 0.034*\"twin\" + 0.021*\"new\" + 0.018*\"separated\" + 0.015*\"boy\" + 0.015*\"anias\" + 0.014*\"jadon\" + 0.013*\"caption\" + 0.012*\"life\" + 0.012*\"mcdonald\" + 0.011*\"surgery\"\n",
      "2019-10-29 00:45:21,150 : INFO : topic diff=1.116457, rho=1.000000\n",
      "2019-10-29 00:45:21,550 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:21,552 : INFO : built Dictionary(81 unique tokens: ['way', 'flurry', 'appreciation', 'know', 'nominee']...) from 5 documents (total 510 corpus positions)\n",
      "2019-10-29 00:45:21,553 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:21,555 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:21,556 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:21,558 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:21,560 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:21,605 : INFO : -6.917 per-word bound, 120.9 perplexity estimate based on a held-out corpus of 5 documents with 510 words\n",
      "2019-10-29 00:45:21,607 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:21,614 : INFO : topic #9 (0.100): 0.084*\"day\" + 0.056*\"national\" + 0.033*\"holiday\" + 0.025*\"opinion\" + 0.023*\"need\" + 0.021*\"coffee\" + 0.019*\"j\" + 0.018*\"think\" + 0.015*\"way\" + 0.014*\"tempted\"\n",
      "2019-10-29 00:45:21,618 : INFO : topic #8 (0.100): 0.092*\"day\" + 0.055*\"national\" + 0.022*\"holiday\" + 0.022*\"think\" + 0.020*\"way\" + 0.018*\"j\" + 0.015*\"need\" + 0.015*\"coffee\" + 0.014*\"opinion\" + 0.013*\"year\"\n",
      "2019-10-29 00:45:21,620 : INFO : topic #0 (0.100): 0.065*\"day\" + 0.046*\"national\" + 0.027*\"holiday\" + 0.023*\"way\" + 0.022*\"need\" + 0.021*\"think\" + 0.019*\"j\" + 0.018*\"coffee\" + 0.018*\"opinion\" + 0.014*\"twitter\"\n",
      "2019-10-29 00:45:21,621 : INFO : topic #3 (0.100): 0.068*\"day\" + 0.039*\"national\" + 0.023*\"holiday\" + 0.022*\"coffee\" + 0.021*\"opinion\" + 0.019*\"think\" + 0.019*\"j\" + 0.018*\"need\" + 0.015*\"way\" + 0.013*\"designated\"\n",
      "2019-10-29 00:45:21,626 : INFO : topic #6 (0.100): 0.071*\"day\" + 0.051*\"national\" + 0.027*\"holiday\" + 0.022*\"way\" + 0.021*\"opinion\" + 0.018*\"j\" + 0.017*\"think\" + 0.015*\"coffee\" + 0.014*\"free\" + 0.013*\"author\"\n",
      "2019-10-29 00:45:21,630 : INFO : topic diff=0.739497, rho=1.000000\n",
      "2019-10-29 00:45:22,038 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:22,042 : INFO : built Dictionary(283 unique tokens: ['although', 'violence', 'school', 'small', 'pew']...) from 5 documents (total 2295 corpus positions)\n",
      "2019-10-29 00:45:22,046 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:22,048 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:22,049 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:22,053 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:22,055 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:22,157 : INFO : -7.609 per-word bound, 195.2 perplexity estimate based on a held-out corpus of 5 documents with 2295 words\n",
      "2019-10-29 00:45:22,158 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:22,166 : INFO : topic #3 (0.100): 0.055*\"gun\" + 0.018*\"world\" + 0.017*\"american\" + 0.016*\"firearm\" + 0.016*\"u\" + 0.014*\"shooting\" + 0.014*\"according\" + 0.012*\"people\" + 0.012*\"related\" + 0.011*\"mass\"\n",
      "2019-10-29 00:45:22,168 : INFO : topic #0 (0.100): 0.076*\"gun\" + 0.021*\"u\" + 0.020*\"world\" + 0.015*\"firearm\" + 0.015*\"shooting\" + 0.013*\"according\" + 0.012*\"people\" + 0.012*\"civilian\" + 0.011*\"mass\" + 0.011*\"america\"\n",
      "2019-10-29 00:45:22,170 : INFO : topic #8 (0.100): 0.048*\"gun\" + 0.020*\"u\" + 0.019*\"according\" + 0.018*\"people\" + 0.016*\"shooting\" + 0.016*\"firearm\" + 0.013*\"world\" + 0.013*\"mass\" + 0.012*\"related\" + 0.011*\"civilian\"\n",
      "2019-10-29 00:45:22,172 : INFO : topic #6 (0.100): 0.069*\"gun\" + 0.021*\"u\" + 0.015*\"firearm\" + 0.014*\"shooting\" + 0.013*\"people\" + 0.013*\"according\" + 0.012*\"world\" + 0.012*\"related\" + 0.011*\"america\" + 0.010*\"civilian\"\n",
      "2019-10-29 00:45:22,174 : INFO : topic #7 (0.100): 0.061*\"gun\" + 0.023*\"u\" + 0.020*\"according\" + 0.020*\"firearm\" + 0.016*\"world\" + 0.014*\"shooting\" + 0.014*\"american\" + 0.014*\"people\" + 0.012*\"related\" + 0.011*\"america\"\n",
      "2019-10-29 00:45:22,177 : INFO : topic diff=0.868015, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:22,634 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:22,643 : INFO : built Dictionary(350 unique tokens: ['let', 'camp', 'trying', 'one', 'self']...) from 5 documents (total 2490 corpus positions)\n",
      "2019-10-29 00:45:22,649 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:22,650 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:22,652 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:22,658 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:22,661 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:22,816 : INFO : -8.010 per-word bound, 257.8 perplexity estimate based on a held-out corpus of 5 documents with 2490 words\n",
      "2019-10-29 00:45:22,817 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:22,827 : INFO : topic #7 (0.100): 0.025*\"gun\" + 0.009*\"could\" + 0.009*\"school\" + 0.008*\"fun\" + 0.008*\"problem\" + 0.007*\"ashley\" + 0.007*\"friend\" + 0.007*\"family\" + 0.007*\"college\" + 0.007*\"one\"\n",
      "2019-10-29 00:45:22,831 : INFO : topic #0 (0.100): 0.028*\"gun\" + 0.011*\"problem\" + 0.008*\"mom\" + 0.008*\"school\" + 0.008*\"shot\" + 0.008*\"three\" + 0.007*\"u\" + 0.007*\"violence\" + 0.007*\"fun\" + 0.007*\"uncle\"\n",
      "2019-10-29 00:45:22,834 : INFO : topic #2 (0.100): 0.020*\"gun\" + 0.011*\"problem\" + 0.011*\"violence\" + 0.009*\"friend\" + 0.008*\"vega\" + 0.008*\"cousin\" + 0.007*\"mom\" + 0.007*\"health\" + 0.007*\"thought\" + 0.007*\"could\"\n",
      "2019-10-29 00:45:22,836 : INFO : topic #6 (0.100): 0.023*\"gun\" + 0.009*\"problem\" + 0.009*\"mom\" + 0.008*\"vega\" + 0.008*\"fun\" + 0.008*\"one\" + 0.008*\"could\" + 0.007*\"violence\" + 0.007*\"la\" + 0.007*\"shot\"\n",
      "2019-10-29 00:45:22,838 : INFO : topic #4 (0.100): 0.023*\"gun\" + 0.010*\"three\" + 0.009*\"problem\" + 0.008*\"fun\" + 0.008*\"friend\" + 0.008*\"mom\" + 0.007*\"could\" + 0.007*\"vega\" + 0.007*\"shot\" + 0.007*\"one\"\n",
      "2019-10-29 00:45:22,840 : INFO : topic diff=0.779238, rho=1.000000\n",
      "2019-10-29 00:45:23,294 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:23,301 : INFO : built Dictionary(337 unique tokens: ['real', 'watch', 'attending', 'come', 'mourning']...) from 5 documents (total 2350 corpus positions)\n",
      "2019-10-29 00:45:23,303 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:23,304 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:23,305 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:23,309 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:23,312 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:23,414 : INFO : -8.005 per-word bound, 256.9 perplexity estimate based on a held-out corpus of 5 documents with 2350 words\n",
      "2019-10-29 00:45:23,415 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:23,423 : INFO : topic #9 (0.100): 0.023*\"puerto\" + 0.016*\"rico\" + 0.013*\"day\" + 0.012*\"death\" + 0.011*\"people\" + 0.010*\"family\" + 0.009*\"year\" + 0.009*\"home\" + 0.009*\"hurricane\" + 0.008*\"one\"\n",
      "2019-10-29 00:45:23,425 : INFO : topic #0 (0.100): 0.021*\"rico\" + 0.021*\"puerto\" + 0.015*\"death\" + 0.013*\"storm\" + 0.012*\"day\" + 0.009*\"year\" + 0.009*\"doctor\" + 0.008*\"hurricane\" + 0.008*\"visit\" + 0.008*\"family\"\n",
      "2019-10-29 00:45:23,427 : INFO : topic #7 (0.100): 0.019*\"rico\" + 0.018*\"puerto\" + 0.014*\"day\" + 0.013*\"death\" + 0.010*\"visit\" + 0.009*\"hurricane\" + 0.009*\"could\" + 0.008*\"doctor\" + 0.008*\"help\" + 0.008*\"people\"\n",
      "2019-10-29 00:45:23,428 : INFO : topic #8 (0.100): 0.019*\"rico\" + 0.018*\"puerto\" + 0.013*\"death\" + 0.012*\"storm\" + 0.009*\"day\" + 0.009*\"people\" + 0.008*\"hurricane\" + 0.008*\"help\" + 0.007*\"year\" + 0.007*\"family\"\n",
      "2019-10-29 00:45:23,430 : INFO : topic #1 (0.100): 0.020*\"puerto\" + 0.018*\"day\" + 0.017*\"rico\" + 0.013*\"death\" + 0.010*\"people\" + 0.009*\"know\" + 0.009*\"family\" + 0.008*\"help\" + 0.008*\"storm\" + 0.008*\"visit\"\n",
      "2019-10-29 00:45:23,431 : INFO : topic diff=0.766087, rho=1.000000\n",
      "2019-10-29 00:45:23,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:23,957 : INFO : built Dictionary(638 unique tokens: ['although', 'let', 'energy', 'ammonia', 'portion']...) from 5 documents (total 8500 corpus positions)\n",
      "2019-10-29 00:45:23,966 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:23,968 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:23,971 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:23,975 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:23,977 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:24,167 : INFO : -7.830 per-word bound, 227.6 perplexity estimate based on a held-out corpus of 5 documents with 8500 words\n",
      "2019-10-29 00:45:24,169 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:24,179 : INFO : topic #8 (0.100): 0.042*\"universe\" + 0.031*\"photo\" + 0.030*\"wonder\" + 0.027*\"image\" + 0.026*\"caption\" + 0.025*\"hide\" + 0.020*\"galaxy\" + 0.019*\"star\" + 0.014*\"telescope\" + 0.011*\"time\"\n",
      "2019-10-29 00:45:24,182 : INFO : topic #6 (0.100): 0.039*\"hide\" + 0.036*\"caption\" + 0.033*\"wonder\" + 0.029*\"photo\" + 0.027*\"universe\" + 0.023*\"image\" + 0.023*\"galaxy\" + 0.015*\"telescope\" + 0.012*\"star\" + 0.010*\"space\"\n",
      "2019-10-29 00:45:24,185 : INFO : topic #1 (0.100): 0.038*\"hide\" + 0.037*\"universe\" + 0.035*\"wonder\" + 0.034*\"photo\" + 0.022*\"image\" + 0.022*\"caption\" + 0.016*\"star\" + 0.016*\"galaxy\" + 0.014*\"telescope\" + 0.014*\"nasa\"\n",
      "2019-10-29 00:45:24,189 : INFO : topic #3 (0.100): 0.035*\"photo\" + 0.029*\"wonder\" + 0.027*\"universe\" + 0.027*\"caption\" + 0.024*\"image\" + 0.021*\"star\" + 0.020*\"galaxy\" + 0.020*\"hide\" + 0.013*\"space\" + 0.012*\"telescope\"\n",
      "2019-10-29 00:45:24,192 : INFO : topic #9 (0.100): 0.044*\"caption\" + 0.035*\"photo\" + 0.032*\"wonder\" + 0.030*\"hide\" + 0.028*\"universe\" + 0.024*\"galaxy\" + 0.020*\"image\" + 0.015*\"star\" + 0.013*\"space\" + 0.011*\"nasa\"\n",
      "2019-10-29 00:45:24,195 : INFO : topic diff=1.143290, rho=1.000000\n",
      "2019-10-29 00:45:24,617 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:24,619 : INFO : built Dictionary(71 unique tokens: ['previously', 'extracted', 'purpose', 'learn', 'back']...) from 5 documents (total 485 corpus positions)\n",
      "2019-10-29 00:45:24,621 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:24,623 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:24,624 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:24,627 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:24,628 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:24,666 : INFO : -6.658 per-word bound, 101.0 perplexity estimate based on a held-out corpus of 5 documents with 485 words\n",
      "2019-10-29 00:45:24,668 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:24,674 : INFO : topic #4 (0.100): 0.077*\"turtle\" + 0.055*\"sea\" + 0.032*\"endangered\" + 0.030*\"critically\" + 0.029*\"kiponda\" + 0.022*\"job\" + 0.019*\"project\" + 0.019*\"saving\" + 0.019*\"wanted\" + 0.018*\"person\"\n",
      "2019-10-29 00:45:24,677 : INFO : topic #0 (0.100): 0.052*\"turtle\" + 0.042*\"sea\" + 0.035*\"kiponda\" + 0.033*\"endangered\" + 0.028*\"critically\" + 0.025*\"saving\" + 0.023*\"project\" + 0.021*\"watamu\" + 0.020*\"cnn\" + 0.020*\"job\"\n",
      "2019-10-29 00:45:24,681 : INFO : topic #8 (0.100): 0.073*\"turtle\" + 0.042*\"sea\" + 0.027*\"critically\" + 0.026*\"later\" + 0.025*\"kiponda\" + 0.025*\"endangered\" + 0.024*\"person\" + 0.023*\"cnn\" + 0.021*\"watamu\" + 0.021*\"fikiri\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:24,685 : INFO : topic #5 (0.100): 0.068*\"sea\" + 0.057*\"turtle\" + 0.032*\"critically\" + 0.030*\"endangered\" + 0.024*\"kiponda\" + 0.021*\"watamu\" + 0.021*\"project\" + 0.021*\"fikiri\" + 0.020*\"job\" + 0.020*\"wanted\"\n",
      "2019-10-29 00:45:24,688 : INFO : topic #7 (0.100): 0.045*\"turtle\" + 0.040*\"sea\" + 0.032*\"kiponda\" + 0.028*\"fikiri\" + 0.027*\"later\" + 0.026*\"wanted\" + 0.025*\"endangered\" + 0.024*\"critically\" + 0.023*\"got\" + 0.022*\"project\"\n",
      "2019-10-29 00:45:24,691 : INFO : topic diff=0.765017, rho=1.000000\n",
      "2019-10-29 00:45:25,110 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:25,118 : INFO : built Dictionary(356 unique tokens: ['bland', 'language', 'extent', 'stop', 'resistant']...) from 5 documents (total 2930 corpus positions)\n",
      "2019-10-29 00:45:25,122 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:25,123 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:25,125 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:25,128 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:25,129 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:25,253 : INFO : -7.803 per-word bound, 223.3 perplexity estimate based on a held-out corpus of 5 documents with 2930 words\n",
      "2019-10-29 00:45:25,254 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:25,261 : INFO : topic #0 (0.100): 0.023*\"new\" + 0.020*\"pronoun\" + 0.019*\"language\" + 0.016*\"one\" + 0.016*\"like\" + 0.014*\"people\" + 0.013*\"thing\" + 0.012*\"gender\" + 0.011*\"time\" + 0.010*\"plural\"\n",
      "2019-10-29 00:45:25,263 : INFO : topic #6 (0.100): 0.032*\"pronoun\" + 0.029*\"new\" + 0.019*\"language\" + 0.016*\"one\" + 0.014*\"like\" + 0.013*\"people\" + 0.013*\"change\" + 0.012*\"gender\" + 0.012*\"time\" + 0.011*\"however\"\n",
      "2019-10-29 00:45:25,264 : INFO : topic #2 (0.100): 0.027*\"new\" + 0.024*\"pronoun\" + 0.020*\"language\" + 0.017*\"one\" + 0.014*\"people\" + 0.013*\"like\" + 0.013*\"thing\" + 0.012*\"however\" + 0.012*\"gender\" + 0.010*\"change\"\n",
      "2019-10-29 00:45:25,267 : INFO : topic #3 (0.100): 0.021*\"pronoun\" + 0.021*\"new\" + 0.019*\"one\" + 0.016*\"language\" + 0.015*\"like\" + 0.014*\"people\" + 0.013*\"gender\" + 0.012*\"thing\" + 0.011*\"however\" + 0.010*\"singular\"\n",
      "2019-10-29 00:45:25,269 : INFO : topic #1 (0.100): 0.034*\"new\" + 0.021*\"language\" + 0.020*\"pronoun\" + 0.014*\"people\" + 0.013*\"like\" + 0.013*\"one\" + 0.010*\"however\" + 0.010*\"word\" + 0.010*\"plural\" + 0.009*\"gender\"\n",
      "2019-10-29 00:45:25,271 : INFO : topic diff=0.883509, rho=1.000000\n",
      "2019-10-29 00:45:25,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:25,697 : INFO : built Dictionary(184 unique tokens: ['josh', 'paradise', 'end', 'crest', 'subdivision']...) from 5 documents (total 2585 corpus positions)\n",
      "2019-10-29 00:45:25,701 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:25,703 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:25,707 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:25,711 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:25,715 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:25,789 : INFO : -6.593 per-word bound, 96.5 perplexity estimate based on a held-out corpus of 5 documents with 2585 words\n",
      "2019-10-29 00:45:25,791 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:25,797 : INFO : topic #4 (0.100): 0.070*\"blaze\" + 0.063*\"wildfire\" + 0.057*\"caption\" + 0.049*\"california\" + 0.048*\"photo\" + 0.047*\"october\" + 0.038*\"hide\" + 0.024*\"santa\" + 0.023*\"rosa\" + 0.022*\"home\"\n",
      "2019-10-29 00:45:25,799 : INFO : topic #5 (0.100): 0.069*\"blaze\" + 0.068*\"california\" + 0.068*\"photo\" + 0.061*\"wildfire\" + 0.055*\"caption\" + 0.052*\"october\" + 0.047*\"hide\" + 0.024*\"santa\" + 0.020*\"burn\" + 0.018*\"home\"\n",
      "2019-10-29 00:45:25,802 : INFO : topic #8 (0.100): 0.072*\"california\" + 0.063*\"hide\" + 0.058*\"wildfire\" + 0.058*\"blaze\" + 0.056*\"october\" + 0.056*\"photo\" + 0.037*\"caption\" + 0.024*\"santa\" + 0.020*\"rosa\" + 0.018*\"napa\"\n",
      "2019-10-29 00:45:25,804 : INFO : topic #7 (0.100): 0.070*\"wildfire\" + 0.066*\"caption\" + 0.066*\"october\" + 0.061*\"blaze\" + 0.058*\"california\" + 0.056*\"hide\" + 0.046*\"photo\" + 0.022*\"santa\" + 0.018*\"home\" + 0.016*\"rosa\"\n",
      "2019-10-29 00:45:25,806 : INFO : topic #3 (0.100): 0.084*\"wildfire\" + 0.063*\"photo\" + 0.063*\"california\" + 0.056*\"hide\" + 0.054*\"blaze\" + 0.045*\"caption\" + 0.045*\"october\" + 0.024*\"rosa\" + 0.023*\"santa\" + 0.018*\"home\"\n",
      "2019-10-29 00:45:25,809 : INFO : topic diff=1.249347, rho=1.000000\n",
      "2019-10-29 00:45:26,219 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:26,221 : INFO : built Dictionary(13 unique tokens: ['happening', 'facebook', 'messenger', 'chat', 'engulf']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:45:26,222 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:26,223 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:26,225 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:26,226 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:26,227 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:26,242 : INFO : -6.405 per-word bound, 84.7 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n",
      "2019-10-29 00:45:26,243 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:26,248 : INFO : topic #9 (0.100): 0.096*\"engulf\" + 0.083*\"happening\" + 0.082*\"world\" + 0.081*\"country\" + 0.081*\"facebook\" + 0.080*\"flame\" + 0.078*\"chat\" + 0.078*\"unfolds\" + 0.073*\"u\" + 0.073*\"find\"\n",
      "2019-10-29 00:45:26,250 : INFO : topic #0 (0.100): 0.089*\"messenger\" + 0.088*\"chat\" + 0.085*\"u\" + 0.080*\"find\" + 0.079*\"wine\" + 0.079*\"unfolds\" + 0.078*\"flame\" + 0.078*\"engulf\" + 0.075*\"happening\" + 0.074*\"country\"\n",
      "2019-10-29 00:45:26,251 : INFO : topic #8 (0.100): 0.099*\"unfolds\" + 0.091*\"wine\" + 0.087*\"world\" + 0.087*\"engulf\" + 0.083*\"find\" + 0.082*\"flame\" + 0.079*\"california\" + 0.074*\"happening\" + 0.071*\"messenger\" + 0.069*\"facebook\"\n",
      "2019-10-29 00:45:26,254 : INFO : topic #4 (0.100): 0.085*\"facebook\" + 0.084*\"messenger\" + 0.084*\"california\" + 0.083*\"happening\" + 0.081*\"unfolds\" + 0.079*\"u\" + 0.079*\"find\" + 0.079*\"wine\" + 0.077*\"flame\" + 0.074*\"world\"\n",
      "2019-10-29 00:45:26,256 : INFO : topic #6 (0.100): 0.097*\"california\" + 0.089*\"country\" + 0.086*\"chat\" + 0.084*\"wine\" + 0.084*\"world\" + 0.082*\"flame\" + 0.076*\"u\" + 0.070*\"unfolds\" + 0.070*\"engulf\" + 0.069*\"find\"\n",
      "2019-10-29 00:45:26,258 : INFO : topic diff=0.510543, rho=1.000000\n",
      "2019-10-29 00:45:26,657 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:26,658 : INFO : built Dictionary(12 unique tokens: ['happening', 'dark', 'facebook', 'messenger', 'find']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:45:26,659 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:26,661 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:26,662 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:26,663 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:26,665 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:26,676 : INFO : -6.161 per-word bound, 71.5 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:26,678 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:26,684 : INFO : topic #3 (0.100): 0.137*\"u\" + 0.090*\"happening\" + 0.088*\"world\" + 0.086*\"chat\" + 0.085*\"unfolds\" + 0.082*\"messenger\" + 0.079*\"biden\" + 0.079*\"find\" + 0.077*\"walking\" + 0.073*\"path\"\n",
      "2019-10-29 00:45:26,685 : INFO : topic #9 (0.100): 0.134*\"u\" + 0.089*\"happening\" + 0.087*\"unfolds\" + 0.086*\"dark\" + 0.085*\"messenger\" + 0.085*\"walking\" + 0.079*\"path\" + 0.077*\"world\" + 0.076*\"facebook\" + 0.074*\"chat\"\n",
      "2019-10-29 00:45:26,687 : INFO : topic #0 (0.100): 0.151*\"u\" + 0.110*\"chat\" + 0.086*\"unfolds\" + 0.086*\"happening\" + 0.076*\"dark\" + 0.074*\"facebook\" + 0.073*\"biden\" + 0.073*\"messenger\" + 0.071*\"path\" + 0.069*\"walking\"\n",
      "2019-10-29 00:45:26,688 : INFO : topic #5 (0.100): 0.146*\"u\" + 0.086*\"facebook\" + 0.085*\"find\" + 0.085*\"biden\" + 0.083*\"dark\" + 0.081*\"unfolds\" + 0.080*\"walking\" + 0.078*\"messenger\" + 0.073*\"world\" + 0.070*\"happening\"\n",
      "2019-10-29 00:45:26,690 : INFO : topic #6 (0.100): 0.135*\"u\" + 0.091*\"path\" + 0.087*\"happening\" + 0.086*\"facebook\" + 0.083*\"walking\" + 0.082*\"find\" + 0.077*\"dark\" + 0.076*\"messenger\" + 0.072*\"chat\" + 0.072*\"unfolds\"\n",
      "2019-10-29 00:45:26,691 : INFO : topic diff=0.591728, rho=1.000000\n",
      "2019-10-29 00:45:27,093 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:27,096 : INFO : built Dictionary(66 unique tokens: ['catholic', 'show', 'focus', 'life', 'series']...) from 5 documents (total 455 corpus positions)\n",
      "2019-10-29 00:45:27,106 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:27,108 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:27,109 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:27,120 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:27,121 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:27,161 : INFO : -6.584 per-word bound, 95.9 perplexity estimate based on a held-out corpus of 5 documents with 455 words\n",
      "2019-10-29 00:45:27,163 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:27,177 : INFO : topic #0 (0.100): 0.055*\"muslim\" + 0.044*\"cuban\" + 0.042*\"alvado\" + 0.037*\"cuba\" + 0.031*\"joan\" + 0.030*\"catholic\" + 0.026*\"photo\" + 0.025*\"islam\" + 0.022*\"said\" + 0.021*\"people\"\n",
      "2019-10-29 00:45:27,181 : INFO : topic #6 (0.100): 0.053*\"alvado\" + 0.050*\"muslim\" + 0.039*\"cuban\" + 0.032*\"islam\" + 0.029*\"catholic\" + 0.026*\"joan\" + 0.025*\"cuba\" + 0.024*\"said\" + 0.022*\"photo\" + 0.021*\"series\"\n",
      "2019-10-29 00:45:27,187 : INFO : topic #1 (0.100): 0.072*\"muslim\" + 0.043*\"alvado\" + 0.036*\"cuban\" + 0.032*\"cuba\" + 0.028*\"islam\" + 0.028*\"catholic\" + 0.027*\"joan\" + 0.022*\"series\" + 0.021*\"people\" + 0.021*\"photo\"\n",
      "2019-10-29 00:45:27,190 : INFO : topic #4 (0.100): 0.053*\"alvado\" + 0.049*\"muslim\" + 0.040*\"cuban\" + 0.031*\"cuba\" + 0.030*\"joan\" + 0.029*\"islam\" + 0.027*\"catholic\" + 0.025*\"religion\" + 0.024*\"people\" + 0.022*\"photo\"\n",
      "2019-10-29 00:45:27,192 : INFO : topic #9 (0.100): 0.055*\"alvado\" + 0.054*\"muslim\" + 0.038*\"cuban\" + 0.034*\"joan\" + 0.034*\"islam\" + 0.031*\"catholic\" + 0.030*\"cuba\" + 0.023*\"religion\" + 0.022*\"series\" + 0.021*\"say\"\n",
      "2019-10-29 00:45:27,195 : INFO : topic diff=0.794238, rho=1.000000\n",
      "2019-10-29 00:45:27,669 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:27,677 : INFO : built Dictionary(484 unique tokens: ['although', 'earned', 'energy', 'clientele', 'extensive']...) from 5 documents (total 4625 corpus positions)\n",
      "2019-10-29 00:45:27,683 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:27,684 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:27,685 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:27,689 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:27,692 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:27,834 : INFO : -7.904 per-word bound, 239.5 perplexity estimate based on a held-out corpus of 5 documents with 4625 words\n",
      "2019-10-29 00:45:27,835 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:27,845 : INFO : topic #3 (0.100): 0.027*\"government\" + 0.025*\"class\" + 0.024*\"working\" + 0.021*\"white\" + 0.012*\"like\" + 0.011*\"said\" + 0.011*\"help\" + 0.009*\"job\" + 0.009*\"school\" + 0.009*\"get\"\n",
      "2019-10-29 00:45:27,846 : INFO : topic #1 (0.100): 0.028*\"working\" + 0.020*\"white\" + 0.020*\"class\" + 0.018*\"government\" + 0.014*\"said\" + 0.010*\"clearfield\" + 0.009*\"american\" + 0.009*\"federal\" + 0.008*\"school\" + 0.008*\"help\"\n",
      "2019-10-29 00:45:27,848 : INFO : topic #6 (0.100): 0.028*\"working\" + 0.021*\"class\" + 0.019*\"white\" + 0.019*\"government\" + 0.013*\"said\" + 0.011*\"like\" + 0.010*\"help\" + 0.010*\"get\" + 0.010*\"olah\" + 0.009*\"job\"\n",
      "2019-10-29 00:45:27,849 : INFO : topic #5 (0.100): 0.024*\"working\" + 0.024*\"white\" + 0.019*\"class\" + 0.019*\"government\" + 0.013*\"said\" + 0.011*\"american\" + 0.011*\"get\" + 0.010*\"help\" + 0.010*\"people\" + 0.010*\"job\"\n",
      "2019-10-29 00:45:27,851 : INFO : topic #7 (0.100): 0.023*\"class\" + 0.022*\"government\" + 0.021*\"white\" + 0.020*\"working\" + 0.015*\"said\" + 0.012*\"clearfield\" + 0.011*\"people\" + 0.010*\"help\" + 0.010*\"get\" + 0.009*\"job\"\n",
      "2019-10-29 00:45:27,854 : INFO : topic diff=0.955702, rho=1.000000\n",
      "2019-10-29 00:45:28,272 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:28,278 : INFO : built Dictionary(266 unique tokens: ['although', 'deter', 'product', 'spot', 'advantage']...) from 5 documents (total 2115 corpus positions)\n",
      "2019-10-29 00:45:28,281 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:28,282 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:28,284 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:28,287 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:28,290 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:28,410 : INFO : -7.579 per-word bound, 191.2 perplexity estimate based on a held-out corpus of 5 documents with 2115 words\n",
      "2019-10-29 00:45:28,412 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:28,421 : INFO : topic #7 (0.100): 0.028*\"opioid\" + 0.025*\"said\" + 0.021*\"cigna\" + 0.019*\"abuse\" + 0.015*\"oxycontin\" + 0.013*\"pill\" + 0.011*\"medication\" + 0.011*\"release\" + 0.010*\"american\" + 0.010*\"pain\"\n",
      "2019-10-29 00:45:28,424 : INFO : topic #9 (0.100): 0.024*\"oxycontin\" + 0.022*\"said\" + 0.020*\"cigna\" + 0.020*\"opioid\" + 0.015*\"abuse\" + 0.013*\"pain\" + 0.011*\"prescription\" + 0.010*\"release\" + 0.010*\"drug\" + 0.009*\"decision\"\n",
      "2019-10-29 00:45:28,428 : INFO : topic #5 (0.100): 0.028*\"opioid\" + 0.026*\"cigna\" + 0.022*\"oxycontin\" + 0.018*\"abuse\" + 0.016*\"said\" + 0.015*\"pill\" + 0.011*\"drug\" + 0.010*\"medication\" + 0.010*\"decision\" + 0.009*\"american\"\n",
      "2019-10-29 00:45:28,431 : INFO : topic #2 (0.100): 0.027*\"opioid\" + 0.021*\"said\" + 0.017*\"oxycontin\" + 0.017*\"cigna\" + 0.014*\"pill\" + 0.014*\"pain\" + 0.012*\"abuse\" + 0.011*\"xtampza\" + 0.010*\"drug\" + 0.010*\"decision\"\n",
      "2019-10-29 00:45:28,434 : INFO : topic #6 (0.100): 0.031*\"said\" + 0.022*\"opioid\" + 0.021*\"cigna\" + 0.014*\"pill\" + 0.014*\"oxycontin\" + 0.013*\"abuse\" + 0.011*\"extended\" + 0.010*\"decision\" + 0.009*\"medication\" + 0.009*\"dosage\"\n",
      "2019-10-29 00:45:28,437 : INFO : topic diff=0.838598, rho=1.000000\n",
      "2019-10-29 00:45:28,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:28,940 : INFO : built Dictionary(14 unique tokens: ['happening', 'beyoncé', 'messenger', 'song', 'u']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:45:28,941 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:28,943 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:28,944 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:28,946 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:28,948 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:28,963 : INFO : -6.425 per-word bound, 85.9 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:45:28,965 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:28,972 : INFO : topic #0 (0.100): 0.102*\"u\" + 0.084*\"chat\" + 0.080*\"happening\" + 0.078*\"beyoncé\" + 0.078*\"find\" + 0.074*\"inequality\" + 0.074*\"fierce\" + 0.067*\"world\" + 0.067*\"girl\" + 0.065*\"facebook\"\n",
      "2019-10-29 00:45:28,973 : INFO : topic #8 (0.100): 0.085*\"girl\" + 0.079*\"find\" + 0.079*\"beyoncé\" + 0.076*\"song\" + 0.075*\"world\" + 0.075*\"chat\" + 0.075*\"fight\" + 0.072*\"inequality\" + 0.070*\"u\" + 0.069*\"messenger\"\n",
      "2019-10-29 00:45:28,975 : INFO : topic #1 (0.100): 0.088*\"find\" + 0.084*\"world\" + 0.081*\"unfolds\" + 0.074*\"messenger\" + 0.074*\"happening\" + 0.074*\"u\" + 0.073*\"song\" + 0.072*\"beyoncé\" + 0.071*\"girl\" + 0.064*\"fierce\"\n",
      "2019-10-29 00:45:28,977 : INFO : topic #3 (0.100): 0.085*\"chat\" + 0.084*\"song\" + 0.077*\"girl\" + 0.075*\"inequality\" + 0.075*\"happening\" + 0.073*\"unfolds\" + 0.071*\"fierce\" + 0.070*\"facebook\" + 0.068*\"messenger\" + 0.067*\"world\"\n",
      "2019-10-29 00:45:28,978 : INFO : topic #7 (0.100): 0.093*\"unfolds\" + 0.082*\"fight\" + 0.079*\"facebook\" + 0.075*\"happening\" + 0.072*\"fierce\" + 0.071*\"girl\" + 0.070*\"u\" + 0.070*\"beyoncé\" + 0.069*\"song\" + 0.068*\"messenger\"\n",
      "2019-10-29 00:45:28,980 : INFO : topic diff=0.504261, rho=1.000000\n",
      "2019-10-29 00:45:29,459 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:29,468 : INFO : built Dictionary(358 unique tokens: ['previously', 'transmits', 'latin', 'advantage', 'asked']...) from 5 documents (total 3265 corpus positions)\n",
      "2019-10-29 00:45:29,473 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:29,474 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:29,476 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:29,479 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:29,481 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:29,618 : INFO : -7.670 per-word bound, 203.6 perplexity estimate based on a held-out corpus of 5 documents with 3265 words\n",
      "2019-10-29 00:45:29,620 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:29,628 : INFO : topic #4 (0.100): 0.027*\"brain\" + 0.026*\"said\" + 0.025*\"nerve\" + 0.022*\"state\" + 0.021*\"vagus\" + 0.017*\"patient\" + 0.014*\"vegetative\" + 0.014*\"stimulation\" + 0.014*\"study\" + 0.013*\"sirigu\"\n",
      "2019-10-29 00:45:29,629 : INFO : topic #3 (0.100): 0.036*\"brain\" + 0.024*\"nerve\" + 0.019*\"state\" + 0.018*\"said\" + 0.017*\"vegetative\" + 0.017*\"consciousness\" + 0.017*\"vagus\" + 0.017*\"stimulation\" + 0.015*\"patient\" + 0.011*\"sirigu\"\n",
      "2019-10-29 00:45:29,631 : INFO : topic #6 (0.100): 0.028*\"brain\" + 0.020*\"vegetative\" + 0.020*\"nerve\" + 0.020*\"said\" + 0.018*\"state\" + 0.018*\"vagus\" + 0.016*\"patient\" + 0.015*\"consciousness\" + 0.012*\"stimulation\" + 0.011*\"injury\"\n",
      "2019-10-29 00:45:29,633 : INFO : topic #9 (0.100): 0.030*\"brain\" + 0.025*\"nerve\" + 0.023*\"state\" + 0.021*\"said\" + 0.020*\"vegetative\" + 0.016*\"vagus\" + 0.015*\"patient\" + 0.013*\"stimulation\" + 0.013*\"study\" + 0.013*\"consciousness\"\n",
      "2019-10-29 00:45:29,634 : INFO : topic #1 (0.100): 0.032*\"brain\" + 0.026*\"nerve\" + 0.020*\"said\" + 0.020*\"patient\" + 0.018*\"state\" + 0.018*\"vagus\" + 0.017*\"vegetative\" + 0.016*\"stimulation\" + 0.014*\"study\" + 0.012*\"injury\"\n",
      "2019-10-29 00:45:29,637 : INFO : topic diff=0.892941, rho=1.000000\n",
      "2019-10-29 00:45:30,112 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:30,115 : INFO : built Dictionary(128 unique tokens: ['courtesy', 'fewer', 'end', 'come', 'greatest']...) from 5 documents (total 1070 corpus positions)\n",
      "2019-10-29 00:45:30,119 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:30,124 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:30,127 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:30,135 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:30,138 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:30,239 : INFO : -6.826 per-word bound, 113.5 perplexity estimate based on a held-out corpus of 5 documents with 1070 words\n",
      "2019-10-29 00:45:30,241 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:30,250 : INFO : topic #8 (0.100): 0.047*\"painting\" + 0.031*\"one\" + 0.026*\"mundi\" + 0.026*\"salvator\" + 0.024*\"vinci\" + 0.022*\"da\" + 0.017*\"christie\" + 0.016*\"world\" + 0.016*\"time\" + 0.016*\"auction\"\n",
      "2019-10-29 00:45:30,253 : INFO : topic #9 (0.100): 0.049*\"painting\" + 0.038*\"vinci\" + 0.032*\"one\" + 0.024*\"mundi\" + 0.023*\"christie\" + 0.023*\"salvator\" + 0.020*\"da\" + 0.019*\"auction\" + 0.016*\"known\" + 0.016*\"sold\"\n",
      "2019-10-29 00:45:30,256 : INFO : topic #0 (0.100): 0.049*\"painting\" + 0.031*\"one\" + 0.029*\"da\" + 0.027*\"mundi\" + 0.025*\"auction\" + 0.023*\"salvator\" + 0.022*\"vinci\" + 0.021*\"christie\" + 0.017*\"world\" + 0.016*\"ever\"\n",
      "2019-10-29 00:45:30,258 : INFO : topic #7 (0.100): 0.045*\"painting\" + 0.034*\"da\" + 0.033*\"one\" + 0.028*\"salvator\" + 0.025*\"mundi\" + 0.024*\"christie\" + 0.022*\"vinci\" + 0.015*\"auction\" + 0.015*\"ever\" + 0.014*\"world\"\n",
      "2019-10-29 00:45:30,261 : INFO : topic #1 (0.100): 0.046*\"painting\" + 0.033*\"vinci\" + 0.030*\"da\" + 0.028*\"mundi\" + 0.026*\"salvator\" + 0.026*\"one\" + 0.025*\"christie\" + 0.023*\"auction\" + 0.014*\"time\" + 0.014*\"world\"\n",
      "2019-10-29 00:45:30,263 : INFO : topic diff=0.838558, rho=1.000000\n",
      "2019-10-29 00:45:30,777 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:30,784 : INFO : built Dictionary(428 unique tokens: ['shower', 'extent', 'expert', 'stop', 'beijing']...) from 5 documents (total 3795 corpus positions)\n",
      "2019-10-29 00:45:30,791 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:30,793 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:30,794 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:30,798 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:30,800 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:30,946 : INFO : -7.880 per-word bound, 235.6 perplexity estimate based on a held-out corpus of 5 documents with 3795 words\n",
      "2019-10-29 00:45:30,948 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:30,958 : INFO : topic #0 (0.100): 0.028*\"air\" + 0.018*\"said\" + 0.016*\"particle\" + 0.014*\"khatri\" + 0.013*\"pollution\" + 0.010*\"people\" + 0.009*\"health\" + 0.009*\"exposure\" + 0.009*\"use\" + 0.008*\"reduce\"\n",
      "2019-10-29 00:45:30,961 : INFO : topic #1 (0.100): 0.033*\"air\" + 0.018*\"said\" + 0.015*\"pollution\" + 0.014*\"level\" + 0.012*\"khatri\" + 0.011*\"exposure\" + 0.011*\"particle\" + 0.010*\"use\" + 0.009*\"people\" + 0.009*\"clean\"\n",
      "2019-10-29 00:45:30,964 : INFO : topic #7 (0.100): 0.028*\"air\" + 0.021*\"said\" + 0.016*\"pollution\" + 0.015*\"people\" + 0.012*\"particle\" + 0.011*\"level\" + 0.010*\"khatri\" + 0.009*\"health\" + 0.008*\"clean\" + 0.008*\"exposure\"\n",
      "2019-10-29 00:45:30,967 : INFO : topic #3 (0.100): 0.026*\"air\" + 0.022*\"said\" + 0.017*\"level\" + 0.016*\"pollution\" + 0.012*\"particle\" + 0.010*\"reduce\" + 0.010*\"exposure\" + 0.009*\"pollutant\" + 0.009*\"mask\" + 0.009*\"people\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:30,970 : INFO : topic #4 (0.100): 0.034*\"air\" + 0.024*\"said\" + 0.014*\"pollution\" + 0.014*\"particle\" + 0.012*\"level\" + 0.012*\"khatri\" + 0.010*\"reduce\" + 0.010*\"exposure\" + 0.008*\"people\" + 0.008*\"pollutant\"\n",
      "2019-10-29 00:45:30,972 : INFO : topic diff=0.877437, rho=1.000000\n",
      "2019-10-29 00:45:31,431 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:31,432 : INFO : built Dictionary(80 unique tokens: ['although', 'story', 'sheet', 'book', 'brightly']...) from 5 documents (total 515 corpus positions)\n",
      "2019-10-29 00:45:31,434 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:31,436 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:31,437 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:31,440 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:31,441 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:31,483 : INFO : -6.876 per-word bound, 117.5 perplexity estimate based on a held-out corpus of 5 documents with 515 words\n",
      "2019-10-29 00:45:31,485 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:31,498 : INFO : topic #2 (0.100): 0.083*\"child\" + 0.038*\"bedroom\" + 0.030*\"sleep\" + 0.028*\"mollison\" + 0.027*\"around\" + 0.023*\"world\" + 0.022*\"people\" + 0.019*\"background\" + 0.015*\"collection\" + 0.015*\"photo\"\n",
      "2019-10-29 00:45:31,502 : INFO : topic #7 (0.100): 0.070*\"child\" + 0.048*\"bedroom\" + 0.030*\"sleep\" + 0.030*\"around\" + 0.029*\"mollison\" + 0.026*\"world\" + 0.018*\"background\" + 0.017*\"people\" + 0.017*\"photo\" + 0.015*\"collection\"\n",
      "2019-10-29 00:45:31,506 : INFO : topic #0 (0.100): 0.057*\"child\" + 0.046*\"bedroom\" + 0.032*\"sleep\" + 0.032*\"world\" + 0.031*\"mollison\" + 0.028*\"around\" + 0.023*\"background\" + 0.020*\"people\" + 0.020*\"collection\" + 0.020*\"photo\"\n",
      "2019-10-29 00:45:31,509 : INFO : topic #1 (0.100): 0.076*\"child\" + 0.036*\"bedroom\" + 0.025*\"mollison\" + 0.024*\"sleep\" + 0.024*\"world\" + 0.023*\"background\" + 0.021*\"around\" + 0.020*\"people\" + 0.019*\"photo\" + 0.018*\"collection\"\n",
      "2019-10-29 00:45:31,518 : INFO : topic #4 (0.100): 0.077*\"child\" + 0.037*\"bedroom\" + 0.029*\"world\" + 0.027*\"around\" + 0.023*\"sleep\" + 0.022*\"mollison\" + 0.021*\"photo\" + 0.020*\"people\" + 0.018*\"collection\" + 0.015*\"background\"\n",
      "2019-10-29 00:45:31,525 : INFO : topic diff=0.769190, rho=1.000000\n",
      "2019-10-29 00:45:32,072 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:32,086 : INFO : built Dictionary(694 unique tokens: ['although', 'wave', 'renamed', 'focus', 'asked']...) from 5 documents (total 7005 corpus positions)\n",
      "2019-10-29 00:45:32,098 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:32,099 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:32,103 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:32,107 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:32,109 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:32,377 : INFO : -8.197 per-word bound, 293.5 perplexity estimate based on a held-out corpus of 5 documents with 7005 words\n",
      "2019-10-29 00:45:32,379 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:32,391 : INFO : topic #1 (0.100): 0.039*\"woman\" + 0.021*\"code\" + 0.015*\"would\" + 0.011*\"book\" + 0.011*\"war\" + 0.010*\"work\" + 0.008*\"american\" + 0.008*\"story\" + 0.008*\"really\" + 0.008*\"breaking\"\n",
      "2019-10-29 00:45:32,394 : INFO : topic #0 (0.100): 0.052*\"woman\" + 0.018*\"code\" + 0.016*\"war\" + 0.011*\"mundy\" + 0.011*\"would\" + 0.011*\"work\" + 0.010*\"book\" + 0.010*\"breaking\" + 0.009*\"story\" + 0.009*\"american\"\n",
      "2019-10-29 00:45:32,397 : INFO : topic #8 (0.100): 0.040*\"woman\" + 0.017*\"war\" + 0.014*\"code\" + 0.012*\"work\" + 0.012*\"book\" + 0.011*\"breaking\" + 0.011*\"american\" + 0.010*\"would\" + 0.009*\"mundy\" + 0.008*\"pregnant\"\n",
      "2019-10-29 00:45:32,400 : INFO : topic #6 (0.100): 0.043*\"woman\" + 0.016*\"war\" + 0.014*\"code\" + 0.012*\"work\" + 0.011*\"book\" + 0.011*\"would\" + 0.011*\"mundy\" + 0.010*\"story\" + 0.010*\"breaking\" + 0.008*\"really\"\n",
      "2019-10-29 00:45:32,402 : INFO : topic #4 (0.100): 0.049*\"woman\" + 0.021*\"war\" + 0.017*\"code\" + 0.014*\"would\" + 0.012*\"work\" + 0.010*\"american\" + 0.009*\"mundy\" + 0.009*\"breaking\" + 0.007*\"pregnant\" + 0.007*\"story\"\n",
      "2019-10-29 00:45:32,405 : INFO : topic diff=0.951380, rho=1.000000\n",
      "2019-10-29 00:45:32,896 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:32,899 : INFO : built Dictionary(245 unique tokens: ['malibu', 'extensive', 'happy', 'game', 'lake']...) from 5 documents (total 1630 corpus positions)\n",
      "2019-10-29 00:45:32,902 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:32,906 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:32,909 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:32,913 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:32,916 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:33,041 : INFO : -7.794 per-word bound, 221.9 perplexity estimate based on a held-out corpus of 5 documents with 1630 words\n",
      "2019-10-29 00:45:33,044 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:33,051 : INFO : topic #8 (0.100): 0.037*\"died\" + 0.016*\"age\" + 0.015*\"actor\" + 0.012*\"whose\" + 0.011*\"show\" + 0.011*\"1960s\" + 0.011*\"demme\" + 0.009*\"according\" + 0.009*\"said\" + 0.009*\"petty\"\n",
      "2019-10-29 00:45:33,054 : INFO : topic #1 (0.100): 0.043*\"died\" + 0.016*\"age\" + 0.015*\"according\" + 0.011*\"show\" + 0.010*\"petty\" + 0.009*\"actor\" + 0.009*\"demme\" + 0.009*\"april\" + 0.009*\"fame\" + 0.008*\"whose\"\n",
      "2019-10-29 00:45:33,056 : INFO : topic #5 (0.100): 0.041*\"died\" + 0.015*\"according\" + 0.014*\"age\" + 0.011*\"actor\" + 0.011*\"said\" + 0.010*\"show\" + 0.009*\"fame\" + 0.009*\"april\" + 0.009*\"tittle\" + 0.009*\"1960s\"\n",
      "2019-10-29 00:45:33,059 : INFO : topic #2 (0.100): 0.033*\"died\" + 0.016*\"age\" + 0.013*\"according\" + 0.011*\"show\" + 0.010*\"actor\" + 0.010*\"said\" + 0.009*\"tittle\" + 0.008*\"april\" + 0.008*\"demme\" + 0.008*\"complication\"\n",
      "2019-10-29 00:45:33,062 : INFO : topic #4 (0.100): 0.040*\"died\" + 0.016*\"according\" + 0.013*\"show\" + 0.013*\"age\" + 0.011*\"said\" + 0.011*\"actor\" + 0.010*\"whose\" + 0.010*\"petty\" + 0.009*\"complication\" + 0.009*\"april\"\n",
      "2019-10-29 00:45:33,065 : INFO : topic diff=0.740559, rho=1.000000\n",
      "2019-10-29 00:45:33,608 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:33,620 : INFO : built Dictionary(666 unique tokens: ['valley', 'energy', 'deep', 'hong', 'cool']...) from 5 documents (total 5980 corpus positions)\n",
      "2019-10-29 00:45:33,632 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:33,638 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:33,641 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:33,646 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:33,648 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:33,928 : INFO : -8.294 per-word bound, 313.9 perplexity estimate based on a held-out corpus of 5 documents with 5980 words\n",
      "2019-10-29 00:45:33,930 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:33,942 : INFO : topic #5 (0.100): 0.027*\"pool\" + 0.012*\"night\" + 0.010*\"hotel\" + 0.009*\"guest\" + 0.009*\"com\" + 0.008*\"per\" + 0.008*\"swimming\" + 0.008*\"resort\" + 0.007*\"meter\" + 0.007*\"villa\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:33,944 : INFO : topic #9 (0.100): 0.029*\"pool\" + 0.011*\"com\" + 0.011*\"night\" + 0.009*\"per\" + 0.009*\"hotel\" + 0.008*\"guest\" + 0.008*\"room\" + 0.007*\"swimming\" + 0.007*\"resort\" + 0.007*\"serengeti\"\n",
      "2019-10-29 00:45:33,947 : INFO : topic #0 (0.100): 0.024*\"pool\" + 0.014*\"night\" + 0.010*\"com\" + 0.010*\"hotel\" + 0.009*\"guest\" + 0.008*\"per\" + 0.007*\"resort\" + 0.006*\"kohanaiki\" + 0.006*\"serengeti\" + 0.006*\"swimming\"\n",
      "2019-10-29 00:45:33,950 : INFO : topic #6 (0.100): 0.021*\"pool\" + 0.012*\"com\" + 0.012*\"guest\" + 0.011*\"per\" + 0.008*\"night\" + 0.008*\"hotel\" + 0.008*\"resort\" + 0.008*\"villa\" + 0.007*\"season\" + 0.007*\"serengeti\"\n",
      "2019-10-29 00:45:33,953 : INFO : topic #1 (0.100): 0.028*\"pool\" + 0.013*\"night\" + 0.013*\"guest\" + 0.011*\"hotel\" + 0.010*\"per\" + 0.009*\"resort\" + 0.007*\"room\" + 0.006*\"infinity\" + 0.006*\"villa\" + 0.006*\"swimming\"\n",
      "2019-10-29 00:45:33,956 : INFO : topic diff=0.912309, rho=1.000000\n",
      "2019-10-29 00:45:34,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:34,501 : INFO : built Dictionary(1230 unique tokens: ['although', 'located', 'wave', 'chasing', 'interplay']...) from 5 documents (total 10785 corpus positions)\n",
      "2019-10-29 00:45:34,514 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:34,515 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:34,520 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:34,527 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:34,553 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:34,949 : INFO : -8.924 per-word bound, 485.7 perplexity estimate based on a held-out corpus of 5 documents with 10785 words\n",
      "2019-10-29 00:45:34,950 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:34,964 : INFO : topic #8 (0.100): 0.008*\"world\" + 0.006*\"com\" + 0.006*\"day\" + 0.006*\"best\" + 0.006*\"year\" + 0.005*\"one\" + 0.005*\"city\" + 0.005*\"night\" + 0.005*\"tour\" + 0.005*\"around\"\n",
      "2019-10-29 00:45:34,966 : INFO : topic #0 (0.100): 0.010*\"world\" + 0.007*\"best\" + 0.007*\"com\" + 0.007*\"day\" + 0.006*\"one\" + 0.006*\"tour\" + 0.005*\"night\" + 0.005*\"including\" + 0.005*\"city\" + 0.004*\"around\"\n",
      "2019-10-29 00:45:34,968 : INFO : topic #6 (0.100): 0.008*\"world\" + 0.008*\"com\" + 0.007*\"day\" + 0.007*\"night\" + 0.007*\"including\" + 0.006*\"best\" + 0.006*\"tour\" + 0.006*\"city\" + 0.005*\"rock\" + 0.005*\"view\"\n",
      "2019-10-29 00:45:34,970 : INFO : topic #3 (0.100): 0.008*\"world\" + 0.006*\"com\" + 0.006*\"view\" + 0.006*\"night\" + 0.006*\"best\" + 0.006*\"around\" + 0.006*\"day\" + 0.005*\"tour\" + 0.005*\"one\" + 0.005*\"bus\"\n",
      "2019-10-29 00:45:34,972 : INFO : topic #9 (0.100): 0.010*\"world\" + 0.007*\"com\" + 0.007*\"day\" + 0.006*\"one\" + 0.006*\"best\" + 0.005*\"tour\" + 0.005*\"around\" + 0.005*\"bus\" + 0.004*\"river\" + 0.004*\"city\"\n",
      "2019-10-29 00:45:34,974 : INFO : topic diff=0.896666, rho=1.000000\n",
      "2019-10-29 00:45:35,403 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:35,406 : INFO : built Dictionary(268 unique tokens: ['school', 'bone', 'sound', 'come', 'rather']...) from 5 documents (total 2290 corpus positions)\n",
      "2019-10-29 00:45:35,410 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:35,412 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:35,413 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:35,417 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:35,418 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:35,506 : INFO : -7.489 per-word bound, 179.7 perplexity estimate based on a held-out corpus of 5 documents with 2290 words\n",
      "2019-10-29 00:45:35,508 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:35,514 : INFO : topic #5 (0.100): 0.037*\"said\" + 0.033*\"anderson\" + 0.027*\"baby\" + 0.019*\"knight\" + 0.016*\"placenta\" + 0.014*\"cord\" + 0.013*\"instructed\" + 0.013*\"could\" + 0.012*\"dad\" + 0.011*\"farrell\"\n",
      "2019-10-29 00:45:35,516 : INFO : topic #6 (0.100): 0.045*\"said\" + 0.031*\"anderson\" + 0.026*\"baby\" + 0.020*\"knight\" + 0.017*\"placenta\" + 0.015*\"watkins\" + 0.015*\"cord\" + 0.013*\"could\" + 0.011*\"farrell\" + 0.011*\"uterus\"\n",
      "2019-10-29 00:45:35,518 : INFO : topic #4 (0.100): 0.036*\"said\" + 0.026*\"anderson\" + 0.026*\"baby\" + 0.020*\"knight\" + 0.015*\"cord\" + 0.012*\"could\" + 0.011*\"mother\" + 0.011*\"placenta\" + 0.011*\"watkins\" + 0.010*\"emergency\"\n",
      "2019-10-29 00:45:35,521 : INFO : topic #1 (0.100): 0.036*\"said\" + 0.031*\"anderson\" + 0.025*\"baby\" + 0.021*\"knight\" + 0.015*\"watkins\" + 0.014*\"could\" + 0.014*\"cord\" + 0.013*\"placenta\" + 0.013*\"dad\" + 0.012*\"instructed\"\n",
      "2019-10-29 00:45:35,524 : INFO : topic #0 (0.100): 0.033*\"anderson\" + 0.031*\"baby\" + 0.029*\"said\" + 0.020*\"knight\" + 0.019*\"could\" + 0.015*\"placenta\" + 0.014*\"watkins\" + 0.013*\"cord\" + 0.011*\"farrell\" + 0.010*\"mother\"\n",
      "2019-10-29 00:45:35,526 : INFO : topic diff=0.864984, rho=1.000000\n",
      "2019-10-29 00:45:35,944 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:35,948 : INFO : built Dictionary(321 unique tokens: ['rage', 'let', 'school', 'method', 'caution']...) from 5 documents (total 2595 corpus positions)\n",
      "2019-10-29 00:45:35,952 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:35,957 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:35,960 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:35,964 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:35,967 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:36,075 : INFO : -7.731 per-word bound, 212.4 perplexity estimate based on a held-out corpus of 5 documents with 2595 words\n",
      "2019-10-29 00:45:36,076 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:36,084 : INFO : topic #5 (0.100): 0.047*\"game\" + 0.038*\"video\" + 0.023*\"violent\" + 0.018*\"violence\" + 0.013*\"playing\" + 0.013*\"behavior\" + 0.011*\"american\" + 0.010*\"said\" + 0.009*\"may\" + 0.008*\"study\"\n",
      "2019-10-29 00:45:36,086 : INFO : topic #6 (0.100): 0.047*\"game\" + 0.040*\"video\" + 0.026*\"violent\" + 0.018*\"violence\" + 0.014*\"american\" + 0.014*\"playing\" + 0.012*\"said\" + 0.011*\"behavior\" + 0.009*\"psychological\" + 0.008*\"academy\"\n",
      "2019-10-29 00:45:36,088 : INFO : topic #8 (0.100): 0.040*\"game\" + 0.040*\"video\" + 0.020*\"violent\" + 0.014*\"violence\" + 0.013*\"behavior\" + 0.011*\"american\" + 0.011*\"may\" + 0.011*\"playing\" + 0.009*\"psychological\" + 0.009*\"study\"\n",
      "2019-10-29 00:45:36,092 : INFO : topic #1 (0.100): 0.032*\"game\" + 0.028*\"violent\" + 0.026*\"video\" + 0.015*\"playing\" + 0.015*\"said\" + 0.014*\"violence\" + 0.012*\"study\" + 0.011*\"may\" + 0.010*\"child\" + 0.009*\"psychological\"\n",
      "2019-10-29 00:45:36,095 : INFO : topic #9 (0.100): 0.053*\"game\" + 0.033*\"video\" + 0.026*\"violent\" + 0.012*\"american\" + 0.011*\"violence\" + 0.010*\"playing\" + 0.010*\"said\" + 0.009*\"academy\" + 0.009*\"child\" + 0.009*\"psychological\"\n",
      "2019-10-29 00:45:36,098 : INFO : topic diff=0.854576, rho=1.000000\n",
      "2019-10-29 00:45:36,562 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:36,572 : INFO : built Dictionary(577 unique tokens: ['wave', 'color', 'asleep', 'excitement', 'spokesman']...) from 5 documents (total 5730 corpus positions)\n",
      "2019-10-29 00:45:36,580 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:36,581 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:36,583 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:36,588 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:36,591 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:36,790 : INFO : -8.032 per-word bound, 261.8 perplexity estimate based on a held-out corpus of 5 documents with 5730 words\n",
      "2019-10-29 00:45:36,792 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:36,804 : INFO : topic #6 (0.100): 0.038*\"naacp\" + 0.027*\"black\" + 0.023*\"say\" + 0.016*\"group\" + 0.015*\"advisory\" + 0.014*\"matter\" + 0.012*\"travel\" + 0.012*\"missouri\" + 0.011*\"life\" + 0.009*\"right\"\n",
      "2019-10-29 00:45:36,806 : INFO : topic #4 (0.100): 0.030*\"say\" + 0.028*\"naacp\" + 0.024*\"black\" + 0.021*\"advisory\" + 0.016*\"group\" + 0.015*\"missouri\" + 0.014*\"matter\" + 0.011*\"life\" + 0.010*\"travel\" + 0.010*\"civil\"\n",
      "2019-10-29 00:45:36,807 : INFO : topic #8 (0.100): 0.037*\"naacp\" + 0.026*\"black\" + 0.026*\"say\" + 0.017*\"advisory\" + 0.015*\"group\" + 0.014*\"missouri\" + 0.011*\"life\" + 0.011*\"matter\" + 0.010*\"right\" + 0.010*\"may\"\n",
      "2019-10-29 00:45:36,809 : INFO : topic #7 (0.100): 0.030*\"naacp\" + 0.025*\"say\" + 0.021*\"black\" + 0.016*\"advisory\" + 0.016*\"group\" + 0.013*\"life\" + 0.012*\"missouri\" + 0.011*\"matter\" + 0.010*\"travel\" + 0.008*\"leader\"\n",
      "2019-10-29 00:45:36,811 : INFO : topic #1 (0.100): 0.029*\"naacp\" + 0.026*\"black\" + 0.020*\"say\" + 0.016*\"group\" + 0.016*\"advisory\" + 0.013*\"matter\" + 0.013*\"missouri\" + 0.012*\"travel\" + 0.010*\"life\" + 0.010*\"leader\"\n",
      "2019-10-29 00:45:36,812 : INFO : topic diff=0.928373, rho=1.000000\n",
      "2019-10-29 00:45:37,227 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:37,231 : INFO : built Dictionary(245 unique tokens: ['school', 'significant', 'deep', 'hero', 'come']...) from 5 documents (total 2065 corpus positions)\n",
      "2019-10-29 00:45:37,234 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:37,236 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:37,237 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:37,240 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:37,241 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:37,321 : INFO : -7.414 per-word bound, 170.6 perplexity estimate based on a held-out corpus of 5 documents with 2065 words\n",
      "2019-10-29 00:45:37,322 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:37,330 : INFO : topic #6 (0.100): 0.031*\"couch\" + 0.021*\"people\" + 0.021*\"community\" + 0.017*\"healthy\" + 0.017*\"food\" + 0.013*\"cere\" + 0.012*\"cancer\" + 0.012*\"cnn\" + 0.012*\"program\" + 0.011*\"really\"\n",
      "2019-10-29 00:45:37,333 : INFO : topic #5 (0.100): 0.032*\"couch\" + 0.020*\"food\" + 0.017*\"community\" + 0.017*\"cnn\" + 0.016*\"people\" + 0.015*\"healthy\" + 0.014*\"program\" + 0.013*\"meal\" + 0.012*\"youth\" + 0.012*\"project\"\n",
      "2019-10-29 00:45:37,336 : INFO : topic #1 (0.100): 0.027*\"couch\" + 0.020*\"cere\" + 0.018*\"cnn\" + 0.017*\"cancer\" + 0.016*\"healthy\" + 0.015*\"food\" + 0.015*\"community\" + 0.015*\"people\" + 0.014*\"program\" + 0.011*\"young\"\n",
      "2019-10-29 00:45:37,340 : INFO : topic #2 (0.100): 0.027*\"couch\" + 0.020*\"food\" + 0.019*\"people\" + 0.017*\"cnn\" + 0.017*\"cere\" + 0.013*\"community\" + 0.013*\"cancer\" + 0.013*\"program\" + 0.013*\"healthy\" + 0.012*\"youth\"\n",
      "2019-10-29 00:45:37,343 : INFO : topic #8 (0.100): 0.024*\"couch\" + 0.020*\"community\" + 0.018*\"people\" + 0.017*\"food\" + 0.016*\"cnn\" + 0.016*\"also\" + 0.015*\"cere\" + 0.014*\"healthy\" + 0.013*\"cancer\" + 0.012*\"project\"\n",
      "2019-10-29 00:45:37,347 : INFO : topic diff=0.847035, rho=1.000000\n",
      "2019-10-29 00:45:37,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:37,786 : INFO : built Dictionary(453 unique tokens: ['dating', 'extensive', 'energy', 'focus', 'drive']...) from 5 documents (total 3305 corpus positions)\n",
      "2019-10-29 00:45:37,790 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:37,792 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:37,793 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:37,798 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:37,800 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:37,933 : INFO : -8.212 per-word bound, 296.6 perplexity estimate based on a held-out corpus of 5 documents with 3305 words\n",
      "2019-10-29 00:45:37,936 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:37,944 : INFO : topic #5 (0.100): 0.022*\"city\" + 0.016*\"johannesburg\" + 0.016*\"town\" + 0.012*\"new\" + 0.011*\"cape\" + 0.011*\"old\" + 0.010*\"restaurant\" + 0.008*\"gallery\" + 0.008*\"building\" + 0.007*\"africa\"\n",
      "2019-10-29 00:45:37,946 : INFO : topic #1 (0.100): 0.027*\"city\" + 0.023*\"johannesburg\" + 0.013*\"new\" + 0.011*\"town\" + 0.011*\"cape\" + 0.010*\"restaurant\" + 0.009*\"old\" + 0.007*\"art\" + 0.007*\"building\" + 0.007*\"museum\"\n",
      "2019-10-29 00:45:37,948 : INFO : topic #6 (0.100): 0.018*\"johannesburg\" + 0.015*\"city\" + 0.013*\"town\" + 0.012*\"cape\" + 0.012*\"new\" + 0.011*\"restaurant\" + 0.008*\"old\" + 0.007*\"neighborhood\" + 0.007*\"building\" + 0.007*\"street\"\n",
      "2019-10-29 00:45:37,949 : INFO : topic #8 (0.100): 0.016*\"city\" + 0.016*\"johannesburg\" + 0.015*\"restaurant\" + 0.013*\"town\" + 0.011*\"cape\" + 0.011*\"new\" + 0.010*\"old\" + 0.009*\"building\" + 0.008*\"best\" + 0.007*\"south\"\n",
      "2019-10-29 00:45:37,950 : INFO : topic #4 (0.100): 0.023*\"city\" + 0.014*\"town\" + 0.013*\"johannesburg\" + 0.011*\"new\" + 0.011*\"old\" + 0.010*\"cape\" + 0.009*\"restaurant\" + 0.008*\"art\" + 0.008*\"south\" + 0.007*\"africa\"\n",
      "2019-10-29 00:45:37,953 : INFO : topic diff=0.786161, rho=1.000000\n",
      "2019-10-29 00:45:38,365 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:38,367 : INFO : built Dictionary(76 unique tokens: ['approach', 'way', 'estate', 'overhaul', 'nation']...) from 5 documents (total 590 corpus positions)\n",
      "2019-10-29 00:45:38,370 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:38,371 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:38,372 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:38,375 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:38,377 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:38,410 : INFO : -6.496 per-word bound, 90.3 perplexity estimate based on a held-out corpus of 5 documents with 590 words\n",
      "2019-10-29 00:45:38,412 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:38,419 : INFO : topic #8 (0.100): 0.068*\"tax\" + 0.048*\"cnn\" + 0.039*\"debate\" + 0.037*\"sander\" + 0.035*\"trump\" + 0.032*\"cruz\" + 0.021*\"washington\" + 0.019*\"tapper\" + 0.018*\"reducing\" + 0.018*\"sen\"\n",
      "2019-10-29 00:45:38,422 : INFO : topic #9 (0.100): 0.069*\"tax\" + 0.049*\"cnn\" + 0.042*\"debate\" + 0.039*\"sander\" + 0.035*\"cruz\" + 0.029*\"trump\" + 0.023*\"washington\" + 0.020*\"reducing\" + 0.019*\"ted\" + 0.018*\"correspondent\"\n",
      "2019-10-29 00:45:38,426 : INFO : topic #1 (0.100): 0.054*\"tax\" + 0.045*\"cnn\" + 0.039*\"sander\" + 0.036*\"trump\" + 0.036*\"cruz\" + 0.030*\"debate\" + 0.022*\"washington\" + 0.020*\"correspondent\" + 0.019*\"bernie\" + 0.018*\"dana\"\n",
      "2019-10-29 00:45:38,429 : INFO : topic #7 (0.100): 0.049*\"cnn\" + 0.048*\"tax\" + 0.042*\"sander\" + 0.035*\"trump\" + 0.034*\"debate\" + 0.034*\"cruz\" + 0.023*\"washington\" + 0.021*\"take\" + 0.020*\"bash\" + 0.020*\"reducing\"\n",
      "2019-10-29 00:45:38,432 : INFO : topic #4 (0.100): 0.058*\"tax\" + 0.049*\"debate\" + 0.042*\"cnn\" + 0.035*\"sander\" + 0.030*\"washington\" + 0.027*\"cruz\" + 0.027*\"trump\" + 0.020*\"plan\" + 0.020*\"sen\" + 0.019*\"chief\"\n",
      "2019-10-29 00:45:38,436 : INFO : topic diff=0.808224, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:38,875 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:38,879 : INFO : built Dictionary(136 unique tokens: ['although', 'military', 'enterprise', 'nature', 'industry']...) from 5 documents (total 900 corpus positions)\n",
      "2019-10-29 00:45:38,881 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:38,883 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:38,885 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:38,888 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:38,890 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:38,957 : INFO : -7.267 per-word bound, 154.0 perplexity estimate based on a held-out corpus of 5 documents with 900 words\n",
      "2019-10-29 00:45:38,959 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:38,965 : INFO : topic #5 (0.100): 0.038*\"science\" + 0.028*\"nye\" + 0.022*\"u\" + 0.020*\"bill\" + 0.018*\"nation\" + 0.018*\"long\" + 0.016*\"engineer\" + 0.014*\"world\" + 0.013*\"quo\" + 0.012*\"scientific\"\n",
      "2019-10-29 00:45:38,967 : INFO : topic #0 (0.100): 0.075*\"science\" + 0.023*\"u\" + 0.020*\"nye\" + 0.016*\"nation\" + 0.016*\"engineer\" + 0.014*\"bill\" + 0.013*\"force\" + 0.013*\"world\" + 0.012*\"quo\" + 0.012*\"respected\"\n",
      "2019-10-29 00:45:38,971 : INFO : topic #3 (0.100): 0.065*\"science\" + 0.020*\"nye\" + 0.018*\"long\" + 0.015*\"u\" + 0.015*\"engineer\" + 0.013*\"scientist\" + 0.013*\"bill\" + 0.013*\"nation\" + 0.013*\"interest\" + 0.012*\"march\"\n",
      "2019-10-29 00:45:38,974 : INFO : topic #1 (0.100): 0.050*\"science\" + 0.026*\"u\" + 0.023*\"nye\" + 0.019*\"bill\" + 0.017*\"nation\" + 0.016*\"engineer\" + 0.015*\"long\" + 0.014*\"motivated\" + 0.013*\"undermined\" + 0.013*\"quo\"\n",
      "2019-10-29 00:45:38,976 : INFO : topic #2 (0.100): 0.055*\"science\" + 0.030*\"nye\" + 0.019*\"u\" + 0.017*\"long\" + 0.016*\"bill\" + 0.016*\"nation\" + 0.014*\"maintain\" + 0.013*\"motivated\" + 0.013*\"engineer\" + 0.012*\"research\"\n",
      "2019-10-29 00:45:38,979 : INFO : topic diff=0.750535, rho=1.000000\n",
      "2019-10-29 00:45:39,395 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:39,399 : INFO : built Dictionary(113 unique tokens: ['school', 'presidency', 'queue', 'turned', 'alexander']...) from 5 documents (total 1200 corpus positions)\n",
      "2019-10-29 00:45:39,403 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:39,405 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:39,408 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:39,412 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:39,414 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:39,482 : INFO : -6.410 per-word bound, 85.0 perplexity estimate based on a held-out corpus of 5 documents with 1200 words\n",
      "2019-10-29 00:45:39,486 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:39,492 : INFO : topic #0 (0.100): 0.058*\"liberia\" + 0.052*\"election\" + 0.046*\"picture\" + 0.044*\"photo\" + 0.040*\"hide\" + 0.035*\"getty\" + 0.032*\"caption\" + 0.029*\"image\" + 0.029*\"credit\" + 0.023*\"vote\"\n",
      "2019-10-29 00:45:39,496 : INFO : topic #5 (0.100): 0.072*\"liberia\" + 0.059*\"election\" + 0.047*\"picture\" + 0.039*\"credit\" + 0.037*\"caption\" + 0.037*\"photo\" + 0.033*\"hide\" + 0.032*\"image\" + 0.027*\"getty\" + 0.023*\"vote\"\n",
      "2019-10-29 00:45:39,500 : INFO : topic #4 (0.100): 0.062*\"election\" + 0.051*\"liberia\" + 0.040*\"hide\" + 0.040*\"picture\" + 0.037*\"credit\" + 0.034*\"caption\" + 0.030*\"photo\" + 0.030*\"getty\" + 0.029*\"image\" + 0.026*\"cast\"\n",
      "2019-10-29 00:45:39,503 : INFO : topic #6 (0.100): 0.062*\"election\" + 0.049*\"liberia\" + 0.044*\"credit\" + 0.042*\"picture\" + 0.035*\"photo\" + 0.034*\"hide\" + 0.033*\"caption\" + 0.032*\"getty\" + 0.030*\"image\" + 0.021*\"cast\"\n",
      "2019-10-29 00:45:39,506 : INFO : topic #9 (0.100): 0.061*\"election\" + 0.060*\"liberia\" + 0.045*\"photo\" + 0.042*\"picture\" + 0.040*\"caption\" + 0.038*\"hide\" + 0.033*\"image\" + 0.031*\"credit\" + 0.025*\"getty\" + 0.022*\"polling\"\n",
      "2019-10-29 00:45:39,509 : INFO : topic diff=1.061894, rho=1.000000\n",
      "2019-10-29 00:45:39,992 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:39,998 : INFO : built Dictionary(254 unique tokens: ['attacked', 'attending', 'roof', 'terrorist', 'mistake']...) from 5 documents (total 3455 corpus positions)\n",
      "2019-10-29 00:45:40,002 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:40,003 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:40,005 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:40,008 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:40,010 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:40,103 : INFO : -6.920 per-word bound, 121.1 perplexity estimate based on a held-out corpus of 5 documents with 3455 words\n",
      "2019-10-29 00:45:40,104 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:40,112 : INFO : topic #4 (0.100): 0.063*\"vega\" + 0.060*\"shooting\" + 0.047*\"hide\" + 0.047*\"caption\" + 0.045*\"la\" + 0.043*\"festival\" + 0.043*\"music\" + 0.039*\"mass\" + 0.035*\"photo\" + 0.013*\"people\"\n",
      "2019-10-29 00:45:40,114 : INFO : topic #6 (0.100): 0.059*\"festival\" + 0.055*\"shooting\" + 0.053*\"photo\" + 0.048*\"vega\" + 0.043*\"la\" + 0.043*\"mass\" + 0.043*\"music\" + 0.043*\"hide\" + 0.041*\"caption\" + 0.017*\"people\"\n",
      "2019-10-29 00:45:40,117 : INFO : topic #1 (0.100): 0.064*\"la\" + 0.064*\"festival\" + 0.061*\"shooting\" + 0.058*\"mass\" + 0.045*\"hide\" + 0.042*\"vega\" + 0.040*\"caption\" + 0.037*\"music\" + 0.028*\"photo\" + 0.016*\"people\"\n",
      "2019-10-29 00:45:40,120 : INFO : topic #3 (0.100): 0.062*\"shooting\" + 0.057*\"music\" + 0.049*\"la\" + 0.046*\"vega\" + 0.042*\"mass\" + 0.041*\"photo\" + 0.038*\"hide\" + 0.035*\"caption\" + 0.031*\"festival\" + 0.020*\"people\"\n",
      "2019-10-29 00:45:40,122 : INFO : topic #8 (0.100): 0.067*\"vega\" + 0.059*\"festival\" + 0.045*\"shooting\" + 0.045*\"la\" + 0.044*\"mass\" + 0.039*\"music\" + 0.039*\"photo\" + 0.035*\"hide\" + 0.035*\"caption\" + 0.018*\"people\"\n",
      "2019-10-29 00:45:40,124 : INFO : topic diff=1.251723, rho=1.000000\n",
      "2019-10-29 00:45:40,510 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:40,512 : INFO : built Dictionary(90 unique tokens: ['located', 'beat', 'come', 'sponsorship', 'visiting']...) from 5 documents (total 540 corpus positions)\n",
      "2019-10-29 00:45:40,514 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:40,515 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:40,520 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:40,524 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:40,528 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:40,564 : INFO : -7.096 per-word bound, 136.8 perplexity estimate based on a held-out corpus of 5 documents with 540 words\n",
      "2019-10-29 00:45:40,566 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:40,571 : INFO : topic #6 (0.100): 0.058*\"tohoku\" + 0.034*\"japan\" + 0.028*\"region\" + 0.024*\"cnn\" + 0.019*\"city\" + 0.018*\"offer\" + 0.015*\"prefecture\" + 0.015*\"beauty\" + 0.015*\"miyagi\" + 0.014*\"natural\"\n",
      "2019-10-29 00:45:40,574 : INFO : topic #8 (0.100): 0.047*\"tohoku\" + 0.034*\"japan\" + 0.027*\"cnn\" + 0.025*\"region\" + 0.023*\"beauty\" + 0.022*\"miyagi\" + 0.021*\"offer\" + 0.019*\"prefecture\" + 0.016*\"city\" + 0.015*\"natural\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:40,579 : INFO : topic #0 (0.100): 0.054*\"tohoku\" + 0.026*\"japan\" + 0.025*\"cnn\" + 0.022*\"region\" + 0.020*\"miyagi\" + 0.019*\"beauty\" + 0.017*\"offer\" + 0.017*\"prefecture\" + 0.017*\"city\" + 0.015*\"natural\"\n",
      "2019-10-29 00:45:40,582 : INFO : topic #3 (0.100): 0.061*\"tohoku\" + 0.034*\"japan\" + 0.028*\"cnn\" + 0.019*\"natural\" + 0.018*\"offer\" + 0.018*\"beauty\" + 0.017*\"miyagi\" + 0.017*\"prefecture\" + 0.017*\"city\" + 0.016*\"region\"\n",
      "2019-10-29 00:45:40,585 : INFO : topic #4 (0.100): 0.051*\"tohoku\" + 0.036*\"japan\" + 0.027*\"cnn\" + 0.026*\"region\" + 0.018*\"city\" + 0.018*\"natural\" + 0.017*\"prefecture\" + 0.017*\"offer\" + 0.014*\"beauty\" + 0.014*\"miyagi\"\n",
      "2019-10-29 00:45:40,588 : INFO : topic diff=0.694115, rho=1.000000\n",
      "2019-10-29 00:45:41,028 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:41,032 : INFO : built Dictionary(284 unique tokens: ['previously', 'school', 'campaign', 'nation', 'come']...) from 5 documents (total 2720 corpus positions)\n",
      "2019-10-29 00:45:41,036 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:41,037 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:41,039 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:41,043 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:41,044 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:41,144 : INFO : -7.387 per-word bound, 167.4 perplexity estimate based on a held-out corpus of 5 documents with 2720 words\n",
      "2019-10-29 00:45:41,145 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:41,153 : INFO : topic #3 (0.100): 0.044*\"people\" + 0.034*\"hiv\" + 0.023*\"among\" + 0.019*\"older\" + 0.018*\"diagnosed\" + 0.017*\"new\" + 0.016*\"age\" + 0.015*\"tavoschi\" + 0.014*\"health\" + 0.013*\"need\"\n",
      "2019-10-29 00:45:41,154 : INFO : topic #7 (0.100): 0.043*\"hiv\" + 0.034*\"people\" + 0.030*\"among\" + 0.022*\"age\" + 0.020*\"diagnosed\" + 0.018*\"new\" + 0.017*\"older\" + 0.015*\"group\" + 0.014*\"said\" + 0.014*\"diagnosis\"\n",
      "2019-10-29 00:45:41,155 : INFO : topic #6 (0.100): 0.042*\"people\" + 0.037*\"hiv\" + 0.029*\"among\" + 0.021*\"older\" + 0.019*\"diagnosed\" + 0.017*\"age\" + 0.016*\"new\" + 0.016*\"tavoschi\" + 0.012*\"health\" + 0.011*\"diagnosis\"\n",
      "2019-10-29 00:45:41,157 : INFO : topic #5 (0.100): 0.042*\"people\" + 0.037*\"hiv\" + 0.023*\"older\" + 0.022*\"among\" + 0.019*\"new\" + 0.018*\"diagnosed\" + 0.015*\"group\" + 0.013*\"age\" + 0.012*\"tavoschi\" + 0.012*\"health\"\n",
      "2019-10-29 00:45:41,158 : INFO : topic #1 (0.100): 0.040*\"hiv\" + 0.036*\"people\" + 0.030*\"among\" + 0.017*\"older\" + 0.017*\"diagnosed\" + 0.017*\"tavoschi\" + 0.016*\"diagnosis\" + 0.016*\"age\" + 0.015*\"new\" + 0.015*\"said\"\n",
      "2019-10-29 00:45:41,160 : INFO : topic diff=0.969039, rho=1.000000\n",
      "2019-10-29 00:45:41,587 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:41,591 : INFO : built Dictionary(252 unique tokens: ['extremely', 'watch', 'hero', 'come', 'hospice']...) from 5 documents (total 2160 corpus positions)\n",
      "2019-10-29 00:45:41,594 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:41,596 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:41,597 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:41,600 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:41,602 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:41,689 : INFO : -7.420 per-word bound, 171.3 perplexity estimate based on a held-out corpus of 5 documents with 2160 words\n",
      "2019-10-29 00:45:41,690 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:41,697 : INFO : topic #2 (0.100): 0.038*\"dog\" + 0.028*\"allen\" + 0.017*\"work\" + 0.017*\"life\" + 0.017*\"cnn\" + 0.015*\"house\" + 0.014*\"need\" + 0.014*\"monkey\" + 0.014*\"want\" + 0.012*\"said\"\n",
      "2019-10-29 00:45:41,699 : INFO : topic #3 (0.100): 0.039*\"allen\" + 0.036*\"dog\" + 0.017*\"work\" + 0.016*\"life\" + 0.016*\"monkey\" + 0.015*\"cnn\" + 0.013*\"want\" + 0.013*\"house\" + 0.011*\"need\" + 0.010*\"time\"\n",
      "2019-10-29 00:45:41,701 : INFO : topic #4 (0.100): 0.050*\"dog\" + 0.037*\"allen\" + 0.020*\"monkey\" + 0.020*\"life\" + 0.018*\"cnn\" + 0.015*\"work\" + 0.013*\"want\" + 0.013*\"said\" + 0.013*\"care\" + 0.012*\"way\"\n",
      "2019-10-29 00:45:41,702 : INFO : topic #7 (0.100): 0.041*\"dog\" + 0.038*\"allen\" + 0.018*\"monkey\" + 0.016*\"work\" + 0.014*\"life\" + 0.013*\"want\" + 0.013*\"cnn\" + 0.012*\"house\" + 0.012*\"need\" + 0.011*\"volunteer\"\n",
      "2019-10-29 00:45:41,704 : INFO : topic #0 (0.100): 0.039*\"dog\" + 0.031*\"allen\" + 0.021*\"cnn\" + 0.019*\"life\" + 0.016*\"monkey\" + 0.015*\"work\" + 0.015*\"house\" + 0.014*\"want\" + 0.014*\"way\" + 0.014*\"care\"\n",
      "2019-10-29 00:45:41,705 : INFO : topic diff=0.862431, rho=1.000000\n",
      "2019-10-29 00:45:42,141 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:42,150 : INFO : built Dictionary(463 unique tokens: ['earned', 'catholic', 'located', 'wheel', 'exterior']...) from 5 documents (total 3695 corpus positions)\n",
      "2019-10-29 00:45:42,157 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:42,159 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:42,163 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:42,168 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:42,170 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:42,332 : INFO : -8.103 per-word bound, 274.9 perplexity estimate based on a held-out corpus of 5 documents with 3695 words\n",
      "2019-10-29 00:45:42,333 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:42,341 : INFO : topic #7 (0.100): 0.024*\"seattle\" + 0.022*\"kundig\" + 0.014*\"space\" + 0.008*\"place\" + 0.008*\"also\" + 0.007*\"chapel\" + 0.007*\"sculpture\" + 0.007*\"olson\" + 0.007*\"local\" + 0.006*\"original\"\n",
      "2019-10-29 00:45:42,343 : INFO : topic #1 (0.100): 0.031*\"seattle\" + 0.027*\"kundig\" + 0.013*\"space\" + 0.009*\"place\" + 0.008*\"also\" + 0.007*\"chapel\" + 0.007*\"needle\" + 0.007*\"square\" + 0.007*\"year\" + 0.007*\"georgetown\"\n",
      "2019-10-29 00:45:42,345 : INFO : topic #9 (0.100): 0.021*\"seattle\" + 0.021*\"kundig\" + 0.015*\"space\" + 0.009*\"chapel\" + 0.008*\"original\" + 0.008*\"georgetown\" + 0.008*\"place\" + 0.008*\"natural\" + 0.007*\"park\" + 0.007*\"olson\"\n",
      "2019-10-29 00:45:42,347 : INFO : topic #4 (0.100): 0.032*\"seattle\" + 0.027*\"kundig\" + 0.016*\"space\" + 0.009*\"georgetown\" + 0.008*\"chapel\" + 0.007*\"place\" + 0.007*\"also\" + 0.007*\"square\" + 0.007*\"architect\" + 0.006*\"design\"\n",
      "2019-10-29 00:45:42,349 : INFO : topic #2 (0.100): 0.033*\"seattle\" + 0.026*\"kundig\" + 0.012*\"space\" + 0.008*\"chapel\" + 0.007*\"city\" + 0.007*\"place\" + 0.007*\"park\" + 0.007*\"pioneer\" + 0.006*\"original\" + 0.006*\"also\"\n",
      "2019-10-29 00:45:42,352 : INFO : topic diff=0.836860, rho=1.000000\n",
      "2019-10-29 00:45:42,739 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:42,740 : INFO : built Dictionary(13 unique tokens: ['happening', 'facebook', 'messenger', 'chat', 'engulf']...) from 5 documents (total 65 corpus positions)\n",
      "2019-10-29 00:45:42,741 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:42,742 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:42,743 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:42,745 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:42,746 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:42,757 : INFO : -6.411 per-word bound, 85.1 perplexity estimate based on a held-out corpus of 5 documents with 65 words\n",
      "2019-10-29 00:45:42,758 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:42,765 : INFO : topic #4 (0.100): 0.101*\"facebook\" + 0.085*\"california\" + 0.084*\"wine\" + 0.083*\"flame\" + 0.082*\"engulf\" + 0.082*\"messenger\" + 0.081*\"happening\" + 0.075*\"country\" + 0.072*\"world\" + 0.068*\"unfolds\"\n",
      "2019-10-29 00:45:42,767 : INFO : topic #8 (0.100): 0.093*\"happening\" + 0.083*\"country\" + 0.082*\"chat\" + 0.081*\"flame\" + 0.079*\"engulf\" + 0.079*\"california\" + 0.078*\"u\" + 0.077*\"find\" + 0.074*\"world\" + 0.073*\"unfolds\"\n",
      "2019-10-29 00:45:42,768 : INFO : topic #6 (0.100): 0.093*\"flame\" + 0.087*\"wine\" + 0.087*\"u\" + 0.087*\"find\" + 0.084*\"happening\" + 0.083*\"world\" + 0.077*\"chat\" + 0.072*\"unfolds\" + 0.068*\"engulf\" + 0.068*\"facebook\"\n",
      "2019-10-29 00:45:42,770 : INFO : topic #2 (0.100): 0.094*\"wine\" + 0.087*\"world\" + 0.084*\"flame\" + 0.081*\"facebook\" + 0.079*\"engulf\" + 0.078*\"messenger\" + 0.076*\"california\" + 0.074*\"country\" + 0.073*\"happening\" + 0.071*\"chat\"\n",
      "2019-10-29 00:45:42,772 : INFO : topic #7 (0.100): 0.093*\"engulf\" + 0.087*\"world\" + 0.086*\"unfolds\" + 0.081*\"u\" + 0.080*\"happening\" + 0.078*\"california\" + 0.076*\"country\" + 0.075*\"find\" + 0.073*\"facebook\" + 0.072*\"messenger\"\n",
      "2019-10-29 00:45:42,774 : INFO : topic diff=0.500353, rho=1.000000\n",
      "2019-10-29 00:45:43,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:43,260 : INFO : built Dictionary(440 unique tokens: ['translated', 'deep', 'pedaled', 'asked', 'drive']...) from 5 documents (total 3590 corpus positions)\n",
      "2019-10-29 00:45:43,269 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:43,271 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:43,280 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:43,287 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:43,290 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:43,430 : INFO : -8.023 per-word bound, 260.1 perplexity estimate based on a held-out corpus of 5 documents with 3590 words\n",
      "2019-10-29 00:45:43,431 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:43,441 : INFO : topic #6 (0.100): 0.047*\"car\" + 0.020*\"cuba\" + 0.019*\"cuban\" + 0.019*\"american\" + 0.013*\"havana\" + 0.011*\"classic\" + 0.011*\"old\" + 0.010*\"work\" + 0.010*\"roberto\" + 0.010*\"island\"\n",
      "2019-10-29 00:45:43,444 : INFO : topic #9 (0.100): 0.039*\"car\" + 0.023*\"cuban\" + 0.021*\"american\" + 0.019*\"cuba\" + 0.018*\"havana\" + 0.012*\"classic\" + 0.012*\"old\" + 0.010*\"roberto\" + 0.009*\"every\" + 0.007*\"island\"\n",
      "2019-10-29 00:45:43,447 : INFO : topic #5 (0.100): 0.051*\"car\" + 0.022*\"american\" + 0.020*\"cuba\" + 0.015*\"cuban\" + 0.015*\"roberto\" + 0.013*\"havana\" + 0.011*\"classic\" + 0.009*\"work\" + 0.009*\"old\" + 0.008*\"one\"\n",
      "2019-10-29 00:45:43,451 : INFO : topic #8 (0.100): 0.040*\"car\" + 0.021*\"cuba\" + 0.020*\"american\" + 0.018*\"old\" + 0.017*\"cuban\" + 0.016*\"havana\" + 0.012*\"roberto\" + 0.011*\"classic\" + 0.009*\"tourist\" + 0.008*\"every\"\n",
      "2019-10-29 00:45:43,454 : INFO : topic #4 (0.100): 0.049*\"car\" + 0.027*\"cuban\" + 0.022*\"american\" + 0.020*\"cuba\" + 0.014*\"old\" + 0.013*\"havana\" + 0.012*\"roberto\" + 0.010*\"classic\" + 0.009*\"island\" + 0.008*\"work\"\n",
      "2019-10-29 00:45:43,458 : INFO : topic diff=0.892205, rho=1.000000\n",
      "2019-10-29 00:45:43,958 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:43,968 : INFO : built Dictionary(741 unique tokens: ['although', 'fossil', 'focus', 'asked', 'mounting']...) from 5 documents (total 8810 corpus positions)\n",
      "2019-10-29 00:45:43,978 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:43,979 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:43,981 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:43,986 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:43,988 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:44,256 : INFO : -8.088 per-word bound, 272.1 perplexity estimate based on a held-out corpus of 5 documents with 8810 words\n",
      "2019-10-29 00:45:44,258 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:44,273 : INFO : topic #3 (0.100): 0.048*\"win\" + 0.024*\"trump\" + 0.021*\"final\" + 0.014*\"donald\" + 0.011*\"dow\" + 0.011*\"woman\" + 0.011*\"president\" + 0.011*\"country\" + 0.011*\"visit\" + 0.011*\"first\"\n",
      "2019-10-29 00:45:44,276 : INFO : topic #2 (0.100): 0.045*\"win\" + 0.032*\"trump\" + 0.023*\"final\" + 0.016*\"donald\" + 0.013*\"first\" + 0.012*\"approval\" + 0.011*\"country\" + 0.011*\"peace\" + 0.011*\"prize\" + 0.010*\"dow\"\n",
      "2019-10-29 00:45:44,279 : INFO : topic #1 (0.100): 0.057*\"win\" + 0.028*\"trump\" + 0.021*\"final\" + 0.017*\"donald\" + 0.013*\"world\" + 0.011*\"first\" + 0.010*\"oscar\" + 0.010*\"woman\" + 0.010*\"last\" + 0.010*\"visit\"\n",
      "2019-10-29 00:45:44,282 : INFO : topic #9 (0.100): 0.059*\"win\" + 0.028*\"trump\" + 0.020*\"final\" + 0.015*\"donald\" + 0.013*\"first\" + 0.012*\"approval\" + 0.011*\"president\" + 0.011*\"nobel\" + 0.011*\"peace\" + 0.010*\"best\"\n",
      "2019-10-29 00:45:44,284 : INFO : topic #0 (0.100): 0.042*\"win\" + 0.025*\"trump\" + 0.019*\"donald\" + 0.017*\"final\" + 0.012*\"peace\" + 0.012*\"first\" + 0.011*\"movie\" + 0.010*\"oscar\" + 0.010*\"president\" + 0.010*\"best\"\n",
      "2019-10-29 00:45:44,287 : INFO : topic diff=1.180242, rho=1.000000\n",
      "2019-10-29 00:45:44,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:44,752 : INFO : built Dictionary(101 unique tokens: ['concern', 'leone', 'equipped', 'nation', 'drinking']...) from 5 documents (total 630 corpus positions)\n",
      "2019-10-29 00:45:44,754 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:44,756 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:44,757 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:44,760 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:44,762 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:44,823 : INFO : -7.121 per-word bound, 139.2 perplexity estimate based on a held-out corpus of 5 documents with 630 words\n",
      "2019-10-29 00:45:44,827 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:44,834 : INFO : topic #5 (0.100): 0.041*\"sierra\" + 0.037*\"leone\" + 0.029*\"mudslide\" + 0.024*\"people\" + 0.019*\"water\" + 0.019*\"flood\" + 0.018*\"cholera\" + 0.016*\"child\" + 0.015*\"hundred\" + 0.015*\"missing\"\n",
      "2019-10-29 00:45:44,837 : INFO : topic #9 (0.100): 0.043*\"sierra\" + 0.038*\"leone\" + 0.033*\"mudslide\" + 0.026*\"people\" + 0.023*\"flood\" + 0.022*\"many\" + 0.018*\"cholera\" + 0.017*\"child\" + 0.016*\"said\" + 0.015*\"missing\"\n",
      "2019-10-29 00:45:44,842 : INFO : topic #8 (0.100): 0.045*\"leone\" + 0.031*\"sierra\" + 0.027*\"flood\" + 0.025*\"people\" + 0.024*\"mudslide\" + 0.017*\"many\" + 0.017*\"said\" + 0.017*\"missing\" + 0.016*\"water\" + 0.015*\"flooding\"\n",
      "2019-10-29 00:45:44,844 : INFO : topic #0 (0.100): 0.042*\"leone\" + 0.037*\"mudslide\" + 0.032*\"sierra\" + 0.020*\"flood\" + 0.018*\"flooding\" + 0.016*\"water\" + 0.016*\"hundred\" + 0.016*\"many\" + 0.016*\"victim\" + 0.015*\"people\"\n",
      "2019-10-29 00:45:44,847 : INFO : topic #4 (0.100): 0.041*\"leone\" + 0.038*\"sierra\" + 0.023*\"mudslide\" + 0.022*\"flood\" + 0.018*\"victim\" + 0.018*\"people\" + 0.017*\"child\" + 0.015*\"cholera\" + 0.015*\"missing\" + 0.015*\"water\"\n",
      "2019-10-29 00:45:44,849 : INFO : topic diff=0.724800, rho=1.000000\n",
      "2019-10-29 00:45:45,326 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:45,331 : INFO : built Dictionary(353 unique tokens: ['party', 'gigabyte', 'sorry', 'computer', 'u']...) from 5 documents (total 3140 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:45,337 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:45,338 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:45,342 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:45,347 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:45,350 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:45,467 : INFO : -7.693 per-word bound, 206.9 perplexity estimate based on a held-out corpus of 5 documents with 3140 words\n",
      "2019-10-29 00:45:45,468 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:45,476 : INFO : topic #2 (0.100): 0.034*\"north\" + 0.028*\"korea\" + 0.026*\"u\" + 0.019*\"korean\" + 0.018*\"said\" + 0.017*\"south\" + 0.011*\"plan\" + 0.010*\"defense\" + 0.009*\"nuclear\" + 0.009*\"hacker\"\n",
      "2019-10-29 00:45:45,478 : INFO : topic #4 (0.100): 0.035*\"north\" + 0.033*\"korea\" + 0.021*\"korean\" + 0.019*\"u\" + 0.016*\"said\" + 0.015*\"plan\" + 0.011*\"defense\" + 0.010*\"south\" + 0.010*\"information\" + 0.009*\"hacker\"\n",
      "2019-10-29 00:45:45,481 : INFO : topic #7 (0.100): 0.037*\"north\" + 0.033*\"korea\" + 0.024*\"u\" + 0.016*\"korean\" + 0.013*\"south\" + 0.013*\"plan\" + 0.012*\"operation\" + 0.012*\"hacker\" + 0.010*\"defense\" + 0.010*\"said\"\n",
      "2019-10-29 00:45:45,483 : INFO : topic #1 (0.100): 0.032*\"north\" + 0.028*\"korea\" + 0.018*\"korean\" + 0.017*\"u\" + 0.015*\"plan\" + 0.013*\"hacker\" + 0.013*\"defense\" + 0.012*\"south\" + 0.011*\"trump\" + 0.010*\"said\"\n",
      "2019-10-29 00:45:45,486 : INFO : topic #3 (0.100): 0.037*\"north\" + 0.031*\"korea\" + 0.018*\"u\" + 0.018*\"south\" + 0.016*\"korean\" + 0.012*\"plan\" + 0.012*\"said\" + 0.010*\"trump\" + 0.010*\"defense\" + 0.009*\"operation\"\n",
      "2019-10-29 00:45:45,489 : INFO : topic diff=0.852658, rho=1.000000\n",
      "2019-10-29 00:45:45,916 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:45,922 : INFO : built Dictionary(507 unique tokens: ['paradise', 'wave', 'deep', 'party', 'drinking']...) from 5 documents (total 3730 corpus positions)\n",
      "2019-10-29 00:45:45,928 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:45,930 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:45,931 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:45,936 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:45,938 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:46,109 : INFO : -8.312 per-word bound, 317.9 perplexity estimate based on a held-out corpus of 5 documents with 3730 words\n",
      "2019-10-29 00:45:46,111 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:46,123 : INFO : topic #1 (0.100): 0.024*\"puerto\" + 0.018*\"island\" + 0.013*\"rico\" + 0.011*\"many\" + 0.009*\"ricans\" + 0.009*\"state\" + 0.008*\"maria\" + 0.008*\"family\" + 0.008*\"united\" + 0.006*\"york\"\n",
      "2019-10-29 00:45:46,125 : INFO : topic #6 (0.100): 0.027*\"puerto\" + 0.022*\"island\" + 0.017*\"ricans\" + 0.011*\"state\" + 0.010*\"rico\" + 0.008*\"many\" + 0.007*\"united\" + 0.006*\"would\" + 0.006*\"family\" + 0.006*\"maria\"\n",
      "2019-10-29 00:45:46,127 : INFO : topic #3 (0.100): 0.028*\"puerto\" + 0.024*\"island\" + 0.012*\"ricans\" + 0.012*\"many\" + 0.010*\"state\" + 0.009*\"rico\" + 0.008*\"maria\" + 0.008*\"would\" + 0.008*\"u\" + 0.007*\"family\"\n",
      "2019-10-29 00:45:46,128 : INFO : topic #4 (0.100): 0.027*\"puerto\" + 0.017*\"island\" + 0.014*\"ricans\" + 0.013*\"many\" + 0.011*\"rico\" + 0.008*\"state\" + 0.008*\"maria\" + 0.008*\"united\" + 0.008*\"would\" + 0.006*\"one\"\n",
      "2019-10-29 00:45:46,131 : INFO : topic #8 (0.100): 0.027*\"puerto\" + 0.026*\"island\" + 0.014*\"ricans\" + 0.012*\"united\" + 0.011*\"state\" + 0.011*\"many\" + 0.009*\"rico\" + 0.008*\"would\" + 0.008*\"new\" + 0.007*\"u\"\n",
      "2019-10-29 00:45:46,132 : INFO : topic diff=0.822752, rho=1.000000\n",
      "2019-10-29 00:45:46,546 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:46,552 : INFO : built Dictionary(343 unique tokens: ['acceptable', 'party', 'focus', 'game', 'prime']...) from 5 documents (total 2570 corpus positions)\n",
      "2019-10-29 00:45:46,555 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:46,556 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:46,558 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:46,561 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:46,563 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:46,668 : INFO : -7.906 per-word bound, 239.9 perplexity estimate based on a held-out corpus of 5 documents with 2570 words\n",
      "2019-10-29 00:45:46,669 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:46,677 : INFO : topic #7 (0.100): 0.025*\"eu\" + 0.023*\"may\" + 0.018*\"uk\" + 0.016*\"deal\" + 0.015*\"minister\" + 0.014*\"brexit\" + 0.012*\"british\" + 0.011*\"britain\" + 0.011*\"want\" + 0.009*\"prime\"\n",
      "2019-10-29 00:45:46,680 : INFO : topic #6 (0.100): 0.025*\"brexit\" + 0.022*\"eu\" + 0.018*\"may\" + 0.017*\"minister\" + 0.017*\"deal\" + 0.015*\"uk\" + 0.013*\"britain\" + 0.013*\"prime\" + 0.010*\"theresa\" + 0.009*\"want\"\n",
      "2019-10-29 00:45:46,683 : INFO : topic #0 (0.100): 0.027*\"eu\" + 0.023*\"brexit\" + 0.022*\"uk\" + 0.018*\"may\" + 0.015*\"minister\" + 0.014*\"deal\" + 0.011*\"britain\" + 0.011*\"brussels\" + 0.010*\"want\" + 0.010*\"month\"\n",
      "2019-10-29 00:45:46,686 : INFO : topic #5 (0.100): 0.025*\"eu\" + 0.025*\"may\" + 0.021*\"uk\" + 0.020*\"brexit\" + 0.018*\"deal\" + 0.015*\"minister\" + 0.014*\"brussels\" + 0.011*\"want\" + 0.011*\"britain\" + 0.011*\"british\"\n",
      "2019-10-29 00:45:46,689 : INFO : topic #8 (0.100): 0.022*\"brexit\" + 0.020*\"eu\" + 0.020*\"minister\" + 0.018*\"deal\" + 0.018*\"uk\" + 0.015*\"may\" + 0.011*\"britain\" + 0.010*\"brussels\" + 0.010*\"even\" + 0.010*\"way\"\n",
      "2019-10-29 00:45:46,693 : INFO : topic diff=0.825562, rho=1.000000\n",
      "2019-10-29 00:45:47,109 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:47,114 : INFO : built Dictionary(232 unique tokens: ['creating', 'launch', 'part', 'unrecognized', 'series']...) from 5 documents (total 1490 corpus positions)\n",
      "2019-10-29 00:45:47,119 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:47,120 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:47,122 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:47,125 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:47,126 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:47,210 : INFO : -7.797 per-word bound, 222.4 perplexity estimate based on a held-out corpus of 5 documents with 1490 words\n",
      "2019-10-29 00:45:47,211 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:47,217 : INFO : topic #6 (0.100): 0.028*\"bench\" + 0.023*\"park\" + 0.020*\"designer\" + 0.015*\"project\" + 0.014*\"superbenches\" + 0.012*\"part\" + 0.011*\"burrichter\" + 0.008*\"kvarnbacken\" + 0.008*\"based\" + 0.008*\"use\"\n",
      "2019-10-29 00:45:47,220 : INFO : topic #9 (0.100): 0.037*\"bench\" + 0.022*\"park\" + 0.017*\"superbenches\" + 0.016*\"designer\" + 0.016*\"project\" + 0.010*\"based\" + 0.010*\"part\" + 0.009*\"kvarnbacken\" + 0.009*\"resident\" + 0.008*\"idea\"\n",
      "2019-10-29 00:45:47,222 : INFO : topic #0 (0.100): 0.022*\"bench\" + 0.021*\"park\" + 0.019*\"superbenches\" + 0.015*\"project\" + 0.014*\"designer\" + 0.013*\"based\" + 0.011*\"burrichter\" + 0.009*\"kvarnbacken\" + 0.009*\"part\" + 0.008*\"intervention\"\n",
      "2019-10-29 00:45:47,225 : INFO : topic #3 (0.100): 0.029*\"park\" + 0.024*\"bench\" + 0.020*\"superbenches\" + 0.019*\"designer\" + 0.016*\"project\" + 0.010*\"resident\" + 0.010*\"burrichter\" + 0.009*\"part\" + 0.008*\"foster\" + 0.008*\"year\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:47,227 : INFO : topic #1 (0.100): 0.029*\"bench\" + 0.020*\"park\" + 0.017*\"designer\" + 0.016*\"superbenches\" + 0.014*\"project\" + 0.011*\"resident\" + 0.009*\"part\" + 0.009*\"kvarnbacken\" + 0.008*\"burrichter\" + 0.008*\"local\"\n",
      "2019-10-29 00:45:47,229 : INFO : topic diff=0.731867, rho=1.000000\n",
      "2019-10-29 00:45:47,613 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:47,617 : INFO : built Dictionary(94 unique tokens: ['let', 'deadly', 'gunman', 'shooting', 'get']...) from 5 documents (total 780 corpus positions)\n",
      "2019-10-29 00:45:47,620 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:47,623 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:47,626 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:47,630 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:47,632 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:47,686 : INFO : -6.573 per-word bound, 95.2 perplexity estimate based on a held-out corpus of 5 documents with 780 words\n",
      "2019-10-29 00:45:47,689 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:47,703 : INFO : topic #1 (0.100): 0.049*\"aldean\" + 0.036*\"horrific\" + 0.027*\"tonight\" + 0.027*\"jason\" + 0.025*\"know\" + 0.023*\"everyone\" + 0.023*\"performing\" + 0.021*\"festival\" + 0.021*\"beyond\" + 0.019*\"music\"\n",
      "2019-10-29 00:45:47,705 : INFO : topic #9 (0.100): 0.051*\"aldean\" + 0.030*\"tonight\" + 0.029*\"horrific\" + 0.026*\"everyone\" + 0.026*\"beyond\" + 0.026*\"jason\" + 0.025*\"know\" + 0.022*\"performing\" + 0.019*\"music\" + 0.018*\"enjoy\"\n",
      "2019-10-29 00:45:47,706 : INFO : topic #7 (0.100): 0.055*\"aldean\" + 0.037*\"tonight\" + 0.028*\"horrific\" + 0.026*\"everyone\" + 0.025*\"know\" + 0.022*\"performing\" + 0.021*\"jason\" + 0.019*\"beyond\" + 0.019*\"music\" + 0.017*\"festival\"\n",
      "2019-10-29 00:45:47,716 : INFO : topic #8 (0.100): 0.050*\"aldean\" + 0.031*\"know\" + 0.029*\"performing\" + 0.028*\"everyone\" + 0.027*\"horrific\" + 0.023*\"tonight\" + 0.022*\"festival\" + 0.020*\"jason\" + 0.020*\"music\" + 0.018*\"beyond\"\n",
      "2019-10-29 00:45:47,720 : INFO : topic #6 (0.100): 0.042*\"aldean\" + 0.030*\"tonight\" + 0.029*\"horrific\" + 0.028*\"beyond\" + 0.024*\"know\" + 0.022*\"everyone\" + 0.022*\"performing\" + 0.020*\"music\" + 0.019*\"festival\" + 0.017*\"jason\"\n",
      "2019-10-29 00:45:47,723 : INFO : topic diff=0.748828, rho=1.000000\n",
      "2019-10-29 00:45:48,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:48,169 : INFO : built Dictionary(279 unique tokens: ['diaz', 'de', 'danish', 'yard', 'place']...) from 5 documents (total 2820 corpus positions)\n",
      "2019-10-29 00:45:48,173 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:48,175 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:48,178 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:48,182 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:48,185 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:48,295 : INFO : -7.317 per-word bound, 159.4 perplexity estimate based on a held-out corpus of 5 documents with 2820 words\n",
      "2019-10-29 00:45:48,296 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:48,302 : INFO : topic #8 (0.100): 0.067*\"photo\" + 0.043*\"hide\" + 0.041*\"sport\" + 0.035*\"amazing\" + 0.034*\"caption\" + 0.024*\"september\" + 0.024*\"shot\" + 0.021*\"sunday\" + 0.021*\"october\" + 0.013*\"game\"\n",
      "2019-10-29 00:45:48,305 : INFO : topic #6 (0.100): 0.060*\"photo\" + 0.042*\"shot\" + 0.039*\"caption\" + 0.035*\"amazing\" + 0.032*\"sport\" + 0.030*\"hide\" + 0.020*\"october\" + 0.016*\"sunday\" + 0.015*\"september\" + 0.011*\"game\"\n",
      "2019-10-29 00:45:48,309 : INFO : topic #9 (0.100): 0.085*\"photo\" + 0.040*\"amazing\" + 0.038*\"shot\" + 0.037*\"caption\" + 0.035*\"sport\" + 0.029*\"hide\" + 0.023*\"september\" + 0.017*\"october\" + 0.016*\"sunday\" + 0.011*\"game\"\n",
      "2019-10-29 00:45:48,311 : INFO : topic #0 (0.100): 0.098*\"photo\" + 0.044*\"amazing\" + 0.037*\"hide\" + 0.037*\"sport\" + 0.035*\"shot\" + 0.035*\"caption\" + 0.018*\"september\" + 0.017*\"sunday\" + 0.011*\"october\" + 0.009*\"game\"\n",
      "2019-10-29 00:45:48,313 : INFO : topic #4 (0.100): 0.052*\"photo\" + 0.039*\"amazing\" + 0.039*\"hide\" + 0.039*\"shot\" + 0.031*\"sport\" + 0.031*\"caption\" + 0.021*\"october\" + 0.018*\"sunday\" + 0.017*\"september\" + 0.013*\"game\"\n",
      "2019-10-29 00:45:48,315 : INFO : topic diff=1.004898, rho=1.000000\n",
      "2019-10-29 00:45:48,826 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:48,840 : INFO : built Dictionary(786 unique tokens: ['let', 'paradise', 'phase', 'overgraze', 'happy']...) from 5 documents (total 6410 corpus positions)\n",
      "2019-10-29 00:45:48,850 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:48,853 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:48,855 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:48,860 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:48,863 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:49,184 : INFO : -8.585 per-word bound, 384.1 perplexity estimate based on a held-out corpus of 5 documents with 6410 words\n",
      "2019-10-29 00:45:49,187 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:49,202 : INFO : topic #6 (0.100): 0.022*\"say\" + 0.007*\"mountain\" + 0.007*\"travel\" + 0.006*\"national\" + 0.006*\"beach\" + 0.006*\"spot\" + 0.006*\"park\" + 0.005*\"go\" + 0.005*\"take\" + 0.005*\"traveler\"\n",
      "2019-10-29 00:45:49,205 : INFO : topic #7 (0.100): 0.026*\"say\" + 0.007*\"national\" + 0.007*\"travel\" + 0.006*\"park\" + 0.005*\"beach\" + 0.005*\"go\" + 0.005*\"suggest\" + 0.005*\"spot\" + 0.005*\"expert\" + 0.004*\"animal\"\n",
      "2019-10-29 00:45:49,208 : INFO : topic #8 (0.100): 0.018*\"say\" + 0.010*\"travel\" + 0.009*\"park\" + 0.005*\"city\" + 0.005*\"mountain\" + 0.005*\"recommends\" + 0.005*\"national\" + 0.004*\"beach\" + 0.004*\"great\" + 0.004*\"year\"\n",
      "2019-10-29 00:45:49,211 : INFO : topic #0 (0.100): 0.022*\"say\" + 0.008*\"travel\" + 0.007*\"park\" + 0.006*\"national\" + 0.005*\"beach\" + 0.005*\"great\" + 0.005*\"heading\" + 0.005*\"go\" + 0.005*\"suggest\" + 0.005*\"mountain\"\n",
      "2019-10-29 00:45:49,215 : INFO : topic #1 (0.100): 0.020*\"say\" + 0.007*\"park\" + 0.006*\"national\" + 0.006*\"city\" + 0.006*\"travel\" + 0.005*\"beach\" + 0.005*\"mountain\" + 0.005*\"recommends\" + 0.005*\"think\" + 0.005*\"recommend\"\n",
      "2019-10-29 00:45:49,217 : INFO : topic diff=0.828254, rho=1.000000\n",
      "2019-10-29 00:45:49,660 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:49,663 : INFO : built Dictionary(200 unique tokens: ['extensive', 'perhaps', 'hardened', 'hero', 'series']...) from 5 documents (total 1330 corpus positions)\n",
      "2019-10-29 00:45:49,667 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:49,671 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:49,675 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:49,679 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:49,682 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:49,760 : INFO : -7.596 per-word bound, 193.5 perplexity estimate based on a held-out corpus of 5 documents with 1330 words\n",
      "2019-10-29 00:45:49,762 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:49,769 : INFO : topic #9 (0.100): 0.036*\"tattoo\" + 0.020*\"kuniyoshi\" + 0.019*\"japanese\" + 0.018*\"art\" + 0.016*\"print\" + 0.012*\"thompson\" + 0.012*\"margin\" + 0.011*\"japan\" + 0.011*\"motif\" + 0.011*\"design\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:49,772 : INFO : topic #2 (0.100): 0.074*\"tattoo\" + 0.026*\"art\" + 0.018*\"japanese\" + 0.018*\"print\" + 0.015*\"kuniyoshi\" + 0.012*\"new\" + 0.011*\"pictorial\" + 0.011*\"motif\" + 0.010*\"design\" + 0.010*\"hero\"\n",
      "2019-10-29 00:45:49,774 : INFO : topic #8 (0.100): 0.050*\"tattoo\" + 0.021*\"art\" + 0.019*\"print\" + 0.018*\"japanese\" + 0.016*\"kuniyoshi\" + 0.012*\"pictorial\" + 0.012*\"hero\" + 0.012*\"thompson\" + 0.011*\"water\" + 0.011*\"margin\"\n",
      "2019-10-29 00:45:49,777 : INFO : topic #7 (0.100): 0.051*\"tattoo\" + 0.026*\"print\" + 0.021*\"art\" + 0.018*\"japanese\" + 0.016*\"kuniyoshi\" + 0.012*\"pictorial\" + 0.012*\"thompson\" + 0.011*\"artist\" + 0.011*\"new\" + 0.010*\"design\"\n",
      "2019-10-29 00:45:49,780 : INFO : topic #0 (0.100): 0.039*\"tattoo\" + 0.020*\"print\" + 0.019*\"kuniyoshi\" + 0.019*\"art\" + 0.014*\"japanese\" + 0.013*\"japan\" + 0.013*\"new\" + 0.012*\"thompson\" + 0.012*\"artist\" + 0.012*\"design\"\n",
      "2019-10-29 00:45:49,783 : INFO : topic diff=0.778434, rho=1.000000\n",
      "2019-10-29 00:45:50,232 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:50,238 : INFO : built Dictionary(439 unique tokens: ['let', 'hero', 'midwestcitypd', 'planned', 'one']...) from 5 documents (total 3850 corpus positions)\n",
      "2019-10-29 00:45:50,244 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:50,246 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:50,247 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:50,254 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:50,257 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:50,446 : INFO : -7.915 per-word bound, 241.3 perplexity estimate based on a held-out corpus of 5 documents with 3850 words\n",
      "2019-10-29 00:45:50,448 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:50,458 : INFO : topic #3 (0.100): 0.038*\"huff\" + 0.025*\"zoey\" + 0.021*\"said\" + 0.018*\"wallace\" + 0.012*\"officer\" + 0.011*\"miller\" + 0.010*\"police\" + 0.009*\"call\" + 0.009*\"keating\" + 0.008*\"life\"\n",
      "2019-10-29 00:45:50,460 : INFO : topic #7 (0.100): 0.025*\"huff\" + 0.022*\"zoey\" + 0.021*\"said\" + 0.017*\"wallace\" + 0.014*\"officer\" + 0.012*\"miller\" + 0.011*\"police\" + 0.010*\"call\" + 0.009*\"year\" + 0.008*\"life\"\n",
      "2019-10-29 00:45:50,464 : INFO : topic #8 (0.100): 0.030*\"huff\" + 0.022*\"zoey\" + 0.020*\"wallace\" + 0.018*\"said\" + 0.012*\"officer\" + 0.012*\"police\" + 0.011*\"miller\" + 0.010*\"call\" + 0.009*\"life\" + 0.008*\"situation\"\n",
      "2019-10-29 00:45:50,467 : INFO : topic #2 (0.100): 0.027*\"huff\" + 0.022*\"zoey\" + 0.016*\"said\" + 0.013*\"wallace\" + 0.012*\"police\" + 0.011*\"officer\" + 0.011*\"miller\" + 0.009*\"keating\" + 0.009*\"call\" + 0.008*\"life\"\n",
      "2019-10-29 00:45:50,470 : INFO : topic #0 (0.100): 0.031*\"zoey\" + 0.029*\"huff\" + 0.026*\"said\" + 0.018*\"wallace\" + 0.015*\"officer\" + 0.011*\"miller\" + 0.009*\"police\" + 0.009*\"life\" + 0.008*\"know\" + 0.008*\"call\"\n",
      "2019-10-29 00:45:50,474 : INFO : topic diff=0.882504, rho=1.000000\n",
      "2019-10-29 00:45:50,969 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:50,977 : INFO : built Dictionary(685 unique tokens: ['located', 'cambodian', 'camp', 'headquartered', 'golden']...) from 5 documents (total 6360 corpus positions)\n",
      "2019-10-29 00:45:50,986 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:50,987 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:50,991 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:50,997 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:51,000 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:51,209 : INFO : -8.280 per-word bound, 310.9 perplexity estimate based on a held-out corpus of 5 documents with 6360 words\n",
      "2019-10-29 00:45:51,210 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:51,221 : INFO : topic #8 (0.100): 0.018*\"camp\" + 0.016*\"tent\" + 0.010*\"tented\" + 0.010*\"traveler\" + 0.010*\"elephant\" + 0.009*\"safari\" + 0.009*\"wildlife\" + 0.007*\"tiger\" + 0.007*\"jungle\" + 0.007*\"experience\"\n",
      "2019-10-29 00:45:51,224 : INFO : topic #5 (0.100): 0.025*\"camp\" + 0.014*\"tent\" + 0.013*\"elephant\" + 0.010*\"tented\" + 0.010*\"wildlife\" + 0.008*\"luxury\" + 0.008*\"safari\" + 0.007*\"tiger\" + 0.007*\"jungle\" + 0.007*\"park\"\n",
      "2019-10-29 00:45:51,226 : INFO : topic #7 (0.100): 0.027*\"camp\" + 0.014*\"tent\" + 0.014*\"tented\" + 0.011*\"elephant\" + 0.011*\"wildlife\" + 0.011*\"safari\" + 0.008*\"luxury\" + 0.008*\"traveler\" + 0.008*\"private\" + 0.007*\"experience\"\n",
      "2019-10-29 00:45:51,229 : INFO : topic #0 (0.100): 0.023*\"camp\" + 0.014*\"tent\" + 0.013*\"tented\" + 0.010*\"jungle\" + 0.009*\"elephant\" + 0.009*\"traveler\" + 0.008*\"luxury\" + 0.008*\"open\" + 0.008*\"private\" + 0.008*\"safari\"\n",
      "2019-10-29 00:45:51,232 : INFO : topic #3 (0.100): 0.019*\"camp\" + 0.016*\"elephant\" + 0.012*\"tent\" + 0.011*\"traveler\" + 0.010*\"tented\" + 0.009*\"experience\" + 0.008*\"jungle\" + 0.008*\"safari\" + 0.007*\"tiger\" + 0.007*\"luxury\"\n",
      "2019-10-29 00:45:51,235 : INFO : topic diff=0.908927, rho=1.000000\n",
      "2019-10-29 00:45:51,709 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:51,715 : INFO : built Dictionary(448 unique tokens: ['relation', 'wave', 'happy', 'eve', 'shut']...) from 5 documents (total 3455 corpus positions)\n",
      "2019-10-29 00:45:51,721 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:51,722 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:51,723 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:51,727 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:51,728 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:51,860 : INFO : -8.115 per-word bound, 277.3 perplexity estimate based on a held-out corpus of 5 documents with 3455 words\n",
      "2019-10-29 00:45:51,861 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:51,871 : INFO : topic #0 (0.100): 0.034*\"cuba\" + 0.026*\"u\" + 0.020*\"american\" + 0.017*\"havana\" + 0.013*\"cuban\" + 0.013*\"island\" + 0.012*\"flight\" + 0.011*\"every\" + 0.009*\"first\" + 0.009*\"trip\"\n",
      "2019-10-29 00:45:51,872 : INFO : topic #2 (0.100): 0.035*\"cuba\" + 0.025*\"u\" + 0.022*\"american\" + 0.019*\"havana\" + 0.015*\"flight\" + 0.010*\"every\" + 0.010*\"year\" + 0.009*\"island\" + 0.009*\"cuban\" + 0.008*\"first\"\n",
      "2019-10-29 00:45:51,874 : INFO : topic #8 (0.100): 0.038*\"cuba\" + 0.027*\"u\" + 0.020*\"american\" + 0.015*\"havana\" + 0.014*\"cuban\" + 0.011*\"island\" + 0.011*\"year\" + 0.010*\"flight\" + 0.009*\"every\" + 0.007*\"first\"\n",
      "2019-10-29 00:45:51,876 : INFO : topic #7 (0.100): 0.030*\"cuba\" + 0.023*\"u\" + 0.021*\"havana\" + 0.018*\"american\" + 0.013*\"cuban\" + 0.012*\"island\" + 0.010*\"year\" + 0.010*\"flight\" + 0.010*\"first\" + 0.010*\"many\"\n",
      "2019-10-29 00:45:51,878 : INFO : topic #6 (0.100): 0.039*\"cuba\" + 0.025*\"american\" + 0.025*\"u\" + 0.017*\"havana\" + 0.015*\"cuban\" + 0.013*\"flight\" + 0.011*\"first\" + 0.011*\"island\" + 0.010*\"time\" + 0.009*\"every\"\n",
      "2019-10-29 00:45:51,880 : INFO : topic diff=0.857739, rho=1.000000\n",
      "2019-10-29 00:45:52,266 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:52,268 : INFO : built Dictionary(66 unique tokens: ['care', 'security', 'brazilian', 'torched', 'southeastern']...) from 5 documents (total 505 corpus positions)\n",
      "2019-10-29 00:45:52,272 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:52,274 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:52,277 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:52,279 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:52,281 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:52,304 : INFO : -6.397 per-word bound, 84.3 perplexity estimate based on a held-out corpus of 5 documents with 505 words\n",
      "2019-10-29 00:45:52,306 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:52,311 : INFO : topic #9 (0.100): 0.049*\"fire\" + 0.036*\"child\" + 0.035*\"hospital\" + 0.032*\"center\" + 0.031*\"four\" + 0.031*\"cnn\" + 0.029*\"state\" + 0.025*\"day\" + 0.024*\"care\" + 0.023*\"died\"\n",
      "2019-10-29 00:45:52,313 : INFO : topic #6 (0.100): 0.038*\"fire\" + 0.035*\"child\" + 0.035*\"center\" + 0.033*\"day\" + 0.030*\"care\" + 0.030*\"hospital\" + 0.030*\"state\" + 0.026*\"injured\" + 0.024*\"cnn\" + 0.023*\"four\"\n",
      "2019-10-29 00:45:52,316 : INFO : topic #1 (0.100): 0.049*\"fire\" + 0.034*\"child\" + 0.031*\"state\" + 0.029*\"four\" + 0.028*\"center\" + 0.028*\"day\" + 0.026*\"cnn\" + 0.025*\"died\" + 0.025*\"hospital\" + 0.024*\"care\"\n",
      "2019-10-29 00:45:52,318 : INFO : topic #8 (0.100): 0.045*\"child\" + 0.037*\"fire\" + 0.036*\"state\" + 0.028*\"day\" + 0.028*\"care\" + 0.027*\"four\" + 0.026*\"rodrigues\" + 0.026*\"center\" + 0.026*\"started\" + 0.026*\"hospital\"\n",
      "2019-10-29 00:45:52,319 : INFO : topic #4 (0.100): 0.055*\"fire\" + 0.035*\"child\" + 0.032*\"day\" + 0.030*\"cnn\" + 0.030*\"care\" + 0.028*\"four\" + 0.027*\"center\" + 0.026*\"hospital\" + 0.026*\"southeastern\" + 0.024*\"others\"\n",
      "2019-10-29 00:45:52,322 : INFO : topic diff=0.755430, rho=1.000000\n",
      "2019-10-29 00:45:52,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:52,785 : INFO : built Dictionary(271 unique tokens: ['forward', 'puerto', 'campaign', 'hero', 'come']...) from 5 documents (total 1770 corpus positions)\n",
      "2019-10-29 00:45:52,788 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:52,791 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:52,795 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:52,797 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:52,799 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:52,901 : INFO : -7.912 per-word bound, 240.8 perplexity estimate based on a held-out corpus of 5 documents with 1770 words\n",
      "2019-10-29 00:45:52,903 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:52,910 : INFO : topic #6 (0.100): 0.035*\"cause\" + 0.017*\"f\" + 0.016*\"like\" + 0.014*\"trump\" + 0.011*\"come\" + 0.011*\"gonna\" + 0.010*\"got\" + 0.010*\"get\" + 0.009*\"k\" + 0.009*\"eminem\"\n",
      "2019-10-29 00:45:52,913 : INFO : topic #7 (0.100): 0.023*\"cause\" + 0.018*\"like\" + 0.017*\"trump\" + 0.015*\"f\" + 0.011*\"come\" + 0.010*\"gonna\" + 0.010*\"til\" + 0.010*\"get\" + 0.009*\"got\" + 0.009*\"eminem\"\n",
      "2019-10-29 00:45:52,916 : INFO : topic #8 (0.100): 0.024*\"cause\" + 0.020*\"like\" + 0.015*\"trump\" + 0.014*\"f\" + 0.012*\"got\" + 0.012*\"get\" + 0.010*\"gonna\" + 0.010*\"come\" + 0.009*\"k\" + 0.008*\"full\"\n",
      "2019-10-29 00:45:52,918 : INFO : topic #3 (0.100): 0.024*\"cause\" + 0.020*\"like\" + 0.019*\"f\" + 0.016*\"trump\" + 0.013*\"gonna\" + 0.011*\"get\" + 0.010*\"got\" + 0.009*\"til\" + 0.009*\"storm\" + 0.009*\"king\"\n",
      "2019-10-29 00:45:52,919 : INFO : topic #9 (0.100): 0.023*\"cause\" + 0.020*\"like\" + 0.015*\"trump\" + 0.015*\"f\" + 0.012*\"come\" + 0.011*\"got\" + 0.010*\"king\" + 0.009*\"gonna\" + 0.009*\"eminem\" + 0.008*\"keep\"\n",
      "2019-10-29 00:45:52,921 : INFO : topic diff=0.755373, rho=1.000000\n",
      "2019-10-29 00:45:53,372 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:53,376 : INFO : built Dictionary(274 unique tokens: ['although', 'concern', 'significant', 'campaign', 'leader']...) from 5 documents (total 2210 corpus positions)\n",
      "2019-10-29 00:45:53,379 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:53,380 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:53,382 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:53,386 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:53,387 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:53,483 : INFO : -7.579 per-word bound, 191.3 perplexity estimate based on a held-out corpus of 5 documents with 2210 words\n",
      "2019-10-29 00:45:53,484 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:53,491 : INFO : topic #1 (0.100): 0.041*\"health\" + 0.026*\"care\" + 0.022*\"statement\" + 0.015*\"american\" + 0.013*\"bill\" + 0.013*\"house\" + 0.012*\"association\" + 0.012*\"said\" + 0.012*\"group\" + 0.011*\"legislation\"\n",
      "2019-10-29 00:45:53,493 : INFO : topic #3 (0.100): 0.045*\"health\" + 0.025*\"statement\" + 0.022*\"care\" + 0.016*\"legislation\" + 0.014*\"house\" + 0.014*\"american\" + 0.014*\"group\" + 0.013*\"said\" + 0.013*\"association\" + 0.012*\"president\"\n",
      "2019-10-29 00:45:53,496 : INFO : topic #2 (0.100): 0.037*\"health\" + 0.028*\"care\" + 0.021*\"legislation\" + 0.018*\"statement\" + 0.016*\"said\" + 0.014*\"association\" + 0.014*\"house\" + 0.014*\"group\" + 0.012*\"president\" + 0.011*\"american\"\n",
      "2019-10-29 00:45:53,498 : INFO : topic #9 (0.100): 0.042*\"health\" + 0.022*\"care\" + 0.020*\"statement\" + 0.020*\"said\" + 0.018*\"legislation\" + 0.016*\"association\" + 0.013*\"house\" + 0.013*\"american\" + 0.012*\"group\" + 0.011*\"president\"\n",
      "2019-10-29 00:45:53,501 : INFO : topic #5 (0.100): 0.058*\"health\" + 0.023*\"care\" + 0.021*\"legislation\" + 0.017*\"statement\" + 0.014*\"group\" + 0.014*\"said\" + 0.012*\"american\" + 0.012*\"association\" + 0.010*\"president\" + 0.010*\"planned\"\n",
      "2019-10-29 00:45:53,503 : INFO : topic diff=0.863760, rho=1.000000\n",
      "2019-10-29 00:45:53,923 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:53,927 : INFO : built Dictionary(340 unique tokens: ['franco', 'previously', 'prime', 'assuming', 'catalonia']...) from 5 documents (total 2590 corpus positions)\n",
      "2019-10-29 00:45:53,931 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:53,933 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:53,935 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:53,939 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:53,940 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:54,048 : INFO : -7.864 per-word bound, 233.0 perplexity estimate based on a held-out corpus of 5 documents with 2590 words\n",
      "2019-10-29 00:45:54,050 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:54,058 : INFO : topic #7 (0.100): 0.022*\"catalan\" + 0.022*\"puigdemont\" + 0.020*\"independence\" + 0.015*\"catalonia\" + 0.014*\"spain\" + 0.013*\"region\" + 0.013*\"rajoy\" + 0.013*\"vote\" + 0.011*\"spanish\" + 0.010*\"could\"\n",
      "2019-10-29 00:45:54,060 : INFO : topic #5 (0.100): 0.035*\"catalan\" + 0.020*\"puigdemont\" + 0.018*\"catalonia\" + 0.016*\"independence\" + 0.015*\"spain\" + 0.012*\"vote\" + 0.012*\"rajoy\" + 0.011*\"region\" + 0.011*\"spanish\" + 0.010*\"secessionist\"\n",
      "2019-10-29 00:45:54,063 : INFO : topic #1 (0.100): 0.027*\"catalan\" + 0.019*\"puigdemont\" + 0.018*\"independence\" + 0.018*\"catalonia\" + 0.017*\"spanish\" + 0.013*\"spain\" + 0.012*\"rajoy\" + 0.011*\"secessionist\" + 0.010*\"region\" + 0.009*\"side\"\n",
      "2019-10-29 00:45:54,066 : INFO : topic #8 (0.100): 0.032*\"catalan\" + 0.021*\"catalonia\" + 0.020*\"spanish\" + 0.018*\"puigdemont\" + 0.017*\"independence\" + 0.014*\"spain\" + 0.012*\"rajoy\" + 0.011*\"vote\" + 0.010*\"secessionist\" + 0.010*\"region\"\n",
      "2019-10-29 00:45:54,070 : INFO : topic #0 (0.100): 0.034*\"catalan\" + 0.020*\"independence\" + 0.018*\"spain\" + 0.016*\"catalonia\" + 0.015*\"puigdemont\" + 0.014*\"spanish\" + 0.013*\"secessionist\" + 0.013*\"rajoy\" + 0.012*\"could\" + 0.011*\"region\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:54,074 : INFO : topic diff=0.830428, rho=1.000000\n",
      "2019-10-29 00:45:54,483 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:54,486 : INFO : built Dictionary(67 unique tokens: ['overflew', 'petrel', 'nation', 'time', 'oversees']...) from 5 documents (total 550 corpus positions)\n",
      "2019-10-29 00:45:54,488 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:54,490 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:54,491 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:54,493 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:54,496 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:54,533 : INFO : -6.303 per-word bound, 79.0 perplexity estimate based on a held-out corpus of 5 documents with 550 words\n",
      "2019-10-29 00:45:54,535 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:54,544 : INFO : topic #6 (0.100): 0.065*\"north\" + 0.052*\"korea\" + 0.046*\"ship\" + 0.037*\"port\" + 0.035*\"security\" + 0.032*\"council\" + 0.031*\"grenade\" + 0.029*\"ban\" + 0.028*\"caught\" + 0.025*\"un\"\n",
      "2019-10-29 00:45:54,547 : INFO : topic #4 (0.100): 0.065*\"north\" + 0.052*\"korea\" + 0.043*\"ship\" + 0.038*\"un\" + 0.033*\"grenade\" + 0.031*\"council\" + 0.031*\"ban\" + 0.031*\"port\" + 0.027*\"security\" + 0.023*\"smuggling\"\n",
      "2019-10-29 00:45:54,552 : INFO : topic #2 (0.100): 0.061*\"korea\" + 0.059*\"north\" + 0.054*\"ship\" + 0.044*\"ban\" + 0.030*\"un\" + 0.030*\"port\" + 0.027*\"smuggling\" + 0.026*\"caught\" + 0.025*\"security\" + 0.024*\"council\"\n",
      "2019-10-29 00:45:54,556 : INFO : topic #0 (0.100): 0.050*\"korea\" + 0.048*\"ship\" + 0.042*\"north\" + 0.037*\"port\" + 0.036*\"un\" + 0.033*\"ban\" + 0.027*\"caught\" + 0.027*\"grenade\" + 0.024*\"council\" + 0.024*\"security\"\n",
      "2019-10-29 00:45:54,559 : INFO : topic #3 (0.100): 0.061*\"north\" + 0.054*\"ship\" + 0.042*\"korea\" + 0.037*\"smuggling\" + 0.033*\"un\" + 0.031*\"port\" + 0.029*\"ban\" + 0.024*\"council\" + 0.024*\"security\" + 0.023*\"grenade\"\n",
      "2019-10-29 00:45:54,563 : INFO : topic diff=0.886735, rho=1.000000\n",
      "2019-10-29 00:45:54,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:54,978 : INFO : built Dictionary(123 unique tokens: ['dating', 'offered', 'help', 'home', 'making']...) from 5 documents (total 885 corpus positions)\n",
      "2019-10-29 00:45:54,981 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:54,983 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:54,984 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:54,987 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:54,989 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:55,083 : INFO : -7.036 per-word bound, 131.3 perplexity estimate based on a held-out corpus of 5 documents with 885 words\n",
      "2019-10-29 00:45:55,085 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:55,094 : INFO : topic #6 (0.100): 0.051*\"test\" + 0.038*\"kit\" + 0.036*\"hiv\" + 0.035*\"study\" + 0.032*\"grindr\" + 0.019*\"men\" + 0.016*\"self\" + 0.013*\"user\" + 0.013*\"ad\" + 0.012*\"stigma\"\n",
      "2019-10-29 00:45:55,097 : INFO : topic #8 (0.100): 0.047*\"test\" + 0.039*\"study\" + 0.039*\"hiv\" + 0.032*\"kit\" + 0.027*\"grindr\" + 0.025*\"men\" + 0.019*\"self\" + 0.014*\"spread\" + 0.013*\"getting\" + 0.013*\"tested\"\n",
      "2019-10-29 00:45:55,100 : INFO : topic #1 (0.100): 0.046*\"hiv\" + 0.039*\"test\" + 0.035*\"study\" + 0.031*\"grindr\" + 0.026*\"kit\" + 0.022*\"men\" + 0.014*\"survey\" + 0.014*\"self\" + 0.013*\"app\" + 0.012*\"often\"\n",
      "2019-10-29 00:45:55,104 : INFO : topic #7 (0.100): 0.050*\"hiv\" + 0.048*\"test\" + 0.038*\"study\" + 0.034*\"kit\" + 0.023*\"grindr\" + 0.020*\"men\" + 0.016*\"ad\" + 0.013*\"getting\" + 0.012*\"survey\" + 0.012*\"tested\"\n",
      "2019-10-29 00:45:55,107 : INFO : topic #9 (0.100): 0.048*\"test\" + 0.037*\"hiv\" + 0.034*\"study\" + 0.026*\"kit\" + 0.021*\"grindr\" + 0.018*\"men\" + 0.014*\"self\" + 0.014*\"according\" + 0.013*\"user\" + 0.013*\"result\"\n",
      "2019-10-29 00:45:55,110 : INFO : topic diff=0.803569, rho=1.000000\n",
      "2019-10-29 00:45:55,600 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:55,607 : INFO : built Dictionary(248 unique tokens: ['let', 'school', 'campaign', 'come', 'trying']...) from 5 documents (total 2050 corpus positions)\n",
      "2019-10-29 00:45:55,613 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:55,617 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:55,620 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:55,625 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:55,628 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:55,757 : INFO : -7.460 per-word bound, 176.1 perplexity estimate based on a held-out corpus of 5 documents with 2050 words\n",
      "2019-10-29 00:45:55,759 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:55,767 : INFO : topic #7 (0.100): 0.062*\"girl\" + 0.025*\"education\" + 0.021*\"school\" + 0.018*\"country\" + 0.013*\"learn\" + 0.012*\"many\" + 0.012*\"like\" + 0.012*\"first\" + 0.012*\"world\" + 0.011*\"state\"\n",
      "2019-10-29 00:45:55,770 : INFO : topic #3 (0.100): 0.065*\"girl\" + 0.020*\"education\" + 0.019*\"school\" + 0.014*\"learn\" + 0.013*\"country\" + 0.012*\"year\" + 0.012*\"first\" + 0.012*\"like\" + 0.012*\"global\" + 0.011*\"let\"\n",
      "2019-10-29 00:45:55,773 : INFO : topic #2 (0.100): 0.061*\"girl\" + 0.020*\"education\" + 0.016*\"country\" + 0.015*\"school\" + 0.015*\"learn\" + 0.013*\"first\" + 0.013*\"world\" + 0.012*\"united\" + 0.011*\"year\" + 0.011*\"many\"\n",
      "2019-10-29 00:45:55,777 : INFO : topic #0 (0.100): 0.030*\"girl\" + 0.023*\"education\" + 0.018*\"country\" + 0.016*\"school\" + 0.013*\"many\" + 0.013*\"first\" + 0.012*\"learn\" + 0.011*\"world\" + 0.011*\"dream\" + 0.011*\"year\"\n",
      "2019-10-29 00:45:55,780 : INFO : topic #6 (0.100): 0.060*\"girl\" + 0.018*\"country\" + 0.017*\"school\" + 0.016*\"learn\" + 0.015*\"education\" + 0.014*\"like\" + 0.012*\"many\" + 0.012*\"state\" + 0.011*\"year\" + 0.010*\"first\"\n",
      "2019-10-29 00:45:55,782 : INFO : topic diff=0.848975, rho=1.000000\n",
      "2019-10-29 00:45:56,191 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:56,194 : INFO : built Dictionary(146 unique tokens: ['affected', 'afterward', 'come', 'focus', 'retains']...) from 5 documents (total 1065 corpus positions)\n",
      "2019-10-29 00:45:56,196 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:56,198 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:56,199 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:56,201 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:56,203 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:56,268 : INFO : -7.165 per-word bound, 143.5 perplexity estimate based on a held-out corpus of 5 documents with 1065 words\n",
      "2019-10-29 00:45:56,269 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:56,275 : INFO : topic #4 (0.100): 0.042*\"exercise\" + 0.038*\"muscle\" + 0.030*\"doms\" + 0.024*\"soreness\" + 0.021*\"pain\" + 0.017*\"acid\" + 0.016*\"lactic\" + 0.016*\"day\" + 0.015*\"sign\" + 0.013*\"stronger\"\n",
      "2019-10-29 00:45:56,278 : INFO : topic #8 (0.100): 0.043*\"exercise\" + 0.034*\"doms\" + 0.032*\"muscle\" + 0.024*\"soreness\" + 0.022*\"pain\" + 0.019*\"day\" + 0.017*\"lactic\" + 0.017*\"stronger\" + 0.015*\"acid\" + 0.014*\"sign\"\n",
      "2019-10-29 00:45:56,283 : INFO : topic #6 (0.100): 0.047*\"exercise\" + 0.033*\"muscle\" + 0.030*\"doms\" + 0.027*\"soreness\" + 0.024*\"pain\" + 0.019*\"day\" + 0.019*\"occur\" + 0.018*\"acid\" + 0.015*\"lactic\" + 0.011*\"stronger\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:56,286 : INFO : topic #7 (0.100): 0.053*\"exercise\" + 0.033*\"muscle\" + 0.029*\"doms\" + 0.028*\"soreness\" + 0.021*\"acid\" + 0.017*\"sign\" + 0.017*\"lactic\" + 0.014*\"stronger\" + 0.014*\"pain\" + 0.014*\"occur\"\n",
      "2019-10-29 00:45:56,288 : INFO : topic #9 (0.100): 0.037*\"exercise\" + 0.033*\"muscle\" + 0.030*\"doms\" + 0.030*\"soreness\" + 0.027*\"pain\" + 0.019*\"lactic\" + 0.014*\"acid\" + 0.012*\"occur\" + 0.012*\"day\" + 0.012*\"stronger\"\n",
      "2019-10-29 00:45:56,291 : INFO : topic diff=0.821086, rho=1.000000\n",
      "2019-10-29 00:45:56,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:56,695 : INFO : built Dictionary(77 unique tokens: ['administration', 'interview', 'story', 'failure', 'interior']...) from 5 documents (total 455 corpus positions)\n",
      "2019-10-29 00:45:56,696 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:56,698 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:56,699 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:56,701 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:56,702 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:56,742 : INFO : -7.003 per-word bound, 128.2 perplexity estimate based on a held-out corpus of 5 documents with 455 words\n",
      "2019-10-29 00:45:56,743 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:56,751 : INFO : topic #5 (0.100): 0.059*\"trump\" + 0.027*\"department\" + 0.024*\"agency\" + 0.022*\"need\" + 0.021*\"interview\" + 0.021*\"behind\" + 0.020*\"vacancy\" + 0.020*\"new\" + 0.020*\"certain\" + 0.017*\"say\"\n",
      "2019-10-29 00:45:56,753 : INFO : topic #7 (0.100): 0.054*\"trump\" + 0.024*\"say\" + 0.023*\"behind\" + 0.022*\"need\" + 0.021*\"interview\" + 0.021*\"presidential\" + 0.020*\"department\" + 0.020*\"certain\" + 0.019*\"agency\" + 0.017*\"vacancy\"\n",
      "2019-10-29 00:45:56,757 : INFO : topic #4 (0.100): 0.055*\"trump\" + 0.028*\"vacancy\" + 0.022*\"need\" + 0.022*\"agency\" + 0.021*\"certain\" + 0.019*\"interview\" + 0.018*\"new\" + 0.018*\"behind\" + 0.018*\"presidential\" + 0.017*\"say\"\n",
      "2019-10-29 00:45:56,761 : INFO : topic #1 (0.100): 0.038*\"trump\" + 0.024*\"certain\" + 0.023*\"presidential\" + 0.022*\"new\" + 0.021*\"need\" + 0.021*\"say\" + 0.021*\"department\" + 0.020*\"behind\" + 0.020*\"agency\" + 0.019*\"vacancy\"\n",
      "2019-10-29 00:45:56,764 : INFO : topic #2 (0.100): 0.051*\"trump\" + 0.028*\"department\" + 0.025*\"new\" + 0.024*\"presidential\" + 0.021*\"behind\" + 0.021*\"certain\" + 0.020*\"need\" + 0.019*\"interview\" + 0.017*\"vacancy\" + 0.016*\"say\"\n",
      "2019-10-29 00:45:56,766 : INFO : topic diff=0.650110, rho=1.000000\n",
      "2019-10-29 00:45:57,169 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:57,171 : INFO : built Dictionary(100 unique tokens: ['approach', 'negotiating', 'industry', 'come', 'life']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:45:57,173 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:57,175 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:57,178 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:57,182 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:57,185 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:57,232 : INFO : -7.064 per-word bound, 133.8 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:45:57,234 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:57,240 : INFO : topic #4 (0.100): 0.031*\"technology\" + 0.029*\"enforcement\" + 0.028*\"said\" + 0.024*\"law\" + 0.024*\"encryption\" + 0.021*\"criminal\" + 0.018*\"rosenstein\" + 0.016*\"company\" + 0.016*\"rod\" + 0.015*\"approach\"\n",
      "2019-10-29 00:45:57,243 : INFO : topic #9 (0.100): 0.032*\"law\" + 0.031*\"said\" + 0.030*\"technology\" + 0.030*\"enforcement\" + 0.026*\"company\" + 0.023*\"encryption\" + 0.023*\"criminal\" + 0.019*\"rosenstein\" + 0.018*\"attorney\" + 0.017*\"frustrated\"\n",
      "2019-10-29 00:45:57,246 : INFO : topic #0 (0.100): 0.031*\"law\" + 0.030*\"enforcement\" + 0.028*\"technology\" + 0.026*\"encryption\" + 0.023*\"criminal\" + 0.021*\"rosenstein\" + 0.019*\"said\" + 0.017*\"company\" + 0.017*\"approach\" + 0.016*\"issue\"\n",
      "2019-10-29 00:45:57,250 : INFO : topic #7 (0.100): 0.032*\"enforcement\" + 0.031*\"law\" + 0.028*\"said\" + 0.026*\"technology\" + 0.025*\"company\" + 0.024*\"encryption\" + 0.023*\"general\" + 0.019*\"rosenstein\" + 0.018*\"criminal\" + 0.016*\"attorney\"\n",
      "2019-10-29 00:45:57,255 : INFO : topic #2 (0.100): 0.038*\"said\" + 0.031*\"law\" + 0.030*\"technology\" + 0.026*\"rosenstein\" + 0.025*\"enforcement\" + 0.023*\"criminal\" + 0.020*\"company\" + 0.018*\"enable\" + 0.017*\"rod\" + 0.017*\"encryption\"\n",
      "2019-10-29 00:45:57,258 : INFO : topic diff=0.745247, rho=1.000000\n",
      "2019-10-29 00:45:57,729 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:57,739 : INFO : built Dictionary(539 unique tokens: ['let', 'symbol', 'deter', 'remained', 'planned']...) from 5 documents (total 4745 corpus positions)\n",
      "2019-10-29 00:45:57,749 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:57,750 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:57,752 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:57,756 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:57,758 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:57,934 : INFO : -8.112 per-word bound, 276.7 perplexity estimate based on a held-out corpus of 5 documents with 4745 words\n",
      "2019-10-29 00:45:57,935 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:57,945 : INFO : topic #2 (0.100): 0.032*\"price\" + 0.018*\"health\" + 0.016*\"said\" + 0.014*\"care\" + 0.013*\"patient\" + 0.013*\"system\" + 0.010*\"state\" + 0.008*\"people\" + 0.007*\"administration\" + 0.007*\"money\"\n",
      "2019-10-29 00:45:57,947 : INFO : topic #5 (0.100): 0.019*\"price\" + 0.017*\"health\" + 0.016*\"system\" + 0.015*\"said\" + 0.015*\"state\" + 0.012*\"patient\" + 0.009*\"people\" + 0.008*\"care\" + 0.008*\"trump\" + 0.008*\"administration\"\n",
      "2019-10-29 00:45:57,949 : INFO : topic #9 (0.100): 0.038*\"price\" + 0.017*\"health\" + 0.016*\"said\" + 0.015*\"state\" + 0.011*\"system\" + 0.010*\"care\" + 0.010*\"patient\" + 0.007*\"trump\" + 0.006*\"people\" + 0.006*\"georgia\"\n",
      "2019-10-29 00:45:57,951 : INFO : topic #3 (0.100): 0.025*\"price\" + 0.023*\"said\" + 0.016*\"system\" + 0.015*\"state\" + 0.014*\"health\" + 0.014*\"care\" + 0.011*\"patient\" + 0.008*\"people\" + 0.008*\"georgia\" + 0.007*\"republican\"\n",
      "2019-10-29 00:45:57,952 : INFO : topic #1 (0.100): 0.036*\"price\" + 0.020*\"state\" + 0.017*\"said\" + 0.013*\"system\" + 0.013*\"health\" + 0.011*\"patient\" + 0.010*\"care\" + 0.009*\"trump\" + 0.008*\"georgia\" + 0.006*\"much\"\n",
      "2019-10-29 00:45:57,955 : INFO : topic diff=0.877080, rho=1.000000\n",
      "2019-10-29 00:45:58,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:58,361 : INFO : built Dictionary(212 unique tokens: ['angeles', 'de', 'come', 'think', 'matching']...) from 5 documents (total 1440 corpus positions)\n",
      "2019-10-29 00:45:58,364 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:58,365 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:58,367 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:58,370 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:58,371 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:45:58,451 : INFO : -7.617 per-word bound, 196.3 perplexity estimate based on a held-out corpus of 5 documents with 1440 words\n",
      "2019-10-29 00:45:58,453 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:58,460 : INFO : topic #5 (0.100): 0.056*\"hair\" + 0.033*\"mindu\" + 0.032*\"le\" + 0.017*\"wig\" + 0.015*\"like\" + 0.014*\"hairdressing\" + 0.012*\"one\" + 0.010*\"gaga\" + 0.009*\"clothes\" + 0.009*\"said\"\n",
      "2019-10-29 00:45:58,462 : INFO : topic #9 (0.100): 0.060*\"hair\" + 0.038*\"mindu\" + 0.026*\"le\" + 0.016*\"hairdressing\" + 0.014*\"wig\" + 0.012*\"like\" + 0.010*\"club\" + 0.009*\"people\" + 0.009*\"clothes\" + 0.009*\"one\"\n",
      "2019-10-29 00:45:58,465 : INFO : topic #7 (0.100): 0.044*\"hair\" + 0.030*\"le\" + 0.026*\"mindu\" + 0.015*\"like\" + 0.012*\"hairdressing\" + 0.011*\"club\" + 0.011*\"wig\" + 0.011*\"said\" + 0.011*\"clothes\" + 0.009*\"charlie\"\n",
      "2019-10-29 00:45:58,468 : INFO : topic #4 (0.100): 0.045*\"hair\" + 0.041*\"le\" + 0.036*\"mindu\" + 0.012*\"wig\" + 0.012*\"said\" + 0.011*\"hairdressing\" + 0.010*\"one\" + 0.010*\"club\" + 0.010*\"like\" + 0.009*\"wanted\"\n",
      "2019-10-29 00:45:58,470 : INFO : topic #0 (0.100): 0.046*\"hair\" + 0.039*\"mindu\" + 0.034*\"le\" + 0.013*\"like\" + 0.012*\"wig\" + 0.011*\"gaga\" + 0.011*\"people\" + 0.011*\"clothes\" + 0.010*\"hairdressing\" + 0.010*\"club\"\n",
      "2019-10-29 00:45:58,473 : INFO : topic diff=0.786132, rho=1.000000\n",
      "2019-10-29 00:45:58,888 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:58,891 : INFO : built Dictionary(95 unique tokens: ['campaign', 'life', 'melinda', 'spotlight', 'new']...) from 5 documents (total 670 corpus positions)\n",
      "2019-10-29 00:45:58,894 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:58,897 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:58,899 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:58,903 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:58,906 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:58,947 : INFO : -6.842 per-word bound, 114.7 perplexity estimate based on a held-out corpus of 5 documents with 670 words\n",
      "2019-10-29 00:45:58,950 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:58,956 : INFO : topic #7 (0.100): 0.070*\"girl\" + 0.030*\"film\" + 0.030*\"freedom\" + 0.027*\"world\" + 0.025*\"day\" + 0.024*\"beyonce\" + 0.019*\"documentary\" + 0.016*\"channel\" + 0.015*\"campaign\" + 0.015*\"released\"\n",
      "2019-10-29 00:45:58,958 : INFO : topic #4 (0.100): 0.088*\"girl\" + 0.035*\"film\" + 0.027*\"day\" + 0.024*\"world\" + 0.023*\"freedom\" + 0.021*\"beyonce\" + 0.018*\"melinda\" + 0.017*\"demanding\" + 0.016*\"mark\" + 0.016*\"campaign\"\n",
      "2019-10-29 00:45:58,960 : INFO : topic #6 (0.100): 0.069*\"girl\" + 0.034*\"world\" + 0.031*\"beyonce\" + 0.031*\"day\" + 0.028*\"freedom\" + 0.023*\"film\" + 0.018*\"kid\" + 0.017*\"melinda\" + 0.017*\"documentary\" + 0.016*\"channel\"\n",
      "2019-10-29 00:45:58,963 : INFO : topic #1 (0.100): 0.074*\"girl\" + 0.033*\"world\" + 0.029*\"film\" + 0.028*\"freedom\" + 0.024*\"day\" + 0.022*\"beyonce\" + 0.017*\"kid\" + 0.017*\"feature\" + 0.017*\"gate\" + 0.016*\"education\"\n",
      "2019-10-29 00:45:58,966 : INFO : topic #2 (0.100): 0.078*\"girl\" + 0.032*\"beyonce\" + 0.028*\"day\" + 0.026*\"freedom\" + 0.026*\"film\" + 0.023*\"world\" + 0.017*\"released\" + 0.016*\"demanding\" + 0.016*\"international\" + 0.016*\"kid\"\n",
      "2019-10-29 00:45:58,970 : INFO : topic diff=0.787345, rho=1.000000\n",
      "2019-10-29 00:45:59,369 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:59,373 : INFO : built Dictionary(226 unique tokens: ['rage', 'person', 'described', 'come', 'huff']...) from 5 documents (total 1510 corpus positions)\n",
      "2019-10-29 00:45:59,376 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:59,377 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:59,378 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:59,381 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:59,383 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:45:59,457 : INFO : -7.706 per-word bound, 208.9 perplexity estimate based on a held-out corpus of 5 documents with 1510 words\n",
      "2019-10-29 00:45:59,458 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:45:59,465 : INFO : topic #3 (0.100): 0.028*\"trump\" + 0.023*\"eminem\" + 0.016*\"people\" + 0.014*\"rap\" + 0.013*\"say\" + 0.011*\"said\" + 0.010*\"lot\" + 0.010*\"emotion\" + 0.010*\"democrat\" + 0.010*\"two\"\n",
      "2019-10-29 00:45:59,467 : INFO : topic #2 (0.100): 0.032*\"trump\" + 0.021*\"eminem\" + 0.020*\"people\" + 0.014*\"said\" + 0.013*\"say\" + 0.012*\"democrat\" + 0.012*\"lot\" + 0.011*\"rapper\" + 0.011*\"rap\" + 0.009*\"feel\"\n",
      "2019-10-29 00:45:59,469 : INFO : topic #9 (0.100): 0.035*\"trump\" + 0.035*\"eminem\" + 0.021*\"people\" + 0.015*\"lot\" + 0.012*\"say\" + 0.012*\"said\" + 0.010*\"rap\" + 0.010*\"angry\" + 0.010*\"democrat\" + 0.009*\"emotion\"\n",
      "2019-10-29 00:45:59,470 : INFO : topic #6 (0.100): 0.027*\"trump\" + 0.026*\"eminem\" + 0.017*\"people\" + 0.015*\"say\" + 0.014*\"said\" + 0.012*\"lot\" + 0.012*\"rap\" + 0.011*\"feel\" + 0.011*\"angry\" + 0.010*\"two\"\n",
      "2019-10-29 00:45:59,472 : INFO : topic #0 (0.100): 0.043*\"trump\" + 0.030*\"eminem\" + 0.015*\"people\" + 0.013*\"say\" + 0.012*\"said\" + 0.011*\"rap\" + 0.011*\"emotion\" + 0.010*\"lot\" + 0.010*\"angry\" + 0.010*\"feel\"\n",
      "2019-10-29 00:45:59,474 : INFO : topic diff=0.757888, rho=1.000000\n",
      "2019-10-29 00:45:59,966 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:45:59,977 : INFO : built Dictionary(473 unique tokens: ['portion', 'laboratory', 'spot', 'wheel', 'planned']...) from 5 documents (total 7645 corpus positions)\n",
      "2019-10-29 00:45:59,987 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:45:59,989 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:45:59,991 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:45:59,994 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:45:59,997 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:00,168 : INFO : -7.396 per-word bound, 168.5 perplexity estimate based on a held-out corpus of 5 documents with 7645 words\n",
      "2019-10-29 00:46:00,170 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:00,181 : INFO : topic #2 (0.100): 0.063*\"rover\" + 0.061*\"curiosity\" + 0.050*\"mar\" + 0.042*\"photo\" + 0.038*\"hide\" + 0.032*\"caption\" + 0.030*\"image\" + 0.019*\"nasa\" + 0.017*\"camera\" + 0.015*\"rock\"\n",
      "2019-10-29 00:46:00,183 : INFO : topic #3 (0.100): 0.082*\"rover\" + 0.060*\"curiosity\" + 0.054*\"mar\" + 0.041*\"photo\" + 0.035*\"caption\" + 0.033*\"hide\" + 0.027*\"image\" + 0.020*\"camera\" + 0.018*\"rock\" + 0.014*\"taken\"\n",
      "2019-10-29 00:46:00,187 : INFO : topic #8 (0.100): 0.067*\"rover\" + 0.062*\"mar\" + 0.050*\"curiosity\" + 0.049*\"hide\" + 0.038*\"caption\" + 0.038*\"photo\" + 0.028*\"image\" + 0.017*\"camera\" + 0.015*\"rock\" + 0.013*\"taken\"\n",
      "2019-10-29 00:46:00,191 : INFO : topic #5 (0.100): 0.077*\"rover\" + 0.063*\"mar\" + 0.058*\"curiosity\" + 0.033*\"hide\" + 0.029*\"caption\" + 0.029*\"photo\" + 0.027*\"image\" + 0.020*\"camera\" + 0.016*\"nasa\" + 0.016*\"taken\"\n",
      "2019-10-29 00:46:00,194 : INFO : topic #4 (0.100): 0.074*\"rover\" + 0.062*\"curiosity\" + 0.060*\"mar\" + 0.040*\"photo\" + 0.039*\"caption\" + 0.030*\"hide\" + 0.024*\"image\" + 0.018*\"camera\" + 0.015*\"nasa\" + 0.014*\"taken\"\n",
      "2019-10-29 00:46:00,198 : INFO : topic diff=1.214203, rho=1.000000\n",
      "2019-10-29 00:46:00,595 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:00,597 : INFO : built Dictionary(66 unique tokens: ['help', 'roaming', 'recently', 'morning', 'checking']...) from 5 documents (total 570 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:00,599 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:00,600 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:00,602 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:00,604 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:00,606 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:00,637 : INFO : -6.213 per-word bound, 74.2 perplexity estimate based on a held-out corpus of 5 documents with 570 words\n",
      "2019-10-29 00:46:00,638 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:00,645 : INFO : topic #1 (0.100): 0.057*\"nail\" + 0.053*\"rock\" + 0.049*\"fall\" + 0.041*\"police\" + 0.036*\"hour\" + 0.030*\"figure\" + 0.030*\"putting\" + 0.029*\"trying\" + 0.028*\"parent\" + 0.028*\"random\"\n",
      "2019-10-29 00:46:00,649 : INFO : topic #3 (0.100): 0.045*\"nail\" + 0.043*\"police\" + 0.034*\"driveway\" + 0.033*\"fall\" + 0.033*\"putting\" + 0.030*\"figure\" + 0.030*\"hour\" + 0.030*\"rock\" + 0.030*\"trying\" + 0.028*\"random\"\n",
      "2019-10-29 00:46:00,652 : INFO : topic #6 (0.100): 0.053*\"nail\" + 0.050*\"fall\" + 0.039*\"police\" + 0.036*\"rock\" + 0.036*\"hour\" + 0.034*\"figure\" + 0.031*\"driveway\" + 0.028*\"kid\" + 0.026*\"random\" + 0.026*\"putting\"\n",
      "2019-10-29 00:46:00,655 : INFO : topic #2 (0.100): 0.048*\"nail\" + 0.043*\"driveway\" + 0.041*\"rock\" + 0.040*\"police\" + 0.036*\"figure\" + 0.035*\"fall\" + 0.033*\"hour\" + 0.032*\"kid\" + 0.026*\"trying\" + 0.025*\"putting\"\n",
      "2019-10-29 00:46:00,657 : INFO : topic #0 (0.100): 0.045*\"nail\" + 0.041*\"rock\" + 0.040*\"hour\" + 0.036*\"fall\" + 0.036*\"kid\" + 0.034*\"figure\" + 0.033*\"putting\" + 0.033*\"parent\" + 0.031*\"driveway\" + 0.031*\"trying\"\n",
      "2019-10-29 00:46:00,659 : INFO : topic diff=0.880112, rho=1.000000\n",
      "2019-10-29 00:46:01,098 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:01,106 : INFO : built Dictionary(277 unique tokens: ['previously', 'concern', 'book', 'wading', 'come']...) from 5 documents (total 2245 corpus positions)\n",
      "2019-10-29 00:46:01,109 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:01,110 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:01,112 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:01,118 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:01,120 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:01,236 : INFO : -7.590 per-word bound, 192.7 perplexity estimate based on a held-out corpus of 5 documents with 2245 words\n",
      "2019-10-29 00:46:01,237 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:01,246 : INFO : topic #8 (0.100): 0.051*\"trump\" + 0.024*\"first\" + 0.018*\"said\" + 0.015*\"ivana\" + 0.015*\"lady\" + 0.015*\"wife\" + 0.014*\"president\" + 0.013*\"donald\" + 0.010*\"really\" + 0.009*\"book\"\n",
      "2019-10-29 00:46:01,249 : INFO : topic #0 (0.100): 0.043*\"trump\" + 0.024*\"president\" + 0.024*\"first\" + 0.023*\"said\" + 0.020*\"lady\" + 0.015*\"donald\" + 0.015*\"wife\" + 0.013*\"book\" + 0.012*\"ex\" + 0.012*\"ivana\"\n",
      "2019-10-29 00:46:01,252 : INFO : topic #7 (0.100): 0.039*\"trump\" + 0.022*\"lady\" + 0.022*\"first\" + 0.022*\"said\" + 0.020*\"president\" + 0.014*\"ivana\" + 0.013*\"donald\" + 0.011*\"book\" + 0.010*\"melania\" + 0.009*\"ex\"\n",
      "2019-10-29 00:46:01,255 : INFO : topic #2 (0.100): 0.039*\"trump\" + 0.027*\"first\" + 0.022*\"said\" + 0.017*\"president\" + 0.016*\"lady\" + 0.015*\"ivana\" + 0.014*\"really\" + 0.014*\"donald\" + 0.013*\"wife\" + 0.011*\"melania\"\n",
      "2019-10-29 00:46:01,257 : INFO : topic #6 (0.100): 0.047*\"trump\" + 0.022*\"said\" + 0.021*\"first\" + 0.020*\"lady\" + 0.017*\"president\" + 0.014*\"donald\" + 0.013*\"wife\" + 0.011*\"ivana\" + 0.010*\"book\" + 0.009*\"really\"\n",
      "2019-10-29 00:46:01,260 : INFO : topic diff=0.853322, rho=1.000000\n",
      "2019-10-29 00:46:01,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:01,735 : INFO : built Dictionary(447 unique tokens: ['located', 'assignment', 'deep', 'specie', 'surprisingly']...) from 5 documents (total 3465 corpus positions)\n",
      "2019-10-29 00:46:01,741 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:01,742 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:01,747 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:01,752 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:01,756 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:01,910 : INFO : -8.104 per-word bound, 275.1 perplexity estimate based on a held-out corpus of 5 documents with 3465 words\n",
      "2019-10-29 00:46:01,912 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:01,924 : INFO : topic #0 (0.100): 0.033*\"reef\" + 0.024*\"sea\" + 0.023*\"coral\" + 0.012*\"turtle\" + 0.011*\"barrier\" + 0.011*\"one\" + 0.011*\"shark\" + 0.010*\"island\" + 0.009*\"great\" + 0.009*\"world\"\n",
      "2019-10-29 00:46:01,926 : INFO : topic #5 (0.100): 0.039*\"reef\" + 0.021*\"sea\" + 0.021*\"coral\" + 0.015*\"great\" + 0.014*\"barrier\" + 0.011*\"island\" + 0.010*\"turtle\" + 0.009*\"world\" + 0.008*\"shark\" + 0.008*\"one\"\n",
      "2019-10-29 00:46:01,932 : INFO : topic #2 (0.100): 0.038*\"reef\" + 0.029*\"sea\" + 0.021*\"coral\" + 0.013*\"great\" + 0.013*\"barrier\" + 0.011*\"island\" + 0.011*\"turtle\" + 0.009*\"world\" + 0.009*\"one\" + 0.007*\"shark\"\n",
      "2019-10-29 00:46:01,940 : INFO : topic #9 (0.100): 0.028*\"reef\" + 0.027*\"coral\" + 0.024*\"sea\" + 0.019*\"great\" + 0.012*\"turtle\" + 0.012*\"barrier\" + 0.011*\"island\" + 0.010*\"shark\" + 0.009*\"one\" + 0.007*\"water\"\n",
      "2019-10-29 00:46:01,943 : INFO : topic #1 (0.100): 0.037*\"reef\" + 0.030*\"coral\" + 0.025*\"sea\" + 0.013*\"turtle\" + 0.012*\"great\" + 0.012*\"shark\" + 0.010*\"world\" + 0.010*\"island\" + 0.009*\"water\" + 0.008*\"egg\"\n",
      "2019-10-29 00:46:01,946 : INFO : topic diff=0.848284, rho=1.000000\n",
      "2019-10-29 00:46:02,393 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:02,398 : INFO : built Dictionary(259 unique tokens: ['violence', 'espinosa', 'vague', 'reserved', 'u']...) from 5 documents (total 2020 corpus positions)\n",
      "2019-10-29 00:46:02,401 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:02,402 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:02,403 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:02,407 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:02,409 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:02,495 : INFO : -7.578 per-word bound, 191.1 perplexity estimate based on a held-out corpus of 5 documents with 2020 words\n",
      "2019-10-29 00:46:02,496 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:02,505 : INFO : topic #7 (0.100): 0.028*\"health\" + 0.027*\"condition\" + 0.025*\"existing\" + 0.018*\"pre\" + 0.017*\"care\" + 0.014*\"insurer\" + 0.013*\"could\" + 0.011*\"pregnancy\" + 0.011*\"disease\" + 0.010*\"list\"\n",
      "2019-10-29 00:46:02,508 : INFO : topic #4 (0.100): 0.036*\"condition\" + 0.031*\"health\" + 0.025*\"existing\" + 0.024*\"pre\" + 0.015*\"could\" + 0.013*\"insurer\" + 0.013*\"list\" + 0.012*\"disease\" + 0.011*\"pregnancy\" + 0.010*\"uninsurable\"\n",
      "2019-10-29 00:46:02,511 : INFO : topic #8 (0.100): 0.034*\"condition\" + 0.028*\"health\" + 0.028*\"existing\" + 0.025*\"pre\" + 0.013*\"list\" + 0.013*\"care\" + 0.012*\"disease\" + 0.012*\"insurer\" + 0.011*\"could\" + 0.010*\"issue\"\n",
      "2019-10-29 00:46:02,515 : INFO : topic #3 (0.100): 0.031*\"health\" + 0.028*\"condition\" + 0.027*\"pre\" + 0.021*\"existing\" + 0.013*\"care\" + 0.012*\"insurer\" + 0.012*\"could\" + 0.012*\"pregnancy\" + 0.011*\"new\" + 0.009*\"disease\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:02,517 : INFO : topic #1 (0.100): 0.034*\"condition\" + 0.027*\"existing\" + 0.025*\"health\" + 0.022*\"pre\" + 0.014*\"could\" + 0.012*\"disease\" + 0.012*\"list\" + 0.011*\"issue\" + 0.011*\"pregnancy\" + 0.010*\"insurer\"\n",
      "2019-10-29 00:46:02,521 : INFO : topic diff=0.827171, rho=1.000000\n",
      "2019-10-29 00:46:02,977 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:02,986 : INFO : built Dictionary(555 unique tokens: ['although', 'earned', 'prime', 'wave', 'across']...) from 5 documents (total 5720 corpus positions)\n",
      "2019-10-29 00:46:02,994 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:02,996 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:02,997 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:03,000 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:03,002 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:03,177 : INFO : -7.955 per-word bound, 248.1 perplexity estimate based on a held-out corpus of 5 documents with 5720 words\n",
      "2019-10-29 00:46:03,179 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:03,191 : INFO : topic #9 (0.100): 0.019*\"resort\" + 0.018*\"golf\" + 0.018*\"hole\" + 0.016*\"course\" + 0.014*\"two\" + 0.014*\"including\" + 0.010*\"round\" + 0.009*\"cost\" + 0.008*\"regular\" + 0.008*\"island\"\n",
      "2019-10-29 00:46:03,194 : INFO : topic #7 (0.100): 0.021*\"two\" + 0.019*\"course\" + 0.018*\"golf\" + 0.016*\"including\" + 0.015*\"hole\" + 0.011*\"round\" + 0.011*\"resort\" + 0.010*\"night\" + 0.009*\"island\" + 0.008*\"three\"\n",
      "2019-10-29 00:46:03,198 : INFO : topic #5 (0.100): 0.019*\"course\" + 0.017*\"golf\" + 0.017*\"two\" + 0.016*\"resort\" + 0.016*\"hole\" + 0.013*\"including\" + 0.011*\"night\" + 0.010*\"island\" + 0.010*\"couple\" + 0.009*\"round\"\n",
      "2019-10-29 00:46:03,201 : INFO : topic #4 (0.100): 0.023*\"golf\" + 0.022*\"two\" + 0.018*\"course\" + 0.016*\"hole\" + 0.014*\"resort\" + 0.013*\"including\" + 0.011*\"round\" + 0.010*\"cost\" + 0.010*\"total\" + 0.008*\"night\"\n",
      "2019-10-29 00:46:03,205 : INFO : topic #2 (0.100): 0.022*\"golf\" + 0.019*\"hole\" + 0.019*\"two\" + 0.016*\"course\" + 0.015*\"resort\" + 0.013*\"including\" + 0.012*\"night\" + 0.011*\"total\" + 0.008*\"round\" + 0.007*\"grand\"\n",
      "2019-10-29 00:46:03,208 : INFO : topic diff=0.967698, rho=1.000000\n",
      "2019-10-29 00:46:03,631 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:03,636 : INFO : built Dictionary(133 unique tokens: ['ovation', 'affected', 'end', 'extensive', 'place']...) from 5 documents (total 830 corpus positions)\n",
      "2019-10-29 00:46:03,641 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:03,643 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:03,646 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:03,650 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:03,653 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:03,741 : INFO : -7.352 per-word bound, 163.4 perplexity estimate based on a held-out corpus of 5 documents with 830 words\n",
      "2019-10-29 00:46:03,750 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:03,757 : INFO : topic #7 (0.100): 0.039*\"youssif\" + 0.023*\"story\" + 0.023*\"child\" + 0.022*\"tear\" + 0.021*\"heart\" + 0.017*\"young\" + 0.016*\"cnn\" + 0.014*\"world\" + 0.014*\"captured\" + 0.013*\"make\"\n",
      "2019-10-29 00:46:03,759 : INFO : topic #1 (0.100): 0.036*\"youssif\" + 0.027*\"child\" + 0.022*\"tear\" + 0.022*\"story\" + 0.018*\"world\" + 0.017*\"young\" + 0.015*\"heart\" + 0.015*\"chance\" + 0.014*\"cnn\" + 0.012*\"make\"\n",
      "2019-10-29 00:46:03,762 : INFO : topic #0 (0.100): 0.031*\"youssif\" + 0.029*\"child\" + 0.023*\"story\" + 0.022*\"world\" + 0.021*\"tear\" + 0.020*\"cnn\" + 0.018*\"young\" + 0.015*\"heart\" + 0.013*\"million\" + 0.013*\"make\"\n",
      "2019-10-29 00:46:03,765 : INFO : topic #9 (0.100): 0.042*\"youssif\" + 0.031*\"child\" + 0.027*\"story\" + 0.019*\"tear\" + 0.018*\"young\" + 0.017*\"world\" + 0.017*\"cnn\" + 0.015*\"heart\" + 0.014*\"one\" + 0.013*\"man\"\n",
      "2019-10-29 00:46:03,767 : INFO : topic #2 (0.100): 0.035*\"youssif\" + 0.024*\"tear\" + 0.022*\"child\" + 0.019*\"heart\" + 0.019*\"story\" + 0.018*\"cnn\" + 0.017*\"young\" + 0.016*\"world\" + 0.015*\"damon\" + 0.014*\"one\"\n",
      "2019-10-29 00:46:03,770 : INFO : topic diff=0.731345, rho=1.000000\n",
      "2019-10-29 00:46:04,208 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:04,211 : INFO : built Dictionary(251 unique tokens: ['even', 'prime', 'beleaguered', 'campaign', 'party']...) from 5 documents (total 1730 corpus positions)\n",
      "2019-10-29 00:46:04,215 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:04,216 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:04,218 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:04,221 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:04,222 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:04,310 : INFO : -7.747 per-word bound, 214.9 perplexity estimate based on a held-out corpus of 5 documents with 1730 words\n",
      "2019-10-29 00:46:04,311 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:04,319 : INFO : topic #0 (0.100): 0.030*\"may\" + 0.019*\"speech\" + 0.017*\"theresa\" + 0.016*\"brodkin\" + 0.016*\"minister\" + 0.013*\"prime\" + 0.011*\"stage\" + 0.010*\"britain\" + 0.009*\"party\" + 0.009*\"election\"\n",
      "2019-10-29 00:46:04,322 : INFO : topic #5 (0.100): 0.023*\"speech\" + 0.022*\"may\" + 0.016*\"minister\" + 0.016*\"party\" + 0.013*\"prime\" + 0.013*\"theresa\" + 0.011*\"brodkin\" + 0.009*\"conference\" + 0.009*\"stage\" + 0.009*\"fall\"\n",
      "2019-10-29 00:46:04,324 : INFO : topic #3 (0.100): 0.026*\"may\" + 0.019*\"speech\" + 0.017*\"theresa\" + 0.015*\"prime\" + 0.015*\"minister\" + 0.012*\"brodkin\" + 0.011*\"party\" + 0.010*\"keynote\" + 0.010*\"conference\" + 0.009*\"fall\"\n",
      "2019-10-29 00:46:04,327 : INFO : topic #7 (0.100): 0.030*\"may\" + 0.022*\"speech\" + 0.019*\"theresa\" + 0.016*\"minister\" + 0.014*\"party\" + 0.012*\"prime\" + 0.011*\"brodkin\" + 0.009*\"britain\" + 0.009*\"cough\" + 0.009*\"marred\"\n",
      "2019-10-29 00:46:04,330 : INFO : topic #2 (0.100): 0.024*\"may\" + 0.021*\"speech\" + 0.017*\"brodkin\" + 0.017*\"party\" + 0.016*\"theresa\" + 0.015*\"minister\" + 0.012*\"stage\" + 0.011*\"prime\" + 0.011*\"campaign\" + 0.008*\"cough\"\n",
      "2019-10-29 00:46:04,333 : INFO : topic diff=0.758657, rho=1.000000\n",
      "2019-10-29 00:46:04,720 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:04,722 : INFO : built Dictionary(76 unique tokens: ['miracle', 'nutritious', 'grown', 'transforming', 'cultivated']...) from 5 documents (total 520 corpus positions)\n",
      "2019-10-29 00:46:04,724 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:04,726 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:04,731 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:04,734 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:04,737 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:04,778 : INFO : -6.715 per-word bound, 105.1 perplexity estimate based on a held-out corpus of 5 documents with 520 words\n",
      "2019-10-29 00:46:04,779 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:04,786 : INFO : topic #9 (0.100): 0.048*\"grain\" + 0.036*\"fonio\" + 0.034*\"could\" + 0.029*\"economy\" + 0.029*\"sahel\" + 0.027*\"miracle\" + 0.026*\"thiam\" + 0.024*\"quinoa\" + 0.021*\"exporting\" + 0.020*\"chef\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:04,788 : INFO : topic #8 (0.100): 0.065*\"grain\" + 0.032*\"fonio\" + 0.032*\"thiam\" + 0.030*\"could\" + 0.029*\"economy\" + 0.028*\"sahel\" + 0.024*\"quinoa\" + 0.024*\"miracle\" + 0.020*\"belief\" + 0.018*\"year\"\n",
      "2019-10-29 00:46:04,790 : INFO : topic #3 (0.100): 0.041*\"fonio\" + 0.039*\"grain\" + 0.031*\"thiam\" + 0.030*\"economy\" + 0.028*\"sahel\" + 0.026*\"miracle\" + 0.026*\"quinoa\" + 0.025*\"year\" + 0.025*\"next\" + 0.022*\"pierre\"\n",
      "2019-10-29 00:46:04,796 : INFO : topic #6 (0.100): 0.060*\"grain\" + 0.033*\"miracle\" + 0.032*\"quinoa\" + 0.029*\"economy\" + 0.028*\"fonio\" + 0.026*\"sahel\" + 0.025*\"thiam\" + 0.024*\"could\" + 0.021*\"next\" + 0.021*\"belief\"\n",
      "2019-10-29 00:46:04,799 : INFO : topic #7 (0.100): 0.051*\"fonio\" + 0.050*\"grain\" + 0.033*\"sahel\" + 0.030*\"economy\" + 0.028*\"quinoa\" + 0.027*\"could\" + 0.023*\"miracle\" + 0.022*\"chef\" + 0.021*\"thiam\" + 0.020*\"africa\"\n",
      "2019-10-29 00:46:04,802 : INFO : topic diff=0.785036, rho=1.000000\n",
      "2019-10-29 00:46:05,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:05,254 : INFO : built Dictionary(29 unique tokens: ['murray', 'interview', 'bob', 'setting', 'president']...) from 5 documents (total 170 corpus positions)\n",
      "2019-10-29 00:46:05,255 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:05,257 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:05,258 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:05,260 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:05,262 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:05,282 : INFO : -6.339 per-word bound, 80.9 perplexity estimate based on a held-out corpus of 5 documents with 170 words\n",
      "2019-10-29 00:46:05,283 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:05,289 : INFO : topic #9 (0.100): 0.062*\"trump\" + 0.055*\"iii\" + 0.054*\"war\" + 0.047*\"senator\" + 0.047*\"world\" + 0.038*\"gop\" + 0.035*\"report\" + 0.035*\"path\" + 0.034*\"u\" + 0.034*\"new\"\n",
      "2019-10-29 00:46:05,290 : INFO : topic #3 (0.100): 0.060*\"trump\" + 0.056*\"world\" + 0.052*\"senator\" + 0.048*\"iii\" + 0.047*\"war\" + 0.040*\"gop\" + 0.037*\"bob\" + 0.035*\"country\" + 0.035*\"murray\" + 0.034*\"fear\"\n",
      "2019-10-29 00:46:05,296 : INFO : topic #4 (0.100): 0.065*\"world\" + 0.063*\"war\" + 0.061*\"senator\" + 0.053*\"iii\" + 0.045*\"trump\" + 0.037*\"york\" + 0.037*\"setting\" + 0.036*\"foreign\" + 0.035*\"corker\" + 0.034*\"relation\"\n",
      "2019-10-29 00:46:05,299 : INFO : topic #6 (0.100): 0.069*\"world\" + 0.061*\"senator\" + 0.057*\"iii\" + 0.053*\"war\" + 0.044*\"trump\" + 0.039*\"foreign\" + 0.036*\"cnn\" + 0.036*\"relation\" + 0.035*\"murray\" + 0.034*\"new\"\n",
      "2019-10-29 00:46:05,303 : INFO : topic #8 (0.100): 0.062*\"world\" + 0.061*\"trump\" + 0.061*\"iii\" + 0.053*\"senator\" + 0.045*\"war\" + 0.039*\"time\" + 0.034*\"corker\" + 0.033*\"pushing\" + 0.033*\"york\" + 0.032*\"relation\"\n",
      "2019-10-29 00:46:05,307 : INFO : topic diff=0.628437, rho=1.000000\n",
      "2019-10-29 00:46:05,817 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:05,832 : INFO : built Dictionary(981 unique tokens: ['although', 'let', 'filed', 'portion', 'wade']...) from 5 documents (total 10130 corpus positions)\n",
      "2019-10-29 00:46:05,843 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:05,844 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:05,846 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:05,851 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:05,853 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:06,180 : INFO : -8.509 per-word bound, 364.2 perplexity estimate based on a held-out corpus of 5 documents with 10130 words\n",
      "2019-10-29 00:46:06,182 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:06,198 : INFO : topic #4 (0.100): 0.021*\"lesli\" + 0.016*\"say\" + 0.016*\"dortha\" + 0.016*\"would\" + 0.011*\"year\" + 0.009*\"texas\" + 0.008*\"daughter\" + 0.007*\"doctor\" + 0.007*\"birth\" + 0.007*\"hand\"\n",
      "2019-10-29 00:46:06,203 : INFO : topic #6 (0.100): 0.021*\"dortha\" + 0.020*\"say\" + 0.017*\"lesli\" + 0.012*\"would\" + 0.010*\"daughter\" + 0.009*\"texas\" + 0.009*\"home\" + 0.008*\"never\" + 0.007*\"hand\" + 0.006*\"mother\"\n",
      "2019-10-29 00:46:06,208 : INFO : topic #7 (0.100): 0.025*\"lesli\" + 0.020*\"dortha\" + 0.014*\"would\" + 0.011*\"say\" + 0.010*\"texas\" + 0.009*\"year\" + 0.008*\"never\" + 0.008*\"birth\" + 0.008*\"daughter\" + 0.007*\"child\"\n",
      "2019-10-29 00:46:06,211 : INFO : topic #9 (0.100): 0.023*\"dortha\" + 0.022*\"lesli\" + 0.018*\"say\" + 0.013*\"would\" + 0.009*\"daughter\" + 0.008*\"texas\" + 0.008*\"year\" + 0.007*\"doctor\" + 0.007*\"hand\" + 0.007*\"never\"\n",
      "2019-10-29 00:46:06,214 : INFO : topic #1 (0.100): 0.024*\"dortha\" + 0.022*\"lesli\" + 0.014*\"would\" + 0.012*\"say\" + 0.008*\"hand\" + 0.008*\"texas\" + 0.008*\"home\" + 0.008*\"birth\" + 0.008*\"year\" + 0.007*\"doctor\"\n",
      "2019-10-29 00:46:06,218 : INFO : topic diff=0.975629, rho=1.000000\n",
      "2019-10-29 00:46:06,719 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:06,725 : INFO : built Dictionary(273 unique tokens: ['josh', 'forecast', 'digit', 'end', 'crest']...) from 5 documents (total 3270 corpus positions)\n",
      "2019-10-29 00:46:06,729 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:06,730 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:06,732 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:06,736 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:06,737 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:06,830 : INFO : -7.117 per-word bound, 138.8 perplexity estimate based on a held-out corpus of 5 documents with 3270 words\n",
      "2019-10-29 00:46:06,831 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:06,839 : INFO : topic #0 (0.100): 0.055*\"wildfire\" + 0.049*\"california\" + 0.046*\"blaze\" + 0.043*\"october\" + 0.041*\"photo\" + 0.039*\"caption\" + 0.035*\"hide\" + 0.021*\"home\" + 0.017*\"santa\" + 0.016*\"rosa\"\n",
      "2019-10-29 00:46:06,842 : INFO : topic #9 (0.100): 0.056*\"october\" + 0.054*\"wildfire\" + 0.052*\"california\" + 0.050*\"photo\" + 0.048*\"caption\" + 0.040*\"hide\" + 0.039*\"blaze\" + 0.024*\"santa\" + 0.017*\"rosa\" + 0.015*\"napa\"\n",
      "2019-10-29 00:46:06,844 : INFO : topic #3 (0.100): 0.068*\"wildfire\" + 0.051*\"photo\" + 0.047*\"caption\" + 0.042*\"california\" + 0.042*\"blaze\" + 0.039*\"hide\" + 0.034*\"october\" + 0.018*\"rosa\" + 0.015*\"napa\" + 0.015*\"santa\"\n",
      "2019-10-29 00:46:06,847 : INFO : topic #4 (0.100): 0.068*\"california\" + 0.066*\"wildfire\" + 0.047*\"october\" + 0.043*\"blaze\" + 0.043*\"hide\" + 0.042*\"caption\" + 0.039*\"photo\" + 0.019*\"home\" + 0.019*\"santa\" + 0.014*\"rosa\"\n",
      "2019-10-29 00:46:06,848 : INFO : topic #8 (0.100): 0.058*\"california\" + 0.055*\"caption\" + 0.048*\"photo\" + 0.046*\"october\" + 0.043*\"wildfire\" + 0.043*\"blaze\" + 0.041*\"hide\" + 0.018*\"rosa\" + 0.018*\"santa\" + 0.013*\"napa\"\n",
      "2019-10-29 00:46:06,850 : INFO : topic diff=1.152405, rho=1.000000\n",
      "2019-10-29 00:46:07,251 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:07,253 : INFO : built Dictionary(37 unique tokens: ['existing', 'considered', 'bill', 'could', 'problem']...) from 5 documents (total 275 corpus positions)\n",
      "2019-10-29 00:46:07,255 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:07,257 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:07,258 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:07,260 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:07,261 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:07,282 : INFO : -6.009 per-word bound, 64.4 perplexity estimate based on a held-out corpus of 5 documents with 275 words\n",
      "2019-10-29 00:46:07,284 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:07,289 : INFO : topic #7 (0.100): 0.082*\"health\" + 0.073*\"existing\" + 0.069*\"condition\" + 0.065*\"pre\" + 0.049*\"list\" + 0.037*\"care\" + 0.035*\"new\" + 0.032*\"bill\" + 0.025*\"million\" + 0.025*\"adult\"\n",
      "2019-10-29 00:46:07,292 : INFO : topic #1 (0.100): 0.074*\"health\" + 0.073*\"pre\" + 0.069*\"condition\" + 0.067*\"existing\" + 0.045*\"list\" + 0.042*\"care\" + 0.035*\"new\" + 0.029*\"bill\" + 0.027*\"estimated\" + 0.025*\"comprehensive\"\n",
      "2019-10-29 00:46:07,295 : INFO : topic #6 (0.100): 0.093*\"condition\" + 0.078*\"pre\" + 0.058*\"existing\" + 0.055*\"health\" + 0.051*\"list\" + 0.033*\"care\" + 0.031*\"new\" + 0.025*\"bill\" + 0.025*\"gop\" + 0.022*\"declinable\"\n",
      "2019-10-29 00:46:07,297 : INFO : topic #0 (0.100): 0.096*\"health\" + 0.094*\"existing\" + 0.071*\"pre\" + 0.049*\"condition\" + 0.046*\"list\" + 0.042*\"care\" + 0.037*\"bill\" + 0.034*\"new\" + 0.026*\"problem\" + 0.024*\"issue\"\n",
      "2019-10-29 00:46:07,299 : INFO : topic #9 (0.100): 0.096*\"health\" + 0.069*\"existing\" + 0.065*\"condition\" + 0.049*\"list\" + 0.047*\"pre\" + 0.037*\"new\" + 0.035*\"bill\" + 0.028*\"care\" + 0.025*\"term\" + 0.025*\"protection\"\n",
      "2019-10-29 00:46:07,300 : INFO : topic diff=0.866572, rho=1.000000\n",
      "2019-10-29 00:46:07,760 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:07,771 : INFO : built Dictionary(625 unique tokens: ['previously', 'let', 'person', 'relationship', 'laboratory']...) from 5 documents (total 5375 corpus positions)\n",
      "2019-10-29 00:46:07,781 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:07,784 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:07,788 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:07,793 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:07,796 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:08,009 : INFO : -8.287 per-word bound, 312.2 perplexity estimate based on a held-out corpus of 5 documents with 5375 words\n",
      "2019-10-29 00:46:08,011 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:08,022 : INFO : topic #5 (0.100): 0.033*\"color\" + 0.014*\"one\" + 0.012*\"blue\" + 0.010*\"synesthesia\" + 0.009*\"would\" + 0.008*\"back\" + 0.007*\"like\" + 0.007*\"time\" + 0.007*\"sensory\" + 0.006*\"janet\"\n",
      "2019-10-29 00:46:08,024 : INFO : topic #4 (0.100): 0.033*\"color\" + 0.016*\"one\" + 0.012*\"synesthesia\" + 0.009*\"blue\" + 0.009*\"would\" + 0.007*\"daniel\" + 0.007*\"back\" + 0.007*\"sensory\" + 0.006*\"like\" + 0.006*\"time\"\n",
      "2019-10-29 00:46:08,025 : INFO : topic #2 (0.100): 0.039*\"color\" + 0.018*\"one\" + 0.012*\"blue\" + 0.012*\"synesthesia\" + 0.008*\"sensory\" + 0.007*\"time\" + 0.007*\"would\" + 0.007*\"back\" + 0.007*\"giles\" + 0.006*\"vision\"\n",
      "2019-10-29 00:46:08,027 : INFO : topic #1 (0.100): 0.033*\"color\" + 0.015*\"one\" + 0.014*\"blue\" + 0.010*\"synesthesia\" + 0.009*\"time\" + 0.008*\"would\" + 0.007*\"back\" + 0.007*\"sensory\" + 0.006*\"visual\" + 0.006*\"vision\"\n",
      "2019-10-29 00:46:08,028 : INFO : topic #0 (0.100): 0.031*\"color\" + 0.014*\"synesthesia\" + 0.012*\"one\" + 0.011*\"blue\" + 0.008*\"daniel\" + 0.007*\"time\" + 0.007*\"would\" + 0.007*\"visual\" + 0.006*\"vision\" + 0.006*\"brain\"\n",
      "2019-10-29 00:46:08,031 : INFO : topic diff=0.892698, rho=1.000000\n",
      "2019-10-29 00:46:08,482 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:08,486 : INFO : built Dictionary(333 unique tokens: ['kugelman', 'offered', 'perhaps', 'campaign', 'nation']...) from 5 documents (total 2320 corpus positions)\n",
      "2019-10-29 00:46:08,490 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:08,491 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:08,492 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:08,496 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:08,497 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:08,603 : INFO : -7.998 per-word bound, 255.6 perplexity estimate based on a held-out corpus of 5 documents with 2320 words\n",
      "2019-10-29 00:46:08,604 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:08,610 : INFO : topic #4 (0.100): 0.023*\"afghanistan\" + 0.022*\"war\" + 0.020*\"american\" + 0.019*\"year\" + 0.014*\"strategy\" + 0.013*\"u\" + 0.010*\"america\" + 0.010*\"new\" + 0.010*\"qaeda\" + 0.008*\"time\"\n",
      "2019-10-29 00:46:08,612 : INFO : topic #0 (0.100): 0.020*\"afghanistan\" + 0.018*\"war\" + 0.017*\"american\" + 0.016*\"strategy\" + 0.014*\"year\" + 0.013*\"america\" + 0.012*\"u\" + 0.009*\"qaeda\" + 0.009*\"al\" + 0.008*\"new\"\n",
      "2019-10-29 00:46:08,614 : INFO : topic #6 (0.100): 0.028*\"afghanistan\" + 0.021*\"war\" + 0.016*\"u\" + 0.014*\"american\" + 0.013*\"year\" + 0.012*\"america\" + 0.010*\"new\" + 0.009*\"yet\" + 0.009*\"strategy\" + 0.008*\"al\"\n",
      "2019-10-29 00:46:08,617 : INFO : topic #3 (0.100): 0.026*\"war\" + 0.022*\"american\" + 0.016*\"year\" + 0.015*\"afghanistan\" + 0.014*\"u\" + 0.012*\"strategy\" + 0.011*\"new\" + 0.009*\"america\" + 0.008*\"billion\" + 0.008*\"qaeda\"\n",
      "2019-10-29 00:46:08,620 : INFO : topic #1 (0.100): 0.024*\"war\" + 0.023*\"afghanistan\" + 0.019*\"american\" + 0.016*\"u\" + 0.016*\"year\" + 0.014*\"strategy\" + 0.010*\"new\" + 0.010*\"america\" + 0.010*\"yet\" + 0.008*\"qaeda\"\n",
      "2019-10-29 00:46:08,623 : INFO : topic diff=0.810186, rho=1.000000\n",
      "2019-10-29 00:46:09,029 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:09,033 : INFO : built Dictionary(298 unique tokens: ['face', 'span', 'small', 'camp', 'severely']...) from 5 documents (total 2280 corpus positions)\n",
      "2019-10-29 00:46:09,037 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:09,038 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:09,039 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:09,043 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:09,044 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:09,148 : INFO : -7.738 per-word bound, 213.6 perplexity estimate based on a held-out corpus of 5 documents with 2280 words\n",
      "2019-10-29 00:46:09,149 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:09,157 : INFO : topic #1 (0.100): 0.022*\"hoopen\" + 0.021*\"ten\" + 0.017*\"refugee\" + 0.017*\"said\" + 0.014*\"way\" + 0.014*\"hospital\" + 0.013*\"photo\" + 0.012*\"studio\" + 0.011*\"people\" + 0.011*\"used\"\n",
      "2019-10-29 00:46:09,160 : INFO : topic #9 (0.100): 0.022*\"ten\" + 0.021*\"refugee\" + 0.016*\"hoopen\" + 0.015*\"hospital\" + 0.015*\"said\" + 0.014*\"studio\" + 0.013*\"photo\" + 0.012*\"way\" + 0.011*\"one\" + 0.010*\"people\"\n",
      "2019-10-29 00:46:09,163 : INFO : topic #2 (0.100): 0.023*\"ten\" + 0.022*\"refugee\" + 0.020*\"hoopen\" + 0.018*\"studio\" + 0.015*\"hospital\" + 0.014*\"said\" + 0.012*\"way\" + 0.010*\"one\" + 0.009*\"photo\" + 0.008*\"person\"\n",
      "2019-10-29 00:46:09,167 : INFO : topic #5 (0.100): 0.019*\"ten\" + 0.018*\"refugee\" + 0.016*\"hoopen\" + 0.015*\"said\" + 0.015*\"studio\" + 0.015*\"hospital\" + 0.013*\"photo\" + 0.012*\"people\" + 0.012*\"way\" + 0.011*\"one\"\n",
      "2019-10-29 00:46:09,171 : INFO : topic #6 (0.100): 0.019*\"hoopen\" + 0.019*\"hospital\" + 0.018*\"studio\" + 0.016*\"refugee\" + 0.015*\"ten\" + 0.015*\"said\" + 0.013*\"photo\" + 0.012*\"people\" + 0.011*\"way\" + 0.010*\"one\"\n",
      "2019-10-29 00:46:09,174 : INFO : topic diff=0.832320, rho=1.000000\n",
      "2019-10-29 00:46:09,636 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:09,647 : INFO : built Dictionary(712 unique tokens: ['earned', 'assignment', 'across', 'vecchio', 'instant']...) from 5 documents (total 5950 corpus positions)\n",
      "2019-10-29 00:46:09,655 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:09,657 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:09,660 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:09,664 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:09,666 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:09,891 : INFO : -8.453 per-word bound, 350.5 perplexity estimate based on a held-out corpus of 5 documents with 5950 words\n",
      "2019-10-29 00:46:09,893 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:09,904 : INFO : topic #4 (0.100): 0.029*\"photograph\" + 0.022*\"photo\" + 0.022*\"caption\" + 0.022*\"iconic\" + 0.019*\"hide\" + 0.012*\"image\" + 0.010*\"war\" + 0.007*\"prize\" + 0.007*\"time\" + 0.007*\"people\"\n",
      "2019-10-29 00:46:09,907 : INFO : topic #1 (0.100): 0.022*\"iconic\" + 0.020*\"caption\" + 0.020*\"photograph\" + 0.019*\"photo\" + 0.018*\"image\" + 0.017*\"hide\" + 0.010*\"photographer\" + 0.008*\"prize\" + 0.008*\"war\" + 0.007*\"people\"\n",
      "2019-10-29 00:46:09,910 : INFO : topic #7 (0.100): 0.030*\"photograph\" + 0.020*\"hide\" + 0.020*\"photo\" + 0.019*\"caption\" + 0.014*\"image\" + 0.013*\"iconic\" + 0.008*\"war\" + 0.008*\"photographer\" + 0.007*\"prize\" + 0.007*\"time\"\n",
      "2019-10-29 00:46:09,914 : INFO : topic #6 (0.100): 0.038*\"photograph\" + 0.021*\"caption\" + 0.021*\"iconic\" + 0.017*\"hide\" + 0.017*\"photo\" + 0.014*\"image\" + 0.008*\"war\" + 0.008*\"became\" + 0.007*\"people\" + 0.007*\"photographer\"\n",
      "2019-10-29 00:46:09,917 : INFO : topic #2 (0.100): 0.041*\"photograph\" + 0.017*\"hide\" + 0.017*\"photo\" + 0.015*\"caption\" + 0.013*\"iconic\" + 0.012*\"image\" + 0.010*\"war\" + 0.008*\"photographer\" + 0.007*\"time\" + 0.006*\"later\"\n",
      "2019-10-29 00:46:09,920 : INFO : topic diff=0.884813, rho=1.000000\n",
      "2019-10-29 00:46:10,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:10,479 : INFO : built Dictionary(1113 unique tokens: ['although', 'let', 'phase', 'treasured', 'grew']...) from 5 documents (total 10610 corpus positions)\n",
      "2019-10-29 00:46:10,491 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:10,493 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:10,495 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:10,500 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:10,505 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:10,843 : INFO : -8.726 per-word bound, 423.4 perplexity estimate based on a held-out corpus of 5 documents with 10610 words\n",
      "2019-10-29 00:46:10,844 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:10,859 : INFO : topic #9 (0.100): 0.033*\"claire\" + 0.013*\"say\" + 0.009*\"life\" + 0.007*\"yeager\" + 0.007*\"said\" + 0.007*\"hospital\" + 0.006*\"day\" + 0.005*\"like\" + 0.005*\"sick\" + 0.005*\"year\"\n",
      "2019-10-29 00:46:10,861 : INFO : topic #5 (0.100): 0.035*\"claire\" + 0.014*\"say\" + 0.009*\"said\" + 0.008*\"life\" + 0.007*\"people\" + 0.007*\"hospital\" + 0.007*\"yeager\" + 0.006*\"feel\" + 0.006*\"body\" + 0.006*\"day\"\n",
      "2019-10-29 00:46:10,864 : INFO : topic #4 (0.100): 0.034*\"claire\" + 0.016*\"say\" + 0.008*\"yeager\" + 0.007*\"said\" + 0.007*\"life\" + 0.007*\"sick\" + 0.006*\"make\" + 0.006*\"like\" + 0.006*\"hospital\" + 0.005*\"people\"\n",
      "2019-10-29 00:46:10,869 : INFO : topic #2 (0.100): 0.033*\"claire\" + 0.014*\"say\" + 0.008*\"life\" + 0.008*\"said\" + 0.006*\"sick\" + 0.006*\"lung\" + 0.006*\"never\" + 0.006*\"people\" + 0.006*\"day\" + 0.005*\"year\"\n",
      "2019-10-29 00:46:10,872 : INFO : topic #3 (0.100): 0.037*\"claire\" + 0.011*\"say\" + 0.009*\"said\" + 0.008*\"life\" + 0.007*\"yeager\" + 0.006*\"sick\" + 0.006*\"could\" + 0.006*\"hospital\" + 0.006*\"day\" + 0.005*\"people\"\n",
      "2019-10-29 00:46:10,875 : INFO : topic diff=0.928480, rho=1.000000\n",
      "2019-10-29 00:46:11,275 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:11,276 : INFO : built Dictionary(28 unique tokens: ['picturesque', 'guy', 'see', 'cnn', 'fishing']...) from 5 documents (total 155 corpus positions)\n",
      "2019-10-29 00:46:11,278 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:11,279 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:11,280 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:11,282 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:11,283 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:11,305 : INFO : -6.456 per-word bound, 87.8 perplexity estimate based on a held-out corpus of 5 documents with 155 words\n",
      "2019-10-29 00:46:11,307 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:11,314 : INFO : topic #6 (0.100): 0.066*\"cnn\" + 0.061*\"north\" + 0.059*\"korea\" + 0.043*\"videogames\" + 0.039*\"guy\" + 0.036*\"day\" + 0.036*\"follow\" + 0.036*\"rare\" + 0.036*\"life\" + 0.035*\"picturesque\"\n",
      "2019-10-29 00:46:11,316 : INFO : topic #1 (0.100): 0.059*\"cnn\" + 0.056*\"north\" + 0.050*\"korea\" + 0.044*\"missile\" + 0.042*\"see\" + 0.039*\"answer\" + 0.039*\"rare\" + 0.038*\"guy\" + 0.038*\"watching\" + 0.037*\"ripley\"\n",
      "2019-10-29 00:46:11,318 : INFO : topic #2 (0.100): 0.061*\"korea\" + 0.058*\"cnn\" + 0.049*\"north\" + 0.041*\"fishing\" + 0.039*\"watching\" + 0.039*\"see\" + 0.038*\"follow\" + 0.037*\"privileged\" + 0.036*\"videogames\" + 0.035*\"glimpse\"\n",
      "2019-10-29 00:46:11,320 : INFO : topic #3 (0.100): 0.069*\"korea\" + 0.067*\"cnn\" + 0.054*\"north\" + 0.040*\"everyday\" + 0.039*\"ripley\" + 0.038*\"day\" + 0.036*\"videogames\" + 0.036*\"ordinary\" + 0.036*\"pyongyang\" + 0.036*\"missile\"\n",
      "2019-10-29 00:46:11,322 : INFO : topic #5 (0.100): 0.075*\"korea\" + 0.072*\"north\" + 0.064*\"cnn\" + 0.046*\"answer\" + 0.039*\"fishing\" + 0.038*\"store\" + 0.038*\"get\" + 0.037*\"american\" + 0.036*\"launch\" + 0.035*\"bad\"\n",
      "2019-10-29 00:46:11,323 : INFO : topic diff=0.596407, rho=1.000000\n",
      "2019-10-29 00:46:11,746 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:11,749 : INFO : built Dictionary(174 unique tokens: ['relation', 'significant', 'job', 'needed', 'avail']...) from 5 documents (total 1045 corpus positions)\n",
      "2019-10-29 00:46:11,752 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:11,753 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:11,755 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:11,757 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:11,758 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:11,852 : INFO : -7.668 per-word bound, 203.4 perplexity estimate based on a held-out corpus of 5 documents with 1045 words\n",
      "2019-10-29 00:46:11,853 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:11,862 : INFO : topic #9 (0.100): 0.026*\"tillerson\" + 0.021*\"trump\" + 0.020*\"secretary\" + 0.018*\"president\" + 0.016*\"state\" + 0.012*\"administration\" + 0.011*\"public\" + 0.011*\"way\" + 0.010*\"thing\" + 0.010*\"white\"\n",
      "2019-10-29 00:46:11,864 : INFO : topic #7 (0.100): 0.025*\"tillerson\" + 0.021*\"trump\" + 0.018*\"president\" + 0.017*\"state\" + 0.015*\"secretary\" + 0.014*\"way\" + 0.013*\"administration\" + 0.011*\"zelizer\" + 0.010*\"house\" + 0.010*\"rex\"\n",
      "2019-10-29 00:46:11,868 : INFO : topic #1 (0.100): 0.028*\"tillerson\" + 0.018*\"trump\" + 0.016*\"secretary\" + 0.016*\"state\" + 0.015*\"way\" + 0.014*\"president\" + 0.013*\"week\" + 0.012*\"house\" + 0.012*\"story\" + 0.011*\"resign\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:11,871 : INFO : topic #2 (0.100): 0.025*\"tillerson\" + 0.024*\"secretary\" + 0.019*\"trump\" + 0.017*\"state\" + 0.017*\"president\" + 0.016*\"administration\" + 0.014*\"way\" + 0.011*\"thing\" + 0.011*\"zelizer\" + 0.009*\"public\"\n",
      "2019-10-29 00:46:11,874 : INFO : topic #6 (0.100): 0.029*\"tillerson\" + 0.024*\"trump\" + 0.023*\"secretary\" + 0.020*\"president\" + 0.015*\"state\" + 0.015*\"administration\" + 0.011*\"white\" + 0.011*\"way\" + 0.011*\"resign\" + 0.010*\"rex\"\n",
      "2019-10-29 00:46:11,877 : INFO : topic diff=0.700097, rho=1.000000\n",
      "2019-10-29 00:46:12,312 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:12,314 : INFO : built Dictionary(42 unique tokens: ['early', 'book', 'something', 'knew', 'get']...) from 5 documents (total 235 corpus positions)\n",
      "2019-10-29 00:46:12,315 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:12,316 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:12,318 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:12,320 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:12,325 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:12,355 : INFO : -6.683 per-word bound, 102.7 perplexity estimate based on a held-out corpus of 5 documents with 235 words\n",
      "2019-10-29 00:46:12,363 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:12,372 : INFO : topic #3 (0.100): 0.046*\"would\" + 0.041*\"dancing\" + 0.039*\"creative\" + 0.035*\"outlet\" + 0.028*\"world\" + 0.027*\"told\" + 0.026*\"payal\" + 0.026*\"innovator\" + 0.025*\"fitness\" + 0.025*\"something\"\n",
      "2019-10-29 00:46:12,374 : INFO : topic #2 (0.100): 0.049*\"outlet\" + 0.047*\"would\" + 0.045*\"dancing\" + 0.031*\"creative\" + 0.030*\"importantly\" + 0.027*\"early\" + 0.027*\"innovator\" + 0.027*\"even\" + 0.026*\"allows\" + 0.025*\"founder\"\n",
      "2019-10-29 00:46:12,380 : INFO : topic #4 (0.100): 0.059*\"would\" + 0.034*\"creative\" + 0.033*\"dancing\" + 0.033*\"outlet\" + 0.031*\"cnnmoney\" + 0.028*\"everything\" + 0.026*\"become\" + 0.026*\"payal\" + 0.025*\"performing\" + 0.025*\"always\"\n",
      "2019-10-29 00:46:12,383 : INFO : topic #0 (0.100): 0.054*\"would\" + 0.040*\"outlet\" + 0.035*\"creative\" + 0.034*\"dancing\" + 0.029*\"book\" + 0.028*\"founder\" + 0.027*\"become\" + 0.026*\"get\" + 0.025*\"around\" + 0.025*\"early\"\n",
      "2019-10-29 00:46:12,388 : INFO : topic #5 (0.100): 0.054*\"dancing\" + 0.044*\"creative\" + 0.044*\"would\" + 0.033*\"outlet\" + 0.028*\"le\" + 0.027*\"get\" + 0.026*\"world\" + 0.025*\"lost\" + 0.025*\"knew\" + 0.025*\"app\"\n",
      "2019-10-29 00:46:12,392 : INFO : topic diff=0.621706, rho=1.000000\n",
      "2019-10-29 00:46:12,798 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:12,801 : INFO : built Dictionary(206 unique tokens: ['mirrored', 'valley', 'phase', 'plaster', 'aitken']...) from 5 documents (total 1315 corpus positions)\n",
      "2019-10-29 00:46:12,804 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:12,805 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:12,807 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:12,810 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:12,811 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:12,885 : INFO : -7.701 per-word bound, 208.1 perplexity estimate based on a held-out corpus of 5 documents with 1315 words\n",
      "2019-10-29 00:46:12,886 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:12,892 : INFO : topic #7 (0.100): 0.031*\"container\" + 0.017*\"design\" + 0.014*\"joshua\" + 0.014*\"desert\" + 0.013*\"whitaker\" + 0.012*\"hechingen\" + 0.012*\"together\" + 0.012*\"tree\" + 0.012*\"like\" + 0.011*\"house\"\n",
      "2019-10-29 00:46:12,894 : INFO : topic #9 (0.100): 0.036*\"container\" + 0.014*\"whitaker\" + 0.014*\"design\" + 0.014*\"joshua\" + 0.013*\"together\" + 0.012*\"like\" + 0.012*\"desert\" + 0.012*\"house\" + 0.011*\"tree\" + 0.010*\"hechingen\"\n",
      "2019-10-29 00:46:12,895 : INFO : topic #6 (0.100): 0.028*\"container\" + 0.014*\"whitaker\" + 0.013*\"tree\" + 0.013*\"design\" + 0.012*\"together\" + 0.011*\"joshua\" + 0.011*\"like\" + 0.010*\"residence\" + 0.010*\"hechingen\" + 0.010*\"house\"\n",
      "2019-10-29 00:46:12,897 : INFO : topic #3 (0.100): 0.023*\"container\" + 0.016*\"joshua\" + 0.014*\"desert\" + 0.014*\"whitaker\" + 0.012*\"like\" + 0.012*\"design\" + 0.011*\"hechingen\" + 0.010*\"house\" + 0.009*\"california\" + 0.009*\"outside\"\n",
      "2019-10-29 00:46:12,899 : INFO : topic #5 (0.100): 0.027*\"container\" + 0.016*\"desert\" + 0.014*\"whitaker\" + 0.012*\"design\" + 0.012*\"house\" + 0.012*\"joshua\" + 0.012*\"tree\" + 0.011*\"hechingen\" + 0.011*\"together\" + 0.009*\"like\"\n",
      "2019-10-29 00:46:12,901 : INFO : topic diff=0.721436, rho=1.000000\n",
      "2019-10-29 00:46:13,311 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:13,314 : INFO : built Dictionary(203 unique tokens: ['forward', 'previously', 'filed', 'relative', 'relation']...) from 5 documents (total 1475 corpus positions)\n",
      "2019-10-29 00:46:13,316 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:13,318 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:13,319 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:13,322 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:13,324 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:13,407 : INFO : -7.468 per-word bound, 177.1 perplexity estimate based on a held-out corpus of 5 documents with 1475 words\n",
      "2019-10-29 00:46:13,408 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:13,414 : INFO : topic #2 (0.100): 0.022*\"player\" + 0.020*\"anthem\" + 0.020*\"jones\" + 0.020*\"said\" + 0.019*\"stand\" + 0.018*\"cowboy\" + 0.018*\"labor\" + 0.012*\"according\" + 0.011*\"would\" + 0.011*\"national\"\n",
      "2019-10-29 00:46:13,416 : INFO : topic #8 (0.100): 0.025*\"anthem\" + 0.022*\"player\" + 0.022*\"stand\" + 0.021*\"said\" + 0.018*\"jones\" + 0.016*\"cowboy\" + 0.013*\"fan\" + 0.012*\"according\" + 0.012*\"would\" + 0.012*\"local\"\n",
      "2019-10-29 00:46:13,419 : INFO : topic #6 (0.100): 0.021*\"player\" + 0.019*\"anthem\" + 0.018*\"stand\" + 0.017*\"said\" + 0.015*\"cowboy\" + 0.015*\"jones\" + 0.014*\"fan\" + 0.012*\"national\" + 0.012*\"would\" + 0.012*\"labor\"\n",
      "2019-10-29 00:46:13,421 : INFO : topic #9 (0.100): 0.027*\"jones\" + 0.024*\"player\" + 0.021*\"said\" + 0.018*\"stand\" + 0.016*\"anthem\" + 0.015*\"national\" + 0.015*\"labor\" + 0.015*\"according\" + 0.012*\"tuesday\" + 0.012*\"cowboy\"\n",
      "2019-10-29 00:46:13,424 : INFO : topic #0 (0.100): 0.025*\"anthem\" + 0.023*\"jones\" + 0.021*\"stand\" + 0.015*\"said\" + 0.015*\"cowboy\" + 0.014*\"player\" + 0.013*\"local\" + 0.012*\"labor\" + 0.012*\"would\" + 0.012*\"national\"\n",
      "2019-10-29 00:46:13,427 : INFO : topic diff=0.801622, rho=1.000000\n",
      "2019-10-29 00:46:13,835 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:13,841 : INFO : built Dictionary(292 unique tokens: ['forward', 'republished', 'diminished', 'spokesperson', 'cool']...) from 5 documents (total 2005 corpus positions)\n",
      "2019-10-29 00:46:13,844 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:13,847 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:13,851 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:13,855 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:13,858 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:13,954 : INFO : -7.890 per-word bound, 237.3 perplexity estimate based on a held-out corpus of 5 documents with 2005 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:13,955 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:13,963 : INFO : topic #5 (0.100): 0.054*\"generation\" + 0.046*\"x\" + 0.012*\"even\" + 0.010*\"going\" + 0.009*\"parent\" + 0.009*\"want\" + 0.008*\"little\" + 0.007*\"much\" + 0.007*\"time\" + 0.007*\"thing\"\n",
      "2019-10-29 00:46:13,965 : INFO : topic #2 (0.100): 0.068*\"generation\" + 0.055*\"x\" + 0.017*\"even\" + 0.011*\"time\" + 0.009*\"better\" + 0.008*\"going\" + 0.008*\"used\" + 0.008*\"bullshit\" + 0.007*\"little\" + 0.007*\"thing\"\n",
      "2019-10-29 00:46:13,968 : INFO : topic #6 (0.100): 0.080*\"generation\" + 0.052*\"x\" + 0.013*\"even\" + 0.010*\"going\" + 0.010*\"used\" + 0.009*\"time\" + 0.008*\"much\" + 0.008*\"thing\" + 0.007*\"read\" + 0.007*\"want\"\n",
      "2019-10-29 00:46:13,970 : INFO : topic #3 (0.100): 0.057*\"generation\" + 0.038*\"x\" + 0.012*\"even\" + 0.010*\"parent\" + 0.010*\"going\" + 0.009*\"time\" + 0.009*\"read\" + 0.008*\"voice\" + 0.008*\"want\" + 0.007*\"much\"\n",
      "2019-10-29 00:46:13,972 : INFO : topic #7 (0.100): 0.057*\"x\" + 0.047*\"generation\" + 0.012*\"even\" + 0.011*\"parent\" + 0.011*\"time\" + 0.009*\"going\" + 0.009*\"want\" + 0.008*\"thing\" + 0.008*\"read\" + 0.008*\"better\"\n",
      "2019-10-29 00:46:13,973 : INFO : topic diff=0.788842, rho=1.000000\n",
      "2019-10-29 00:46:14,429 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:14,434 : INFO : built Dictionary(301 unique tokens: ['aviation', 'cylinder', 'deep', 'concern', 'focus']...) from 5 documents (total 2190 corpus positions)\n",
      "2019-10-29 00:46:14,437 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:14,438 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:14,440 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:14,443 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:14,445 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:14,556 : INFO : -7.834 per-word bound, 228.2 perplexity estimate based on a held-out corpus of 5 documents with 2190 words\n",
      "2019-10-29 00:46:14,559 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:14,567 : INFO : topic #8 (0.100): 0.058*\"ge\" + 0.013*\"year\" + 0.012*\"ceo\" + 0.012*\"immelt\" + 0.011*\"stock\" + 0.010*\"analyst\" + 0.009*\"company\" + 0.009*\"problem\" + 0.009*\"business\" + 0.008*\"said\"\n",
      "2019-10-29 00:46:14,570 : INFO : topic #3 (0.100): 0.074*\"ge\" + 0.016*\"year\" + 0.014*\"ceo\" + 0.013*\"immelt\" + 0.011*\"business\" + 0.011*\"stock\" + 0.010*\"problem\" + 0.010*\"analyst\" + 0.009*\"company\" + 0.009*\"management\"\n",
      "2019-10-29 00:46:14,572 : INFO : topic #5 (0.100): 0.059*\"ge\" + 0.017*\"immelt\" + 0.014*\"year\" + 0.014*\"ceo\" + 0.012*\"company\" + 0.011*\"business\" + 0.010*\"financial\" + 0.010*\"stock\" + 0.009*\"analyst\" + 0.009*\"said\"\n",
      "2019-10-29 00:46:14,575 : INFO : topic #7 (0.100): 0.055*\"ge\" + 0.023*\"year\" + 0.014*\"ceo\" + 0.013*\"immelt\" + 0.013*\"analyst\" + 0.012*\"business\" + 0.010*\"management\" + 0.009*\"company\" + 0.008*\"said\" + 0.008*\"problem\"\n",
      "2019-10-29 00:46:14,578 : INFO : topic #4 (0.100): 0.056*\"ge\" + 0.018*\"business\" + 0.018*\"year\" + 0.012*\"ceo\" + 0.012*\"company\" + 0.011*\"said\" + 0.011*\"stock\" + 0.010*\"analyst\" + 0.010*\"new\" + 0.009*\"immelt\"\n",
      "2019-10-29 00:46:14,580 : INFO : topic diff=0.810889, rho=1.000000\n",
      "2019-10-29 00:46:14,986 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:14,988 : INFO : built Dictionary(111 unique tokens: ['prime', 'catalonia', 'interview', 'ago', 'needed']...) from 5 documents (total 740 corpus positions)\n",
      "2019-10-29 00:46:14,990 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:14,991 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:14,992 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:14,995 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:14,997 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:15,057 : INFO : -7.075 per-word bound, 134.9 perplexity estimate based on a held-out corpus of 5 documents with 740 words\n",
      "2019-10-29 00:46:15,060 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:15,069 : INFO : topic #2 (0.100): 0.044*\"independence\" + 0.040*\"catalonia\" + 0.028*\"rajoy\" + 0.021*\"spanish\" + 0.020*\"leader\" + 0.019*\"spain\" + 0.017*\"barcelona\" + 0.015*\"region\" + 0.015*\"suspending\" + 0.014*\"mariano\"\n",
      "2019-10-29 00:46:15,072 : INFO : topic #4 (0.100): 0.046*\"catalonia\" + 0.046*\"rajoy\" + 0.040*\"independence\" + 0.020*\"spain\" + 0.018*\"region\" + 0.018*\"spanish\" + 0.017*\"minister\" + 0.017*\"leader\" + 0.014*\"barcelona\" + 0.014*\"week\"\n",
      "2019-10-29 00:46:15,078 : INFO : topic #7 (0.100): 0.043*\"independence\" + 0.032*\"rajoy\" + 0.025*\"catalonia\" + 0.021*\"spanish\" + 0.021*\"leader\" + 0.018*\"spain\" + 0.017*\"region\" + 0.015*\"prime\" + 0.015*\"suspending\" + 0.015*\"autonomous\"\n",
      "2019-10-29 00:46:15,081 : INFO : topic #3 (0.100): 0.043*\"catalonia\" + 0.040*\"rajoy\" + 0.037*\"independence\" + 0.022*\"spanish\" + 0.021*\"region\" + 0.020*\"spain\" + 0.019*\"leader\" + 0.016*\"week\" + 0.015*\"prime\" + 0.014*\"held\"\n",
      "2019-10-29 00:46:15,084 : INFO : topic #8 (0.100): 0.040*\"catalonia\" + 0.039*\"independence\" + 0.031*\"rajoy\" + 0.026*\"spanish\" + 0.018*\"spain\" + 0.018*\"region\" + 0.018*\"leader\" + 0.016*\"law\" + 0.015*\"minister\" + 0.015*\"autonomy\"\n",
      "2019-10-29 00:46:15,087 : INFO : topic diff=0.762788, rho=1.000000\n",
      "2019-10-29 00:46:15,498 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:15,500 : INFO : built Dictionary(84 unique tokens: ['route', 'military', 'prime', 'cambodian', 'ii']...) from 5 documents (total 565 corpus positions)\n",
      "2019-10-29 00:46:15,503 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:15,508 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:15,511 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:15,514 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:15,517 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:15,565 : INFO : -6.824 per-word bound, 113.3 perplexity estimate based on a held-out corpus of 5 documents with 565 words\n",
      "2019-10-29 00:46:15,567 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:15,579 : INFO : topic #7 (0.100): 0.048*\"sultan\" + 0.040*\"chariot\" + 0.038*\"golden\" + 0.027*\"world\" + 0.024*\"procession\" + 0.021*\"jubilee\" + 0.020*\"minister\" + 0.018*\"according\" + 0.017*\"prime\" + 0.017*\"brunei\"\n",
      "2019-10-29 00:46:15,584 : INFO : topic #6 (0.100): 0.060*\"sultan\" + 0.039*\"chariot\" + 0.031*\"golden\" + 0.022*\"world\" + 0.021*\"year\" + 0.021*\"procession\" + 0.019*\"brunei\" + 0.019*\"prime\" + 0.018*\"band\" + 0.017*\"according\"\n",
      "2019-10-29 00:46:15,586 : INFO : topic #9 (0.100): 0.045*\"chariot\" + 0.042*\"sultan\" + 0.029*\"world\" + 0.025*\"golden\" + 0.025*\"procession\" + 0.021*\"royal\" + 0.020*\"marked\" + 0.020*\"one\" + 0.018*\"parade\" + 0.018*\"minister\"\n",
      "2019-10-29 00:46:15,589 : INFO : topic #1 (0.100): 0.046*\"chariot\" + 0.045*\"sultan\" + 0.034*\"world\" + 0.029*\"golden\" + 0.024*\"prime\" + 0.021*\"procession\" + 0.020*\"according\" + 0.018*\"royal\" + 0.018*\"parade\" + 0.017*\"band\"\n",
      "2019-10-29 00:46:15,592 : INFO : topic #2 (0.100): 0.040*\"sultan\" + 0.039*\"chariot\" + 0.035*\"golden\" + 0.026*\"procession\" + 0.024*\"world\" + 0.021*\"parade\" + 0.018*\"people\" + 0.018*\"marked\" + 0.018*\"royal\" + 0.017*\"according\"\n",
      "2019-10-29 00:46:15,594 : INFO : topic diff=0.746000, rho=1.000000\n",
      "2019-10-29 00:46:16,007 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:16,012 : INFO : built Dictionary(245 unique tokens: ['although', 'energy', 'portion', 'size', 'induce']...) from 5 documents (total 1925 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:16,015 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:16,016 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:16,018 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:16,021 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:16,023 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:16,119 : INFO : -7.518 per-word bound, 183.3 perplexity estimate based on a held-out corpus of 5 documents with 1925 words\n",
      "2019-10-29 00:46:16,122 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:16,130 : INFO : topic #7 (0.100): 0.070*\"sugar\" + 0.022*\"food\" + 0.020*\"say\" + 0.017*\"gram\" + 0.016*\"drayer\" + 0.012*\"even\" + 0.011*\"intake\" + 0.010*\"contain\" + 0.009*\"addiction\" + 0.009*\"day\"\n",
      "2019-10-29 00:46:16,133 : INFO : topic #0 (0.100): 0.076*\"sugar\" + 0.018*\"say\" + 0.016*\"gram\" + 0.015*\"food\" + 0.013*\"intake\" + 0.013*\"drayer\" + 0.011*\"like\" + 0.011*\"contain\" + 0.010*\"addiction\" + 0.010*\"people\"\n",
      "2019-10-29 00:46:16,136 : INFO : topic #1 (0.100): 0.090*\"sugar\" + 0.022*\"say\" + 0.020*\"drayer\" + 0.015*\"food\" + 0.013*\"gram\" + 0.011*\"even\" + 0.010*\"like\" + 0.010*\"intake\" + 0.009*\"addiction\" + 0.009*\"people\"\n",
      "2019-10-29 00:46:16,139 : INFO : topic #2 (0.100): 0.060*\"sugar\" + 0.018*\"drayer\" + 0.017*\"say\" + 0.013*\"food\" + 0.012*\"intake\" + 0.012*\"addiction\" + 0.012*\"gram\" + 0.011*\"even\" + 0.010*\"contain\" + 0.010*\"hard\"\n",
      "2019-10-29 00:46:16,142 : INFO : topic #9 (0.100): 0.086*\"sugar\" + 0.020*\"say\" + 0.020*\"food\" + 0.017*\"drayer\" + 0.012*\"gram\" + 0.012*\"like\" + 0.011*\"addiction\" + 0.011*\"intake\" + 0.010*\"people\" + 0.010*\"contain\"\n",
      "2019-10-29 00:46:16,144 : INFO : topic diff=0.838565, rho=1.000000\n",
      "2019-10-29 00:46:16,589 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:16,598 : INFO : built Dictionary(302 unique tokens: ['although', 'deter', 'product', 'significant', 'taxpayer']...) from 5 documents (total 2430 corpus positions)\n",
      "2019-10-29 00:46:16,604 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:16,606 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:16,608 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:16,612 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:16,614 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:16,757 : INFO : -7.678 per-word bound, 204.8 perplexity estimate based on a held-out corpus of 5 documents with 2430 words\n",
      "2019-10-29 00:46:16,759 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:16,768 : INFO : topic #7 (0.100): 0.034*\"study\" + 0.031*\"program\" + 0.027*\"baby\" + 0.018*\"girl\" + 0.016*\"simulator\" + 0.015*\"said\" + 0.015*\"pregnancy\" + 0.013*\"brinkman\" + 0.012*\"realityworks\" + 0.012*\"educational\"\n",
      "2019-10-29 00:46:16,770 : INFO : topic #4 (0.100): 0.033*\"program\" + 0.033*\"study\" + 0.027*\"girl\" + 0.026*\"baby\" + 0.019*\"said\" + 0.014*\"brinkman\" + 0.013*\"simulator\" + 0.013*\"educational\" + 0.010*\"teenage\" + 0.009*\"australia\"\n",
      "2019-10-29 00:46:16,773 : INFO : topic #8 (0.100): 0.032*\"program\" + 0.031*\"baby\" + 0.030*\"study\" + 0.019*\"said\" + 0.017*\"brinkman\" + 0.016*\"girl\" + 0.012*\"simulator\" + 0.011*\"educational\" + 0.011*\"pregnancy\" + 0.010*\"realityworks\"\n",
      "2019-10-29 00:46:16,776 : INFO : topic #0 (0.100): 0.031*\"study\" + 0.030*\"baby\" + 0.025*\"program\" + 0.019*\"girl\" + 0.018*\"said\" + 0.014*\"brinkman\" + 0.012*\"simulator\" + 0.011*\"educational\" + 0.009*\"australia\" + 0.009*\"pregnancy\"\n",
      "2019-10-29 00:46:16,779 : INFO : topic #5 (0.100): 0.031*\"program\" + 0.029*\"study\" + 0.025*\"baby\" + 0.019*\"girl\" + 0.017*\"educational\" + 0.015*\"said\" + 0.015*\"brinkman\" + 0.013*\"pregnancy\" + 0.012*\"simulator\" + 0.012*\"researcher\"\n",
      "2019-10-29 00:46:16,782 : INFO : topic diff=0.846659, rho=1.000000\n",
      "2019-10-29 00:46:17,250 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:17,256 : INFO : built Dictionary(229 unique tokens: ['although', 'incentivize', 'campaign', 'nation', 'come']...) from 5 documents (total 1850 corpus positions)\n",
      "2019-10-29 00:46:17,263 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:17,265 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:17,268 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:17,272 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:17,274 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:17,354 : INFO : -7.417 per-word bound, 170.9 perplexity estimate based on a held-out corpus of 5 documents with 1850 words\n",
      "2019-10-29 00:46:17,356 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:17,361 : INFO : topic #4 (0.100): 0.051*\"tax\" + 0.039*\"cut\" + 0.028*\"state\" + 0.021*\"trump\" + 0.017*\"business\" + 0.012*\"rate\" + 0.012*\"income\" + 0.012*\"revenue\" + 0.012*\"economic\" + 0.011*\"job\"\n",
      "2019-10-29 00:46:17,363 : INFO : topic #0 (0.100): 0.047*\"tax\" + 0.033*\"state\" + 0.031*\"cut\" + 0.020*\"business\" + 0.018*\"trump\" + 0.015*\"rate\" + 0.014*\"job\" + 0.014*\"income\" + 0.014*\"capital\" + 0.011*\"revenue\"\n",
      "2019-10-29 00:46:17,364 : INFO : topic #1 (0.100): 0.052*\"tax\" + 0.027*\"cut\" + 0.025*\"state\" + 0.019*\"trump\" + 0.015*\"rate\" + 0.014*\"business\" + 0.014*\"capital\" + 0.014*\"corporate\" + 0.014*\"income\" + 0.013*\"economic\"\n",
      "2019-10-29 00:46:17,365 : INFO : topic #2 (0.100): 0.054*\"tax\" + 0.034*\"cut\" + 0.032*\"state\" + 0.021*\"business\" + 0.020*\"trump\" + 0.016*\"rate\" + 0.012*\"revenue\" + 0.012*\"income\" + 0.010*\"corporate\" + 0.010*\"capital\"\n",
      "2019-10-29 00:46:17,367 : INFO : topic #9 (0.100): 0.057*\"tax\" + 0.029*\"cut\" + 0.026*\"state\" + 0.018*\"business\" + 0.015*\"trump\" + 0.014*\"rate\" + 0.014*\"income\" + 0.014*\"capital\" + 0.010*\"nine\" + 0.010*\"revenue\"\n",
      "2019-10-29 00:46:17,368 : INFO : topic diff=0.864700, rho=1.000000\n",
      "2019-10-29 00:46:17,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:17,881 : INFO : built Dictionary(546 unique tokens: ['josh', 'forecast', 'journey', 'crest', 'francisco']...) from 5 documents (total 6495 corpus positions)\n",
      "2019-10-29 00:46:17,888 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:17,889 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:17,890 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:17,894 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:17,896 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:18,062 : INFO : -7.787 per-word bound, 220.9 perplexity estimate based on a held-out corpus of 5 documents with 6495 words\n",
      "2019-10-29 00:46:18,064 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:18,074 : INFO : topic #1 (0.100): 0.030*\"california\" + 0.029*\"caption\" + 0.027*\"wildfire\" + 0.023*\"blaze\" + 0.022*\"hide\" + 0.019*\"fire\" + 0.018*\"photo\" + 0.017*\"said\" + 0.017*\"october\" + 0.016*\"napa\"\n",
      "2019-10-29 00:46:18,076 : INFO : topic #8 (0.100): 0.035*\"wildfire\" + 0.034*\"california\" + 0.029*\"october\" + 0.027*\"fire\" + 0.024*\"blaze\" + 0.022*\"photo\" + 0.021*\"caption\" + 0.018*\"said\" + 0.017*\"rosa\" + 0.017*\"santa\"\n",
      "2019-10-29 00:46:18,078 : INFO : topic #3 (0.100): 0.031*\"wildfire\" + 0.030*\"california\" + 0.030*\"fire\" + 0.027*\"october\" + 0.027*\"blaze\" + 0.024*\"hide\" + 0.021*\"photo\" + 0.018*\"caption\" + 0.018*\"said\" + 0.016*\"rosa\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:18,080 : INFO : topic #4 (0.100): 0.034*\"california\" + 0.033*\"wildfire\" + 0.030*\"blaze\" + 0.029*\"fire\" + 0.026*\"photo\" + 0.024*\"hide\" + 0.022*\"caption\" + 0.018*\"santa\" + 0.018*\"october\" + 0.017*\"napa\"\n",
      "2019-10-29 00:46:18,082 : INFO : topic #7 (0.100): 0.038*\"wildfire\" + 0.037*\"california\" + 0.027*\"fire\" + 0.027*\"photo\" + 0.024*\"said\" + 0.023*\"blaze\" + 0.022*\"october\" + 0.020*\"caption\" + 0.019*\"hide\" + 0.016*\"rosa\"\n",
      "2019-10-29 00:46:18,083 : INFO : topic diff=1.101937, rho=1.000000\n",
      "2019-10-29 00:46:18,530 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:18,538 : INFO : built Dictionary(365 unique tokens: ['midfielder', 'francisco', 'game', 'holland', 'u']...) from 5 documents (total 3895 corpus positions)\n",
      "2019-10-29 00:46:18,545 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:18,546 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:18,547 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:18,550 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:18,553 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:18,676 : INFO : -7.494 per-word bound, 180.3 perplexity estimate based on a held-out corpus of 5 documents with 3895 words\n",
      "2019-10-29 00:46:18,677 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:18,686 : INFO : topic #4 (0.100): 0.076*\"photo\" + 0.042*\"amazing\" + 0.039*\"shot\" + 0.038*\"september\" + 0.037*\"hide\" + 0.033*\"caption\" + 0.027*\"sport\" + 0.018*\"game\" + 0.012*\"sunday\" + 0.011*\"saturday\"\n",
      "2019-10-29 00:46:18,688 : INFO : topic #3 (0.100): 0.064*\"photo\" + 0.043*\"caption\" + 0.039*\"shot\" + 0.038*\"hide\" + 0.034*\"amazing\" + 0.033*\"sport\" + 0.029*\"september\" + 0.017*\"game\" + 0.014*\"sunday\" + 0.012*\"saturday\"\n",
      "2019-10-29 00:46:18,691 : INFO : topic #6 (0.100): 0.084*\"photo\" + 0.044*\"sport\" + 0.041*\"caption\" + 0.033*\"hide\" + 0.028*\"amazing\" + 0.027*\"shot\" + 0.021*\"september\" + 0.015*\"game\" + 0.014*\"sunday\" + 0.013*\"saturday\"\n",
      "2019-10-29 00:46:18,694 : INFO : topic #9 (0.100): 0.081*\"photo\" + 0.040*\"amazing\" + 0.040*\"september\" + 0.036*\"sport\" + 0.034*\"shot\" + 0.033*\"caption\" + 0.033*\"hide\" + 0.015*\"game\" + 0.012*\"sunday\" + 0.008*\"league\"\n",
      "2019-10-29 00:46:18,696 : INFO : topic #5 (0.100): 0.067*\"photo\" + 0.043*\"shot\" + 0.036*\"sport\" + 0.035*\"amazing\" + 0.033*\"september\" + 0.031*\"caption\" + 0.029*\"hide\" + 0.016*\"game\" + 0.014*\"sunday\" + 0.011*\"team\"\n",
      "2019-10-29 00:46:18,698 : INFO : topic diff=0.999716, rho=1.000000\n",
      "2019-10-29 00:46:19,117 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:19,123 : INFO : built Dictionary(377 unique tokens: ['although', 'let', 'phase', 'bone', 'party']...) from 5 documents (total 3085 corpus positions)\n",
      "2019-10-29 00:46:19,127 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:19,129 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:19,130 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:19,133 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:19,136 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:19,248 : INFO : -7.868 per-word bound, 233.7 perplexity estimate based on a held-out corpus of 5 documents with 3085 words\n",
      "2019-10-29 00:46:19,250 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:19,258 : INFO : topic #0 (0.100): 0.026*\"callan\" + 0.020*\"war\" + 0.017*\"star\" + 0.015*\"kott\" + 0.015*\"cancer\" + 0.010*\"favorite\" + 0.010*\"force\" + 0.009*\"time\" + 0.009*\"ross\" + 0.009*\"character\"\n",
      "2019-10-29 00:46:19,259 : INFO : topic #1 (0.100): 0.022*\"callan\" + 0.017*\"war\" + 0.016*\"kott\" + 0.015*\"ross\" + 0.014*\"cancer\" + 0.013*\"star\" + 0.012*\"force\" + 0.010*\"family\" + 0.010*\"lisa\" + 0.009*\"favorite\"\n",
      "2019-10-29 00:46:19,261 : INFO : topic #6 (0.100): 0.025*\"callan\" + 0.018*\"kott\" + 0.014*\"star\" + 0.014*\"war\" + 0.013*\"cancer\" + 0.010*\"ross\" + 0.010*\"said\" + 0.009*\"family\" + 0.009*\"would\" + 0.008*\"favorite\"\n",
      "2019-10-29 00:46:19,262 : INFO : topic #3 (0.100): 0.025*\"callan\" + 0.016*\"star\" + 0.015*\"cancer\" + 0.013*\"ross\" + 0.013*\"war\" + 0.011*\"kott\" + 0.011*\"said\" + 0.010*\"family\" + 0.009*\"child\" + 0.009*\"would\"\n",
      "2019-10-29 00:46:19,264 : INFO : topic #5 (0.100): 0.023*\"callan\" + 0.021*\"war\" + 0.016*\"kott\" + 0.016*\"star\" + 0.015*\"ross\" + 0.013*\"cancer\" + 0.012*\"family\" + 0.012*\"said\" + 0.011*\"force\" + 0.009*\"favorite\"\n",
      "2019-10-29 00:46:19,266 : INFO : topic diff=0.860427, rho=1.000000\n",
      "2019-10-29 00:46:19,665 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:19,668 : INFO : built Dictionary(72 unique tokens: ['liability', 'victim', 'financial', 'argue', 'terrorist']...) from 5 documents (total 510 corpus positions)\n",
      "2019-10-29 00:46:19,671 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:19,673 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:19,675 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:19,678 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:19,681 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:19,709 : INFO : -6.598 per-word bound, 96.9 perplexity estimate based on a held-out corpus of 5 documents with 510 words\n",
      "2019-10-29 00:46:19,711 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:19,719 : INFO : topic #0 (0.100): 0.051*\"victim\" + 0.046*\"bank\" + 0.035*\"attack\" + 0.029*\"corporation\" + 0.029*\"court\" + 0.026*\"seek\" + 0.022*\"u\" + 0.022*\"terrorism\" + 0.021*\"human\" + 0.021*\"right\"\n",
      "2019-10-29 00:46:19,721 : INFO : topic #1 (0.100): 0.046*\"victim\" + 0.041*\"bank\" + 0.039*\"court\" + 0.035*\"attack\" + 0.032*\"corporation\" + 0.031*\"u\" + 0.022*\"seek\" + 0.022*\"human\" + 0.021*\"terrorist\" + 0.019*\"case\"\n",
      "2019-10-29 00:46:19,725 : INFO : topic #6 (0.100): 0.038*\"victim\" + 0.036*\"court\" + 0.032*\"attack\" + 0.031*\"corporation\" + 0.026*\"bank\" + 0.024*\"sue\" + 0.023*\"case\" + 0.023*\"u\" + 0.022*\"terrorism\" + 0.021*\"used\"\n",
      "2019-10-29 00:46:19,728 : INFO : topic #2 (0.100): 0.046*\"bank\" + 0.044*\"victim\" + 0.044*\"court\" + 0.034*\"attack\" + 0.032*\"u\" + 0.029*\"corporation\" + 0.023*\"terrorism\" + 0.019*\"question\" + 0.019*\"occurred\" + 0.019*\"sued\"\n",
      "2019-10-29 00:46:19,732 : INFO : topic #3 (0.100): 0.054*\"bank\" + 0.050*\"victim\" + 0.043*\"attack\" + 0.029*\"court\" + 0.025*\"u\" + 0.023*\"corporation\" + 0.022*\"used\" + 0.022*\"sued\" + 0.022*\"supreme\" + 0.021*\"seek\"\n",
      "2019-10-29 00:46:19,734 : INFO : topic diff=0.770287, rho=1.000000\n",
      "2019-10-29 00:46:20,136 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:20,139 : INFO : built Dictionary(147 unique tokens: ['although', 'intricate', 'span', 'reflecting', 'deep']...) from 5 documents (total 1080 corpus positions)\n",
      "2019-10-29 00:46:20,142 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:20,147 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:20,150 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:20,154 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:20,157 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:20,228 : INFO : -7.161 per-word bound, 143.1 perplexity estimate based on a held-out corpus of 5 documents with 1080 words\n",
      "2019-10-29 00:46:20,230 : INFO : PROGRESS: pass 0, at document #5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:20,237 : INFO : topic #8 (0.100): 0.063*\"zeng\" + 0.032*\"work\" + 0.026*\"artist\" + 0.026*\"fanzhi\" + 0.021*\"say\" + 0.018*\"chinese\" + 0.015*\"series\" + 0.014*\"art\" + 0.012*\"painting\" + 0.011*\"contemporary\"\n",
      "2019-10-29 00:46:20,239 : INFO : topic #1 (0.100): 0.051*\"zeng\" + 0.038*\"work\" + 0.028*\"artist\" + 0.028*\"fanzhi\" + 0.023*\"chinese\" + 0.018*\"say\" + 0.014*\"series\" + 0.012*\"supper\" + 0.012*\"art\" + 0.011*\"different\"\n",
      "2019-10-29 00:46:20,243 : INFO : topic #7 (0.100): 0.049*\"zeng\" + 0.035*\"fanzhi\" + 0.034*\"work\" + 0.024*\"artist\" + 0.024*\"chinese\" + 0.014*\"art\" + 0.014*\"say\" + 0.013*\"painting\" + 0.012*\"master\" + 0.011*\"series\"\n",
      "2019-10-29 00:46:20,246 : INFO : topic #4 (0.100): 0.038*\"work\" + 0.036*\"fanzhi\" + 0.031*\"zeng\" + 0.021*\"say\" + 0.020*\"chinese\" + 0.018*\"artist\" + 0.015*\"painting\" + 0.014*\"series\" + 0.013*\"art\" + 0.012*\"different\"\n",
      "2019-10-29 00:46:20,249 : INFO : topic #0 (0.100): 0.046*\"zeng\" + 0.039*\"work\" + 0.037*\"artist\" + 0.027*\"fanzhi\" + 0.021*\"chinese\" + 0.018*\"say\" + 0.018*\"painting\" + 0.015*\"art\" + 0.014*\"master\" + 0.011*\"series\"\n",
      "2019-10-29 00:46:20,251 : INFO : topic diff=0.804594, rho=1.000000\n",
      "2019-10-29 00:46:20,670 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:20,674 : INFO : built Dictionary(281 unique tokens: ['forward', 'fox', 'energy', 'retreat', 'review']...) from 5 documents (total 2175 corpus positions)\n",
      "2019-10-29 00:46:20,678 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:20,680 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:20,681 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:20,685 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:20,686 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:20,781 : INFO : -7.667 per-word bound, 203.2 perplexity estimate based on a held-out corpus of 5 documents with 2175 words\n",
      "2019-10-29 00:46:20,783 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:20,790 : INFO : topic #1 (0.100): 0.034*\"plan\" + 0.027*\"clean\" + 0.027*\"epa\" + 0.025*\"power\" + 0.018*\"said\" + 0.013*\"pruitt\" + 0.013*\"repeal\" + 0.012*\"rule\" + 0.012*\"proposal\" + 0.011*\"would\"\n",
      "2019-10-29 00:46:20,793 : INFO : topic #9 (0.100): 0.032*\"clean\" + 0.031*\"plan\" + 0.027*\"epa\" + 0.021*\"power\" + 0.018*\"said\" + 0.017*\"repeal\" + 0.016*\"proposal\" + 0.013*\"pruitt\" + 0.012*\"rule\" + 0.011*\"climate\"\n",
      "2019-10-29 00:46:20,794 : INFO : topic #7 (0.100): 0.031*\"plan\" + 0.029*\"power\" + 0.029*\"clean\" + 0.028*\"epa\" + 0.019*\"said\" + 0.015*\"proposal\" + 0.015*\"repeal\" + 0.014*\"rule\" + 0.013*\"pruitt\" + 0.011*\"pollution\"\n",
      "2019-10-29 00:46:20,796 : INFO : topic #8 (0.100): 0.028*\"epa\" + 0.027*\"plan\" + 0.027*\"clean\" + 0.024*\"power\" + 0.020*\"said\" + 0.017*\"repeal\" + 0.014*\"proposal\" + 0.013*\"rule\" + 0.012*\"pruitt\" + 0.010*\"president\"\n",
      "2019-10-29 00:46:20,798 : INFO : topic #0 (0.100): 0.028*\"epa\" + 0.025*\"plan\" + 0.025*\"clean\" + 0.024*\"said\" + 0.020*\"power\" + 0.019*\"repeal\" + 0.014*\"pruitt\" + 0.014*\"proposal\" + 0.013*\"climate\" + 0.012*\"rule\"\n",
      "2019-10-29 00:46:20,799 : INFO : topic diff=0.863259, rho=1.000000\n",
      "2019-10-29 00:46:21,218 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:21,220 : INFO : built Dictionary(139 unique tokens: ['malibu', 'flowing', 'speaker', 'irreligion', 'way']...) from 5 documents (total 835 corpus positions)\n",
      "2019-10-29 00:46:21,222 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:21,224 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:21,225 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:21,228 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:21,229 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:21,290 : INFO : -7.469 per-word bound, 177.1 perplexity estimate based on a held-out corpus of 5 documents with 835 words\n",
      "2019-10-29 00:46:21,292 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:21,300 : INFO : topic #6 (0.100): 0.050*\"god\" + 0.023*\"ryan\" + 0.020*\"bell\" + 0.015*\"would\" + 0.013*\"pastor\" + 0.013*\"see\" + 0.013*\"january\" + 0.012*\"way\" + 0.012*\"general\" + 0.012*\"theological\"\n",
      "2019-10-29 00:46:21,303 : INFO : topic #1 (0.100): 0.034*\"god\" + 0.023*\"ryan\" + 0.021*\"bell\" + 0.019*\"would\" + 0.016*\"sitting\" + 0.013*\"january\" + 0.013*\"find\" + 0.013*\"life\" + 0.013*\"general\" + 0.013*\"looking\"\n",
      "2019-10-29 00:46:21,305 : INFO : topic #7 (0.100): 0.026*\"ryan\" + 0.026*\"god\" + 0.024*\"bell\" + 0.015*\"sitting\" + 0.014*\"beach\" + 0.014*\"way\" + 0.013*\"year\" + 0.012*\"pastor\" + 0.012*\"would\" + 0.012*\"find\"\n",
      "2019-10-29 00:46:21,308 : INFO : topic #5 (0.100): 0.037*\"god\" + 0.023*\"bell\" + 0.023*\"ryan\" + 0.020*\"would\" + 0.013*\"general\" + 0.013*\"atheist\" + 0.012*\"looking\" + 0.012*\"find\" + 0.012*\"pastor\" + 0.012*\"see\"\n",
      "2019-10-29 00:46:21,311 : INFO : topic #3 (0.100): 0.042*\"god\" + 0.026*\"bell\" + 0.022*\"ryan\" + 0.015*\"would\" + 0.014*\"see\" + 0.013*\"theological\" + 0.013*\"atheist\" + 0.013*\"beach\" + 0.012*\"discover\" + 0.012*\"looking\"\n",
      "2019-10-29 00:46:21,314 : INFO : topic diff=0.686862, rho=1.000000\n",
      "2019-10-29 00:46:21,728 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:21,730 : INFO : built Dictionary(21 unique tokens: ['tip', 'agree', 'high', 'privacy', 'policy']...) from 5 documents (total 110 corpus positions)\n",
      "2019-10-29 00:46:21,730 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:21,731 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:21,735 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:21,739 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:21,742 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:21,758 : INFO : -6.451 per-word bound, 87.5 perplexity estimate based on a held-out corpus of 5 documents with 110 words\n",
      "2019-10-29 00:46:21,761 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:21,767 : INFO : topic #9 (0.100): 0.099*\"cooky\" + 0.053*\"continuing\" + 0.050*\"privacy\" + 0.049*\"owner\" + 0.049*\"bar\" + 0.048*\"tip\" + 0.048*\"revised\" + 0.048*\"tokyo\" + 0.048*\"service\" + 0.046*\"five\"\n",
      "2019-10-29 00:46:21,770 : INFO : topic #0 (0.100): 0.074*\"cooky\" + 0.058*\"site\" + 0.053*\"continuing\" + 0.052*\"revised\" + 0.051*\"use\" + 0.051*\"information\" + 0.051*\"bar\" + 0.050*\"photo\" + 0.049*\"privacy\" + 0.046*\"service\"\n",
      "2019-10-29 00:46:21,773 : INFO : topic #2 (0.100): 0.067*\"dining\" + 0.062*\"cooky\" + 0.059*\"policy\" + 0.056*\"tokyo\" + 0.055*\"share\" + 0.050*\"five\" + 0.050*\"photo\" + 0.049*\"tip\" + 0.048*\"browse\" + 0.048*\"agree\"\n",
      "2019-10-29 00:46:21,776 : INFO : topic #1 (0.100): 0.072*\"cooky\" + 0.054*\"term\" + 0.053*\"tokyo\" + 0.052*\"tip\" + 0.052*\"browse\" + 0.051*\"use\" + 0.051*\"high\" + 0.050*\"share\" + 0.050*\"continuing\" + 0.048*\"five\"\n",
      "2019-10-29 00:46:21,779 : INFO : topic #8 (0.100): 0.089*\"cooky\" + 0.056*\"use\" + 0.054*\"tip\" + 0.052*\"high\" + 0.051*\"photo\" + 0.051*\"bar\" + 0.050*\"owner\" + 0.049*\"service\" + 0.048*\"information\" + 0.048*\"site\"\n",
      "2019-10-29 00:46:21,782 : INFO : topic diff=0.553691, rho=1.000000\n",
      "2019-10-29 00:46:22,204 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:22,210 : INFO : built Dictionary(357 unique tokens: ['hotline', 'party', 'advantage', 'expert', 'u']...) from 5 documents (total 2850 corpus positions)\n",
      "2019-10-29 00:46:22,214 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:22,215 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:22,217 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:22,221 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:22,222 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:22,344 : INFO : -7.846 per-word bound, 230.1 perplexity estimate based on a held-out corpus of 5 documents with 2850 words\n",
      "2019-10-29 00:46:22,346 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:22,355 : INFO : topic #2 (0.100): 0.023*\"case\" + 0.018*\"food\" + 0.017*\"worker\" + 0.017*\"florida\" + 0.014*\"say\" + 0.014*\"work\" + 0.012*\"slavery\" + 0.012*\"u\" + 0.011*\"program\" + 0.010*\"germino\"\n",
      "2019-10-29 00:46:22,358 : INFO : topic #1 (0.100): 0.024*\"say\" + 0.020*\"worker\" + 0.018*\"food\" + 0.018*\"case\" + 0.015*\"immokalee\" + 0.015*\"florida\" + 0.013*\"work\" + 0.012*\"farm\" + 0.011*\"right\" + 0.011*\"slavery\"\n",
      "2019-10-29 00:46:22,360 : INFO : topic #7 (0.100): 0.019*\"say\" + 0.018*\"case\" + 0.016*\"worker\" + 0.015*\"florida\" + 0.014*\"food\" + 0.014*\"work\" + 0.014*\"farm\" + 0.012*\"slavery\" + 0.012*\"fair\" + 0.011*\"program\"\n",
      "2019-10-29 00:46:22,363 : INFO : topic #6 (0.100): 0.019*\"worker\" + 0.018*\"say\" + 0.014*\"farm\" + 0.014*\"food\" + 0.013*\"florida\" + 0.013*\"case\" + 0.013*\"fair\" + 0.012*\"work\" + 0.012*\"tomato\" + 0.011*\"slavery\"\n",
      "2019-10-29 00:46:22,366 : INFO : topic #9 (0.100): 0.022*\"worker\" + 0.019*\"say\" + 0.018*\"case\" + 0.018*\"food\" + 0.013*\"florida\" + 0.013*\"fair\" + 0.012*\"right\" + 0.012*\"immokalee\" + 0.011*\"slavery\" + 0.011*\"farm\"\n",
      "2019-10-29 00:46:22,369 : INFO : topic diff=0.891242, rho=1.000000\n",
      "2019-10-29 00:46:22,780 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:22,783 : INFO : built Dictionary(120 unique tokens: ['fighter', 'harsh', 'small', 'color', 'sometimes']...) from 5 documents (total 775 corpus positions)\n",
      "2019-10-29 00:46:22,786 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:22,790 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:22,792 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:22,800 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:22,803 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:22,879 : INFO : -7.203 per-word bound, 147.3 perplexity estimate based on a held-out corpus of 5 documents with 775 words\n",
      "2019-10-29 00:46:22,881 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:22,891 : INFO : topic #2 (0.100): 0.039*\"fight\" + 0.034*\"mazur\" + 0.033*\"club\" + 0.028*\"said\" + 0.017*\"world\" + 0.017*\"close\" + 0.016*\"female\" + 0.016*\"photographer\" + 0.015*\"first\" + 0.014*\"light\"\n",
      "2019-10-29 00:46:22,894 : INFO : topic #5 (0.100): 0.043*\"fight\" + 0.036*\"club\" + 0.031*\"mazur\" + 0.021*\"said\" + 0.019*\"katarzyna\" + 0.018*\"world\" + 0.017*\"close\" + 0.017*\"female\" + 0.015*\"woman\" + 0.014*\"berlin\"\n",
      "2019-10-29 00:46:22,897 : INFO : topic #3 (0.100): 0.031*\"fight\" + 0.030*\"mazur\" + 0.025*\"club\" + 0.023*\"said\" + 0.021*\"female\" + 0.020*\"katarzyna\" + 0.019*\"world\" + 0.019*\"close\" + 0.017*\"spent\" + 0.015*\"light\"\n",
      "2019-10-29 00:46:22,901 : INFO : topic #8 (0.100): 0.039*\"club\" + 0.034*\"mazur\" + 0.029*\"fight\" + 0.025*\"said\" + 0.020*\"world\" + 0.019*\"close\" + 0.019*\"female\" + 0.018*\"katarzyna\" + 0.015*\"berlin\" + 0.013*\"woman\"\n",
      "2019-10-29 00:46:22,904 : INFO : topic #4 (0.100): 0.034*\"fight\" + 0.034*\"club\" + 0.032*\"mazur\" + 0.024*\"said\" + 0.021*\"world\" + 0.020*\"female\" + 0.019*\"katarzyna\" + 0.018*\"close\" + 0.014*\"photographer\" + 0.013*\"berlin\"\n",
      "2019-10-29 00:46:22,907 : INFO : topic diff=0.760062, rho=1.000000\n",
      "2019-10-29 00:46:23,374 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:23,376 : INFO : built Dictionary(61 unique tokens: ['student', 'time', 'name', 'since', 'attainable']...) from 5 documents (total 345 corpus positions)\n",
      "2019-10-29 00:46:23,377 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:23,380 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:23,383 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:23,387 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:23,390 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:23,417 : INFO : -6.918 per-word bound, 121.0 perplexity estimate based on a held-out corpus of 5 documents with 345 words\n",
      "2019-10-29 00:46:23,419 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:23,425 : INFO : topic #4 (0.100): 0.040*\"success\" + 0.035*\"paperless\" + 0.031*\"feel\" + 0.027*\"really\" + 0.026*\"founder\" + 0.024*\"post\" + 0.021*\"hirschfeld\" + 0.019*\"traditional\" + 0.019*\"moved\" + 0.019*\"email\"\n",
      "2019-10-29 00:46:23,428 : INFO : topic #8 (0.100): 0.047*\"success\" + 0.031*\"founder\" + 0.031*\"feel\" + 0.031*\"post\" + 0.028*\"really\" + 0.027*\"hirschfeld\" + 0.021*\"paperless\" + 0.020*\"student\" + 0.019*\"james\" + 0.017*\"invitation\"\n",
      "2019-10-29 00:46:23,431 : INFO : topic #1 (0.100): 0.042*\"success\" + 0.028*\"founder\" + 0.026*\"post\" + 0.026*\"really\" + 0.022*\"feel\" + 0.022*\"paperless\" + 0.021*\"hirschfeld\" + 0.018*\"like\" + 0.018*\"world\" + 0.018*\"amazing\"\n",
      "2019-10-29 00:46:23,435 : INFO : topic #5 (0.100): 0.036*\"success\" + 0.030*\"really\" + 0.029*\"feel\" + 0.027*\"paperless\" + 0.026*\"post\" + 0.026*\"hirschfeld\" + 0.023*\"founder\" + 0.019*\"top\" + 0.018*\"co\" + 0.018*\"entrepreneur\"\n",
      "2019-10-29 00:46:23,439 : INFO : topic #9 (0.100): 0.041*\"success\" + 0.033*\"feel\" + 0.030*\"really\" + 0.026*\"hirschfeld\" + 0.023*\"post\" + 0.022*\"founder\" + 0.020*\"paperless\" + 0.020*\"platform\" + 0.019*\"maybe\" + 0.018*\"attainable\"\n",
      "2019-10-29 00:46:23,442 : INFO : topic diff=0.619930, rho=1.000000\n",
      "2019-10-29 00:46:23,862 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:23,868 : INFO : built Dictionary(253 unique tokens: ['although', 'extensive', 'diagnostic', 'offered', 'transmit']...) from 5 documents (total 2125 corpus positions)\n",
      "2019-10-29 00:46:23,871 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:23,872 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:23,874 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:23,877 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:23,878 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:23,969 : INFO : -7.453 per-word bound, 175.2 perplexity estimate based on a held-out corpus of 5 documents with 2125 words\n",
      "2019-10-29 00:46:23,971 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:23,979 : INFO : topic #1 (0.100): 0.041*\"dental\" + 0.033*\"coverage\" + 0.023*\"benefit\" + 0.021*\"health\" + 0.016*\"state\" + 0.014*\"also\" + 0.014*\"oral\" + 0.013*\"adult\" + 0.013*\"problem\" + 0.013*\"child\"\n",
      "2019-10-29 00:46:23,982 : INFO : topic #8 (0.100): 0.036*\"dental\" + 0.024*\"coverage\" + 0.023*\"state\" + 0.022*\"health\" + 0.018*\"benefit\" + 0.015*\"care\" + 0.013*\"oral\" + 0.013*\"plan\" + 0.013*\"child\" + 0.013*\"also\"\n",
      "2019-10-29 00:46:23,985 : INFO : topic #3 (0.100): 0.044*\"coverage\" + 0.031*\"dental\" + 0.023*\"health\" + 0.022*\"benefit\" + 0.014*\"state\" + 0.014*\"child\" + 0.013*\"also\" + 0.013*\"oral\" + 0.012*\"problem\" + 0.012*\"care\"\n",
      "2019-10-29 00:46:23,988 : INFO : topic #7 (0.100): 0.035*\"coverage\" + 0.027*\"health\" + 0.025*\"benefit\" + 0.022*\"dental\" + 0.018*\"child\" + 0.017*\"state\" + 0.015*\"care\" + 0.015*\"also\" + 0.014*\"plan\" + 0.012*\"oral\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:23,991 : INFO : topic #4 (0.100): 0.035*\"dental\" + 0.034*\"coverage\" + 0.022*\"benefit\" + 0.019*\"health\" + 0.016*\"state\" + 0.015*\"care\" + 0.014*\"child\" + 0.014*\"also\" + 0.013*\"adult\" + 0.013*\"oral\"\n",
      "2019-10-29 00:46:23,994 : INFO : topic diff=0.895474, rho=1.000000\n",
      "2019-10-29 00:46:24,437 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:24,442 : INFO : built Dictionary(330 unique tokens: ['selling', 'consent', 'story', 'single', 'punish']...) from 5 documents (total 2395 corpus positions)\n",
      "2019-10-29 00:46:24,447 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:24,448 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:24,449 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:24,453 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:24,454 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:24,576 : INFO : -7.919 per-word bound, 242.0 perplexity estimate based on a held-out corpus of 5 documents with 2395 words\n",
      "2019-10-29 00:46:24,577 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:24,585 : INFO : topic #7 (0.100): 0.031*\"rape\" + 0.025*\"son\" + 0.025*\"turner\" + 0.020*\"victim\" + 0.012*\"woman\" + 0.011*\"men\" + 0.011*\"alcohol\" + 0.010*\"letter\" + 0.010*\"campus\" + 0.009*\"one\"\n",
      "2019-10-29 00:46:24,587 : INFO : topic #1 (0.100): 0.024*\"victim\" + 0.022*\"rape\" + 0.019*\"turner\" + 0.017*\"son\" + 0.014*\"letter\" + 0.011*\"alcohol\" + 0.010*\"one\" + 0.009*\"woman\" + 0.008*\"men\" + 0.008*\"every\"\n",
      "2019-10-29 00:46:24,589 : INFO : topic #4 (0.100): 0.022*\"rape\" + 0.021*\"turner\" + 0.020*\"son\" + 0.015*\"letter\" + 0.014*\"victim\" + 0.011*\"men\" + 0.010*\"one\" + 0.010*\"woman\" + 0.008*\"campus\" + 0.008*\"offender\"\n",
      "2019-10-29 00:46:24,592 : INFO : topic #0 (0.100): 0.024*\"turner\" + 0.023*\"rape\" + 0.022*\"victim\" + 0.017*\"son\" + 0.015*\"letter\" + 0.012*\"campus\" + 0.010*\"men\" + 0.010*\"judge\" + 0.010*\"one\" + 0.009*\"alcohol\"\n",
      "2019-10-29 00:46:24,595 : INFO : topic #9 (0.100): 0.027*\"rape\" + 0.026*\"victim\" + 0.021*\"son\" + 0.021*\"turner\" + 0.016*\"letter\" + 0.011*\"men\" + 0.010*\"woman\" + 0.010*\"alcohol\" + 0.010*\"campus\" + 0.010*\"one\"\n",
      "2019-10-29 00:46:24,597 : INFO : topic diff=0.826774, rho=1.000000\n",
      "2019-10-29 00:46:25,005 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:25,009 : INFO : built Dictionary(331 unique tokens: ['yes', 'talking', 'magnesium', 'astrologically', 'joint']...) from 5 documents (total 2290 corpus positions)\n",
      "2019-10-29 00:46:25,013 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:25,016 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:25,020 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:25,024 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:25,027 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:25,141 : INFO : -8.001 per-word bound, 256.2 perplexity estimate based on a held-out corpus of 5 documents with 2290 words\n",
      "2019-10-29 00:46:25,142 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:25,149 : INFO : topic #0 (0.100): 0.023*\"smith\" + 0.014*\"research\" + 0.014*\"egg\" + 0.012*\"may\" + 0.009*\"health\" + 0.009*\"say\" + 0.009*\"also\" + 0.008*\"hormone\" + 0.008*\"really\" + 0.008*\"blue\"\n",
      "2019-10-29 00:46:25,151 : INFO : topic #8 (0.100): 0.017*\"smith\" + 0.014*\"egg\" + 0.013*\"say\" + 0.011*\"may\" + 0.011*\"research\" + 0.010*\"health\" + 0.009*\"herb\" + 0.009*\"ingredient\" + 0.008*\"cannabis\" + 0.008*\"yes\"\n",
      "2019-10-29 00:46:25,155 : INFO : topic #2 (0.100): 0.020*\"smith\" + 0.019*\"egg\" + 0.013*\"say\" + 0.011*\"research\" + 0.010*\"may\" + 0.009*\"ingredient\" + 0.008*\"herb\" + 0.008*\"yes\" + 0.008*\"health\" + 0.007*\"cannabis\"\n",
      "2019-10-29 00:46:25,158 : INFO : topic #7 (0.100): 0.017*\"smith\" + 0.014*\"say\" + 0.014*\"egg\" + 0.012*\"may\" + 0.010*\"research\" + 0.010*\"also\" + 0.009*\"claim\" + 0.009*\"herb\" + 0.008*\"ingredient\" + 0.008*\"human\"\n",
      "2019-10-29 00:46:25,161 : INFO : topic #4 (0.100): 0.016*\"egg\" + 0.014*\"research\" + 0.012*\"smith\" + 0.012*\"say\" + 0.010*\"may\" + 0.009*\"herb\" + 0.008*\"blue\" + 0.008*\"health\" + 0.008*\"claim\" + 0.008*\"yes\"\n",
      "2019-10-29 00:46:25,163 : INFO : topic diff=0.777416, rho=1.000000\n",
      "2019-10-29 00:46:25,568 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:25,571 : INFO : built Dictionary(71 unique tokens: ['single', 'chain', 'pepper', 'clunky', 'serving']...) from 5 documents (total 515 corpus positions)\n",
      "2019-10-29 00:46:25,573 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:25,575 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:25,576 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:25,579 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:25,580 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:25,615 : INFO : -6.550 per-word bound, 93.7 perplexity estimate based on a held-out corpus of 5 documents with 515 words\n",
      "2019-10-29 00:46:25,616 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:25,625 : INFO : topic #1 (0.100): 0.054*\"sriracha\" + 0.043*\"sauce\" + 0.036*\"packet\" + 0.034*\"go\" + 0.030*\"lover\" + 0.028*\"hot\" + 0.027*\"food\" + 0.022*\"come\" + 0.022*\"new\" + 0.021*\"fan\"\n",
      "2019-10-29 00:46:25,628 : INFO : topic #4 (0.100): 0.039*\"sriracha\" + 0.037*\"sauce\" + 0.037*\"packet\" + 0.035*\"hot\" + 0.035*\"go\" + 0.034*\"lover\" + 0.029*\"food\" + 0.026*\"red\" + 0.022*\"spicy\" + 0.020*\"fan\"\n",
      "2019-10-29 00:46:25,632 : INFO : topic #7 (0.100): 0.054*\"sriracha\" + 0.046*\"packet\" + 0.046*\"sauce\" + 0.032*\"lover\" + 0.032*\"hot\" + 0.031*\"food\" + 0.029*\"spicy\" + 0.026*\"go\" + 0.025*\"fan\" + 0.024*\"chili\"\n",
      "2019-10-29 00:46:25,637 : INFO : topic #8 (0.100): 0.057*\"sriracha\" + 0.047*\"hot\" + 0.045*\"sauce\" + 0.040*\"packet\" + 0.034*\"lover\" + 0.034*\"spicy\" + 0.027*\"go\" + 0.027*\"food\" + 0.021*\"bottle\" + 0.020*\"around\"\n",
      "2019-10-29 00:46:25,639 : INFO : topic #9 (0.100): 0.051*\"sriracha\" + 0.040*\"packet\" + 0.039*\"sauce\" + 0.037*\"hot\" + 0.031*\"go\" + 0.023*\"get\" + 0.023*\"food\" + 0.022*\"around\" + 0.021*\"spicy\" + 0.021*\"come\"\n",
      "2019-10-29 00:46:25,641 : INFO : topic diff=0.808652, rho=1.000000\n",
      "2019-10-29 00:46:26,051 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:26,054 : INFO : built Dictionary(180 unique tokens: ['overseas', 'internal', 'person', 'way', 'aid']...) from 5 documents (total 1430 corpus positions)\n",
      "2019-10-29 00:46:26,057 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:26,059 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:26,061 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:26,063 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:26,064 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:26,149 : INFO : -7.223 per-word bound, 149.4 perplexity estimate based on a held-out corpus of 5 documents with 1430 words\n",
      "2019-10-29 00:46:26,151 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:26,161 : INFO : topic #9 (0.100): 0.073*\"veteran\" + 0.028*\"said\" + 0.025*\"get\" + 0.022*\"ranch\" + 0.022*\"burton\" + 0.017*\"combat\" + 0.017*\"caparelli\" + 0.013*\"help\" + 0.012*\"day\" + 0.011*\"military\"\n",
      "2019-10-29 00:46:26,163 : INFO : topic #7 (0.100): 0.075*\"veteran\" + 0.038*\"said\" + 0.024*\"ranch\" + 0.021*\"caparelli\" + 0.019*\"burton\" + 0.016*\"get\" + 0.014*\"help\" + 0.014*\"combat\" + 0.013*\"program\" + 0.011*\"often\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:26,167 : INFO : topic #6 (0.100): 0.055*\"veteran\" + 0.028*\"ranch\" + 0.027*\"said\" + 0.017*\"caparelli\" + 0.017*\"help\" + 0.016*\"get\" + 0.015*\"burton\" + 0.014*\"combat\" + 0.010*\"day\" + 0.010*\"program\"\n",
      "2019-10-29 00:46:26,171 : INFO : topic #3 (0.100): 0.084*\"veteran\" + 0.031*\"said\" + 0.026*\"ranch\" + 0.023*\"burton\" + 0.021*\"get\" + 0.021*\"combat\" + 0.014*\"caparelli\" + 0.012*\"program\" + 0.011*\"people\" + 0.010*\"day\"\n",
      "2019-10-29 00:46:26,176 : INFO : topic #0 (0.100): 0.061*\"veteran\" + 0.035*\"said\" + 0.025*\"ranch\" + 0.018*\"burton\" + 0.016*\"get\" + 0.016*\"caparelli\" + 0.014*\"help\" + 0.013*\"combat\" + 0.011*\"often\" + 0.011*\"program\"\n",
      "2019-10-29 00:46:26,179 : INFO : topic diff=0.821040, rho=1.000000\n",
      "2019-10-29 00:46:26,639 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:26,646 : INFO : built Dictionary(351 unique tokens: ['offered', 'party', 'advantage', 'klux', 'game']...) from 5 documents (total 2550 corpus positions)\n",
      "2019-10-29 00:46:26,654 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:26,656 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:26,660 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:26,664 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:26,667 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:26,791 : INFO : -7.971 per-word bound, 250.9 perplexity estimate based on a held-out corpus of 5 documents with 2550 words\n",
      "2019-10-29 00:46:26,792 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:26,800 : INFO : topic #3 (0.100): 0.042*\"trump\" + 0.022*\"know\" + 0.016*\"duke\" + 0.016*\"white\" + 0.014*\"supremacist\" + 0.013*\"american\" + 0.012*\"president\" + 0.010*\"said\" + 0.009*\"indian\" + 0.008*\"like\"\n",
      "2019-10-29 00:46:26,802 : INFO : topic #6 (0.100): 0.050*\"trump\" + 0.019*\"duke\" + 0.018*\"know\" + 0.014*\"white\" + 0.014*\"president\" + 0.013*\"said\" + 0.011*\"american\" + 0.011*\"supremacist\" + 0.010*\"indian\" + 0.009*\"year\"\n",
      "2019-10-29 00:46:26,805 : INFO : topic #7 (0.100): 0.040*\"trump\" + 0.024*\"white\" + 0.017*\"duke\" + 0.016*\"know\" + 0.013*\"president\" + 0.011*\"supremacist\" + 0.011*\"said\" + 0.010*\"year\" + 0.009*\"indian\" + 0.009*\"american\"\n",
      "2019-10-29 00:46:26,807 : INFO : topic #5 (0.100): 0.038*\"trump\" + 0.026*\"white\" + 0.016*\"know\" + 0.015*\"duke\" + 0.012*\"said\" + 0.010*\"american\" + 0.010*\"david\" + 0.010*\"supremacist\" + 0.009*\"president\" + 0.009*\"indian\"\n",
      "2019-10-29 00:46:26,809 : INFO : topic #8 (0.100): 0.031*\"trump\" + 0.018*\"duke\" + 0.018*\"white\" + 0.016*\"know\" + 0.013*\"said\" + 0.012*\"american\" + 0.009*\"like\" + 0.009*\"supremacist\" + 0.009*\"year\" + 0.008*\"president\"\n",
      "2019-10-29 00:46:26,812 : INFO : topic diff=0.814675, rho=1.000000\n",
      "2019-10-29 00:46:27,243 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:27,247 : INFO : built Dictionary(247 unique tokens: ['span', 'gripe', 'end', 'come', 'asked']...) from 5 documents (total 1780 corpus positions)\n",
      "2019-10-29 00:46:27,252 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:27,253 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:27,255 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:27,258 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:27,261 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:27,350 : INFO : -7.658 per-word bound, 202.0 perplexity estimate based on a held-out corpus of 5 documents with 1780 words\n",
      "2019-10-29 00:46:27,351 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:27,358 : INFO : topic #5 (0.100): 0.038*\"generation\" + 0.023*\"xers\" + 0.019*\"gen\" + 0.016*\"generational\" + 0.014*\"millennials\" + 0.014*\"one\" + 0.013*\"boomer\" + 0.011*\"age\" + 0.010*\"political\" + 0.010*\"year\"\n",
      "2019-10-29 00:46:27,359 : INFO : topic #3 (0.100): 0.042*\"generation\" + 0.027*\"xers\" + 0.017*\"gen\" + 0.017*\"one\" + 0.015*\"millennials\" + 0.014*\"boomer\" + 0.014*\"age\" + 0.014*\"political\" + 0.013*\"generational\" + 0.010*\"x\"\n",
      "2019-10-29 00:46:27,361 : INFO : topic #8 (0.100): 0.033*\"generation\" + 0.025*\"xers\" + 0.018*\"millennials\" + 0.017*\"one\" + 0.016*\"age\" + 0.016*\"gen\" + 0.013*\"generational\" + 0.012*\"boomer\" + 0.010*\"reason\" + 0.010*\"year\"\n",
      "2019-10-29 00:46:27,363 : INFO : topic #9 (0.100): 0.027*\"generation\" + 0.024*\"xers\" + 0.018*\"boomer\" + 0.016*\"one\" + 0.016*\"age\" + 0.016*\"millennials\" + 0.012*\"generational\" + 0.011*\"x\" + 0.011*\"political\" + 0.011*\"gen\"\n",
      "2019-10-29 00:46:27,365 : INFO : topic #0 (0.100): 0.028*\"generation\" + 0.027*\"xers\" + 0.019*\"one\" + 0.018*\"gen\" + 0.015*\"boomer\" + 0.015*\"generational\" + 0.015*\"millennials\" + 0.013*\"age\" + 0.012*\"political\" + 0.011*\"x\"\n",
      "2019-10-29 00:46:27,367 : INFO : topic diff=0.808116, rho=1.000000\n",
      "2019-10-29 00:46:27,788 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:27,790 : INFO : built Dictionary(79 unique tokens: ['stick', 'help', 'helpful', 'food', 'may']...) from 5 documents (total 530 corpus positions)\n",
      "2019-10-29 00:46:27,792 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:27,794 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:27,796 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:27,798 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:27,803 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:27,841 : INFO : -6.776 per-word bound, 109.6 perplexity estimate based on a held-out corpus of 5 documents with 530 words\n",
      "2019-10-29 00:46:27,843 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:27,850 : INFO : topic #8 (0.100): 0.054*\"mediterranean\" + 0.049*\"diet\" + 0.027*\"study\" + 0.026*\"death\" + 0.024*\"people\" + 0.021*\"stuck\" + 0.019*\"oil\" + 0.019*\"may\" + 0.018*\"heart\" + 0.018*\"meat\"\n",
      "2019-10-29 00:46:27,855 : INFO : topic #2 (0.100): 0.068*\"diet\" + 0.050*\"mediterranean\" + 0.029*\"people\" + 0.028*\"study\" + 0.021*\"risk\" + 0.020*\"lot\" + 0.018*\"stuck\" + 0.018*\"may\" + 0.017*\"oil\" + 0.017*\"food\"\n",
      "2019-10-29 00:46:27,859 : INFO : topic #1 (0.100): 0.055*\"diet\" + 0.049*\"mediterranean\" + 0.032*\"people\" + 0.026*\"study\" + 0.023*\"food\" + 0.021*\"heart\" + 0.020*\"lot\" + 0.019*\"menu\" + 0.018*\"may\" + 0.018*\"oil\"\n",
      "2019-10-29 00:46:27,863 : INFO : topic #0 (0.100): 0.070*\"diet\" + 0.062*\"mediterranean\" + 0.028*\"people\" + 0.026*\"meat\" + 0.022*\"heart\" + 0.021*\"study\" + 0.021*\"risk\" + 0.021*\"food\" + 0.020*\"oil\" + 0.017*\"lower\"\n",
      "2019-10-29 00:46:27,868 : INFO : topic #4 (0.100): 0.055*\"diet\" + 0.048*\"mediterranean\" + 0.026*\"study\" + 0.023*\"people\" + 0.023*\"may\" + 0.021*\"lower\" + 0.021*\"lot\" + 0.019*\"heart\" + 0.019*\"health\" + 0.018*\"risk\"\n",
      "2019-10-29 00:46:27,871 : INFO : topic diff=0.744626, rho=1.000000\n",
      "2019-10-29 00:46:28,356 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:28,366 : INFO : built Dictionary(419 unique tokens: ['anniversary', 'embody', 'party', 'eve', 'cool']...) from 5 documents (total 3085 corpus positions)\n",
      "2019-10-29 00:46:28,377 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:28,380 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:28,384 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:28,389 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:28,391 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:28,554 : INFO : -8.127 per-word bound, 279.5 perplexity estimate based on a held-out corpus of 5 documents with 3085 words\n",
      "2019-10-29 00:46:28,555 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:28,565 : INFO : topic #9 (0.100): 0.031*\"fiorucci\" + 0.026*\"brand\" + 0.014*\"fashion\" + 0.012*\"would\" + 0.010*\"say\" + 0.008*\"store\" + 0.007*\"culture\" + 0.007*\"shop\" + 0.007*\"time\" + 0.007*\"name\"\n",
      "2019-10-29 00:46:28,567 : INFO : topic #2 (0.100): 0.030*\"fiorucci\" + 0.023*\"brand\" + 0.014*\"fashion\" + 0.010*\"would\" + 0.010*\"store\" + 0.008*\"say\" + 0.007*\"shop\" + 0.007*\"street\" + 0.007*\"name\" + 0.007*\"milan\"\n",
      "2019-10-29 00:46:28,570 : INFO : topic #1 (0.100): 0.024*\"fiorucci\" + 0.024*\"brand\" + 0.013*\"fashion\" + 0.012*\"would\" + 0.011*\"store\" + 0.008*\"say\" + 0.008*\"culture\" + 0.008*\"shop\" + 0.007*\"milan\" + 0.007*\"could\"\n",
      "2019-10-29 00:46:28,572 : INFO : topic #0 (0.100): 0.023*\"fiorucci\" + 0.020*\"brand\" + 0.019*\"fashion\" + 0.009*\"london\" + 0.009*\"store\" + 0.009*\"say\" + 0.008*\"would\" + 0.008*\"street\" + 0.007*\"popular\" + 0.007*\"shop\"\n",
      "2019-10-29 00:46:28,575 : INFO : topic #8 (0.100): 0.032*\"fiorucci\" + 0.023*\"brand\" + 0.014*\"fashion\" + 0.012*\"would\" + 0.012*\"store\" + 0.009*\"say\" + 0.008*\"like\" + 0.008*\"made\" + 0.008*\"london\" + 0.007*\"time\"\n",
      "2019-10-29 00:46:28,577 : INFO : topic diff=0.799379, rho=1.000000\n",
      "2019-10-29 00:46:29,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:29,007 : INFO : built Dictionary(262 unique tokens: ['let', 'prime', 'accommodating', 'chilly', 'walmart']...) from 5 documents (total 2055 corpus positions)\n",
      "2019-10-29 00:46:29,010 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:29,011 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:29,012 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:29,016 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:29,017 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:29,123 : INFO : -7.586 per-word bound, 192.1 perplexity estimate based on a held-out corpus of 5 documents with 2055 words\n",
      "2019-10-29 00:46:29,125 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:29,131 : INFO : topic #4 (0.100): 0.035*\"order\" + 0.028*\"amazonfresh\" + 0.027*\"amazon\" + 0.017*\"delivery\" + 0.017*\"fresh\" + 0.015*\"grocery\" + 0.014*\"item\" + 0.013*\"subscription\" + 0.011*\"service\" + 0.009*\"could\"\n",
      "2019-10-29 00:46:29,133 : INFO : topic #1 (0.100): 0.030*\"order\" + 0.023*\"amazon\" + 0.023*\"amazonfresh\" + 0.016*\"delivery\" + 0.016*\"fresh\" + 0.015*\"subscription\" + 0.014*\"grocery\" + 0.013*\"item\" + 0.011*\"could\" + 0.010*\"free\"\n",
      "2019-10-29 00:46:29,135 : INFO : topic #9 (0.100): 0.033*\"amazon\" + 0.028*\"order\" + 0.024*\"amazonfresh\" + 0.021*\"delivery\" + 0.017*\"fresh\" + 0.015*\"service\" + 0.014*\"grocery\" + 0.013*\"item\" + 0.013*\"could\" + 0.011*\"fee\"\n",
      "2019-10-29 00:46:29,138 : INFO : topic #3 (0.100): 0.037*\"order\" + 0.024*\"amazonfresh\" + 0.023*\"delivery\" + 0.018*\"amazon\" + 0.016*\"grocery\" + 0.014*\"fresh\" + 0.013*\"item\" + 0.013*\"could\" + 0.011*\"one\" + 0.010*\"free\"\n",
      "2019-10-29 00:46:29,141 : INFO : topic #0 (0.100): 0.033*\"order\" + 0.029*\"amazonfresh\" + 0.020*\"amazon\" + 0.019*\"delivery\" + 0.016*\"item\" + 0.014*\"service\" + 0.014*\"grocery\" + 0.011*\"fresh\" + 0.011*\"could\" + 0.010*\"food\"\n",
      "2019-10-29 00:46:29,143 : INFO : topic diff=0.840448, rho=1.000000\n",
      "2019-10-29 00:46:29,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:29,588 : INFO : built Dictionary(381 unique tokens: ['let', 'grew', 'offered', 'planned', 'congressman']...) from 5 documents (total 3255 corpus positions)\n",
      "2019-10-29 00:46:29,592 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:29,594 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:29,596 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:29,600 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:29,602 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:29,726 : INFO : -7.818 per-word bound, 225.7 perplexity estimate based on a held-out corpus of 5 documents with 3255 words\n",
      "2019-10-29 00:46:29,727 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:29,736 : INFO : topic #7 (0.100): 0.041*\"price\" + 0.031*\"trump\" + 0.018*\"flight\" + 0.017*\"private\" + 0.012*\"secretary\" + 0.012*\"plane\" + 0.011*\"said\" + 0.010*\"cost\" + 0.010*\"travel\" + 0.010*\"administration\"\n",
      "2019-10-29 00:46:29,739 : INFO : topic #1 (0.100): 0.047*\"price\" + 0.030*\"trump\" + 0.017*\"private\" + 0.015*\"cost\" + 0.015*\"flight\" + 0.014*\"secretary\" + 0.011*\"travel\" + 0.010*\"charter\" + 0.010*\"plane\" + 0.010*\"administration\"\n",
      "2019-10-29 00:46:29,742 : INFO : topic #0 (0.100): 0.047*\"price\" + 0.031*\"trump\" + 0.015*\"secretary\" + 0.013*\"private\" + 0.012*\"said\" + 0.012*\"plane\" + 0.012*\"flight\" + 0.011*\"hhs\" + 0.010*\"charter\" + 0.009*\"administration\"\n",
      "2019-10-29 00:46:29,746 : INFO : topic #5 (0.100): 0.035*\"price\" + 0.031*\"trump\" + 0.018*\"secretary\" + 0.015*\"flight\" + 0.015*\"said\" + 0.013*\"cost\" + 0.012*\"private\" + 0.011*\"plane\" + 0.010*\"travel\" + 0.009*\"charter\"\n",
      "2019-10-29 00:46:29,750 : INFO : topic #3 (0.100): 0.040*\"price\" + 0.036*\"trump\" + 0.016*\"secretary\" + 0.013*\"private\" + 0.013*\"cost\" + 0.012*\"plane\" + 0.011*\"flight\" + 0.010*\"travel\" + 0.009*\"hhs\" + 0.009*\"said\"\n",
      "2019-10-29 00:46:29,753 : INFO : topic diff=0.856485, rho=1.000000\n",
      "2019-10-29 00:46:30,149 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:30,151 : INFO : built Dictionary(91 unique tokens: ['school', 'de', 'help', 'focus', 'home']...) from 5 documents (total 660 corpus positions)\n",
      "2019-10-29 00:46:30,154 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:30,155 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:30,157 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:30,158 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:30,159 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:30,205 : INFO : -6.754 per-word bound, 107.9 perplexity estimate based on a held-out corpus of 5 documents with 660 words\n",
      "2019-10-29 00:46:30,209 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:30,220 : INFO : topic #5 (0.100): 0.045*\"south\" + 0.036*\"africa\" + 0.029*\"information\" + 0.024*\"aitahealth\" + 0.023*\"app\" + 0.021*\"continent\" + 0.021*\"worker\" + 0.021*\"healthcare\" + 0.020*\"way\" + 0.018*\"lead\"\n",
      "2019-10-29 00:46:30,227 : INFO : topic #8 (0.100): 0.042*\"south\" + 0.037*\"africa\" + 0.031*\"information\" + 0.027*\"aitahealth\" + 0.027*\"app\" + 0.025*\"healthcare\" + 0.024*\"continent\" + 0.022*\"worker\" + 0.021*\"way\" + 0.017*\"infection\"\n",
      "2019-10-29 00:46:30,231 : INFO : topic #3 (0.100): 0.049*\"africa\" + 0.035*\"information\" + 0.033*\"south\" + 0.028*\"aitahealth\" + 0.024*\"healthcare\" + 0.022*\"continent\" + 0.022*\"worker\" + 0.021*\"way\" + 0.021*\"app\" + 0.018*\"day\"\n",
      "2019-10-29 00:46:30,235 : INFO : topic #9 (0.100): 0.050*\"africa\" + 0.033*\"south\" + 0.027*\"aitahealth\" + 0.023*\"continent\" + 0.023*\"information\" + 0.021*\"healthcare\" + 0.021*\"worker\" + 0.019*\"app\" + 0.018*\"day\" + 0.018*\"five\"\n",
      "2019-10-29 00:46:30,238 : INFO : topic #6 (0.100): 0.045*\"south\" + 0.039*\"africa\" + 0.030*\"aitahealth\" + 0.024*\"information\" + 0.023*\"continent\" + 0.023*\"app\" + 0.022*\"way\" + 0.022*\"worker\" + 0.020*\"healthcare\" + 0.020*\"story\"\n",
      "2019-10-29 00:46:30,241 : INFO : topic diff=0.779428, rho=1.000000\n",
      "2019-10-29 00:46:30,683 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:30,686 : INFO : built Dictionary(164 unique tokens: ['miracle', 'front', 'catholic', 'pushed', 'book']...) from 5 documents (total 1215 corpus positions)\n",
      "2019-10-29 00:46:30,688 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:30,689 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:30,691 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:30,693 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:30,694 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:30,771 : INFO : -7.242 per-word bound, 151.4 perplexity estimate based on a held-out corpus of 5 documents with 1215 words\n",
      "2019-10-29 00:46:30,774 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:30,783 : INFO : topic #3 (0.100): 0.039*\"fear\" + 0.025*\"week\" + 0.022*\"afraid\" + 0.019*\"heart\" + 0.018*\"jesus\" + 0.016*\"got\" + 0.015*\"bible\" + 0.014*\"hardened\" + 0.013*\"faith\" + 0.013*\"read\"\n",
      "2019-10-29 00:46:30,785 : INFO : topic #2 (0.100): 0.028*\"week\" + 0.022*\"fear\" + 0.021*\"jesus\" + 0.020*\"afraid\" + 0.017*\"heart\" + 0.016*\"bible\" + 0.015*\"kid\" + 0.014*\"disciple\" + 0.014*\"know\" + 0.012*\"water\"\n",
      "2019-10-29 00:46:30,788 : INFO : topic #9 (0.100): 0.030*\"fear\" + 0.028*\"week\" + 0.024*\"afraid\" + 0.023*\"jesus\" + 0.021*\"disciple\" + 0.019*\"kid\" + 0.018*\"bible\" + 0.018*\"got\" + 0.014*\"water\" + 0.013*\"heart\"\n",
      "2019-10-29 00:46:30,790 : INFO : topic #1 (0.100): 0.036*\"fear\" + 0.023*\"week\" + 0.023*\"jesus\" + 0.021*\"afraid\" + 0.016*\"kid\" + 0.015*\"bible\" + 0.015*\"heart\" + 0.015*\"got\" + 0.014*\"know\" + 0.013*\"faith\"\n",
      "2019-10-29 00:46:30,793 : INFO : topic #0 (0.100): 0.036*\"fear\" + 0.022*\"disciple\" + 0.021*\"afraid\" + 0.021*\"week\" + 0.021*\"jesus\" + 0.017*\"kid\" + 0.014*\"heart\" + 0.014*\"got\" + 0.013*\"read\" + 0.013*\"story\"\n",
      "2019-10-29 00:46:30,802 : INFO : topic diff=0.832479, rho=1.000000\n",
      "2019-10-29 00:46:31,198 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:31,199 : INFO : built Dictionary(15 unique tokens: ['unfolds', 'happening', 'house', 'facebook', 'messenger']...) from 5 documents (total 75 corpus positions)\n",
      "2019-10-29 00:46:31,200 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:31,202 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:31,203 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:31,205 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:31,206 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:31,217 : INFO : -6.457 per-word bound, 87.9 perplexity estimate based on a held-out corpus of 5 documents with 75 words\n",
      "2019-10-29 00:46:31,218 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:31,223 : INFO : topic #3 (0.100): 0.083*\"unfolds\" + 0.079*\"happening\" + 0.077*\"trump\" + 0.074*\"iq\" + 0.072*\"chat\" + 0.070*\"u\" + 0.070*\"comment\" + 0.066*\"messenger\" + 0.066*\"call\" + 0.063*\"world\"\n",
      "2019-10-29 00:46:31,224 : INFO : topic #9 (0.100): 0.088*\"comment\" + 0.075*\"u\" + 0.071*\"facebook\" + 0.070*\"messenger\" + 0.068*\"world\" + 0.068*\"joke\" + 0.067*\"find\" + 0.066*\"house\" + 0.066*\"call\" + 0.065*\"white\"\n",
      "2019-10-29 00:46:31,226 : INFO : topic #2 (0.100): 0.082*\"find\" + 0.079*\"house\" + 0.073*\"happening\" + 0.069*\"world\" + 0.069*\"iq\" + 0.068*\"joke\" + 0.067*\"trump\" + 0.067*\"call\" + 0.064*\"u\" + 0.063*\"comment\"\n",
      "2019-10-29 00:46:31,228 : INFO : topic #0 (0.100): 0.092*\"trump\" + 0.073*\"find\" + 0.073*\"messenger\" + 0.071*\"u\" + 0.069*\"chat\" + 0.068*\"comment\" + 0.068*\"happening\" + 0.067*\"house\" + 0.067*\"iq\" + 0.067*\"world\"\n",
      "2019-10-29 00:46:31,230 : INFO : topic #4 (0.100): 0.078*\"house\" + 0.077*\"iq\" + 0.076*\"world\" + 0.073*\"joke\" + 0.073*\"chat\" + 0.071*\"facebook\" + 0.068*\"trump\" + 0.068*\"white\" + 0.065*\"u\" + 0.064*\"unfolds\"\n",
      "2019-10-29 00:46:31,231 : INFO : topic diff=0.516583, rho=1.000000\n",
      "2019-10-29 00:46:31,710 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:31,716 : INFO : built Dictionary(406 unique tokens: ['josh', 'forecast', 'crest', 'francisco', 'utility']...) from 5 documents (total 4815 corpus positions)\n",
      "2019-10-29 00:46:31,722 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:31,723 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:31,729 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:31,733 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:31,736 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:31,854 : INFO : -7.501 per-word bound, 181.1 perplexity estimate based on a held-out corpus of 5 documents with 4815 words\n",
      "2019-10-29 00:46:31,855 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:31,864 : INFO : topic #2 (0.100): 0.051*\"california\" + 0.038*\"photo\" + 0.037*\"blaze\" + 0.034*\"october\" + 0.033*\"wildfire\" + 0.030*\"hide\" + 0.026*\"caption\" + 0.026*\"fire\" + 0.013*\"rosa\" + 0.012*\"wind\"\n",
      "2019-10-29 00:46:31,867 : INFO : topic #6 (0.100): 0.041*\"wildfire\" + 0.039*\"california\" + 0.038*\"hide\" + 0.037*\"caption\" + 0.030*\"photo\" + 0.030*\"blaze\" + 0.029*\"october\" + 0.026*\"fire\" + 0.013*\"rosa\" + 0.011*\"napa\"\n",
      "2019-10-29 00:46:31,870 : INFO : topic #8 (0.100): 0.042*\"wildfire\" + 0.036*\"blaze\" + 0.035*\"october\" + 0.033*\"california\" + 0.032*\"fire\" + 0.027*\"hide\" + 0.025*\"caption\" + 0.025*\"photo\" + 0.012*\"santa\" + 0.011*\"napa\"\n",
      "2019-10-29 00:46:31,872 : INFO : topic #1 (0.100): 0.038*\"fire\" + 0.038*\"wildfire\" + 0.034*\"caption\" + 0.031*\"blaze\" + 0.030*\"california\" + 0.029*\"photo\" + 0.028*\"hide\" + 0.026*\"october\" + 0.013*\"rosa\" + 0.012*\"santa\"\n",
      "2019-10-29 00:46:31,874 : INFO : topic #4 (0.100): 0.042*\"fire\" + 0.042*\"caption\" + 0.035*\"october\" + 0.034*\"blaze\" + 0.034*\"wildfire\" + 0.031*\"california\" + 0.027*\"photo\" + 0.026*\"hide\" + 0.014*\"santa\" + 0.012*\"napa\"\n",
      "2019-10-29 00:46:31,876 : INFO : topic diff=1.100091, rho=1.000000\n",
      "2019-10-29 00:46:32,270 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:32,274 : INFO : built Dictionary(157 unique tokens: ['surface', 'referee', 'beat', 'entitled', 'provided']...) from 5 documents (total 1080 corpus positions)\n",
      "2019-10-29 00:46:32,278 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:32,279 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:32,280 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:32,282 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:32,284 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:32,349 : INFO : -7.323 per-word bound, 160.1 perplexity estimate based on a held-out corpus of 5 documents with 1080 words\n",
      "2019-10-29 00:46:32,351 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:32,359 : INFO : topic #5 (0.100): 0.029*\"goal\" + 0.025*\"panama\" + 0.022*\"appeal\" + 0.022*\"world\" + 0.021*\"cup\" + 0.017*\"result\" + 0.016*\"rica\" + 0.014*\"final\" + 0.014*\"decision\" + 0.014*\"costa\"\n",
      "2019-10-29 00:46:32,361 : INFO : topic #9 (0.100): 0.026*\"cup\" + 0.022*\"world\" + 0.021*\"panama\" + 0.021*\"appeal\" + 0.019*\"goal\" + 0.015*\"result\" + 0.015*\"rica\" + 0.013*\"costa\" + 0.012*\"state\" + 0.012*\"instead\"\n",
      "2019-10-29 00:46:32,363 : INFO : topic #6 (0.100): 0.027*\"panama\" + 0.022*\"world\" + 0.021*\"appeal\" + 0.018*\"cup\" + 0.015*\"state\" + 0.015*\"final\" + 0.014*\"result\" + 0.014*\"goal\" + 0.014*\"costa\" + 0.013*\"torres\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:32,366 : INFO : topic #4 (0.100): 0.026*\"result\" + 0.025*\"goal\" + 0.023*\"panama\" + 0.021*\"appeal\" + 0.017*\"final\" + 0.015*\"world\" + 0.015*\"state\" + 0.015*\"cup\" + 0.014*\"point\" + 0.011*\"costa\"\n",
      "2019-10-29 00:46:32,368 : INFO : topic #2 (0.100): 0.025*\"cup\" + 0.023*\"panama\" + 0.021*\"world\" + 0.020*\"appeal\" + 0.018*\"goal\" + 0.017*\"result\" + 0.015*\"state\" + 0.015*\"decision\" + 0.014*\"rica\" + 0.013*\"torres\"\n",
      "2019-10-29 00:46:32,370 : INFO : topic diff=0.768137, rho=1.000000\n",
      "2019-10-29 00:46:32,767 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:32,769 : INFO : built Dictionary(20 unique tokens: ['interview', 'tweeting', 'cbs', 'president', 'morning']...) from 5 documents (total 125 corpus positions)\n",
      "2019-10-29 00:46:32,770 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:32,771 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:32,772 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:32,775 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:32,776 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:32,792 : INFO : -5.991 per-word bound, 63.6 perplexity estimate based on a held-out corpus of 5 documents with 125 words\n",
      "2019-10-29 00:46:32,793 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:32,798 : INFO : topic #7 (0.100): 0.138*\"trump\" + 0.091*\"ivana\" + 0.064*\"president\" + 0.055*\"donald\" + 0.051*\"sunday\" + 0.046*\"involved\" + 0.045*\"told\" + 0.044*\"first\" + 0.044*\"said\" + 0.044*\"keep\"\n",
      "2019-10-29 00:46:32,800 : INFO : topic #1 (0.100): 0.122*\"trump\" + 0.070*\"president\" + 0.068*\"ivana\" + 0.066*\"donald\" + 0.063*\"morning\" + 0.050*\"told\" + 0.049*\"life\" + 0.046*\"sunday\" + 0.045*\"interview\" + 0.042*\"along\"\n",
      "2019-10-29 00:46:32,801 : INFO : topic #2 (0.100): 0.092*\"trump\" + 0.083*\"president\" + 0.076*\"donald\" + 0.060*\"ivana\" + 0.054*\"interview\" + 0.053*\"tweeting\" + 0.048*\"along\" + 0.048*\"cbs\" + 0.046*\"told\" + 0.045*\"life\"\n",
      "2019-10-29 00:46:32,803 : INFO : topic #9 (0.100): 0.110*\"trump\" + 0.086*\"ivana\" + 0.077*\"donald\" + 0.072*\"president\" + 0.047*\"wife\" + 0.046*\"said\" + 0.045*\"tweeting\" + 0.044*\"get\" + 0.044*\"melania\" + 0.044*\"life\"\n",
      "2019-10-29 00:46:32,804 : INFO : topic #5 (0.100): 0.119*\"donald\" + 0.104*\"trump\" + 0.082*\"president\" + 0.062*\"ivana\" + 0.054*\"wife\" + 0.044*\"first\" + 0.044*\"sunday\" + 0.044*\"life\" + 0.043*\"tweeting\" + 0.040*\"told\"\n",
      "2019-10-29 00:46:32,805 : INFO : topic diff=0.691686, rho=1.000000\n",
      "2019-10-29 00:46:33,245 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:33,250 : INFO : built Dictionary(380 unique tokens: ['located', 'wave', 'catalyze', 'advantage', 'fueled']...) from 5 documents (total 2730 corpus positions)\n",
      "2019-10-29 00:46:33,254 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:33,257 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:33,258 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:33,265 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:33,268 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:33,389 : INFO : -8.073 per-word bound, 269.3 perplexity estimate based on a held-out corpus of 5 documents with 2730 words\n",
      "2019-10-29 00:46:33,390 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:33,399 : INFO : topic #8 (0.100): 0.022*\"african\" + 0.019*\"africa\" + 0.019*\"human\" + 0.018*\"revolution\" + 0.011*\"today\" + 0.011*\"world\" + 0.011*\"global\" + 0.010*\"future\" + 0.010*\"young\" + 0.009*\"leader\"\n",
      "2019-10-29 00:46:33,401 : INFO : topic #0 (0.100): 0.029*\"african\" + 0.015*\"today\" + 0.014*\"revolution\" + 0.014*\"future\" + 0.014*\"global\" + 0.014*\"africa\" + 0.014*\"human\" + 0.013*\"world\" + 0.009*\"history\" + 0.008*\"young\"\n",
      "2019-10-29 00:46:33,403 : INFO : topic #1 (0.100): 0.021*\"african\" + 0.018*\"human\" + 0.015*\"global\" + 0.014*\"africa\" + 0.013*\"world\" + 0.013*\"future\" + 0.012*\"revolution\" + 0.010*\"today\" + 0.009*\"young\" + 0.009*\"country\"\n",
      "2019-10-29 00:46:33,406 : INFO : topic #3 (0.100): 0.016*\"human\" + 0.015*\"africa\" + 0.015*\"african\" + 0.013*\"global\" + 0.012*\"revolution\" + 0.012*\"future\" + 0.011*\"today\" + 0.010*\"history\" + 0.009*\"leader\" + 0.009*\"young\"\n",
      "2019-10-29 00:46:33,407 : INFO : topic #5 (0.100): 0.019*\"revolution\" + 0.015*\"human\" + 0.015*\"african\" + 0.014*\"africa\" + 0.013*\"global\" + 0.012*\"future\" + 0.010*\"world\" + 0.009*\"today\" + 0.008*\"young\" + 0.007*\"leader\"\n",
      "2019-10-29 00:46:33,409 : INFO : topic diff=0.788861, rho=1.000000\n",
      "2019-10-29 00:46:33,873 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:33,878 : INFO : built Dictionary(123 unique tokens: ['courtesy', 'fiona', 'paris', 'urban', 'de']...) from 5 documents (total 765 corpus positions)\n",
      "2019-10-29 00:46:33,881 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:33,882 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:33,884 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:33,887 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:33,889 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:33,963 : INFO : -7.293 per-word bound, 156.8 perplexity estimate based on a held-out corpus of 5 documents with 765 words\n",
      "2019-10-29 00:46:33,965 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:33,973 : INFO : topic #2 (0.100): 0.024*\"architect\" + 0.021*\"building\" + 0.021*\"art\" + 0.020*\"il\" + 0.019*\"new\" + 0.016*\"idenburg\" + 0.016*\"design\" + 0.015*\"year\" + 0.014*\"space\" + 0.013*\"river\"\n",
      "2019-10-29 00:46:33,976 : INFO : topic #9 (0.100): 0.028*\"il\" + 0.023*\"design\" + 0.021*\"architect\" + 0.019*\"new\" + 0.018*\"building\" + 0.017*\"idenburg\" + 0.016*\"art\" + 0.015*\"competition\" + 0.014*\"l\" + 0.013*\"good\"\n",
      "2019-10-29 00:46:33,979 : INFO : topic #5 (0.100): 0.024*\"il\" + 0.024*\"architect\" + 0.020*\"idenburg\" + 0.018*\"new\" + 0.018*\"design\" + 0.018*\"building\" + 0.016*\"art\" + 0.014*\"good\" + 0.013*\"society\" + 0.013*\"mazas\"\n",
      "2019-10-29 00:46:33,982 : INFO : topic #7 (0.100): 0.027*\"architect\" + 0.022*\"il\" + 0.021*\"building\" + 0.016*\"idenburg\" + 0.016*\"design\" + 0.016*\"art\" + 0.014*\"river\" + 0.014*\"cnn\" + 0.013*\"basel\" + 0.013*\"bank\"\n",
      "2019-10-29 00:46:33,984 : INFO : topic #8 (0.100): 0.024*\"architect\" + 0.022*\"design\" + 0.020*\"building\" + 0.020*\"new\" + 0.018*\"il\" + 0.017*\"idenburg\" + 0.016*\"art\" + 0.015*\"place\" + 0.015*\"bank\" + 0.013*\"river\"\n",
      "2019-10-29 00:46:33,987 : INFO : topic diff=0.702231, rho=1.000000\n",
      "2019-10-29 00:46:34,462 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:34,471 : INFO : built Dictionary(345 unique tokens: ['let', 'catholic', 'cambodian', 'earned', 'language']...) from 5 documents (total 3360 corpus positions)\n",
      "2019-10-29 00:46:34,478 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:34,481 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:34,484 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:34,493 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:34,496 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:34,641 : INFO : -7.554 per-word bound, 187.9 perplexity estimate based on a held-out corpus of 5 documents with 3360 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:34,642 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:34,650 : INFO : topic #4 (0.100): 0.039*\"brick\" + 0.035*\"child\" + 0.030*\"labor\" + 0.027*\"debt\" + 0.025*\"say\" + 0.020*\"kiln\" + 0.016*\"factory\" + 0.012*\"working\" + 0.010*\"penh\" + 0.009*\"cambodia\"\n",
      "2019-10-29 00:46:34,653 : INFO : topic #3 (0.100): 0.032*\"brick\" + 0.025*\"child\" + 0.025*\"kiln\" + 0.022*\"labor\" + 0.022*\"say\" + 0.019*\"debt\" + 0.015*\"factory\" + 0.015*\"working\" + 0.010*\"cambodia\" + 0.009*\"work\"\n",
      "2019-10-29 00:46:34,654 : INFO : topic #2 (0.100): 0.045*\"brick\" + 0.030*\"child\" + 0.028*\"kiln\" + 0.025*\"debt\" + 0.020*\"labor\" + 0.017*\"say\" + 0.013*\"worker\" + 0.013*\"working\" + 0.013*\"factory\" + 0.011*\"cambodia\"\n",
      "2019-10-29 00:46:34,656 : INFO : topic #6 (0.100): 0.035*\"child\" + 0.031*\"kiln\" + 0.030*\"brick\" + 0.027*\"say\" + 0.022*\"debt\" + 0.017*\"labor\" + 0.015*\"factory\" + 0.012*\"cambodia\" + 0.011*\"worker\" + 0.010*\"phnom\"\n",
      "2019-10-29 00:46:34,658 : INFO : topic #0 (0.100): 0.033*\"brick\" + 0.029*\"child\" + 0.028*\"say\" + 0.026*\"debt\" + 0.023*\"labor\" + 0.022*\"kiln\" + 0.014*\"factory\" + 0.012*\"cambodia\" + 0.011*\"work\" + 0.010*\"working\"\n",
      "2019-10-29 00:46:34,660 : INFO : topic diff=0.977181, rho=1.000000\n",
      "2019-10-29 00:46:35,173 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:35,180 : INFO : built Dictionary(452 unique tokens: ['although', 'closure', 'catholic', 'offered', 'focus']...) from 5 documents (total 3835 corpus positions)\n",
      "2019-10-29 00:46:35,186 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:35,188 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:35,189 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:35,192 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:35,195 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:35,380 : INFO : -7.993 per-word bound, 254.8 perplexity estimate based on a held-out corpus of 5 documents with 3835 words\n",
      "2019-10-29 00:46:35,382 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:35,392 : INFO : topic #6 (0.100): 0.029*\"woman\" + 0.024*\"salvador\" + 0.022*\"abortion\" + 0.015*\"el\" + 0.011*\"pregnancy\" + 0.009*\"year\" + 0.008*\"life\" + 0.008*\"court\" + 0.008*\"prison\" + 0.008*\"old\"\n",
      "2019-10-29 00:46:35,395 : INFO : topic #8 (0.100): 0.032*\"woman\" + 0.029*\"abortion\" + 0.017*\"salvador\" + 0.013*\"el\" + 0.010*\"year\" + 0.010*\"pregnancy\" + 0.010*\"life\" + 0.010*\"old\" + 0.008*\"right\" + 0.007*\"child\"\n",
      "2019-10-29 00:46:35,397 : INFO : topic #9 (0.100): 0.028*\"woman\" + 0.025*\"abortion\" + 0.017*\"salvador\" + 0.017*\"el\" + 0.012*\"year\" + 0.009*\"pregnancy\" + 0.008*\"old\" + 0.008*\"reproductive\" + 0.008*\"prison\" + 0.008*\"child\"\n",
      "2019-10-29 00:46:35,400 : INFO : topic #5 (0.100): 0.028*\"abortion\" + 0.027*\"woman\" + 0.023*\"salvador\" + 0.019*\"el\" + 0.013*\"year\" + 0.008*\"san\" + 0.008*\"court\" + 0.008*\"pregnancy\" + 0.008*\"reproductive\" + 0.007*\"old\"\n",
      "2019-10-29 00:46:35,402 : INFO : topic #2 (0.100): 0.028*\"abortion\" + 0.023*\"salvador\" + 0.021*\"woman\" + 0.018*\"el\" + 0.010*\"old\" + 0.009*\"court\" + 0.009*\"year\" + 0.008*\"prison\" + 0.008*\"pregnancy\" + 0.007*\"including\"\n",
      "2019-10-29 00:46:35,405 : INFO : topic diff=0.873091, rho=1.000000\n",
      "2019-10-29 00:46:35,877 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:35,882 : INFO : built Dictionary(133 unique tokens: ['forward', 'school', 'filed', 'though', 'inquiry']...) from 5 documents (total 915 corpus positions)\n",
      "2019-10-29 00:46:35,885 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:35,887 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:35,890 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:35,894 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:35,898 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:35,972 : INFO : -7.172 per-word bound, 144.3 perplexity estimate based on a held-out corpus of 5 documents with 915 words\n",
      "2019-10-29 00:46:35,974 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:35,981 : INFO : topic #6 (0.100): 0.039*\"district\" + 0.035*\"school\" + 0.020*\"shawnee\" + 0.020*\"mission\" + 0.019*\"report\" + 0.018*\"middle\" + 0.016*\"lawsuit\" + 0.015*\"boy\" + 0.015*\"westridge\" + 0.014*\"document\"\n",
      "2019-10-29 00:46:35,984 : INFO : topic #3 (0.100): 0.046*\"school\" + 0.034*\"district\" + 0.027*\"report\" + 0.024*\"shawnee\" + 0.021*\"middle\" + 0.019*\"claim\" + 0.019*\"lawsuit\" + 0.018*\"mission\" + 0.016*\"westridge\" + 0.015*\"document\"\n",
      "2019-10-29 00:46:35,987 : INFO : topic #5 (0.100): 0.038*\"district\" + 0.038*\"school\" + 0.025*\"lawsuit\" + 0.024*\"report\" + 0.021*\"mission\" + 0.017*\"boy\" + 0.015*\"shawnee\" + 0.014*\"claim\" + 0.014*\"middle\" + 0.013*\"victim\"\n",
      "2019-10-29 00:46:35,990 : INFO : topic #0 (0.100): 0.049*\"school\" + 0.038*\"district\" + 0.019*\"mission\" + 0.019*\"lawsuit\" + 0.017*\"middle\" + 0.017*\"victim\" + 0.017*\"report\" + 0.017*\"shawnee\" + 0.016*\"boy\" + 0.016*\"claim\"\n",
      "2019-10-29 00:46:35,992 : INFO : topic #1 (0.100): 0.039*\"school\" + 0.029*\"district\" + 0.027*\"middle\" + 0.022*\"lawsuit\" + 0.020*\"mission\" + 0.018*\"report\" + 0.018*\"shawnee\" + 0.016*\"victim\" + 0.016*\"westridge\" + 0.015*\"claim\"\n",
      "2019-10-29 00:46:35,994 : INFO : topic diff=0.795425, rho=1.000000\n",
      "2019-10-29 00:46:36,489 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:36,496 : INFO : built Dictionary(515 unique tokens: ['although', 'located', 'catholic', 'shambhala', 'party']...) from 5 documents (total 3815 corpus positions)\n",
      "2019-10-29 00:46:36,501 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:36,503 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:36,504 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:36,509 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:36,510 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:36,725 : INFO : -8.315 per-word bound, 318.4 perplexity estimate based on a held-out corpus of 5 documents with 3815 words\n",
      "2019-10-29 00:46:36,727 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:36,738 : INFO : topic #0 (0.100): 0.038*\"goa\" + 0.027*\"beach\" + 0.011*\"market\" + 0.010*\"also\" + 0.009*\"anjuna\" + 0.009*\"goan\" + 0.008*\"north\" + 0.007*\"mapusa\" + 0.006*\"vagator\" + 0.006*\"road\"\n",
      "2019-10-29 00:46:36,740 : INFO : topic #7 (0.100): 0.039*\"goa\" + 0.029*\"beach\" + 0.010*\"market\" + 0.009*\"mapusa\" + 0.009*\"also\" + 0.008*\"goan\" + 0.007*\"anjuna\" + 0.006*\"vagator\" + 0.005*\"find\" + 0.005*\"around\"\n",
      "2019-10-29 00:46:36,743 : INFO : topic #5 (0.100): 0.032*\"goa\" + 0.020*\"beach\" + 0.011*\"goan\" + 0.009*\"market\" + 0.009*\"also\" + 0.008*\"anjuna\" + 0.006*\"meal\" + 0.006*\"north\" + 0.006*\"south\" + 0.006*\"vagator\"\n",
      "2019-10-29 00:46:36,747 : INFO : topic #4 (0.100): 0.034*\"goa\" + 0.016*\"beach\" + 0.010*\"anjuna\" + 0.009*\"also\" + 0.009*\"market\" + 0.007*\"vagator\" + 0.007*\"mapusa\" + 0.007*\"goan\" + 0.006*\"cuisine\" + 0.006*\"meal\"\n",
      "2019-10-29 00:46:36,750 : INFO : topic #3 (0.100): 0.035*\"goa\" + 0.028*\"beach\" + 0.010*\"goan\" + 0.009*\"market\" + 0.008*\"anjuna\" + 0.008*\"also\" + 0.008*\"vagator\" + 0.008*\"mapusa\" + 0.006*\"resort\" + 0.005*\"find\"\n",
      "2019-10-29 00:46:36,753 : INFO : topic diff=0.796259, rho=1.000000\n",
      "2019-10-29 00:46:37,292 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:37,303 : INFO : built Dictionary(607 unique tokens: ['filed', 'chasing', 'shower', 'hero', 'refugio']...) from 5 documents (total 5510 corpus positions)\n",
      "2019-10-29 00:46:37,312 : INFO : using symmetric alpha at 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:37,316 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:37,319 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:37,324 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:37,327 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:37,557 : INFO : -8.186 per-word bound, 291.2 perplexity estimate based on a held-out corpus of 5 documents with 5510 words\n",
      "2019-10-29 00:46:37,558 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:37,568 : INFO : topic #2 (0.100): 0.031*\"guzman\" + 0.025*\"el\" + 0.022*\"chapo\" + 0.017*\"prison\" + 0.013*\"drug\" + 0.012*\"said\" + 0.011*\"time\" + 0.010*\"mexico\" + 0.008*\"authority\" + 0.008*\"cartel\"\n",
      "2019-10-29 00:46:37,570 : INFO : topic #5 (0.100): 0.031*\"guzman\" + 0.027*\"chapo\" + 0.021*\"el\" + 0.016*\"prison\" + 0.014*\"said\" + 0.014*\"drug\" + 0.010*\"say\" + 0.010*\"authority\" + 0.009*\"mexican\" + 0.009*\"time\"\n",
      "2019-10-29 00:46:37,573 : INFO : topic #0 (0.100): 0.030*\"guzman\" + 0.020*\"chapo\" + 0.020*\"el\" + 0.016*\"drug\" + 0.015*\"said\" + 0.014*\"prison\" + 0.012*\"mexico\" + 0.012*\"say\" + 0.011*\"authority\" + 0.009*\"time\"\n",
      "2019-10-29 00:46:37,576 : INFO : topic #7 (0.100): 0.024*\"chapo\" + 0.023*\"el\" + 0.021*\"guzman\" + 0.018*\"prison\" + 0.016*\"drug\" + 0.015*\"said\" + 0.011*\"authority\" + 0.009*\"mexican\" + 0.008*\"say\" + 0.008*\"time\"\n",
      "2019-10-29 00:46:37,578 : INFO : topic #8 (0.100): 0.039*\"guzman\" + 0.026*\"el\" + 0.021*\"chapo\" + 0.016*\"said\" + 0.014*\"say\" + 0.013*\"prison\" + 0.012*\"drug\" + 0.010*\"time\" + 0.009*\"mexico\" + 0.007*\"story\"\n",
      "2019-10-29 00:46:37,581 : INFO : topic diff=0.890883, rho=1.000000\n",
      "2019-10-29 00:46:38,034 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:38,037 : INFO : built Dictionary(67 unique tokens: ['story', 'chandigarh', 'forensic', 'working', 'victim']...) from 5 documents (total 550 corpus positions)\n",
      "2019-10-29 00:46:38,040 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:38,041 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:38,043 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:38,045 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:38,047 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:38,083 : INFO : -6.298 per-word bound, 78.7 perplexity estimate based on a held-out corpus of 5 documents with 550 words\n",
      "2019-10-29 00:46:38,085 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:38,095 : INFO : topic #8 (0.100): 0.055*\"police\" + 0.050*\"uncle\" + 0.041*\"second\" + 0.029*\"test\" + 0.028*\"dna\" + 0.028*\"girl\" + 0.027*\"rape\" + 0.025*\"indian\" + 0.024*\"show\" + 0.023*\"taken\"\n",
      "2019-10-29 00:46:38,100 : INFO : topic #5 (0.100): 0.060*\"second\" + 0.053*\"uncle\" + 0.049*\"police\" + 0.033*\"dna\" + 0.029*\"rape\" + 0.028*\"indian\" + 0.026*\"test\" + 0.024*\"cnn\" + 0.023*\"girl\" + 0.022*\"show\"\n",
      "2019-10-29 00:46:38,103 : INFO : topic #2 (0.100): 0.062*\"uncle\" + 0.047*\"police\" + 0.042*\"dna\" + 0.041*\"second\" + 0.028*\"indian\" + 0.025*\"test\" + 0.025*\"rape\" + 0.024*\"show\" + 0.021*\"jagadale\" + 0.020*\"suspect\"\n",
      "2019-10-29 00:46:38,105 : INFO : topic #9 (0.100): 0.092*\"uncle\" + 0.052*\"second\" + 0.051*\"police\" + 0.039*\"dna\" + 0.028*\"show\" + 0.026*\"test\" + 0.025*\"girl\" + 0.025*\"rape\" + 0.025*\"indian\" + 0.022*\"sample\"\n",
      "2019-10-29 00:46:38,108 : INFO : topic #7 (0.100): 0.077*\"uncle\" + 0.059*\"second\" + 0.048*\"police\" + 0.029*\"girl\" + 0.026*\"dna\" + 0.025*\"indian\" + 0.025*\"test\" + 0.025*\"rape\" + 0.024*\"show\" + 0.022*\"forensic\"\n",
      "2019-10-29 00:46:38,110 : INFO : topic diff=0.823992, rho=1.000000\n",
      "2019-10-29 00:46:38,626 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:38,633 : INFO : built Dictionary(439 unique tokens: ['let', 'acceptable', 'deep', 'drinking', 'focus']...) from 5 documents (total 3175 corpus positions)\n",
      "2019-10-29 00:46:38,639 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:38,640 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:38,642 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:38,648 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:38,651 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:38,853 : INFO : -8.195 per-word bound, 293.0 perplexity estimate based on a held-out corpus of 5 documents with 3175 words\n",
      "2019-10-29 00:46:38,855 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:38,873 : INFO : topic #7 (0.100): 0.019*\"lama\" + 0.015*\"dalai\" + 0.014*\"meditation\" + 0.011*\"holiness\" + 0.010*\"even\" + 0.009*\"problem\" + 0.007*\"analytical\" + 0.007*\"mind\" + 0.007*\"year\" + 0.007*\"meditating\"\n",
      "2019-10-29 00:46:38,876 : INFO : topic #4 (0.100): 0.022*\"meditation\" + 0.015*\"lama\" + 0.015*\"dalai\" + 0.008*\"even\" + 0.008*\"holiness\" + 0.007*\"morning\" + 0.007*\"meditating\" + 0.007*\"problem\" + 0.007*\"mind\" + 0.007*\"instead\"\n",
      "2019-10-29 00:46:38,879 : INFO : topic #3 (0.100): 0.021*\"dalai\" + 0.020*\"meditation\" + 0.013*\"lama\" + 0.011*\"problem\" + 0.010*\"even\" + 0.009*\"analytical\" + 0.009*\"meditating\" + 0.007*\"morning\" + 0.007*\"holiness\" + 0.007*\"started\"\n",
      "2019-10-29 00:46:38,882 : INFO : topic #9 (0.100): 0.019*\"dalai\" + 0.019*\"lama\" + 0.015*\"meditation\" + 0.009*\"problem\" + 0.009*\"even\" + 0.009*\"morning\" + 0.008*\"analytical\" + 0.007*\"instead\" + 0.007*\"hand\" + 0.007*\"focus\"\n",
      "2019-10-29 00:46:38,886 : INFO : topic #8 (0.100): 0.023*\"lama\" + 0.022*\"dalai\" + 0.020*\"meditation\" + 0.010*\"holiness\" + 0.009*\"problem\" + 0.008*\"even\" + 0.008*\"meditating\" + 0.007*\"morning\" + 0.007*\"one\" + 0.007*\"focus\"\n",
      "2019-10-29 00:46:38,888 : INFO : topic diff=0.790685, rho=1.000000\n",
      "2019-10-29 00:46:39,375 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:39,379 : INFO : built Dictionary(302 unique tokens: ['let', 'energy', 'person', 'revealed', 'come']...) from 5 documents (total 2285 corpus positions)\n",
      "2019-10-29 00:46:39,383 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:39,384 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:39,387 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:39,391 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:39,392 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:39,491 : INFO : -7.765 per-word bound, 217.5 perplexity estimate based on a held-out corpus of 5 documents with 2285 words\n",
      "2019-10-29 00:46:39,492 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:39,500 : INFO : topic #4 (0.100): 0.047*\"rainbow\" + 0.041*\"gathering\" + 0.020*\"krivic\" + 0.016*\"like\" + 0.015*\"go\" + 0.014*\"people\" + 0.012*\"said\" + 0.011*\"take\" + 0.011*\"photo\" + 0.010*\"viewer\"\n",
      "2019-10-29 00:46:39,502 : INFO : topic #1 (0.100): 0.045*\"rainbow\" + 0.043*\"gathering\" + 0.025*\"krivic\" + 0.019*\"people\" + 0.018*\"like\" + 0.014*\"said\" + 0.012*\"year\" + 0.011*\"take\" + 0.009*\"go\" + 0.009*\"photo\"\n",
      "2019-10-29 00:46:39,503 : INFO : topic #9 (0.100): 0.035*\"gathering\" + 0.032*\"rainbow\" + 0.026*\"krivic\" + 0.018*\"like\" + 0.014*\"go\" + 0.013*\"take\" + 0.013*\"year\" + 0.013*\"people\" + 0.012*\"said\" + 0.011*\"photography\"\n",
      "2019-10-29 00:46:39,506 : INFO : topic #5 (0.100): 0.039*\"gathering\" + 0.036*\"rainbow\" + 0.023*\"krivic\" + 0.018*\"like\" + 0.014*\"people\" + 0.011*\"photo\" + 0.011*\"take\" + 0.011*\"one\" + 0.011*\"said\" + 0.011*\"place\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:39,507 : INFO : topic #7 (0.100): 0.050*\"gathering\" + 0.045*\"rainbow\" + 0.022*\"krivic\" + 0.013*\"said\" + 0.013*\"like\" + 0.013*\"go\" + 0.011*\"year\" + 0.011*\"people\" + 0.011*\"take\" + 0.008*\"one\"\n",
      "2019-10-29 00:46:39,509 : INFO : topic diff=0.853089, rho=1.000000\n",
      "2019-10-29 00:46:39,914 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:39,916 : INFO : built Dictionary(18 unique tokens: ['describes', 'charlottesville', 'protest', 'speaks', 'cnn']...) from 5 documents (total 100 corpus positions)\n",
      "2019-10-29 00:46:39,918 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:39,919 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:39,920 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:39,922 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:39,923 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:39,935 : INFO : -6.235 per-word bound, 75.3 perplexity estimate based on a held-out corpus of 5 documents with 100 words\n",
      "2019-10-29 00:46:39,937 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:39,943 : INFO : topic #2 (0.100): 0.106*\"friend\" + 0.097*\"beating\" + 0.060*\"protest\" + 0.056*\"bloody\" + 0.056*\"virginia\" + 0.053*\"baldwin\" + 0.052*\"brooke\" + 0.051*\"long\" + 0.050*\"cnn\" + 0.049*\"vonzz\"\n",
      "2019-10-29 00:46:39,944 : INFO : topic #0 (0.100): 0.106*\"friend\" + 0.081*\"beating\" + 0.065*\"speaks\" + 0.057*\"charlottesville\" + 0.055*\"long\" + 0.054*\"virginia\" + 0.053*\"brooke\" + 0.053*\"deandre\" + 0.053*\"protester\" + 0.052*\"baldwin\"\n",
      "2019-10-29 00:46:39,946 : INFO : topic #7 (0.100): 0.090*\"beating\" + 0.089*\"friend\" + 0.061*\"cnn\" + 0.059*\"bloody\" + 0.058*\"brooke\" + 0.058*\"leading\" + 0.055*\"moment\" + 0.055*\"harris\" + 0.051*\"vonzz\" + 0.050*\"deandre\"\n",
      "2019-10-29 00:46:39,948 : INFO : topic #8 (0.100): 0.096*\"beating\" + 0.086*\"friend\" + 0.063*\"speaks\" + 0.060*\"charlottesville\" + 0.059*\"virginia\" + 0.056*\"describes\" + 0.054*\"brooke\" + 0.053*\"protest\" + 0.052*\"long\" + 0.051*\"cnn\"\n",
      "2019-10-29 00:46:39,949 : INFO : topic #1 (0.100): 0.097*\"friend\" + 0.090*\"beating\" + 0.063*\"leading\" + 0.057*\"harris\" + 0.056*\"baldwin\" + 0.055*\"protester\" + 0.055*\"moment\" + 0.055*\"describes\" + 0.053*\"deandre\" + 0.050*\"protest\"\n",
      "2019-10-29 00:46:39,950 : INFO : topic diff=0.614007, rho=1.000000\n",
      "2019-10-29 00:46:40,410 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:40,415 : INFO : built Dictionary(273 unique tokens: ['josh', 'forecast', 'digit', 'end', 'crest']...) from 5 documents (total 3270 corpus positions)\n",
      "2019-10-29 00:46:40,419 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:40,423 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:40,426 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:40,430 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:40,433 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:40,527 : INFO : -7.105 per-word bound, 137.7 perplexity estimate based on a held-out corpus of 5 documents with 3270 words\n",
      "2019-10-29 00:46:40,528 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:40,536 : INFO : topic #2 (0.100): 0.064*\"wildfire\" + 0.061*\"blaze\" + 0.048*\"hide\" + 0.044*\"photo\" + 0.041*\"october\" + 0.040*\"california\" + 0.039*\"caption\" + 0.025*\"rosa\" + 0.018*\"santa\" + 0.015*\"home\"\n",
      "2019-10-29 00:46:40,538 : INFO : topic #9 (0.100): 0.064*\"california\" + 0.057*\"wildfire\" + 0.051*\"hide\" + 0.047*\"october\" + 0.046*\"blaze\" + 0.037*\"caption\" + 0.037*\"photo\" + 0.019*\"santa\" + 0.016*\"rosa\" + 0.016*\"home\"\n",
      "2019-10-29 00:46:40,541 : INFO : topic #1 (0.100): 0.052*\"photo\" + 0.049*\"wildfire\" + 0.048*\"october\" + 0.047*\"hide\" + 0.047*\"caption\" + 0.047*\"california\" + 0.043*\"blaze\" + 0.020*\"rosa\" + 0.017*\"santa\" + 0.015*\"home\"\n",
      "2019-10-29 00:46:40,543 : INFO : topic #6 (0.100): 0.059*\"wildfire\" + 0.053*\"blaze\" + 0.050*\"caption\" + 0.049*\"california\" + 0.048*\"october\" + 0.045*\"photo\" + 0.038*\"hide\" + 0.024*\"santa\" + 0.015*\"rosa\" + 0.012*\"napa\"\n",
      "2019-10-29 00:46:40,546 : INFO : topic #7 (0.100): 0.053*\"wildfire\" + 0.053*\"california\" + 0.050*\"october\" + 0.047*\"blaze\" + 0.045*\"hide\" + 0.038*\"caption\" + 0.037*\"photo\" + 0.018*\"rosa\" + 0.015*\"santa\" + 0.014*\"home\"\n",
      "2019-10-29 00:46:40,548 : INFO : topic diff=1.155486, rho=1.000000\n",
      "2019-10-29 00:46:41,023 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:41,030 : INFO : built Dictionary(526 unique tokens: ['prime', 'presenter', 'real', 'antoine', 'hero']...) from 5 documents (total 6380 corpus positions)\n",
      "2019-10-29 00:46:41,037 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:41,038 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:41,040 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:41,044 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:41,047 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:41,201 : INFO : -7.729 per-word bound, 212.2 perplexity estimate based on a held-out corpus of 5 documents with 6380 words\n",
      "2019-10-29 00:46:41,202 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:41,212 : INFO : topic #2 (0.100): 0.049*\"cup\" + 0.048*\"world\" + 0.032*\"russia\" + 0.026*\"photo\" + 0.025*\"hide\" + 0.022*\"caption\" + 0.022*\"qualifier\" + 0.020*\"qualifying\" + 0.015*\"group\" + 0.014*\"iceland\"\n",
      "2019-10-29 00:46:41,214 : INFO : topic #0 (0.100): 0.043*\"cup\" + 0.039*\"russia\" + 0.038*\"world\" + 0.028*\"hide\" + 0.028*\"caption\" + 0.023*\"qualifier\" + 0.022*\"photo\" + 0.016*\"group\" + 0.014*\"qualifying\" + 0.013*\"team\"\n",
      "2019-10-29 00:46:41,216 : INFO : topic #5 (0.100): 0.057*\"world\" + 0.053*\"cup\" + 0.032*\"russia\" + 0.027*\"hide\" + 0.022*\"qualifier\" + 0.022*\"caption\" + 0.022*\"photo\" + 0.015*\"iceland\" + 0.014*\"qualifying\" + 0.013*\"group\"\n",
      "2019-10-29 00:46:41,219 : INFO : topic #1 (0.100): 0.063*\"world\" + 0.055*\"cup\" + 0.032*\"qualifier\" + 0.032*\"russia\" + 0.024*\"caption\" + 0.023*\"photo\" + 0.020*\"hide\" + 0.016*\"qualifying\" + 0.014*\"iceland\" + 0.013*\"group\"\n",
      "2019-10-29 00:46:41,221 : INFO : topic #9 (0.100): 0.050*\"world\" + 0.046*\"cup\" + 0.044*\"russia\" + 0.024*\"qualifier\" + 0.024*\"caption\" + 0.021*\"photo\" + 0.021*\"hide\" + 0.017*\"iceland\" + 0.016*\"qualifying\" + 0.014*\"team\"\n",
      "2019-10-29 00:46:41,223 : INFO : topic diff=1.049252, rho=1.000000\n",
      "2019-10-29 00:46:41,699 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:41,709 : INFO : built Dictionary(736 unique tokens: ['riken', 'let', 'selection', 'shower', 'fat']...) from 5 documents (total 7330 corpus positions)\n",
      "2019-10-29 00:46:41,717 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:41,719 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:41,721 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:41,726 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:41,728 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:41,974 : INFO : -8.269 per-word bound, 308.5 perplexity estimate based on a held-out corpus of 5 documents with 7330 words\n",
      "2019-10-29 00:46:41,977 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:41,989 : INFO : topic #8 (0.100): 0.041*\"japan\" + 0.021*\"photo\" + 0.019*\"caption\" + 0.019*\"hide\" + 0.018*\"supercomputer\" + 0.017*\"living\" + 0.017*\"future\" + 0.009*\"world\" + 0.009*\"computer\" + 0.008*\"japanese\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:41,991 : INFO : topic #4 (0.100): 0.027*\"japan\" + 0.021*\"future\" + 0.020*\"supercomputer\" + 0.020*\"caption\" + 0.019*\"photo\" + 0.018*\"living\" + 0.017*\"hide\" + 0.009*\"robot\" + 0.009*\"japanese\" + 0.008*\"world\"\n",
      "2019-10-29 00:46:41,994 : INFO : topic #5 (0.100): 0.027*\"japan\" + 0.023*\"photo\" + 0.021*\"hide\" + 0.018*\"future\" + 0.016*\"caption\" + 0.015*\"supercomputer\" + 0.015*\"living\" + 0.009*\"world\" + 0.008*\"car\" + 0.008*\"computer\"\n",
      "2019-10-29 00:46:41,997 : INFO : topic #2 (0.100): 0.032*\"japan\" + 0.029*\"photo\" + 0.025*\"future\" + 0.022*\"hide\" + 0.021*\"caption\" + 0.014*\"supercomputer\" + 0.014*\"living\" + 0.012*\"world\" + 0.009*\"japanese\" + 0.008*\"computer\"\n",
      "2019-10-29 00:46:41,999 : INFO : topic #0 (0.100): 0.027*\"caption\" + 0.021*\"japan\" + 0.020*\"supercomputer\" + 0.019*\"photo\" + 0.017*\"future\" + 0.016*\"living\" + 0.012*\"hide\" + 0.011*\"world\" + 0.009*\"japanese\" + 0.008*\"computer\"\n",
      "2019-10-29 00:46:42,000 : INFO : topic diff=0.974526, rho=1.000000\n",
      "2019-10-29 00:46:42,431 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:42,435 : INFO : built Dictionary(269 unique tokens: ['concern', 'catholic', 'refugee', 'party', 'come']...) from 5 documents (total 2490 corpus positions)\n",
      "2019-10-29 00:46:42,439 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:42,441 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:42,442 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:42,446 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:42,447 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:42,534 : INFO : -7.381 per-word bound, 166.7 perplexity estimate based on a held-out corpus of 5 documents with 2490 words\n",
      "2019-10-29 00:46:42,536 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:42,543 : INFO : topic #2 (0.100): 0.035*\"christian\" + 0.029*\"class\" + 0.028*\"said\" + 0.023*\"value\" + 0.019*\"white\" + 0.019*\"working\" + 0.018*\"evangelicals\" + 0.016*\"trump\" + 0.014*\"believe\" + 0.012*\"voter\"\n",
      "2019-10-29 00:46:42,545 : INFO : topic #0 (0.100): 0.029*\"value\" + 0.025*\"said\" + 0.022*\"working\" + 0.022*\"christian\" + 0.022*\"class\" + 0.018*\"white\" + 0.016*\"believe\" + 0.016*\"evangelicals\" + 0.014*\"trump\" + 0.013*\"many\"\n",
      "2019-10-29 00:46:42,548 : INFO : topic #3 (0.100): 0.029*\"value\" + 0.029*\"said\" + 0.025*\"christian\" + 0.022*\"white\" + 0.020*\"class\" + 0.019*\"working\" + 0.016*\"evangelicals\" + 0.016*\"believe\" + 0.015*\"voter\" + 0.014*\"many\"\n",
      "2019-10-29 00:46:42,551 : INFO : topic #1 (0.100): 0.030*\"christian\" + 0.026*\"value\" + 0.025*\"white\" + 0.025*\"said\" + 0.024*\"class\" + 0.023*\"working\" + 0.019*\"evangelicals\" + 0.014*\"country\" + 0.013*\"voter\" + 0.013*\"attack\"\n",
      "2019-10-29 00:46:42,553 : INFO : topic #5 (0.100): 0.026*\"said\" + 0.025*\"working\" + 0.022*\"class\" + 0.022*\"value\" + 0.021*\"christian\" + 0.020*\"evangelicals\" + 0.019*\"white\" + 0.015*\"voter\" + 0.013*\"believe\" + 0.013*\"trump\"\n",
      "2019-10-29 00:46:42,555 : INFO : topic diff=0.907157, rho=1.000000\n",
      "2019-10-29 00:46:42,945 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:42,949 : INFO : built Dictionary(79 unique tokens: ['deadly', 'roughly', 'camera', 'morning', 'time']...) from 5 documents (total 640 corpus positions)\n",
      "2019-10-29 00:46:42,951 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:42,953 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:42,956 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:42,960 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:42,964 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:43,012 : INFO : -6.464 per-word bound, 88.3 perplexity estimate based on a held-out corpus of 5 documents with 640 words\n",
      "2019-10-29 00:46:43,014 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:43,020 : INFO : topic #1 (0.100): 0.052*\"hospital\" + 0.050*\"patient\" + 0.042*\"evacuated\" + 0.026*\"monday\" + 0.025*\"health\" + 0.024*\"said\" + 0.021*\"permanente\" + 0.021*\"wildfire\" + 0.021*\"kaiser\" + 0.020*\"northern\"\n",
      "2019-10-29 00:46:43,023 : INFO : topic #7 (0.100): 0.064*\"hospital\" + 0.040*\"patient\" + 0.040*\"wildfire\" + 0.035*\"evacuated\" + 0.027*\"least\" + 0.026*\"permanente\" + 0.025*\"monday\" + 0.024*\"said\" + 0.023*\"statement\" + 0.023*\"california\"\n",
      "2019-10-29 00:46:43,027 : INFO : topic #5 (0.100): 0.053*\"hospital\" + 0.045*\"patient\" + 0.033*\"wildfire\" + 0.029*\"evacuated\" + 0.024*\"health\" + 0.023*\"least\" + 0.023*\"permanente\" + 0.023*\"statement\" + 0.022*\"monday\" + 0.022*\"northern\"\n",
      "2019-10-29 00:46:43,030 : INFO : topic #4 (0.100): 0.053*\"hospital\" + 0.040*\"evacuated\" + 0.040*\"patient\" + 0.035*\"wildfire\" + 0.026*\"kaiser\" + 0.024*\"least\" + 0.023*\"said\" + 0.021*\"northern\" + 0.021*\"statement\" + 0.021*\"health\"\n",
      "2019-10-29 00:46:43,034 : INFO : topic #0 (0.100): 0.077*\"hospital\" + 0.037*\"evacuated\" + 0.035*\"patient\" + 0.031*\"california\" + 0.026*\"permanente\" + 0.026*\"northern\" + 0.023*\"kaiser\" + 0.021*\"statement\" + 0.021*\"monday\" + 0.021*\"least\"\n",
      "2019-10-29 00:46:43,044 : INFO : topic diff=0.844023, rho=1.000000\n",
      "2019-10-29 00:46:43,488 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:43,490 : INFO : built Dictionary(88 unique tokens: ['touch', 'vince', 'night', 'market', 'headline']...) from 5 documents (total 895 corpus positions)\n",
      "2019-10-29 00:46:43,491 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:43,496 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:43,499 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:43,502 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:43,505 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:43,550 : INFO : -6.236 per-word bound, 75.4 perplexity estimate based on a held-out corpus of 5 documents with 895 words\n",
      "2019-10-29 00:46:43,555 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:43,563 : INFO : topic #1 (0.100): 0.063*\"festival\" + 0.060*\"music\" + 0.059*\"thing\" + 0.057*\"go\" + 0.052*\"caption\" + 0.048*\"hide\" + 0.037*\"photo\" + 0.022*\"day\" + 0.018*\"rapper\" + 0.017*\"performs\"\n",
      "2019-10-29 00:46:43,567 : INFO : topic #8 (0.100): 0.080*\"festival\" + 0.058*\"hide\" + 0.054*\"thing\" + 0.052*\"music\" + 0.049*\"photo\" + 0.041*\"caption\" + 0.040*\"go\" + 0.018*\"foster\" + 0.017*\"performs\" + 0.017*\"betty\"\n",
      "2019-10-29 00:46:43,570 : INFO : topic #4 (0.100): 0.082*\"festival\" + 0.070*\"thing\" + 0.054*\"music\" + 0.053*\"photo\" + 0.048*\"caption\" + 0.042*\"hide\" + 0.038*\"go\" + 0.018*\"rapper\" + 0.017*\"foster\" + 0.017*\"night\"\n",
      "2019-10-29 00:46:43,574 : INFO : topic #9 (0.100): 0.082*\"festival\" + 0.068*\"go\" + 0.067*\"music\" + 0.054*\"thing\" + 0.048*\"photo\" + 0.045*\"hide\" + 0.044*\"caption\" + 0.020*\"betty\" + 0.017*\"foster\" + 0.017*\"performs\"\n",
      "2019-10-29 00:46:43,578 : INFO : topic #2 (0.100): 0.094*\"festival\" + 0.058*\"go\" + 0.054*\"caption\" + 0.052*\"thing\" + 0.049*\"music\" + 0.039*\"hide\" + 0.036*\"photo\" + 0.022*\"performs\" + 0.018*\"night\" + 0.018*\"foster\"\n",
      "2019-10-29 00:46:43,581 : INFO : topic diff=1.043350, rho=1.000000\n",
      "2019-10-29 00:46:44,168 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:44,189 : INFO : built Dictionary(1474 unique tokens: ['let', 'baba', 'zainab', 'pediatrician', 'wheel']...) from 5 documents (total 17495 corpus positions)\n",
      "2019-10-29 00:46:44,206 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:44,207 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:44,209 : INFO : using serial LDA version on this node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:44,215 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:44,217 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:44,714 : INFO : -8.768 per-word bound, 435.9 perplexity estimate based on a held-out corpus of 5 documents with 17495 words\n",
      "2019-10-29 00:46:44,717 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:44,733 : INFO : topic #5 (0.100): 0.040*\"noor\" + 0.022*\"haider\" + 0.009*\"baghdad\" + 0.008*\"hospital\" + 0.007*\"iraq\" + 0.006*\"life\" + 0.006*\"child\" + 0.006*\"say\" + 0.006*\"one\" + 0.006*\"daughter\"\n",
      "2019-10-29 00:46:44,736 : INFO : topic #9 (0.100): 0.037*\"noor\" + 0.018*\"haider\" + 0.007*\"baghdad\" + 0.007*\"day\" + 0.006*\"daughter\" + 0.006*\"iraq\" + 0.006*\"hospital\" + 0.006*\"see\" + 0.005*\"say\" + 0.005*\"head\"\n",
      "2019-10-29 00:46:44,739 : INFO : topic #7 (0.100): 0.041*\"noor\" + 0.028*\"haider\" + 0.008*\"baghdad\" + 0.007*\"year\" + 0.006*\"hospital\" + 0.006*\"day\" + 0.006*\"say\" + 0.005*\"time\" + 0.005*\"like\" + 0.005*\"doctor\"\n",
      "2019-10-29 00:46:44,743 : INFO : topic #6 (0.100): 0.036*\"noor\" + 0.034*\"haider\" + 0.008*\"baghdad\" + 0.008*\"day\" + 0.007*\"hospital\" + 0.007*\"family\" + 0.007*\"uganda\" + 0.006*\"iraq\" + 0.006*\"take\" + 0.006*\"one\"\n",
      "2019-10-29 00:46:44,746 : INFO : topic #0 (0.100): 0.047*\"noor\" + 0.023*\"haider\" + 0.011*\"baghdad\" + 0.008*\"hospital\" + 0.006*\"daughter\" + 0.006*\"see\" + 0.006*\"iraq\" + 0.006*\"child\" + 0.006*\"day\" + 0.006*\"uganda\"\n",
      "2019-10-29 00:46:44,748 : INFO : topic diff=1.056130, rho=1.000000\n",
      "2019-10-29 00:46:45,233 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:45,244 : INFO : built Dictionary(628 unique tokens: ['although', 'anniversary', 'catholic', 'bone', 'happy']...) from 5 documents (total 5165 corpus positions)\n",
      "2019-10-29 00:46:45,249 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:45,251 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:45,252 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:45,256 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:45,259 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:45,464 : INFO : -8.354 per-word bound, 327.2 perplexity estimate based on a held-out corpus of 5 documents with 5165 words\n",
      "2019-10-29 00:46:45,466 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:45,474 : INFO : topic #2 (0.100): 0.012*\"jew\" + 0.010*\"jewish\" + 0.009*\"ghetto\" + 0.009*\"father\" + 0.008*\"radom\" + 0.008*\"warsaw\" + 0.008*\"u\" + 0.007*\"many\" + 0.007*\"mother\" + 0.007*\"nazi\"\n",
      "2019-10-29 00:46:45,475 : INFO : topic #4 (0.100): 0.013*\"jew\" + 0.011*\"father\" + 0.010*\"jewish\" + 0.010*\"u\" + 0.010*\"radom\" + 0.009*\"family\" + 0.008*\"warsaw\" + 0.008*\"auschwitz\" + 0.008*\"nazi\" + 0.008*\"many\"\n",
      "2019-10-29 00:46:45,477 : INFO : topic #9 (0.100): 0.016*\"jew\" + 0.012*\"u\" + 0.010*\"jewish\" + 0.010*\"ghetto\" + 0.010*\"auschwitz\" + 0.009*\"radom\" + 0.009*\"warsaw\" + 0.008*\"history\" + 0.008*\"nazi\" + 0.007*\"many\"\n",
      "2019-10-29 00:46:45,479 : INFO : topic #8 (0.100): 0.014*\"jew\" + 0.011*\"u\" + 0.011*\"warsaw\" + 0.010*\"radom\" + 0.009*\"family\" + 0.008*\"nazi\" + 0.008*\"ghetto\" + 0.008*\"history\" + 0.008*\"many\" + 0.007*\"jewish\"\n",
      "2019-10-29 00:46:45,480 : INFO : topic #5 (0.100): 0.017*\"jew\" + 0.011*\"family\" + 0.010*\"u\" + 0.010*\"warsaw\" + 0.010*\"radom\" + 0.009*\"jewish\" + 0.008*\"one\" + 0.007*\"nazi\" + 0.007*\"history\" + 0.007*\"father\"\n",
      "2019-10-29 00:46:45,482 : INFO : topic diff=0.861135, rho=1.000000\n",
      "2019-10-29 00:46:45,887 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:45,890 : INFO : built Dictionary(156 unique tokens: ['violence', 'count', 'person', 'prominent', 'end']...) from 5 documents (total 1120 corpus positions)\n",
      "2019-10-29 00:46:45,894 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:45,896 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:45,897 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:45,900 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:45,902 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:45,983 : INFO : -7.246 per-word bound, 151.8 perplexity estimate based on a held-out corpus of 5 documents with 1120 words\n",
      "2019-10-29 00:46:45,985 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:45,991 : INFO : topic #6 (0.100): 0.035*\"mawarire\" + 0.024*\"pastor\" + 0.022*\"zimbabwe\" + 0.020*\"outside\" + 0.016*\"police\" + 0.016*\"subversion\" + 0.016*\"charge\" + 0.016*\"mugabe\" + 0.016*\"right\" + 0.016*\"harare\"\n",
      "2019-10-29 00:46:45,993 : INFO : topic #7 (0.100): 0.031*\"mawarire\" + 0.024*\"police\" + 0.022*\"pastor\" + 0.020*\"zimbabwe\" + 0.019*\"harare\" + 0.017*\"right\" + 0.016*\"mugabe\" + 0.015*\"outside\" + 0.014*\"told\" + 0.014*\"charge\"\n",
      "2019-10-29 00:46:45,996 : INFO : topic #2 (0.100): 0.025*\"mawarire\" + 0.021*\"police\" + 0.020*\"subversion\" + 0.019*\"harare\" + 0.019*\"right\" + 0.016*\"zimbabwe\" + 0.016*\"told\" + 0.015*\"pastor\" + 0.015*\"court\" + 0.014*\"outside\"\n",
      "2019-10-29 00:46:45,998 : INFO : topic #0 (0.100): 0.034*\"mawarire\" + 0.024*\"zimbabwe\" + 0.022*\"police\" + 0.019*\"pastor\" + 0.019*\"right\" + 0.018*\"subversion\" + 0.015*\"court\" + 0.014*\"charge\" + 0.014*\"outside\" + 0.014*\"harare\"\n",
      "2019-10-29 00:46:46,000 : INFO : topic #9 (0.100): 0.030*\"mawarire\" + 0.023*\"zimbabwe\" + 0.020*\"pastor\" + 0.020*\"police\" + 0.018*\"right\" + 0.016*\"charge\" + 0.015*\"told\" + 0.014*\"outside\" + 0.014*\"subversion\" + 0.014*\"u\"\n",
      "2019-10-29 00:46:46,002 : INFO : topic diff=0.811577, rho=1.000000\n",
      "2019-10-29 00:46:46,414 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:46,416 : INFO : built Dictionary(102 unique tokens: ['portion', 'size', 'milk', 'may', 'calorie']...) from 5 documents (total 745 corpus positions)\n",
      "2019-10-29 00:46:46,419 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:46,420 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:46,421 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:46,423 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:46,424 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:46,473 : INFO : -6.845 per-word bound, 115.0 perplexity estimate based on a held-out corpus of 5 documents with 745 words\n",
      "2019-10-29 00:46:46,480 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:46,488 : INFO : topic #2 (0.100): 0.044*\"chocolate\" + 0.043*\"dark\" + 0.034*\"flavanols\" + 0.032*\"cocoa\" + 0.031*\"compound\" + 0.019*\"flavor\" + 0.018*\"lower\" + 0.017*\"benefit\" + 0.017*\"daily\" + 0.015*\"hartings\"\n",
      "2019-10-29 00:46:46,489 : INFO : topic #5 (0.100): 0.083*\"chocolate\" + 0.041*\"flavanols\" + 0.034*\"dark\" + 0.027*\"compound\" + 0.025*\"cocoa\" + 0.020*\"lower\" + 0.019*\"flavor\" + 0.016*\"cognition\" + 0.015*\"blood\" + 0.015*\"cholesterol\"\n",
      "2019-10-29 00:46:46,491 : INFO : topic #7 (0.100): 0.070*\"chocolate\" + 0.039*\"dark\" + 0.035*\"cocoa\" + 0.034*\"flavanols\" + 0.027*\"flavor\" + 0.019*\"compound\" + 0.018*\"lower\" + 0.015*\"cognition\" + 0.015*\"cholesterol\" + 0.014*\"hartings\"\n",
      "2019-10-29 00:46:46,492 : INFO : topic #4 (0.100): 0.059*\"chocolate\" + 0.040*\"flavanols\" + 0.035*\"cocoa\" + 0.032*\"dark\" + 0.026*\"flavor\" + 0.025*\"compound\" + 0.018*\"lower\" + 0.016*\"help\" + 0.015*\"give\" + 0.015*\"health\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:46,497 : INFO : topic #3 (0.100): 0.053*\"chocolate\" + 0.042*\"flavanols\" + 0.035*\"dark\" + 0.029*\"cocoa\" + 0.025*\"compound\" + 0.024*\"flavor\" + 0.018*\"lower\" + 0.017*\"daily\" + 0.016*\"improve\" + 0.015*\"blood\"\n",
      "2019-10-29 00:46:46,501 : INFO : topic diff=0.809753, rho=1.000000\n",
      "2019-10-29 00:46:46,911 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:46,915 : INFO : built Dictionary(217 unique tokens: ['realm', 'small', 'pyramid', '1990s', 'actualized']...) from 5 documents (total 1545 corpus positions)\n",
      "2019-10-29 00:46:46,918 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:46,919 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:46,920 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:46,924 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:46,925 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:47,018 : INFO : -7.555 per-word bound, 188.0 perplexity estimate based on a held-out corpus of 5 documents with 1545 words\n",
      "2019-10-29 00:46:47,020 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:47,027 : INFO : topic #4 (0.100): 0.031*\"scheeren\" + 0.025*\"building\" + 0.019*\"say\" + 0.018*\"space\" + 0.017*\"tower\" + 0.017*\"bangkok\" + 0.017*\"city\" + 0.017*\"mahanakhon\" + 0.015*\"people\" + 0.012*\"design\"\n",
      "2019-10-29 00:46:47,030 : INFO : topic #5 (0.100): 0.027*\"building\" + 0.026*\"scheeren\" + 0.023*\"bangkok\" + 0.019*\"tower\" + 0.018*\"say\" + 0.018*\"mahanakhon\" + 0.017*\"space\" + 0.015*\"city\" + 0.013*\"design\" + 0.011*\"architecture\"\n",
      "2019-10-29 00:46:47,033 : INFO : topic #9 (0.100): 0.031*\"building\" + 0.028*\"bangkok\" + 0.024*\"city\" + 0.021*\"scheeren\" + 0.018*\"mahanakhon\" + 0.018*\"space\" + 0.017*\"tower\" + 0.016*\"say\" + 0.012*\"design\" + 0.011*\"people\"\n",
      "2019-10-29 00:46:47,036 : INFO : topic #7 (0.100): 0.030*\"scheeren\" + 0.026*\"building\" + 0.025*\"say\" + 0.023*\"bangkok\" + 0.019*\"city\" + 0.016*\"tower\" + 0.016*\"space\" + 0.013*\"mahanakhon\" + 0.013*\"design\" + 0.011*\"people\"\n",
      "2019-10-29 00:46:47,039 : INFO : topic #8 (0.100): 0.032*\"building\" + 0.029*\"scheeren\" + 0.025*\"tower\" + 0.021*\"bangkok\" + 0.021*\"space\" + 0.016*\"city\" + 0.014*\"say\" + 0.013*\"design\" + 0.012*\"mahanakhon\" + 0.011*\"credit\"\n",
      "2019-10-29 00:46:47,041 : INFO : topic diff=0.816882, rho=1.000000\n",
      "2019-10-29 00:46:47,502 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:47,509 : INFO : built Dictionary(585 unique tokens: ['anniversary', 'person', 'real', 'internet', 'product']...) from 5 documents (total 4575 corpus positions)\n",
      "2019-10-29 00:46:47,516 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:47,518 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:47,519 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:47,524 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:47,526 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:47,693 : INFO : -8.352 per-word bound, 326.6 perplexity estimate based on a held-out corpus of 5 documents with 4575 words\n",
      "2019-10-29 00:46:47,695 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:47,705 : INFO : topic #6 (0.100): 0.024*\"said\" + 0.016*\"m\" + 0.009*\"death\" + 0.009*\"loss\" + 0.008*\"internet\" + 0.007*\"grief\" + 0.007*\"like\" + 0.006*\"generation\" + 0.006*\"site\" + 0.006*\"support\"\n",
      "2019-10-29 00:46:47,707 : INFO : topic #5 (0.100): 0.023*\"said\" + 0.021*\"m\" + 0.010*\"grief\" + 0.008*\"death\" + 0.007*\"like\" + 0.007*\"life\" + 0.006*\"loss\" + 0.006*\"feldman\" + 0.006*\"support\" + 0.006*\"one\"\n",
      "2019-10-29 00:46:47,709 : INFO : topic #4 (0.100): 0.023*\"said\" + 0.016*\"m\" + 0.009*\"grief\" + 0.009*\"like\" + 0.007*\"internet\" + 0.007*\"loss\" + 0.006*\"death\" + 0.006*\"founder\" + 0.006*\"life\" + 0.006*\"facebook\"\n",
      "2019-10-29 00:46:47,710 : INFO : topic #9 (0.100): 0.023*\"m\" + 0.022*\"said\" + 0.008*\"grief\" + 0.008*\"like\" + 0.008*\"medium\" + 0.008*\"support\" + 0.007*\"internet\" + 0.007*\"death\" + 0.006*\"loss\" + 0.006*\"feldman\"\n",
      "2019-10-29 00:46:47,715 : INFO : topic #1 (0.100): 0.021*\"m\" + 0.018*\"said\" + 0.009*\"like\" + 0.008*\"grief\" + 0.006*\"death\" + 0.006*\"loss\" + 0.006*\"feldman\" + 0.006*\"facebook\" + 0.006*\"internet\" + 0.006*\"funeral\"\n",
      "2019-10-29 00:46:47,718 : INFO : topic diff=0.847715, rho=1.000000\n",
      "2019-10-29 00:46:48,178 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:48,188 : INFO : built Dictionary(305 unique tokens: ['launch', 'person', 'end', 'come', 'brightest']...) from 5 documents (total 4775 corpus positions)\n",
      "2019-10-29 00:46:48,197 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:48,199 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:48,202 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:48,206 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:48,208 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:48,354 : INFO : -6.983 per-word bound, 126.5 perplexity estimate based on a held-out corpus of 5 documents with 4775 words\n",
      "2019-10-29 00:46:48,356 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:48,365 : INFO : topic #7 (0.100): 0.087*\"rosetta\" + 0.079*\"comet\" + 0.042*\"photo\" + 0.042*\"hide\" + 0.040*\"caption\" + 0.033*\"chaser\" + 0.026*\"philae\" + 0.026*\"image\" + 0.019*\"lander\" + 0.015*\"mile\"\n",
      "2019-10-29 00:46:48,368 : INFO : topic #1 (0.100): 0.072*\"rosetta\" + 0.072*\"comet\" + 0.045*\"photo\" + 0.036*\"caption\" + 0.034*\"chaser\" + 0.033*\"hide\" + 0.025*\"philae\" + 0.025*\"image\" + 0.015*\"mile\" + 0.015*\"lander\"\n",
      "2019-10-29 00:46:48,371 : INFO : topic #6 (0.100): 0.081*\"comet\" + 0.066*\"rosetta\" + 0.053*\"chaser\" + 0.047*\"photo\" + 0.043*\"caption\" + 0.029*\"hide\" + 0.027*\"image\" + 0.018*\"lander\" + 0.016*\"67p\" + 0.015*\"mile\"\n",
      "2019-10-29 00:46:48,372 : INFO : topic #4 (0.100): 0.106*\"comet\" + 0.057*\"rosetta\" + 0.042*\"chaser\" + 0.041*\"hide\" + 0.041*\"photo\" + 0.026*\"caption\" + 0.024*\"philae\" + 0.023*\"image\" + 0.017*\"67p\" + 0.015*\"lander\"\n",
      "2019-10-29 00:46:48,374 : INFO : topic #9 (0.100): 0.099*\"rosetta\" + 0.086*\"comet\" + 0.045*\"caption\" + 0.038*\"hide\" + 0.036*\"photo\" + 0.032*\"chaser\" + 0.027*\"image\" + 0.015*\"philae\" + 0.014*\"lander\" + 0.014*\"gerasimenko\"\n",
      "2019-10-29 00:46:48,376 : INFO : topic diff=1.266947, rho=1.000000\n",
      "2019-10-29 00:46:48,949 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:48,968 : INFO : built Dictionary(1194 unique tokens: ['earned', 'wheelchair', 'real', 'anger', 'hotline']...) from 5 documents (total 14915 corpus positions)\n",
      "2019-10-29 00:46:48,980 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:48,982 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:48,984 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:48,989 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:48,991 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:49,353 : INFO : -8.512 per-word bound, 365.0 perplexity estimate based on a held-out corpus of 5 documents with 14915 words\n",
      "2019-10-29 00:46:49,356 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:49,375 : INFO : topic #1 (0.100): 0.023*\"gomez\" + 0.014*\"woman\" + 0.012*\"home\" + 0.011*\"nursing\" + 0.011*\"told\" + 0.011*\"center\" + 0.009*\"state\" + 0.009*\"said\" + 0.009*\"resident\" + 0.008*\"facility\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:49,378 : INFO : topic #5 (0.100): 0.015*\"gomez\" + 0.014*\"nursing\" + 0.013*\"said\" + 0.012*\"center\" + 0.011*\"woman\" + 0.010*\"told\" + 0.010*\"facility\" + 0.009*\"home\" + 0.007*\"state\" + 0.007*\"luis\"\n",
      "2019-10-29 00:46:49,382 : INFO : topic #9 (0.100): 0.020*\"gomez\" + 0.016*\"woman\" + 0.011*\"said\" + 0.010*\"nursing\" + 0.009*\"center\" + 0.009*\"police\" + 0.008*\"told\" + 0.007*\"state\" + 0.007*\"year\" + 0.007*\"resident\"\n",
      "2019-10-29 00:46:49,385 : INFO : topic #0 (0.100): 0.023*\"gomez\" + 0.013*\"woman\" + 0.012*\"nursing\" + 0.011*\"facility\" + 0.011*\"home\" + 0.011*\"center\" + 0.009*\"said\" + 0.009*\"would\" + 0.008*\"told\" + 0.008*\"brian\"\n",
      "2019-10-29 00:46:49,388 : INFO : topic #2 (0.100): 0.025*\"gomez\" + 0.016*\"woman\" + 0.015*\"nursing\" + 0.014*\"said\" + 0.010*\"facility\" + 0.010*\"home\" + 0.009*\"told\" + 0.009*\"brian\" + 0.009*\"police\" + 0.008*\"resident\"\n",
      "2019-10-29 00:46:49,391 : INFO : topic diff=1.067326, rho=1.000000\n",
      "2019-10-29 00:46:49,950 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:49,964 : INFO : built Dictionary(625 unique tokens: ['previously', 'let', 'person', 'relationship', 'laboratory']...) from 5 documents (total 5375 corpus positions)\n",
      "2019-10-29 00:46:49,976 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:49,978 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:49,981 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:49,986 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:49,988 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:50,222 : INFO : -8.288 per-word bound, 312.6 perplexity estimate based on a held-out corpus of 5 documents with 5375 words\n",
      "2019-10-29 00:46:50,223 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:50,232 : INFO : topic #6 (0.100): 0.031*\"color\" + 0.016*\"one\" + 0.012*\"synesthesia\" + 0.010*\"blue\" + 0.008*\"time\" + 0.008*\"would\" + 0.007*\"vision\" + 0.007*\"back\" + 0.006*\"janet\" + 0.006*\"like\"\n",
      "2019-10-29 00:46:50,234 : INFO : topic #7 (0.100): 0.028*\"color\" + 0.019*\"one\" + 0.012*\"synesthesia\" + 0.012*\"blue\" + 0.009*\"sensory\" + 0.008*\"would\" + 0.008*\"back\" + 0.007*\"daniel\" + 0.007*\"time\" + 0.006*\"still\"\n",
      "2019-10-29 00:46:50,236 : INFO : topic #0 (0.100): 0.028*\"color\" + 0.014*\"one\" + 0.011*\"blue\" + 0.010*\"synesthesia\" + 0.007*\"sensory\" + 0.007*\"back\" + 0.007*\"would\" + 0.006*\"sound\" + 0.006*\"first\" + 0.006*\"time\"\n",
      "2019-10-29 00:46:50,237 : INFO : topic #5 (0.100): 0.032*\"color\" + 0.014*\"synesthesia\" + 0.013*\"blue\" + 0.012*\"one\" + 0.008*\"see\" + 0.007*\"back\" + 0.007*\"time\" + 0.007*\"would\" + 0.006*\"visual\" + 0.006*\"sensory\"\n",
      "2019-10-29 00:46:50,240 : INFO : topic #9 (0.100): 0.045*\"color\" + 0.016*\"blue\" + 0.014*\"one\" + 0.012*\"would\" + 0.010*\"synesthesia\" + 0.007*\"visual\" + 0.007*\"back\" + 0.006*\"sound\" + 0.006*\"see\" + 0.006*\"sensory\"\n",
      "2019-10-29 00:46:50,242 : INFO : topic diff=0.893067, rho=1.000000\n",
      "2019-10-29 00:46:50,645 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:50,648 : INFO : built Dictionary(202 unique tokens: ['previously', 'concern', 'harsh', 'de', 'accompanied']...) from 5 documents (total 1490 corpus positions)\n",
      "2019-10-29 00:46:50,651 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:50,653 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:50,654 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:50,657 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:50,658 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:50,743 : INFO : -7.434 per-word bound, 172.9 perplexity estimate based on a held-out corpus of 5 documents with 1490 words\n",
      "2019-10-29 00:46:50,745 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:50,753 : INFO : topic #0 (0.100): 0.037*\"ice\" + 0.025*\"arctic\" + 0.018*\"year\" + 0.017*\"sea\" + 0.014*\"said\" + 0.013*\"tanker\" + 0.013*\"foot\" + 0.013*\"russian\" + 0.012*\"global\" + 0.011*\"old\"\n",
      "2019-10-29 00:46:50,756 : INFO : topic #5 (0.100): 0.050*\"ice\" + 0.020*\"arctic\" + 0.019*\"sea\" + 0.018*\"year\" + 0.014*\"global\" + 0.014*\"russian\" + 0.013*\"tanker\" + 0.012*\"climate\" + 0.012*\"said\" + 0.011*\"foot\"\n",
      "2019-10-29 00:46:50,759 : INFO : topic #8 (0.100): 0.048*\"ice\" + 0.024*\"arctic\" + 0.022*\"sea\" + 0.016*\"year\" + 0.015*\"foot\" + 0.013*\"said\" + 0.013*\"tanker\" + 0.013*\"journey\" + 0.012*\"global\" + 0.012*\"icebreaker\"\n",
      "2019-10-29 00:46:50,762 : INFO : topic #3 (0.100): 0.039*\"ice\" + 0.020*\"arctic\" + 0.017*\"year\" + 0.016*\"sea\" + 0.014*\"route\" + 0.013*\"foot\" + 0.013*\"tanker\" + 0.012*\"said\" + 0.011*\"global\" + 0.011*\"new\"\n",
      "2019-10-29 00:46:50,765 : INFO : topic #7 (0.100): 0.040*\"ice\" + 0.021*\"year\" + 0.016*\"arctic\" + 0.014*\"foot\" + 0.014*\"route\" + 0.013*\"russian\" + 0.012*\"sea\" + 0.011*\"meter\" + 0.011*\"thick\" + 0.011*\"tanker\"\n",
      "2019-10-29 00:46:50,768 : INFO : topic diff=0.805271, rho=1.000000\n",
      "2019-10-29 00:46:51,187 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:51,196 : INFO : built Dictionary(412 unique tokens: ['let', 'remained', 'railroad', 'preferring', 'extent']...) from 5 documents (total 3615 corpus positions)\n",
      "2019-10-29 00:46:51,205 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:51,207 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:51,211 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:51,215 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:51,218 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:51,368 : INFO : -7.856 per-word bound, 231.7 perplexity estimate based on a held-out corpus of 5 documents with 3615 words\n",
      "2019-10-29 00:46:51,369 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:51,379 : INFO : topic #4 (0.100): 0.030*\"mclaughlin\" + 0.025*\"cancer\" + 0.021*\"breast\" + 0.016*\"said\" + 0.015*\"life\" + 0.015*\"tattoo\" + 0.011*\"year\" + 0.011*\"never\" + 0.011*\"michael\" + 0.010*\"like\"\n",
      "2019-10-29 00:46:51,381 : INFO : topic #6 (0.100): 0.032*\"mclaughlin\" + 0.025*\"cancer\" + 0.024*\"tattoo\" + 0.017*\"breast\" + 0.015*\"year\" + 0.013*\"life\" + 0.013*\"said\" + 0.012*\"michael\" + 0.010*\"time\" + 0.008*\"day\"\n",
      "2019-10-29 00:46:51,383 : INFO : topic #2 (0.100): 0.035*\"mclaughlin\" + 0.021*\"cancer\" + 0.019*\"breast\" + 0.015*\"said\" + 0.015*\"tattoo\" + 0.015*\"life\" + 0.015*\"year\" + 0.010*\"michael\" + 0.010*\"never\" + 0.009*\"chest\"\n",
      "2019-10-29 00:46:51,386 : INFO : topic #7 (0.100): 0.026*\"mclaughlin\" + 0.019*\"breast\" + 0.017*\"said\" + 0.017*\"cancer\" + 0.016*\"tattoo\" + 0.014*\"life\" + 0.014*\"doctor\" + 0.013*\"year\" + 0.013*\"time\" + 0.011*\"michael\"\n",
      "2019-10-29 00:46:51,389 : INFO : topic #5 (0.100): 0.029*\"mclaughlin\" + 0.019*\"cancer\" + 0.018*\"breast\" + 0.015*\"life\" + 0.014*\"year\" + 0.013*\"time\" + 0.013*\"tattoo\" + 0.013*\"said\" + 0.010*\"doctor\" + 0.010*\"chest\"\n",
      "2019-10-29 00:46:51,391 : INFO : topic diff=0.908229, rho=1.000000\n",
      "2019-10-29 00:46:51,782 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:51,786 : INFO : built Dictionary(148 unique tokens: ['colleague', 'smitten', 'deep', 'gambon', 'golden']...) from 5 documents (total 820 corpus positions)\n",
      "2019-10-29 00:46:51,788 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:51,789 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:51,791 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:51,794 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:51,795 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:51,854 : INFO : -7.687 per-word bound, 206.1 perplexity estimate based on a held-out corpus of 5 documents with 820 words\n",
      "2019-10-29 00:46:51,856 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:51,864 : INFO : topic #2 (0.100): 0.029*\"queen\" + 0.025*\"abdul\" + 0.019*\"victoria\" + 0.015*\"movie\" + 0.015*\"motif\" + 0.011*\"dench\" + 0.010*\"story\" + 0.010*\"india\" + 0.008*\"watching\" + 0.008*\"octogenarian\"\n",
      "2019-10-29 00:46:51,867 : INFO : topic #8 (0.100): 0.034*\"abdul\" + 0.025*\"queen\" + 0.017*\"victoria\" + 0.015*\"movie\" + 0.015*\"story\" + 0.013*\"dench\" + 0.010*\"india\" + 0.009*\"motif\" + 0.008*\"frears\" + 0.008*\"colleague\"\n",
      "2019-10-29 00:46:51,869 : INFO : topic #9 (0.100): 0.030*\"queen\" + 0.026*\"abdul\" + 0.019*\"movie\" + 0.016*\"victoria\" + 0.014*\"story\" + 0.012*\"india\" + 0.011*\"motif\" + 0.008*\"dench\" + 0.008*\"michael\" + 0.008*\"teacher\"\n",
      "2019-10-29 00:46:51,871 : INFO : topic #0 (0.100): 0.029*\"queen\" + 0.027*\"abdul\" + 0.015*\"movie\" + 0.013*\"story\" + 0.012*\"victoria\" + 0.012*\"motif\" + 0.011*\"india\" + 0.009*\"dench\" + 0.009*\"find\" + 0.008*\"le\"\n",
      "2019-10-29 00:46:51,873 : INFO : topic #4 (0.100): 0.034*\"abdul\" + 0.028*\"queen\" + 0.020*\"movie\" + 0.014*\"victoria\" + 0.013*\"india\" + 0.011*\"dench\" + 0.011*\"motif\" + 0.008*\"regarding\" + 0.008*\"story\" + 0.008*\"minister\"\n",
      "2019-10-29 00:46:51,874 : INFO : topic diff=0.632368, rho=1.000000\n",
      "2019-10-29 00:46:52,261 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:52,263 : INFO : built Dictionary(19 unique tokens: ['main', 'later', 'cnn', 'page', 'specific']...) from 5 documents (total 115 corpus positions)\n",
      "2019-10-29 00:46:52,264 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:52,265 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:52,267 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:52,269 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:52,270 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:52,287 : INFO : -6.046 per-word bound, 66.1 perplexity estimate based on a held-out corpus of 5 documents with 115 words\n",
      "2019-10-29 00:46:52,288 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:52,295 : INFO : topic #9 (0.100): 0.208*\"transcript\" + 0.067*\"page\" + 0.055*\"later\" + 0.053*\"specific\" + 0.048*\"return\" + 0.048*\"continually\" + 0.048*\"segment\" + 0.046*\"main\" + 0.044*\"back\" + 0.043*\"note\"\n",
      "2019-10-29 00:46:52,296 : INFO : topic #5 (0.100): 0.132*\"transcript\" + 0.087*\"page\" + 0.055*\"back\" + 0.054*\"segment\" + 0.053*\"note\" + 0.051*\"cnn\" + 0.048*\"later\" + 0.047*\"return\" + 0.047*\"check\" + 0.046*\"cannot\"\n",
      "2019-10-29 00:46:52,297 : INFO : topic #3 (0.100): 0.130*\"transcript\" + 0.085*\"page\" + 0.059*\"check\" + 0.053*\"find\" + 0.052*\"cannot\" + 0.052*\"segment\" + 0.052*\"available\" + 0.048*\"continually\" + 0.047*\"updated\" + 0.047*\"main\"\n",
      "2019-10-29 00:46:52,304 : INFO : topic #2 (0.100): 0.137*\"transcript\" + 0.116*\"page\" + 0.055*\"return\" + 0.053*\"october\" + 0.051*\"updated\" + 0.051*\"cannot\" + 0.050*\"cnn\" + 0.045*\"become\" + 0.045*\"specific\" + 0.044*\"later\"\n",
      "2019-10-29 00:46:52,307 : INFO : topic #6 (0.100): 0.170*\"transcript\" + 0.074*\"page\" + 0.058*\"new\" + 0.055*\"back\" + 0.051*\"october\" + 0.048*\"become\" + 0.048*\"main\" + 0.047*\"specific\" + 0.047*\"available\" + 0.046*\"return\"\n",
      "2019-10-29 00:46:52,310 : INFO : topic diff=0.712059, rho=1.000000\n",
      "2019-10-29 00:46:52,732 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:52,735 : INFO : built Dictionary(241 unique tokens: ['earned', 'catholic', 'playboy', 'come', 'congratulate']...) from 5 documents (total 1770 corpus positions)\n",
      "2019-10-29 00:46:52,738 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:52,740 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:52,745 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:52,749 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:52,752 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:52,838 : INFO : -7.607 per-word bound, 194.9 perplexity estimate based on a held-out corpus of 5 documents with 1770 words\n",
      "2019-10-29 00:46:52,839 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:52,847 : INFO : topic #6 (0.100): 0.034*\"aunt\" + 0.026*\"black\" + 0.024*\"woman\" + 0.018*\"playboy\" + 0.012*\"jackson\" + 0.011*\"men\" + 0.010*\"self\" + 0.010*\"revolutionary\" + 0.010*\"also\" + 0.009*\"jennifer\"\n",
      "2019-10-29 00:46:52,850 : INFO : topic #7 (0.100): 0.031*\"woman\" + 0.031*\"aunt\" + 0.027*\"black\" + 0.025*\"playboy\" + 0.012*\"revolutionary\" + 0.011*\"jennifer\" + 0.010*\"linda\" + 0.010*\"created\" + 0.010*\"men\" + 0.010*\"also\"\n",
      "2019-10-29 00:46:52,853 : INFO : topic #1 (0.100): 0.028*\"aunt\" + 0.028*\"black\" + 0.023*\"playboy\" + 0.021*\"woman\" + 0.013*\"jennifer\" + 0.012*\"revolutionary\" + 0.011*\"men\" + 0.010*\"jackson\" + 0.010*\"idea\" + 0.010*\"rebecca\"\n",
      "2019-10-29 00:46:52,855 : INFO : topic #9 (0.100): 0.033*\"aunt\" + 0.031*\"woman\" + 0.028*\"black\" + 0.018*\"playboy\" + 0.012*\"jennifer\" + 0.011*\"revolutionary\" + 0.011*\"also\" + 0.010*\"year\" + 0.009*\"idea\" + 0.009*\"artis\"\n",
      "2019-10-29 00:46:52,858 : INFO : topic #3 (0.100): 0.032*\"black\" + 0.025*\"aunt\" + 0.024*\"woman\" + 0.024*\"playboy\" + 0.011*\"jackson\" + 0.011*\"revolutionary\" + 0.010*\"like\" + 0.010*\"men\" + 0.010*\"idea\" + 0.010*\"side\"\n",
      "2019-10-29 00:46:52,861 : INFO : topic diff=0.810511, rho=1.000000\n",
      "2019-10-29 00:46:53,252 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:53,254 : INFO : built Dictionary(77 unique tokens: ['online', 'way', 'reach', 'time', 'focus']...) from 5 documents (total 550 corpus positions)\n",
      "2019-10-29 00:46:53,256 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:53,258 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:53,260 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:53,262 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:53,263 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:53,303 : INFO : -6.643 per-word bound, 99.9 perplexity estimate based on a held-out corpus of 5 documents with 550 words\n",
      "2019-10-29 00:46:53,305 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:53,313 : INFO : topic #1 (0.100): 0.039*\"farm\" + 0.038*\"investor\" + 0.037*\"cow\" + 0.037*\"south\" + 0.029*\"stock\" + 0.029*\"africa\" + 0.025*\"livestock\" + 0.022*\"dividend\" + 0.022*\"cattle\" + 0.021*\"wealth\"\n",
      "2019-10-29 00:46:53,316 : INFO : topic #3 (0.100): 0.054*\"investor\" + 0.040*\"south\" + 0.032*\"cow\" + 0.031*\"farm\" + 0.030*\"africa\" + 0.029*\"cattle\" + 0.027*\"livestock\" + 0.025*\"wealth\" + 0.023*\"stock\" + 0.021*\"baby\"\n",
      "2019-10-29 00:46:53,319 : INFO : topic #6 (0.100): 0.039*\"investor\" + 0.037*\"farm\" + 0.034*\"cow\" + 0.031*\"cattle\" + 0.030*\"livestock\" + 0.025*\"africa\" + 0.025*\"wealth\" + 0.023*\"south\" + 0.020*\"company\" + 0.020*\"online\"\n",
      "2019-10-29 00:46:53,324 : INFO : topic #9 (0.100): 0.039*\"south\" + 0.035*\"investor\" + 0.033*\"farm\" + 0.032*\"cow\" + 0.027*\"cattle\" + 0.026*\"wealth\" + 0.023*\"stock\" + 0.022*\"pregnant\" + 0.021*\"africa\" + 0.020*\"african\"\n",
      "2019-10-29 00:46:53,328 : INFO : topic #8 (0.100): 0.050*\"investor\" + 0.031*\"farm\" + 0.030*\"cow\" + 0.029*\"south\" + 0.028*\"wealth\" + 0.027*\"africa\" + 0.026*\"cattle\" + 0.025*\"stock\" + 0.023*\"livestock\" + 0.022*\"story\"\n",
      "2019-10-29 00:46:53,331 : INFO : topic diff=0.786064, rho=1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:53,748 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:53,750 : INFO : built Dictionary(79 unique tokens: ['school', 'surveillance', 'disappointing', 'recently', 'profit']...) from 5 documents (total 560 corpus positions)\n",
      "2019-10-29 00:46:53,752 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:53,753 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:53,754 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:53,757 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:53,758 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:53,797 : INFO : -6.677 per-word bound, 102.3 perplexity estimate based on a held-out corpus of 5 documents with 560 words\n",
      "2019-10-29 00:46:53,798 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:53,806 : INFO : topic #8 (0.100): 0.043*\"van\" + 0.040*\"gas\" + 0.031*\"kid\" + 0.026*\"get\" + 0.024*\"one\" + 0.022*\"said\" + 0.021*\"school\" + 0.021*\"omaha\" + 0.020*\"tank\" + 0.019*\"cost\"\n",
      "2019-10-29 00:46:53,808 : INFO : topic #9 (0.100): 0.053*\"van\" + 0.037*\"gas\" + 0.028*\"kid\" + 0.026*\"get\" + 0.025*\"said\" + 0.024*\"tank\" + 0.023*\"center\" + 0.021*\"take\" + 0.021*\"say\" + 0.021*\"going\"\n",
      "2019-10-29 00:46:53,813 : INFO : topic #2 (0.100): 0.056*\"van\" + 0.037*\"kid\" + 0.028*\"center\" + 0.026*\"gas\" + 0.024*\"one\" + 0.022*\"get\" + 0.022*\"said\" + 0.020*\"cost\" + 0.020*\"patterson\" + 0.019*\"school\"\n",
      "2019-10-29 00:46:53,817 : INFO : topic #4 (0.100): 0.064*\"van\" + 0.038*\"gas\" + 0.033*\"kid\" + 0.031*\"said\" + 0.029*\"get\" + 0.028*\"one\" + 0.025*\"center\" + 0.022*\"school\" + 0.019*\"take\" + 0.019*\"going\"\n",
      "2019-10-29 00:46:53,819 : INFO : topic #5 (0.100): 0.065*\"van\" + 0.036*\"get\" + 0.030*\"kid\" + 0.029*\"center\" + 0.027*\"gas\" + 0.026*\"one\" + 0.021*\"said\" + 0.021*\"taking\" + 0.021*\"take\" + 0.020*\"crook\"\n",
      "2019-10-29 00:46:53,821 : INFO : topic diff=0.774334, rho=1.000000\n",
      "2019-10-29 00:46:54,248 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:54,254 : INFO : built Dictionary(261 unique tokens: ['product', 'sierra', 'size', 'genetically', 'come']...) from 5 documents (total 2140 corpus positions)\n",
      "2019-10-29 00:46:54,258 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:54,259 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:54,265 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:54,269 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:54,273 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:54,381 : INFO : -7.511 per-word bound, 182.4 perplexity estimate based on a held-out corpus of 5 documents with 2140 words\n",
      "2019-10-29 00:46:54,383 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:54,390 : INFO : topic #2 (0.100): 0.036*\"pea\" + 0.031*\"island\" + 0.027*\"sapelo\" + 0.024*\"red\" + 0.016*\"dixon\" + 0.014*\"crop\" + 0.014*\"resident\" + 0.012*\"georgia\" + 0.012*\"said\" + 0.011*\"year\"\n",
      "2019-10-29 00:46:54,392 : INFO : topic #6 (0.100): 0.031*\"pea\" + 0.030*\"island\" + 0.029*\"sapelo\" + 0.021*\"red\" + 0.015*\"dixon\" + 0.014*\"georgia\" + 0.014*\"year\" + 0.013*\"crop\" + 0.012*\"heirloom\" + 0.011*\"resident\"\n",
      "2019-10-29 00:46:54,395 : INFO : topic #4 (0.100): 0.041*\"sapelo\" + 0.033*\"island\" + 0.021*\"red\" + 0.020*\"pea\" + 0.018*\"year\" + 0.018*\"resident\" + 0.014*\"bailey\" + 0.011*\"crop\" + 0.011*\"georgia\" + 0.011*\"dixon\"\n",
      "2019-10-29 00:46:54,398 : INFO : topic #3 (0.100): 0.035*\"pea\" + 0.031*\"island\" + 0.024*\"sapelo\" + 0.023*\"red\" + 0.018*\"resident\" + 0.014*\"crop\" + 0.014*\"year\" + 0.013*\"georgia\" + 0.012*\"bailey\" + 0.011*\"dixon\"\n",
      "2019-10-29 00:46:54,401 : INFO : topic #9 (0.100): 0.037*\"sapelo\" + 0.030*\"pea\" + 0.029*\"island\" + 0.018*\"crop\" + 0.017*\"red\" + 0.017*\"dixon\" + 0.016*\"resident\" + 0.016*\"year\" + 0.013*\"georgia\" + 0.012*\"bailey\"\n",
      "2019-10-29 00:46:54,404 : INFO : topic diff=0.879789, rho=1.000000\n",
      "2019-10-29 00:46:54,894 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:54,899 : INFO : built Dictionary(312 unique tokens: ['maternal', 'duration', 'take', 'crest', 'may']...) from 5 documents (total 2710 corpus positions)\n",
      "2019-10-29 00:46:54,902 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:54,903 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:54,904 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:54,906 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:54,907 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:55,004 : INFO : -7.607 per-word bound, 195.0 perplexity estimate based on a held-out corpus of 5 documents with 2710 words\n",
      "2019-10-29 00:46:55,006 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:55,012 : INFO : topic #4 (0.100): 0.038*\"fever\" + 0.027*\"defect\" + 0.022*\"said\" + 0.018*\"temperature\" + 0.017*\"pregnancy\" + 0.015*\"ion\" + 0.015*\"heart\" + 0.015*\"cell\" + 0.014*\"channel\" + 0.011*\"benner\"\n",
      "2019-10-29 00:46:55,014 : INFO : topic #8 (0.100): 0.032*\"fever\" + 0.030*\"defect\" + 0.018*\"pregnancy\" + 0.018*\"said\" + 0.016*\"channel\" + 0.014*\"benner\" + 0.013*\"cell\" + 0.012*\"ion\" + 0.012*\"birth\" + 0.012*\"temperature\"\n",
      "2019-10-29 00:46:55,015 : INFO : topic #6 (0.100): 0.036*\"fever\" + 0.029*\"defect\" + 0.020*\"said\" + 0.020*\"heart\" + 0.018*\"birth\" + 0.017*\"pregnancy\" + 0.016*\"cell\" + 0.016*\"ion\" + 0.015*\"channel\" + 0.012*\"benner\"\n",
      "2019-10-29 00:46:55,016 : INFO : topic #7 (0.100): 0.036*\"defect\" + 0.031*\"fever\" + 0.022*\"said\" + 0.021*\"pregnancy\" + 0.019*\"birth\" + 0.014*\"channel\" + 0.013*\"benner\" + 0.012*\"cell\" + 0.012*\"ion\" + 0.012*\"heart\"\n",
      "2019-10-29 00:46:55,017 : INFO : topic #5 (0.100): 0.029*\"defect\" + 0.029*\"fever\" + 0.019*\"pregnancy\" + 0.019*\"said\" + 0.017*\"channel\" + 0.016*\"ion\" + 0.014*\"temperature\" + 0.013*\"cell\" + 0.013*\"birth\" + 0.012*\"heart\"\n",
      "2019-10-29 00:46:55,018 : INFO : topic diff=0.921186, rho=1.000000\n",
      "2019-10-29 00:46:55,467 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:55,469 : INFO : built Dictionary(105 unique tokens: ['extensive', 'perkins', 'regulator', 'watch', 'joint']...) from 5 documents (total 885 corpus positions)\n",
      "2019-10-29 00:46:55,472 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:55,473 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:55,474 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:55,476 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:55,477 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:55,527 : INFO : -6.650 per-word bound, 100.4 perplexity estimate based on a held-out corpus of 5 documents with 885 words\n",
      "2019-10-29 00:46:55,529 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:55,536 : INFO : topic #6 (0.100): 0.060*\"cancer\" + 0.052*\"charity\" + 0.033*\"four\" + 0.026*\"say\" + 0.025*\"fund\" + 0.022*\"cnn\" + 0.019*\"james\" + 0.019*\"reynolds\" + 0.018*\"federal\" + 0.018*\"ceo\"\n",
      "2019-10-29 00:46:55,538 : INFO : topic #1 (0.100): 0.091*\"cancer\" + 0.049*\"charity\" + 0.033*\"say\" + 0.027*\"four\" + 0.023*\"fund\" + 0.022*\"cnn\" + 0.020*\"patient\" + 0.020*\"commission\" + 0.019*\"government\" + 0.017*\"run\"\n",
      "2019-10-29 00:46:55,541 : INFO : topic #2 (0.100): 0.083*\"cancer\" + 0.040*\"charity\" + 0.035*\"four\" + 0.027*\"say\" + 0.020*\"government\" + 0.020*\"james\" + 0.020*\"fund\" + 0.019*\"cnn\" + 0.018*\"support\" + 0.018*\"trade\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:55,543 : INFO : topic #4 (0.100): 0.061*\"cancer\" + 0.047*\"charity\" + 0.033*\"four\" + 0.030*\"say\" + 0.022*\"government\" + 0.022*\"support\" + 0.021*\"james\" + 0.020*\"cnn\" + 0.020*\"run\" + 0.020*\"breast\"\n",
      "2019-10-29 00:46:55,544 : INFO : topic #9 (0.100): 0.065*\"charity\" + 0.063*\"cancer\" + 0.032*\"say\" + 0.027*\"four\" + 0.022*\"government\" + 0.021*\"fund\" + 0.018*\"federal\" + 0.017*\"sham\" + 0.017*\"support\" + 0.016*\"ceo\"\n",
      "2019-10-29 00:46:55,546 : INFO : topic diff=0.941425, rho=1.000000\n",
      "2019-10-29 00:46:56,107 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:56,113 : INFO : built Dictionary(302 unique tokens: ['energy', 'weinstein', '1990s', 'come', 'proud']...) from 5 documents (total 2510 corpus positions)\n",
      "2019-10-29 00:46:56,117 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:56,118 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:56,120 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:56,123 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:56,124 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:56,248 : INFO : -7.630 per-word bound, 198.1 perplexity estimate based on a held-out corpus of 5 documents with 2510 words\n",
      "2019-10-29 00:46:56,250 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:56,258 : INFO : topic #0 (0.100): 0.063*\"weinstein\" + 0.017*\"allegation\" + 0.016*\"story\" + 0.016*\"new\" + 0.015*\"said\" + 0.015*\"told\" + 0.015*\"farrow\" + 0.012*\"sexual\" + 0.012*\"company\" + 0.011*\"actress\"\n",
      "2019-10-29 00:46:56,260 : INFO : topic #6 (0.100): 0.091*\"weinstein\" + 0.019*\"allegation\" + 0.018*\"told\" + 0.017*\"new\" + 0.013*\"story\" + 0.011*\"said\" + 0.011*\"harvey\" + 0.011*\"statement\" + 0.011*\"mr\" + 0.010*\"actress\"\n",
      "2019-10-29 00:46:56,263 : INFO : topic #4 (0.100): 0.071*\"weinstein\" + 0.018*\"allegation\" + 0.018*\"said\" + 0.017*\"new\" + 0.013*\"told\" + 0.013*\"story\" + 0.013*\"harvey\" + 0.011*\"farrow\" + 0.011*\"company\" + 0.011*\"statement\"\n",
      "2019-10-29 00:46:56,265 : INFO : topic #2 (0.100): 0.066*\"weinstein\" + 0.021*\"new\" + 0.016*\"allegation\" + 0.015*\"told\" + 0.014*\"said\" + 0.013*\"harvey\" + 0.013*\"advance\" + 0.012*\"sexual\" + 0.012*\"story\" + 0.011*\"actress\"\n",
      "2019-10-29 00:46:56,267 : INFO : topic #3 (0.100): 0.054*\"weinstein\" + 0.017*\"allegation\" + 0.016*\"told\" + 0.015*\"new\" + 0.014*\"said\" + 0.014*\"also\" + 0.013*\"mr\" + 0.013*\"story\" + 0.013*\"sexual\" + 0.011*\"actress\"\n",
      "2019-10-29 00:46:56,269 : INFO : topic diff=0.871790, rho=1.000000\n",
      "2019-10-29 00:46:56,693 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:56,697 : INFO : built Dictionary(233 unique tokens: ['concern', 'angeles', 'nation', 'come', 'testified']...) from 5 documents (total 2840 corpus positions)\n",
      "2019-10-29 00:46:56,700 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:56,701 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:56,702 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:56,706 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:56,707 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:56,791 : INFO : -6.946 per-word bound, 123.3 perplexity estimate based on a held-out corpus of 5 documents with 2840 words\n",
      "2019-10-29 00:46:56,792 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:56,800 : INFO : topic #5 (0.100): 0.047*\"va\" + 0.039*\"new\" + 0.038*\"wait\" + 0.032*\"veteran\" + 0.029*\"angeles\" + 0.024*\"time\" + 0.023*\"patient\" + 0.022*\"cnn\" + 0.021*\"los\" + 0.019*\"day\"\n",
      "2019-10-29 00:46:56,801 : INFO : topic #7 (0.100): 0.051*\"va\" + 0.038*\"veteran\" + 0.032*\"wait\" + 0.030*\"new\" + 0.027*\"angeles\" + 0.027*\"los\" + 0.024*\"time\" + 0.022*\"day\" + 0.020*\"patient\" + 0.019*\"cnn\"\n",
      "2019-10-29 00:46:56,803 : INFO : topic #0 (0.100): 0.048*\"va\" + 0.034*\"wait\" + 0.032*\"patient\" + 0.029*\"veteran\" + 0.029*\"angeles\" + 0.028*\"time\" + 0.028*\"new\" + 0.028*\"los\" + 0.022*\"day\" + 0.022*\"appointment\"\n",
      "2019-10-29 00:46:56,805 : INFO : topic #2 (0.100): 0.063*\"va\" + 0.034*\"veteran\" + 0.032*\"new\" + 0.029*\"patient\" + 0.028*\"angeles\" + 0.027*\"time\" + 0.026*\"los\" + 0.024*\"wait\" + 0.022*\"day\" + 0.019*\"appointment\"\n",
      "2019-10-29 00:46:56,807 : INFO : topic #6 (0.100): 0.056*\"va\" + 0.037*\"new\" + 0.032*\"veteran\" + 0.029*\"angeles\" + 0.028*\"time\" + 0.027*\"day\" + 0.026*\"patient\" + 0.026*\"los\" + 0.025*\"wait\" + 0.021*\"cnn\"\n",
      "2019-10-29 00:46:56,808 : INFO : topic diff=1.119757, rho=1.000000\n",
      "2019-10-29 00:46:57,196 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:57,197 : INFO : built Dictionary(16 unique tokens: ['agree', 'revised', 'policy', 'best', 'continuing']...) from 5 documents (total 85 corpus positions)\n",
      "2019-10-29 00:46:57,199 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:57,203 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:57,207 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:57,210 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:57,214 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:57,228 : INFO : -6.302 per-word bound, 78.9 perplexity estimate based on a held-out corpus of 5 documents with 85 words\n",
      "2019-10-29 00:46:57,230 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:57,236 : INFO : topic #0 (0.100): 0.144*\"cooky\" + 0.064*\"best\" + 0.064*\"information\" + 0.061*\"photo\" + 0.060*\"use\" + 0.060*\"agree\" + 0.060*\"continuing\" + 0.060*\"world\" + 0.060*\"privacy\" + 0.057*\"travel\"\n",
      "2019-10-29 00:46:57,239 : INFO : topic #8 (0.100): 0.086*\"cooky\" + 0.086*\"service\" + 0.078*\"use\" + 0.070*\"agree\" + 0.066*\"revised\" + 0.063*\"world\" + 0.059*\"best\" + 0.059*\"information\" + 0.057*\"site\" + 0.057*\"continuing\"\n",
      "2019-10-29 00:46:57,242 : INFO : topic #2 (0.100): 0.088*\"cooky\" + 0.071*\"photo\" + 0.070*\"continuing\" + 0.067*\"term\" + 0.065*\"best\" + 0.064*\"revised\" + 0.064*\"service\" + 0.064*\"information\" + 0.060*\"travel\" + 0.060*\"agree\"\n",
      "2019-10-29 00:46:57,245 : INFO : topic #1 (0.100): 0.116*\"cooky\" + 0.076*\"policy\" + 0.071*\"browse\" + 0.065*\"continuing\" + 0.063*\"privacy\" + 0.063*\"use\" + 0.062*\"information\" + 0.061*\"term\" + 0.059*\"best\" + 0.054*\"revised\"\n",
      "2019-10-29 00:46:57,248 : INFO : topic #3 (0.100): 0.108*\"cooky\" + 0.083*\"policy\" + 0.067*\"travel\" + 0.064*\"service\" + 0.063*\"photo\" + 0.062*\"privacy\" + 0.060*\"world\" + 0.059*\"use\" + 0.059*\"best\" + 0.057*\"information\"\n",
      "2019-10-29 00:46:57,250 : INFO : topic diff=0.555342, rho=1.000000\n",
      "2019-10-29 00:46:57,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:57,706 : INFO : built Dictionary(481 unique tokens: ['anniversary', 'valley', 'filed', 'wanting', 'awoke']...) from 5 documents (total 3755 corpus positions)\n",
      "2019-10-29 00:46:57,712 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:57,713 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:57,714 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:57,719 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:57,721 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:57,864 : INFO : -8.170 per-word bound, 288.1 perplexity estimate based on a held-out corpus of 5 documents with 3755 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:46:57,866 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:57,874 : INFO : topic #0 (0.100): 0.034*\"mother\" + 0.017*\"home\" + 0.013*\"would\" + 0.012*\"nursing\" + 0.011*\"father\" + 0.010*\"day\" + 0.008*\"husband\" + 0.007*\"still\" + 0.007*\"young\" + 0.007*\"nurse\"\n",
      "2019-10-29 00:46:57,876 : INFO : topic #2 (0.100): 0.032*\"mother\" + 0.019*\"home\" + 0.017*\"father\" + 0.012*\"would\" + 0.011*\"day\" + 0.011*\"nursing\" + 0.010*\"husband\" + 0.007*\"asked\" + 0.007*\"one\" + 0.007*\"took\"\n",
      "2019-10-29 00:46:57,877 : INFO : topic #6 (0.100): 0.025*\"mother\" + 0.024*\"home\" + 0.014*\"would\" + 0.013*\"nursing\" + 0.013*\"day\" + 0.011*\"husband\" + 0.011*\"father\" + 0.008*\"promised\" + 0.007*\"together\" + 0.006*\"one\"\n",
      "2019-10-29 00:46:57,879 : INFO : topic #3 (0.100): 0.028*\"mother\" + 0.024*\"home\" + 0.015*\"day\" + 0.013*\"father\" + 0.012*\"would\" + 0.010*\"nursing\" + 0.007*\"young\" + 0.007*\"asked\" + 0.007*\"life\" + 0.007*\"nurse\"\n",
      "2019-10-29 00:46:57,880 : INFO : topic #5 (0.100): 0.036*\"mother\" + 0.022*\"home\" + 0.017*\"father\" + 0.015*\"would\" + 0.010*\"day\" + 0.010*\"nursing\" + 0.009*\"husband\" + 0.009*\"told\" + 0.007*\"asked\" + 0.007*\"parent\"\n",
      "2019-10-29 00:46:57,882 : INFO : topic diff=0.830836, rho=1.000000\n",
      "2019-10-29 00:46:58,358 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:58,364 : INFO : built Dictionary(375 unique tokens: ['dating', 'francisco', 'diamond', 'game', 'school']...) from 5 documents (total 2980 corpus positions)\n",
      "2019-10-29 00:46:58,369 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:58,370 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:58,371 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:58,375 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:58,377 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:58,508 : INFO : -7.902 per-word bound, 239.2 perplexity estimate based on a held-out corpus of 5 documents with 2980 words\n",
      "2019-10-29 00:46:58,510 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:58,519 : INFO : topic #8 (0.100): 0.036*\"snow\" + 0.020*\"game\" + 0.017*\"trafficker\" + 0.014*\"trafficking\" + 0.014*\"say\" + 0.012*\"sex\" + 0.012*\"elle\" + 0.010*\"humboldt\" + 0.009*\"met\" + 0.009*\"know\"\n",
      "2019-10-29 00:46:58,521 : INFO : topic #4 (0.100): 0.035*\"snow\" + 0.018*\"say\" + 0.012*\"game\" + 0.012*\"trafficking\" + 0.011*\"trafficker\" + 0.009*\"sex\" + 0.009*\"know\" + 0.009*\"time\" + 0.009*\"elle\" + 0.008*\"humboldt\"\n",
      "2019-10-29 00:46:58,522 : INFO : topic #5 (0.100): 0.043*\"snow\" + 0.016*\"game\" + 0.016*\"say\" + 0.012*\"sex\" + 0.012*\"trafficking\" + 0.011*\"trafficker\" + 0.011*\"elle\" + 0.010*\"humboldt\" + 0.009*\"county\" + 0.008*\"met\"\n",
      "2019-10-29 00:46:58,528 : INFO : topic #2 (0.100): 0.037*\"snow\" + 0.019*\"game\" + 0.015*\"say\" + 0.014*\"trafficker\" + 0.012*\"trafficking\" + 0.012*\"elle\" + 0.010*\"sex\" + 0.010*\"know\" + 0.008*\"humboldt\" + 0.008*\"victim\"\n",
      "2019-10-29 00:46:58,531 : INFO : topic #1 (0.100): 0.040*\"snow\" + 0.017*\"say\" + 0.015*\"trafficking\" + 0.014*\"game\" + 0.013*\"trafficker\" + 0.012*\"sex\" + 0.012*\"elle\" + 0.011*\"humboldt\" + 0.009*\"time\" + 0.009*\"know\"\n",
      "2019-10-29 00:46:58,534 : INFO : topic diff=0.819358, rho=1.000000\n",
      "2019-10-29 00:46:58,971 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:58,977 : INFO : built Dictionary(213 unique tokens: ['trying', 'watch', 'bos', 'despite', 'staff']...) from 5 documents (total 1770 corpus positions)\n",
      "2019-10-29 00:46:58,980 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:58,981 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:58,983 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:58,987 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:58,988 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:59,086 : INFO : -7.312 per-word bound, 159.0 perplexity estimate based on a held-out corpus of 5 documents with 1770 words\n",
      "2019-10-29 00:46:59,087 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:59,095 : INFO : topic #4 (0.100): 0.051*\"trump\" + 0.040*\"tillerson\" + 0.020*\"secretary\" + 0.019*\"state\" + 0.018*\"iq\" + 0.017*\"said\" + 0.017*\"comment\" + 0.014*\"president\" + 0.012*\"relationship\" + 0.012*\"made\"\n",
      "2019-10-29 00:46:59,098 : INFO : topic #5 (0.100): 0.041*\"trump\" + 0.040*\"tillerson\" + 0.023*\"said\" + 0.019*\"secretary\" + 0.019*\"president\" + 0.018*\"state\" + 0.016*\"report\" + 0.013*\"comment\" + 0.013*\"told\" + 0.013*\"iq\"\n",
      "2019-10-29 00:46:59,101 : INFO : topic #6 (0.100): 0.049*\"trump\" + 0.041*\"tillerson\" + 0.022*\"said\" + 0.019*\"comment\" + 0.018*\"secretary\" + 0.018*\"president\" + 0.016*\"iq\" + 0.011*\"state\" + 0.011*\"made\" + 0.011*\"report\"\n",
      "2019-10-29 00:46:59,104 : INFO : topic #8 (0.100): 0.044*\"trump\" + 0.037*\"tillerson\" + 0.025*\"president\" + 0.022*\"secretary\" + 0.018*\"said\" + 0.017*\"comment\" + 0.017*\"state\" + 0.013*\"iq\" + 0.012*\"told\" + 0.011*\"cnn\"\n",
      "2019-10-29 00:46:59,107 : INFO : topic #1 (0.100): 0.048*\"trump\" + 0.033*\"tillerson\" + 0.021*\"said\" + 0.019*\"iq\" + 0.017*\"comment\" + 0.016*\"president\" + 0.015*\"secretary\" + 0.013*\"state\" + 0.012*\"added\" + 0.011*\"relationship\"\n",
      "2019-10-29 00:46:59,109 : INFO : topic diff=0.861040, rho=1.000000\n",
      "2019-10-29 00:46:59,557 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:46:59,567 : INFO : built Dictionary(367 unique tokens: ['prime', 'party', 'mayor', 'spokesman', 'local']...) from 5 documents (total 3120 corpus positions)\n",
      "2019-10-29 00:46:59,574 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:46:59,576 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:46:59,577 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:46:59,580 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:46:59,583 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:46:59,742 : INFO : -7.789 per-word bound, 221.1 perplexity estimate based on a held-out corpus of 5 documents with 3120 words\n",
      "2019-10-29 00:46:59,744 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:46:59,751 : INFO : topic #4 (0.100): 0.023*\"catalonia\" + 0.017*\"catalan\" + 0.017*\"said\" + 0.016*\"would\" + 0.015*\"spain\" + 0.012*\"independence\" + 0.011*\"spanish\" + 0.010*\"minister\" + 0.010*\"government\" + 0.009*\"barcelona\"\n",
      "2019-10-29 00:46:59,753 : INFO : topic #3 (0.100): 0.027*\"catalonia\" + 0.020*\"said\" + 0.018*\"independence\" + 0.018*\"would\" + 0.018*\"spain\" + 0.017*\"catalan\" + 0.012*\"government\" + 0.011*\"barcelona\" + 0.009*\"parliament\" + 0.008*\"european\"\n",
      "2019-10-29 00:46:59,755 : INFO : topic #1 (0.100): 0.022*\"independence\" + 0.021*\"catalonia\" + 0.018*\"catalan\" + 0.017*\"spain\" + 0.013*\"would\" + 0.012*\"spanish\" + 0.012*\"said\" + 0.011*\"government\" + 0.010*\"puigdemont\" + 0.010*\"minister\"\n",
      "2019-10-29 00:46:59,757 : INFO : topic #5 (0.100): 0.025*\"catalonia\" + 0.021*\"said\" + 0.019*\"independence\" + 0.017*\"would\" + 0.014*\"spain\" + 0.014*\"government\" + 0.012*\"catalan\" + 0.009*\"minister\" + 0.009*\"puigdemont\" + 0.009*\"barcelona\"\n",
      "2019-10-29 00:46:59,759 : INFO : topic #9 (0.100): 0.028*\"catalonia\" + 0.022*\"catalan\" + 0.021*\"spain\" + 0.019*\"independence\" + 0.019*\"said\" + 0.015*\"would\" + 0.012*\"government\" + 0.008*\"parliament\" + 0.008*\"cnn\" + 0.008*\"spanish\"\n",
      "2019-10-29 00:46:59,762 : INFO : topic diff=0.870770, rho=1.000000\n",
      "2019-10-29 00:47:00,171 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:00,174 : INFO : built Dictionary(152 unique tokens: ['star', 'online', 'shared', 'disney', 'come']...) from 5 documents (total 1115 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:00,177 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:00,181 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:00,184 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:00,188 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:00,191 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:00,258 : INFO : -7.184 per-word bound, 145.4 perplexity estimate based on a held-out corpus of 5 documents with 1115 words\n",
      "2019-10-29 00:47:00,262 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:00,271 : INFO : topic #6 (0.100): 0.041*\"thornton\" + 0.034*\"love\" + 0.027*\"husband\" + 0.023*\"life\" + 0.020*\"first\" + 0.019*\"chris\" + 0.017*\"day\" + 0.015*\"way\" + 0.014*\"two\" + 0.014*\"tiffany\"\n",
      "2019-10-29 00:47:00,274 : INFO : topic #4 (0.100): 0.041*\"love\" + 0.037*\"thornton\" + 0.023*\"chris\" + 0.021*\"husband\" + 0.018*\"life\" + 0.017*\"first\" + 0.016*\"new\" + 0.015*\"said\" + 0.013*\"day\" + 0.013*\"two\"\n",
      "2019-10-29 00:47:00,281 : INFO : topic #7 (0.100): 0.036*\"thornton\" + 0.030*\"husband\" + 0.029*\"love\" + 0.027*\"life\" + 0.019*\"chris\" + 0.017*\"new\" + 0.017*\"first\" + 0.014*\"way\" + 0.014*\"back\" + 0.013*\"day\"\n",
      "2019-10-29 00:47:00,284 : INFO : topic #3 (0.100): 0.031*\"husband\" + 0.030*\"love\" + 0.030*\"thornton\" + 0.019*\"new\" + 0.017*\"life\" + 0.017*\"chris\" + 0.015*\"way\" + 0.014*\"two\" + 0.014*\"said\" + 0.014*\"back\"\n",
      "2019-10-29 00:47:00,286 : INFO : topic #5 (0.100): 0.032*\"love\" + 0.030*\"husband\" + 0.024*\"thornton\" + 0.021*\"first\" + 0.021*\"chris\" + 0.018*\"life\" + 0.014*\"back\" + 0.013*\"new\" + 0.013*\"instagram\" + 0.012*\"way\"\n",
      "2019-10-29 00:47:00,296 : INFO : topic diff=0.812151, rho=1.000000\n",
      "2019-10-29 00:47:00,733 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:00,736 : INFO : built Dictionary(14 unique tokens: ['motivated', 'greed', 'rape', 'denied', 'attorney']...) from 5 documents (total 90 corpus positions)\n",
      "2019-10-29 00:47:00,737 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:00,739 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:00,740 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:00,742 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:00,744 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:00,761 : INFO : -5.764 per-word bound, 54.4 perplexity estimate based on a held-out corpus of 5 documents with 90 words\n",
      "2019-10-29 00:47:00,764 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:00,769 : INFO : topic #8 (0.100): 0.131*\"suspicion\" + 0.109*\"rape\" + 0.103*\"arrested\" + 0.102*\"nelly\" + 0.066*\"rapper\" + 0.065*\"accusation\" + 0.062*\"motivated\" + 0.057*\"near\" + 0.056*\"said\" + 0.052*\"greed\"\n",
      "2019-10-29 00:47:00,772 : INFO : topic #4 (0.100): 0.125*\"arrested\" + 0.119*\"suspicion\" + 0.105*\"nelly\" + 0.098*\"rape\" + 0.065*\"attorney\" + 0.062*\"said\" + 0.059*\"rapper\" + 0.057*\"motivated\" + 0.055*\"greed\" + 0.055*\"near\"\n",
      "2019-10-29 00:47:00,775 : INFO : topic #3 (0.100): 0.116*\"nelly\" + 0.103*\"rape\" + 0.101*\"suspicion\" + 0.096*\"arrested\" + 0.073*\"near\" + 0.071*\"attorney\" + 0.065*\"accusation\" + 0.063*\"washington\" + 0.062*\"denied\" + 0.055*\"seattle\"\n",
      "2019-10-29 00:47:00,777 : INFO : topic #2 (0.100): 0.122*\"rape\" + 0.100*\"suspicion\" + 0.095*\"nelly\" + 0.082*\"arrested\" + 0.072*\"denied\" + 0.070*\"seattle\" + 0.067*\"motivated\" + 0.062*\"near\" + 0.062*\"attorney\" + 0.060*\"rapper\"\n",
      "2019-10-29 00:47:00,779 : INFO : topic #5 (0.100): 0.119*\"arrested\" + 0.119*\"rape\" + 0.108*\"suspicion\" + 0.105*\"nelly\" + 0.071*\"said\" + 0.063*\"accusation\" + 0.061*\"denied\" + 0.055*\"seattle\" + 0.054*\"washington\" + 0.053*\"attorney\"\n",
      "2019-10-29 00:47:00,781 : INFO : topic diff=0.641707, rho=1.000000\n",
      "2019-10-29 00:47:01,319 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:01,328 : INFO : built Dictionary(517 unique tokens: ['deep', 'genetically', 'francisco', 'asleep', 'comb']...) from 5 documents (total 4465 corpus positions)\n",
      "2019-10-29 00:47:01,336 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:01,338 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:01,343 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:01,347 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:01,348 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:01,519 : INFO : -8.102 per-word bound, 274.7 perplexity estimate based on a held-out corpus of 5 documents with 4465 words\n",
      "2019-10-29 00:47:01,521 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:01,533 : INFO : topic #5 (0.100): 0.025*\"disease\" + 0.022*\"said\" + 0.016*\"vallabh\" + 0.012*\"family\" + 0.012*\"webb\" + 0.011*\"ffi\" + 0.009*\"brain\" + 0.009*\"gene\" + 0.008*\"prion\" + 0.008*\"silvano\"\n",
      "2019-10-29 00:47:01,534 : INFO : topic #7 (0.100): 0.025*\"said\" + 0.018*\"vallabh\" + 0.017*\"disease\" + 0.013*\"family\" + 0.013*\"prion\" + 0.011*\"ffi\" + 0.010*\"brain\" + 0.009*\"gene\" + 0.009*\"one\" + 0.009*\"webb\"\n",
      "2019-10-29 00:47:01,536 : INFO : topic #8 (0.100): 0.029*\"said\" + 0.021*\"vallabh\" + 0.014*\"prion\" + 0.013*\"disease\" + 0.012*\"family\" + 0.012*\"webb\" + 0.010*\"ffi\" + 0.010*\"brain\" + 0.009*\"year\" + 0.009*\"mother\"\n",
      "2019-10-29 00:47:01,540 : INFO : topic #6 (0.100): 0.022*\"disease\" + 0.020*\"vallabh\" + 0.020*\"said\" + 0.013*\"ffi\" + 0.010*\"prion\" + 0.010*\"webb\" + 0.010*\"family\" + 0.009*\"one\" + 0.008*\"brain\" + 0.008*\"mother\"\n",
      "2019-10-29 00:47:01,544 : INFO : topic #4 (0.100): 0.023*\"said\" + 0.020*\"disease\" + 0.019*\"vallabh\" + 0.012*\"webb\" + 0.012*\"prion\" + 0.011*\"ffi\" + 0.010*\"family\" + 0.010*\"gene\" + 0.009*\"brain\" + 0.008*\"year\"\n",
      "2019-10-29 00:47:01,547 : INFO : topic diff=0.911068, rho=1.000000\n",
      "2019-10-29 00:47:01,996 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:02,004 : INFO : built Dictionary(394 unique tokens: ['although', 'deep', 'party', 'slice', 'golden']...) from 5 documents (total 3735 corpus positions)\n",
      "2019-10-29 00:47:02,011 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:02,013 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:02,014 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:02,017 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:02,019 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:02,162 : INFO : -7.720 per-word bound, 210.8 perplexity estimate based on a held-out corpus of 5 documents with 3735 words\n",
      "2019-10-29 00:47:02,163 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:02,172 : INFO : topic #8 (0.100): 0.043*\"fried\" + 0.028*\"fair\" + 0.026*\"geary\" + 0.019*\"recipe\" + 0.019*\"food\" + 0.017*\"dog\" + 0.014*\"say\" + 0.012*\"cheesecake\" + 0.012*\"deep\" + 0.010*\"state\"\n",
      "2019-10-29 00:47:02,175 : INFO : topic #7 (0.100): 0.029*\"fried\" + 0.023*\"fair\" + 0.022*\"dog\" + 0.022*\"geary\" + 0.017*\"recipe\" + 0.017*\"say\" + 0.015*\"food\" + 0.013*\"deep\" + 0.013*\"like\" + 0.012*\"state\"\n",
      "2019-10-29 00:47:02,178 : INFO : topic #5 (0.100): 0.026*\"food\" + 0.024*\"geary\" + 0.024*\"fried\" + 0.020*\"recipe\" + 0.019*\"fair\" + 0.018*\"dog\" + 0.017*\"deep\" + 0.016*\"say\" + 0.013*\"butter\" + 0.012*\"state\"\n",
      "2019-10-29 00:47:02,181 : INFO : topic #2 (0.100): 0.044*\"fair\" + 0.029*\"fried\" + 0.026*\"recipe\" + 0.022*\"dog\" + 0.021*\"food\" + 0.015*\"deep\" + 0.015*\"say\" + 0.015*\"geary\" + 0.011*\"state\" + 0.011*\"butter\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:02,184 : INFO : topic #9 (0.100): 0.032*\"geary\" + 0.031*\"fair\" + 0.029*\"fried\" + 0.020*\"food\" + 0.017*\"recipe\" + 0.015*\"dog\" + 0.014*\"say\" + 0.014*\"deep\" + 0.012*\"state\" + 0.011*\"butter\"\n",
      "2019-10-29 00:47:02,186 : INFO : topic diff=0.946154, rho=1.000000\n",
      "2019-10-29 00:47:02,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:02,600 : INFO : built Dictionary(218 unique tokens: ['consent', 'acceptable', 'weinstein', 'described', 'come']...) from 5 documents (total 1780 corpus positions)\n",
      "2019-10-29 00:47:02,603 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:02,605 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:02,607 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:02,610 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:02,611 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:02,698 : INFO : -7.349 per-word bound, 163.0 perplexity estimate based on a held-out corpus of 5 documents with 1780 words\n",
      "2019-10-29 00:47:02,700 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:02,707 : INFO : topic #9 (0.100): 0.057*\"karan\" + 0.026*\"woman\" + 0.018*\"comment\" + 0.017*\"weinstein\" + 0.017*\"said\" + 0.015*\"donna\" + 0.014*\"statement\" + 0.013*\"asking\" + 0.012*\"harvey\" + 0.012*\"time\"\n",
      "2019-10-29 00:47:02,709 : INFO : topic #0 (0.100): 0.046*\"karan\" + 0.025*\"woman\" + 0.024*\"weinstein\" + 0.024*\"donna\" + 0.019*\"said\" + 0.017*\"statement\" + 0.017*\"comment\" + 0.013*\"october\" + 0.012*\"asking\" + 0.012*\"sexual\"\n",
      "2019-10-29 00:47:02,711 : INFO : topic #5 (0.100): 0.056*\"karan\" + 0.028*\"woman\" + 0.024*\"donna\" + 0.023*\"said\" + 0.022*\"comment\" + 0.017*\"weinstein\" + 0.013*\"harassment\" + 0.012*\"statement\" + 0.012*\"asking\" + 0.011*\"time\"\n",
      "2019-10-29 00:47:02,714 : INFO : topic #3 (0.100): 0.036*\"karan\" + 0.032*\"woman\" + 0.022*\"weinstein\" + 0.020*\"donna\" + 0.018*\"comment\" + 0.016*\"said\" + 0.014*\"statement\" + 0.012*\"asking\" + 0.012*\"harassment\" + 0.012*\"october\"\n",
      "2019-10-29 00:47:02,716 : INFO : topic #2 (0.100): 0.046*\"karan\" + 0.026*\"donna\" + 0.025*\"woman\" + 0.022*\"weinstein\" + 0.018*\"said\" + 0.017*\"comment\" + 0.012*\"harvey\" + 0.012*\"statement\" + 0.012*\"harassment\" + 0.011*\"asking\"\n",
      "2019-10-29 00:47:02,718 : INFO : topic diff=0.825527, rho=1.000000\n",
      "2019-10-29 00:47:03,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:03,197 : INFO : built Dictionary(923 unique tokens: ['let', 'selection', 'bet', 'take', 'focus']...) from 5 documents (total 7730 corpus positions)\n",
      "2019-10-29 00:47:03,206 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:03,207 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:03,209 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:03,216 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:03,219 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:03,497 : INFO : -8.702 per-word bound, 416.3 perplexity estimate based on a held-out corpus of 5 documents with 7730 words\n",
      "2019-10-29 00:47:03,498 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:03,511 : INFO : topic #6 (0.100): 0.017*\"trump\" + 0.010*\"clinton\" + 0.008*\"state\" + 0.007*\"read\" + 0.006*\"president\" + 0.006*\"cnn\" + 0.006*\"donald\" + 0.005*\"america\" + 0.005*\"hillary\" + 0.005*\"first\"\n",
      "2019-10-29 00:47:03,513 : INFO : topic #0 (0.100): 0.019*\"trump\" + 0.011*\"read\" + 0.008*\"cnn\" + 0.007*\"clinton\" + 0.006*\"first\" + 0.006*\"president\" + 0.006*\"state\" + 0.005*\"hate\" + 0.005*\"one\" + 0.005*\"donald\"\n",
      "2019-10-29 00:47:03,514 : INFO : topic #1 (0.100): 0.017*\"trump\" + 0.012*\"read\" + 0.009*\"clinton\" + 0.007*\"president\" + 0.006*\"cnn\" + 0.006*\"first\" + 0.005*\"state\" + 0.005*\"one\" + 0.005*\"donald\" + 0.005*\"would\"\n",
      "2019-10-29 00:47:03,517 : INFO : topic #3 (0.100): 0.017*\"trump\" + 0.013*\"read\" + 0.008*\"clinton\" + 0.008*\"cnn\" + 0.008*\"state\" + 0.006*\"president\" + 0.006*\"america\" + 0.005*\"hate\" + 0.005*\"donald\" + 0.005*\"first\"\n",
      "2019-10-29 00:47:03,518 : INFO : topic #5 (0.100): 0.023*\"trump\" + 0.013*\"read\" + 0.009*\"cnn\" + 0.008*\"donald\" + 0.006*\"clinton\" + 0.006*\"first\" + 0.006*\"state\" + 0.005*\"would\" + 0.005*\"one\" + 0.005*\"president\"\n",
      "2019-10-29 00:47:03,520 : INFO : topic diff=0.875276, rho=1.000000\n",
      "2019-10-29 00:47:03,980 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:03,988 : INFO : built Dictionary(642 unique tokens: ['vacation', 'located', 'selection', 'person', 'shower']...) from 5 documents (total 5080 corpus positions)\n",
      "2019-10-29 00:47:03,995 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:03,997 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:03,998 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:04,003 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:04,005 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:04,212 : INFO : -8.428 per-word bound, 344.5 perplexity estimate based on a held-out corpus of 5 documents with 5080 words\n",
      "2019-10-29 00:47:04,213 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:04,223 : INFO : topic #4 (0.100): 0.016*\"room\" + 0.012*\"hotel\" + 0.011*\"lodge\" + 0.007*\"lake\" + 0.007*\"fall\" + 0.006*\"ranch\" + 0.006*\"inn\" + 0.006*\"fireplace\" + 0.006*\"october\" + 0.006*\"spa\"\n",
      "2019-10-29 00:47:04,225 : INFO : topic #2 (0.100): 0.015*\"lodge\" + 0.014*\"room\" + 0.010*\"hotel\" + 0.010*\"lake\" + 0.007*\"spa\" + 0.006*\"fall\" + 0.006*\"inn\" + 0.006*\"fireplace\" + 0.006*\"october\" + 0.006*\"place\"\n",
      "2019-10-29 00:47:04,226 : INFO : topic #8 (0.100): 0.013*\"lodge\" + 0.011*\"room\" + 0.010*\"hotel\" + 0.008*\"lake\" + 0.008*\"fall\" + 0.007*\"ranch\" + 0.007*\"inn\" + 0.006*\"mountain\" + 0.006*\"spa\" + 0.006*\"october\"\n",
      "2019-10-29 00:47:04,228 : INFO : topic #0 (0.100): 0.015*\"room\" + 0.012*\"lodge\" + 0.012*\"hotel\" + 0.011*\"lake\" + 0.006*\"mountain\" + 0.006*\"b\" + 0.006*\"fall\" + 0.006*\"place\" + 0.005*\"inn\" + 0.005*\"spa\"\n",
      "2019-10-29 00:47:04,229 : INFO : topic #3 (0.100): 0.016*\"room\" + 0.012*\"lodge\" + 0.010*\"hotel\" + 0.008*\"fall\" + 0.007*\"lake\" + 0.007*\"spa\" + 0.006*\"ranch\" + 0.006*\"inn\" + 0.006*\"fireplace\" + 0.006*\"b\"\n",
      "2019-10-29 00:47:04,231 : INFO : topic diff=0.839647, rho=1.000000\n",
      "2019-10-29 00:47:04,699 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:04,707 : INFO : built Dictionary(542 unique tokens: ['although', 'located', 'story', 'filed', 'take']...) from 5 documents (total 7385 corpus positions)\n",
      "2019-10-29 00:47:04,715 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:04,716 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:04,720 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:04,725 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:04,729 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:04,899 : INFO : -7.660 per-word bound, 202.2 perplexity estimate based on a held-out corpus of 5 documents with 7385 words\n",
      "2019-10-29 00:47:04,901 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:04,911 : INFO : topic #3 (0.100): 0.026*\"fraternity\" + 0.025*\"university\" + 0.012*\"parent\" + 0.011*\"hazing\" + 0.010*\"family\" + 0.010*\"said\" + 0.010*\"violation\" + 0.010*\"say\" + 0.010*\"hipps\" + 0.010*\"cnn\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:04,913 : INFO : topic #5 (0.100): 0.032*\"fraternity\" + 0.027*\"university\" + 0.015*\"hazing\" + 0.012*\"alcohol\" + 0.012*\"say\" + 0.011*\"died\" + 0.010*\"violation\" + 0.010*\"parent\" + 0.009*\"burch\" + 0.009*\"clemson\"\n",
      "2019-10-29 00:47:04,916 : INFO : topic #6 (0.100): 0.032*\"university\" + 0.026*\"fraternity\" + 0.013*\"say\" + 0.012*\"hipps\" + 0.012*\"hazing\" + 0.011*\"alcohol\" + 0.011*\"death\" + 0.010*\"died\" + 0.010*\"braham\" + 0.010*\"event\"\n",
      "2019-10-29 00:47:04,920 : INFO : topic #1 (0.100): 0.028*\"university\" + 0.020*\"fraternity\" + 0.014*\"hazing\" + 0.012*\"say\" + 0.012*\"burch\" + 0.011*\"died\" + 0.011*\"hipps\" + 0.010*\"alcohol\" + 0.010*\"death\" + 0.010*\"said\"\n",
      "2019-10-29 00:47:04,922 : INFO : topic #9 (0.100): 0.027*\"fraternity\" + 0.026*\"university\" + 0.013*\"death\" + 0.013*\"hazing\" + 0.011*\"alcohol\" + 0.011*\"died\" + 0.011*\"greek\" + 0.010*\"braham\" + 0.010*\"family\" + 0.010*\"hipps\"\n",
      "2019-10-29 00:47:04,925 : INFO : topic diff=1.079439, rho=1.000000\n",
      "2019-10-29 00:47:05,343 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:05,346 : INFO : built Dictionary(83 unique tokens: ['gear', 'including', '32nd', 'special', 'two']...) from 5 documents (total 715 corpus positions)\n",
      "2019-10-29 00:47:05,349 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:05,350 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:05,352 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:05,355 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:05,356 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:05,399 : INFO : -6.415 per-word bound, 85.3 perplexity estimate based on a held-out corpus of 5 documents with 715 words\n",
      "2019-10-29 00:47:05,402 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:05,410 : INFO : topic #7 (0.100): 0.061*\"tank\" + 0.047*\"round\" + 0.041*\"source\" + 0.032*\"incendiary\" + 0.029*\"fuel\" + 0.025*\"recovered\" + 0.024*\"investigator\" + 0.024*\"fired\" + 0.023*\"paddock\" + 0.022*\"said\"\n",
      "2019-10-29 00:47:05,412 : INFO : topic #3 (0.100): 0.057*\"round\" + 0.052*\"tank\" + 0.043*\"incendiary\" + 0.034*\"source\" + 0.028*\"fuel\" + 0.024*\"fired\" + 0.024*\"investigator\" + 0.023*\"paddock\" + 0.022*\"said\" + 0.021*\"recovered\"\n",
      "2019-10-29 00:47:05,415 : INFO : topic #2 (0.100): 0.064*\"tank\" + 0.058*\"round\" + 0.038*\"incendiary\" + 0.031*\"fuel\" + 0.028*\"fired\" + 0.026*\"paddock\" + 0.025*\"near\" + 0.024*\"source\" + 0.022*\"investigator\" + 0.021*\"struck\"\n",
      "2019-10-29 00:47:05,427 : INFO : topic #9 (0.100): 0.056*\"tank\" + 0.052*\"round\" + 0.040*\"source\" + 0.038*\"incendiary\" + 0.031*\"fuel\" + 0.030*\"room\" + 0.024*\"near\" + 0.023*\"paddock\" + 0.023*\"recovered\" + 0.020*\"said\"\n",
      "2019-10-29 00:47:05,430 : INFO : topic #4 (0.100): 0.055*\"tank\" + 0.053*\"incendiary\" + 0.039*\"fuel\" + 0.036*\"round\" + 0.028*\"source\" + 0.028*\"fired\" + 0.025*\"said\" + 0.024*\"recovered\" + 0.023*\"paddock\" + 0.019*\"struck\"\n",
      "2019-10-29 00:47:05,434 : INFO : topic diff=0.897259, rho=1.000000\n",
      "2019-10-29 00:47:05,855 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:05,859 : INFO : built Dictionary(274 unique tokens: ['although', 'miracle', 'energy', 'superior', 'de']...) from 5 documents (total 1805 corpus positions)\n",
      "2019-10-29 00:47:05,862 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:05,864 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:05,865 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:05,869 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:05,870 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:05,966 : INFO : -7.905 per-word bound, 239.7 perplexity estimate based on a held-out corpus of 5 documents with 1805 words\n",
      "2019-10-29 00:47:05,968 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:05,976 : INFO : topic #3 (0.100): 0.045*\"design\" + 0.016*\"designer\" + 0.016*\"world\" + 0.011*\"consumer\" + 0.009*\"first\" + 0.009*\"invention\" + 0.008*\"good\" + 0.008*\"thing\" + 0.008*\"may\" + 0.008*\"u\"\n",
      "2019-10-29 00:47:05,978 : INFO : topic #0 (0.100): 0.045*\"design\" + 0.016*\"world\" + 0.012*\"designer\" + 0.011*\"consumer\" + 0.010*\"thing\" + 0.010*\"designed\" + 0.009*\"u\" + 0.008*\"mean\" + 0.008*\"first\" + 0.008*\"word\"\n",
      "2019-10-29 00:47:05,980 : INFO : topic #7 (0.100): 0.037*\"design\" + 0.021*\"world\" + 0.012*\"designer\" + 0.011*\"thing\" + 0.010*\"consumer\" + 0.009*\"first\" + 0.009*\"say\" + 0.008*\"designed\" + 0.008*\"mean\" + 0.008*\"contemporary\"\n",
      "2019-10-29 00:47:05,981 : INFO : topic #1 (0.100): 0.063*\"design\" + 0.016*\"world\" + 0.012*\"thing\" + 0.011*\"designer\" + 0.008*\"may\" + 0.008*\"consumer\" + 0.008*\"word\" + 0.008*\"u\" + 0.008*\"invention\" + 0.008*\"mean\"\n",
      "2019-10-29 00:47:05,983 : INFO : topic #8 (0.100): 0.051*\"design\" + 0.015*\"world\" + 0.012*\"thing\" + 0.011*\"designer\" + 0.010*\"good\" + 0.009*\"contemporary\" + 0.009*\"made\" + 0.009*\"u\" + 0.008*\"word\" + 0.008*\"consumer\"\n",
      "2019-10-29 00:47:05,985 : INFO : topic diff=0.748529, rho=1.000000\n",
      "2019-10-29 00:47:06,386 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:06,389 : INFO : built Dictionary(14 unique tokens: ['actor', 'unfolds', 'facebook', 'messenger', 'happening']...) from 5 documents (total 70 corpus positions)\n",
      "2019-10-29 00:47:06,390 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:06,392 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:06,397 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:06,400 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:06,403 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:06,416 : INFO : -6.425 per-word bound, 85.9 perplexity estimate based on a held-out corpus of 5 documents with 70 words\n",
      "2019-10-29 00:47:06,420 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:06,426 : INFO : topic #2 (0.100): 0.082*\"movie\" + 0.081*\"u\" + 0.080*\"world\" + 0.077*\"police\" + 0.076*\"happening\" + 0.074*\"facebook\" + 0.073*\"take\" + 0.071*\"shot\" + 0.071*\"messenger\" + 0.068*\"actor\"\n",
      "2019-10-29 00:47:06,429 : INFO : topic #6 (0.100): 0.091*\"set\" + 0.086*\"shot\" + 0.084*\"messenger\" + 0.078*\"police\" + 0.073*\"facebook\" + 0.070*\"unfolds\" + 0.068*\"take\" + 0.067*\"happening\" + 0.066*\"world\" + 0.065*\"actor\"\n",
      "2019-10-29 00:47:06,432 : INFO : topic #5 (0.100): 0.093*\"u\" + 0.092*\"happening\" + 0.088*\"messenger\" + 0.078*\"police\" + 0.077*\"find\" + 0.075*\"unfolds\" + 0.071*\"set\" + 0.071*\"world\" + 0.069*\"actor\" + 0.066*\"movie\"\n",
      "2019-10-29 00:47:06,435 : INFO : topic #9 (0.100): 0.092*\"facebook\" + 0.084*\"police\" + 0.083*\"movie\" + 0.082*\"find\" + 0.075*\"world\" + 0.072*\"u\" + 0.068*\"actor\" + 0.067*\"shot\" + 0.067*\"messenger\" + 0.064*\"set\"\n",
      "2019-10-29 00:47:06,438 : INFO : topic #3 (0.100): 0.088*\"unfolds\" + 0.084*\"find\" + 0.082*\"chat\" + 0.077*\"movie\" + 0.074*\"actor\" + 0.074*\"police\" + 0.069*\"shot\" + 0.069*\"u\" + 0.068*\"world\" + 0.067*\"set\"\n",
      "2019-10-29 00:47:06,441 : INFO : topic diff=0.506924, rho=1.000000\n",
      "2019-10-29 00:47:06,918 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:06,925 : INFO : built Dictionary(283 unique tokens: ['forward', 'let', 'story', 'deep', 'sochi']...) from 5 documents (total 3080 corpus positions)\n",
      "2019-10-29 00:47:06,930 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:06,932 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:06,935 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:06,938 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:06,940 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:07,042 : INFO : -7.242 per-word bound, 151.3 perplexity estimate based on a held-out corpus of 5 documents with 3080 words\n",
      "2019-10-29 00:47:07,044 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:07,052 : INFO : topic #5 (0.100): 0.025*\"danelle\" + 0.025*\"life\" + 0.024*\"skier\" + 0.023*\"rob\" + 0.022*\"put\" + 0.022*\"husband\" + 0.016*\"blind\" + 0.015*\"sport\" + 0.014*\"vision\" + 0.014*\"winter\"\n",
      "2019-10-29 00:47:07,054 : INFO : topic #7 (0.100): 0.029*\"life\" + 0.028*\"said\" + 0.020*\"danelle\" + 0.020*\"rob\" + 0.019*\"husband\" + 0.018*\"caption\" + 0.017*\"hand\" + 0.015*\"blind\" + 0.015*\"vision\" + 0.015*\"put\"\n",
      "2019-10-29 00:47:07,056 : INFO : topic #1 (0.100): 0.026*\"life\" + 0.026*\"said\" + 0.023*\"rob\" + 0.021*\"skier\" + 0.020*\"danelle\" + 0.019*\"photo\" + 0.016*\"husband\" + 0.015*\"hide\" + 0.014*\"put\" + 0.014*\"skiing\"\n",
      "2019-10-29 00:47:07,059 : INFO : topic #9 (0.100): 0.028*\"life\" + 0.024*\"husband\" + 0.024*\"said\" + 0.022*\"rob\" + 0.019*\"put\" + 0.017*\"danelle\" + 0.017*\"hand\" + 0.017*\"skiing\" + 0.014*\"photo\" + 0.013*\"blind\"\n",
      "2019-10-29 00:47:07,061 : INFO : topic #0 (0.100): 0.028*\"life\" + 0.025*\"rob\" + 0.021*\"danelle\" + 0.021*\"said\" + 0.020*\"husband\" + 0.017*\"put\" + 0.015*\"blind\" + 0.015*\"umstead\" + 0.015*\"hide\" + 0.014*\"photo\"\n",
      "2019-10-29 00:47:07,063 : INFO : topic diff=1.024529, rho=1.000000\n",
      "2019-10-29 00:47:07,486 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:07,487 : INFO : built Dictionary(17 unique tokens: ['claim', 'harvey', 'weinstein', 'harassed', 'journalist']...) from 5 documents (total 90 corpus positions)\n",
      "2019-10-29 00:47:07,489 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:07,490 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:07,491 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:07,493 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:07,494 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:07,509 : INFO : -6.342 per-word bound, 81.1 perplexity estimate based on a held-out corpus of 5 documents with 90 words\n",
      "2019-10-29 00:47:07,510 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:07,516 : INFO : topic #0 (0.100): 0.114*\"weinstein\" + 0.071*\"journalist\" + 0.067*\"reporter\" + 0.063*\"lauren\" + 0.061*\"mogul\" + 0.061*\"harassed\" + 0.059*\"knew\" + 0.055*\"sexual\" + 0.054*\"say\" + 0.054*\"claim\"\n",
      "2019-10-29 00:47:07,517 : INFO : topic #1 (0.100): 0.095*\"weinstein\" + 0.070*\"exactly\" + 0.065*\"reporter\" + 0.064*\"claim\" + 0.064*\"sexually\" + 0.062*\"say\" + 0.057*\"sexual\" + 0.057*\"mogul\" + 0.057*\"harvey\" + 0.055*\"advance\"\n",
      "2019-10-29 00:47:07,519 : INFO : topic #9 (0.100): 0.104*\"weinstein\" + 0.070*\"sexually\" + 0.070*\"sivan\" + 0.065*\"hollywood\" + 0.063*\"lauren\" + 0.061*\"harvey\" + 0.059*\"exactly\" + 0.057*\"advance\" + 0.056*\"mogul\" + 0.054*\"accuses\"\n",
      "2019-10-29 00:47:07,521 : INFO : topic #6 (0.100): 0.110*\"weinstein\" + 0.071*\"sivan\" + 0.068*\"advance\" + 0.065*\"sexual\" + 0.063*\"journalist\" + 0.059*\"knew\" + 0.059*\"hollywood\" + 0.058*\"accuses\" + 0.056*\"harvey\" + 0.053*\"mogul\"\n",
      "2019-10-29 00:47:07,522 : INFO : topic #7 (0.100): 0.100*\"weinstein\" + 0.076*\"harassed\" + 0.062*\"hollywood\" + 0.061*\"lauren\" + 0.060*\"say\" + 0.059*\"harvey\" + 0.059*\"journalist\" + 0.057*\"mogul\" + 0.057*\"accuses\" + 0.056*\"sivan\"\n",
      "2019-10-29 00:47:07,524 : INFO : topic diff=0.575754, rho=1.000000\n",
      "2019-10-29 00:47:07,937 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:07,938 : INFO : built Dictionary(18 unique tokens: ['square', 'agree', 'privacy', 'love', 'time']...) from 5 documents (total 95 corpus positions)\n",
      "2019-10-29 00:47:07,939 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:07,941 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:07,942 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:07,949 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:07,952 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:07,975 : INFO : -6.376 per-word bound, 83.1 perplexity estimate based on a held-out corpus of 5 documents with 95 words\n",
      "2019-10-29 00:47:07,978 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:07,983 : INFO : topic #2 (0.100): 0.111*\"cooky\" + 0.066*\"agree\" + 0.058*\"love\" + 0.058*\"photo\" + 0.056*\"use\" + 0.056*\"site\" + 0.055*\"local\" + 0.055*\"browse\" + 0.055*\"even\" + 0.054*\"square\"\n",
      "2019-10-29 00:47:07,986 : INFO : topic #6 (0.100): 0.096*\"cooky\" + 0.066*\"site\" + 0.060*\"time\" + 0.060*\"use\" + 0.058*\"local\" + 0.056*\"even\" + 0.056*\"browse\" + 0.055*\"love\" + 0.054*\"agree\" + 0.052*\"policy\"\n",
      "2019-10-29 00:47:07,989 : INFO : topic #8 (0.100): 0.093*\"cooky\" + 0.061*\"revised\" + 0.060*\"service\" + 0.059*\"square\" + 0.059*\"privacy\" + 0.057*\"time\" + 0.057*\"agree\" + 0.056*\"love\" + 0.055*\"term\" + 0.053*\"browse\"\n",
      "2019-10-29 00:47:07,992 : INFO : topic #0 (0.100): 0.109*\"cooky\" + 0.063*\"agree\" + 0.061*\"service\" + 0.060*\"policy\" + 0.060*\"browse\" + 0.057*\"site\" + 0.057*\"love\" + 0.056*\"use\" + 0.054*\"even\" + 0.052*\"photo\"\n",
      "2019-10-29 00:47:07,996 : INFO : topic #5 (0.100): 0.113*\"cooky\" + 0.063*\"privacy\" + 0.060*\"even\" + 0.059*\"continuing\" + 0.059*\"local\" + 0.058*\"time\" + 0.056*\"square\" + 0.056*\"policy\" + 0.053*\"service\" + 0.052*\"photo\"\n",
      "2019-10-29 00:47:07,999 : INFO : topic diff=0.566128, rho=1.000000\n",
      "2019-10-29 00:47:08,430 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2019-10-29 00:47:08,435 : INFO : built Dictionary(300 unique tokens: ['although', 'retreat', 'part', 'joint', 'come']...) from 5 documents (total 2320 corpus positions)\n",
      "2019-10-29 00:47:08,440 : INFO : using symmetric alpha at 0.1\n",
      "2019-10-29 00:47:08,442 : INFO : using symmetric eta at 0.1\n",
      "2019-10-29 00:47:08,444 : INFO : using serial LDA version on this node\n",
      "2019-10-29 00:47:08,449 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 5 documents, updating model once every 5 documents, evaluating perplexity every 5 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2019-10-29 00:47:08,451 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2019-10-29 00:47:08,577 : INFO : -7.734 per-word bound, 212.9 perplexity estimate based on a held-out corpus of 5 documents with 2320 words\n",
      "2019-10-29 00:47:08,579 : INFO : PROGRESS: pass 0, at document #5/5\n",
      "2019-10-29 00:47:08,587 : INFO : topic #6 (0.100): 0.031*\"party\" + 0.025*\"merkel\" + 0.015*\"refugee\" + 0.015*\"limit\" + 0.013*\"afd\" + 0.013*\"germany\" + 0.012*\"right\" + 0.012*\"number\" + 0.011*\"election\" + 0.009*\"seehofer\"\n",
      "2019-10-29 00:47:08,589 : INFO : topic #0 (0.100): 0.023*\"party\" + 0.022*\"merkel\" + 0.019*\"refugee\" + 0.017*\"limit\" + 0.013*\"germany\" + 0.011*\"number\" + 0.010*\"monday\" + 0.010*\"afd\" + 0.010*\"policy\" + 0.010*\"right\"\n",
      "2019-10-29 00:47:08,592 : INFO : topic #7 (0.100): 0.029*\"merkel\" + 0.026*\"party\" + 0.021*\"refugee\" + 0.016*\"limit\" + 0.013*\"germany\" + 0.013*\"number\" + 0.012*\"election\" + 0.012*\"afd\" + 0.011*\"position\" + 0.010*\"seehofer\"\n",
      "2019-10-29 00:47:08,595 : INFO : topic #2 (0.100): 0.024*\"party\" + 0.019*\"limit\" + 0.019*\"merkel\" + 0.016*\"refugee\" + 0.015*\"germany\" + 0.012*\"afd\" + 0.012*\"seehofer\" + 0.011*\"position\" + 0.011*\"right\" + 0.009*\"election\"\n",
      "2019-10-29 00:47:08,598 : INFO : topic #4 (0.100): 0.029*\"merkel\" + 0.021*\"refugee\" + 0.021*\"party\" + 0.015*\"number\" + 0.014*\"afd\" + 0.012*\"limit\" + 0.011*\"germany\" + 0.010*\"right\" + 0.010*\"election\" + 0.010*\"two\"\n",
      "2019-10-29 00:47:08,600 : INFO : topic diff=0.826825, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(data)):\n",
    "    result1, result2 = LDA_modul(i)\n",
    "    data['PREDICT_KEYWORDS_PROB'][i] = result1\n",
    "    data['PREDICT_KEYWORDS'][i] = result2\n",
    "    data['HASHTAG'][i] = '#'+' #'.join(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>KEYWORDS</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>ALL_TEXT</th>\n",
       "      <th>PREDICT_KEYWORDS_PROB</th>\n",
       "      <th>PREDICT_KEYWORDS</th>\n",
       "      <th>HASHTAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['energy', 'sugars', 'bars', 'grams', 'syrup',...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Story highlights Don't be fooled by the word \"...</td>\n",
       "      <td>Are energy bars healthy?</td>\n",
       "      <td>https://www.cnn.com/2017/08/25/health/energy-b...</td>\n",
       "      <td>Are energy bars healthy? Story highlights Don'...</td>\n",
       "      <td>[(bar, 0.08965786), (energy, 0.03715309), (sat...</td>\n",
       "      <td>[bar, energy, saturated, fat, sugar, others, c...</td>\n",
       "      <td>#bar #energy #saturated #fat #sugar #others #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['facebook', 'whats', 'world', 'unfolds', 'tam...</td>\n",
       "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>Tamagotchi is back</td>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/10/...</td>\n",
       "      <td>Tamagotchi is back Chat with us in Facebook Me...</td>\n",
       "      <td>[(unfolds, 0.114573814), (find, 0.10926961), (...</td>\n",
       "      <td>[unfolds, find, tamagotchi, happening, messeng...</td>\n",
       "      <td>#unfolds #find #tamagotchi #happening #messeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['jedi', 'shots', 'rey', 'force', 'wars', 'sta...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>ESPN's \"Monday Night Football\" had bears, viki...</td>\n",
       "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
       "      <td>http://money.cnn.com/2017/10/09/media/star-war...</td>\n",
       "      <td>'Star Wars: The Last Jedi' trailer debuts on '...</td>\n",
       "      <td>[(trailer, 0.039500866), (war, 0.03303859), (s...</td>\n",
       "      <td>[trailer, war, star, rey, new, jedi, monday, n...</td>\n",
       "      <td>#trailer #war #star #rey #new #jedi #monday #n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>['clients', 'art', 'science', 'scent', 'collid...</td>\n",
       "      <td>Lyn Harris' independent space, Perfumer H , in...</td>\n",
       "      <td>This feature is part of ' Details ,' a new ser...</td>\n",
       "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
       "      <td>https://www.cnn.com/style/article/details-perf...</td>\n",
       "      <td>Art and science collide in this one-of-a-kind ...</td>\n",
       "      <td>[(harris, 0.048846304), (scent, 0.047987834), ...</td>\n",
       "      <td>[harris, scent, perfumer, art, perfume, one, c...</td>\n",
       "      <td>#harris #scent #perfumer #art #perfume #one #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>['akufoaddo', 'tanker', 'incidents', 'dozens',...</td>\n",
       "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
       "      <td>(CNN) A tanker exploded near a gas station in ...</td>\n",
       "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
       "      <td>https://www.cnn.com/2017/10/08/africa/ghana-ta...</td>\n",
       "      <td>Seven killed, dozens injured in Ghana tanker e...</td>\n",
       "      <td>[(said, 0.04211693), (incident, 0.037273165), ...</td>\n",
       "      <td>[said, incident, ghana, gas, addo, ensure, sev...</td>\n",
       "      <td>#said #incident #ghana #gas #addo #ensure #sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['spanish', 'independence', 'regions', 'meets'...</td>\n",
       "      <td>Carles Puigdemont, the President of Catalonia,...</td>\n",
       "      <td>(CNN) Pro-independence Catalans gathered on th...</td>\n",
       "      <td>Catalans' future on line as parliament meets</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/europe/cataloni...</td>\n",
       "      <td>Catalans' future on line as parliament meets (...</td>\n",
       "      <td>[(catalonia, 0.026233945), (independence, 0.02...</td>\n",
       "      <td>[catalonia, independence, said, spain, catalan...</td>\n",
       "      <td>#catalonia #independence #said #spain #catalan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['press', 'excuse', 'secretary', 'trump', 'hou...</td>\n",
       "      <td>\"I think it's fake news, but if he did that, I...</td>\n",
       "      <td>(CNN) In a Forbes magazine interview published...</td>\n",
       "      <td>The Trump White House's 'joke' excuse</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/politics/trump-j...</td>\n",
       "      <td>The Trump White House's 'joke' excuse (CNN) In...</td>\n",
       "      <td>[(iq, 0.03915731), (tillerson, 0.03371939), (t...</td>\n",
       "      <td>[iq, tillerson, trump, joke, president, know, ...</td>\n",
       "      <td>#iq #tillerson #trump #joke #president #know #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['pollution', 'repeal', 'kellogg', 'asthma', '...</td>\n",
       "      <td>President Barak Obama shakes Camryn Kellogg's ...</td>\n",
       "      <td>(CNN) The days when all three of her children ...</td>\n",
       "      <td>Health impact of Trump environmental repeal</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/health/health-e...</td>\n",
       "      <td>Health impact of Trump environmental repeal (C...</td>\n",
       "      <td>[(kellogg, 0.0209633), (power, 0.018572563), (...</td>\n",
       "      <td>[kellogg, power, air, said, child, asthma, yea...</td>\n",
       "      <td>#kellogg #power #air #said #child #asthma #yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['look', 'response', 'force', 'trump', 'tour',...</td>\n",
       "      <td>(CNN) Finally lumbering into a devastated Puer...</td>\n",
       "      <td>Michael D'Antonio is the author of the book \" ...</td>\n",
       "      <td>Trump in Puerto Rico: A narcissist's tour de f...</td>\n",
       "      <td>https://www.cnn.com/2017/10/03/opinions/trump-...</td>\n",
       "      <td>Trump in Puerto Rico: A narcissist's tour de f...</td>\n",
       "      <td>[(trump, 0.023573738), (said, 0.019111894), (p...</td>\n",
       "      <td>[trump, said, president, rico, puerto, reality...</td>\n",
       "      <td>#trump #said #president #rico #puerto #reality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['okunoin', 'tohoku', 'japan', 'risshakuji', '...</td>\n",
       "      <td>(CNN) — Upon hearing I would have to climb 1,0...</td>\n",
       "      <td>\\n\\n\\n\\nThis article was first published in Ju...</td>\n",
       "      <td>Yamadera Risshakuji in Tohoku: 1,015 steps to ...</td>\n",
       "      <td>https://www.cnn.com/travel/article/yamadera-te...</td>\n",
       "      <td>Yamadera Risshakuji in Tohoku: 1,015 steps to ...</td>\n",
       "      <td>[(temple, 0.034045555), (yamadera, 0.028016137...</td>\n",
       "      <td>[temple, yamadera, station, hall, japan, rissh...</td>\n",
       "      <td>#temple #yamadera #station #hall #japan #rissh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>['land', 'life', 'purchased', 'doug', 'wonder'...</td>\n",
       "      <td>Doug Tompkins and Kristine McDivitt should hav...</td>\n",
       "      <td>Catch \"The Wonder List\" on CNN Saturdays at 9 ...</td>\n",
       "      <td>They purchased paradise ... then gave it all away</td>\n",
       "      <td>http://www.cnn.com/travel/article/wonder-list-...</td>\n",
       "      <td>They purchased paradise ... then gave it all a...</td>\n",
       "      <td>[(tompkins, 0.025351323), (doug, 0.024204291),...</td>\n",
       "      <td>[tompkins, doug, kris, chile, national, south,...</td>\n",
       "      <td>#tompkins #doug #kris #chile #national #south ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>['kids', 'parental', 'really', 'husband', 'ste...</td>\n",
       "      <td>I'm not sure I needed a study to tell me paren...</td>\n",
       "      <td>Kelly Wallace is CNN's digital correspondent a...</td>\n",
       "      <td>Parental burnout: It's really a thing</td>\n",
       "      <td>https://www.cnn.com/2017/05/09/health/parentin...</td>\n",
       "      <td>Parental burnout: It's really a thing Kelly Wa...</td>\n",
       "      <td>[(parent, 0.023723198), (said, 0.01947476), (b...</td>\n",
       "      <td>[parent, said, burnout, mom, need, time, day, ...</td>\n",
       "      <td>#parent #said #burnout #mom #need #time #day #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>['kids', 'television', 'impacts', 'drink', 'ad...</td>\n",
       "      <td>What they found is those underage drinkers who...</td>\n",
       "      <td>Kelly Wallace is CNN's digital correspondent a...</td>\n",
       "      <td>How alcohol advertising impacts underage drinking</td>\n",
       "      <td>https://www.cnn.com/2016/09/07/health/kids-alc...</td>\n",
       "      <td>How alcohol advertising impacts underage drink...</td>\n",
       "      <td>[(alcohol, 0.041508775), (drink, 0.022976939),...</td>\n",
       "      <td>[alcohol, drink, said, study, advertising, und...</td>\n",
       "      <td>#alcohol #drink #said #study #advertising #und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>['kids', 'ferrara', 'way', 'thats', 'ah', 'say...</td>\n",
       "      <td>\"I always say to parents ... you've got to sto...</td>\n",
       "      <td>(CNN) Most parents have experienced it: that m...</td>\n",
       "      <td>Ah! My kid is having a tantrum, and I want to ...</td>\n",
       "      <td>https://www.cnn.com/2017/10/04/health/tantrums...</td>\n",
       "      <td>Ah! My kid is having a tantrum, and I want to ...</td>\n",
       "      <td>[(said, 0.025185507), (kid, 0.020834466), (par...</td>\n",
       "      <td>[said, kid, parent, child, tantrum, going, go,...</td>\n",
       "      <td>#said #kid #parent #child #tantrum #going #go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>['congress', 'issue', 'trump', 'women', 'calls...</td>\n",
       "      <td>Story highlights Ivanka Trump attends Fortune'...</td>\n",
       "      <td>Story highlights Ivanka Trump attends Fortune'...</td>\n",
       "      <td>Ivanka Trump calls on Congress to act on immig...</td>\n",
       "      <td>https://www.cnn.com/2017/10/09/politics/ivanka...</td>\n",
       "      <td>Ivanka Trump calls on Congress to act on immig...</td>\n",
       "      <td>[(trump, 0.037142996), (ivanka, 0.025149425), ...</td>\n",
       "      <td>[trump, ivanka, immigration, issue, program, a...</td>\n",
       "      <td>#trump #ivanka #immigration #issue #program #a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>['partner', 'men', 'low', 'interest', 'women',...</td>\n",
       "      <td>Story highlights Low desire in one partner is ...</td>\n",
       "      <td>Story highlights Low desire in one partner is ...</td>\n",
       "      <td>When you and your partner have mismatched libidos</td>\n",
       "      <td>https://www.cnn.com/2017/09/21/health/mismatch...</td>\n",
       "      <td>When you and your partner have mismatched libi...</td>\n",
       "      <td>[(sex, 0.03935628), (partner, 0.0274307), (des...</td>\n",
       "      <td>[sex, partner, desire, men, one, interest, due...</td>\n",
       "      <td>#sex #partner #desire #men #one #interest #due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>['hes', 'music', 'seattle', 'working', 'world'...</td>\n",
       "      <td>(CNN) When Jay Park became one of the first an...</td>\n",
       "      <td>(CNN) When Jay Park became one of the first an...</td>\n",
       "      <td>Jay Park: from K-pop to Jay-Z</td>\n",
       "      <td>https://www.cnn.com/2017/10/08/asia/jay-park-j...</td>\n",
       "      <td>Jay Park: from K-pop to Jay-Z (CNN) When Jay P...</td>\n",
       "      <td>[(park, 0.04657846), (jay, 0.019225657), (said...</td>\n",
       "      <td>[park, jay, said, asia, seattle, music, pop, b...</td>\n",
       "      <td>#park #jay #said #asia #seattle #music #pop #b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>['plywoods', 'veneer', 'role', 'wood', 'shapin...</td>\n",
       "      <td>This exhibition, \"Plywood: Material of the Mod...</td>\n",
       "      <td>Written by Tom Morris, CNN London\\n\\nChristoph...</td>\n",
       "      <td>Plywood's surprising role in shaping our moder...</td>\n",
       "      <td>https://www.cnn.com/style/article/plywood-mate...</td>\n",
       "      <td>Plywood's surprising role in shaping our moder...</td>\n",
       "      <td>[(plywood, 0.03466115), (material, 0.018155685...</td>\n",
       "      <td>[plywood, material, wilk, veneer, world, say, ...</td>\n",
       "      <td>#plywood #material #wilk #veneer #world #say #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>['men', 'results', 'users', 'way', 'test', 'ki...</td>\n",
       "      <td>Story highlights The app Grindr is an effectiv...</td>\n",
       "      <td>Story highlights The app Grindr is an effectiv...</td>\n",
       "      <td>How Grindr got men to self-test for HIV</td>\n",
       "      <td>https://www.cnn.com/2016/07/25/health/grindr-h...</td>\n",
       "      <td>How Grindr got men to self-test for HIV Story ...</td>\n",
       "      <td>[(test, 0.054868255), (hiv, 0.032611907), (stu...</td>\n",
       "      <td>[test, hiv, study, grindr, kit, men, risk, get...</td>\n",
       "      <td>#test #hiv #study #grindr #kit #men #risk #get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>['according', 'boundaries', 'generations', 'ac...</td>\n",
       "      <td>\"The only generation we do define is Baby Boom...</td>\n",
       "      <td>We can all agree that Millennials are the wors...</td>\n",
       "      <td>Here Is When Each Generation Begins and Ends, ...</td>\n",
       "      <td>http://www.theatlantic.com/national/archive/20...</td>\n",
       "      <td>Here Is When Each Generation Begins and Ends, ...</td>\n",
       "      <td>[(generation, 0.035122823), (time, 0.019235069...</td>\n",
       "      <td>[generation, time, millennials, year, diprete,...</td>\n",
       "      <td>#generation #time #millennials #year #diprete ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>['hollywood', 'women', 'comments', 'player', '...</td>\n",
       "      <td>Designer Donna Karan has apologized for the re...</td>\n",
       "      <td>Designer Donna Karan has apologized for the re...</td>\n",
       "      <td>Donna Karan apologizes for Weinstein comments</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Donna Karan apologizes for Weinstein comments ...</td>\n",
       "      <td>[(donna, 0.09000902), (weinstein, 0.07725886),...</td>\n",
       "      <td>[donna, weinstein, karan, remark, scandal, pla...</td>\n",
       "      <td>#donna #weinstein #karan #remark #scandal #pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>['reckoned', 'history', 'past', 'nazi', 'confe...</td>\n",
       "      <td>(CNN) When it comes to Confederate monuments a...</td>\n",
       "      <td>(CNN) When it comes to Confederate monuments a...</td>\n",
       "      <td>Fareed Zakaria: US could learn from how German...</td>\n",
       "      <td>https://www.cnn.com/2017/08/20/us/fareed-zakar...</td>\n",
       "      <td>Fareed Zakaria: US could learn from how German...</td>\n",
       "      <td>[(zakaria, 0.031084336), (germany, 0.030595995...</td>\n",
       "      <td>[zakaria, germany, said, country, memorial, am...</td>\n",
       "      <td>#zakaria #germany #said #country #memorial #am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>['online', 'responsible', 'really', 'technolog...</td>\n",
       "      <td>James and Alexa Hirschfeld's successful online...</td>\n",
       "      <td>James and Alexa Hirschfeld's successful online...</td>\n",
       "      <td>Paperless Post founder's technology helps get ...</td>\n",
       "      <td>http://money.cnn.com/2017/10/04/technology/bus...</td>\n",
       "      <td>Paperless Post founder's technology helps get ...</td>\n",
       "      <td>[(said, 0.026316134), (company, 0.023529049), ...</td>\n",
       "      <td>[said, company, people, paperless, post, techn...</td>\n",
       "      <td>#said #company #people #paperless #post #techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>['important', 'cheeses', 'healthy', 'nutrients...</td>\n",
       "      <td>Story highlights Cheese contains important nut...</td>\n",
       "      <td>Story highlights Cheese contains important nut...</td>\n",
       "      <td>Is cheese healthy?</td>\n",
       "      <td>https://www.cnn.com/2017/09/25/health/cheese-h...</td>\n",
       "      <td>Is cheese healthy? Story highlights Cheese con...</td>\n",
       "      <td>[(calorie, 0.078114584), (cheese, 0.05672102),...</td>\n",
       "      <td>[calorie, cheese, ounce, nutrient, one, choles...</td>\n",
       "      <td>#calorie #cheese #ounce #nutrient #one #choles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>['planet', 'book', 'degrees', 'science', 'must...</td>\n",
       "      <td>(CNN) \"Climate change is the canvas on which t...</td>\n",
       "      <td>CNN columnist John D. Sutter is spending the r...</td>\n",
       "      <td>Books: 12 must-reads on climate change (2 degr...</td>\n",
       "      <td>https://www.cnn.com/2015/05/19/opinions/sutter...</td>\n",
       "      <td>Books: 12 must-reads on climate change (2 degr...</td>\n",
       "      <td>[(climate, 0.03034277), (degree, 0.024460034),...</td>\n",
       "      <td>[climate, degree, book, change, lynas, world, ...</td>\n",
       "      <td>#climate #degree #book #change #lynas #world #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>['james', 'release', 'thought', 'think', 'w', ...</td>\n",
       "      <td>If you thought you were getting your hands on ...</td>\n",
       "      <td>If you thought you were getting your hands on ...</td>\n",
       "      <td>Whataburger sells out of James Avery charm hou...</td>\n",
       "      <td>http://cw33.com/2017/10/10/whataburger-and-jam...</td>\n",
       "      <td>Whataburger sells out of James Avery charm hou...</td>\n",
       "      <td>[(charm, 0.09363935), (james, 0.05903045), (av...</td>\n",
       "      <td>[charm, james, avery, whataburger, release, on...</td>\n",
       "      <td>#charm #james #avery #whataburger #release #on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>['planned', 'fetus', 'videos', 'center', 'abor...</td>\n",
       "      <td>Abortion photo actually stillborn childThe pho...</td>\n",
       "      <td>Costa Mesa, California (CNN) David Daleiden wa...</td>\n",
       "      <td>The real story behind those Planned Parenthood...</td>\n",
       "      <td>https://www.cnn.com/2015/10/19/politics/planne...</td>\n",
       "      <td>The real story behind those Planned Parenthood...</td>\n",
       "      <td>[(planned, 0.036541793), (parenthood, 0.029388...</td>\n",
       "      <td>[planned, parenthood, video, daleiden, fetus, ...</td>\n",
       "      <td>#planned #parenthood #video #daleiden #fetus #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>['rovers', 'hide', 'image', 'opinion', 'camera...</td>\n",
       "      <td>Photos: Mars rover Curiosity Five years ago an...</td>\n",
       "      <td>Photos: Mars rover Curiosity Five years ago an...</td>\n",
       "      <td>Is it ethical to colonize Mars? (Opinion)</td>\n",
       "      <td>https://www.cnn.com/2015/10/15/opinions/green-...</td>\n",
       "      <td>Is it ethical to colonize Mars? (Opinion) Phot...</td>\n",
       "      <td>[(rover, 0.08781761), (mar, 0.067004286), (cur...</td>\n",
       "      <td>[rover, mar, curiosity, hide, caption, photo, ...</td>\n",
       "      <td>#rover #mar #curiosity #hide #caption #photo #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>['house', 'mary', 'danish', 'prince', 'giant',...</td>\n",
       "      <td>(CNN) — Get ready to embrace your inner child ...</td>\n",
       "      <td>(CNN) — Get ready to embrace your inner child ...</td>\n",
       "      <td>Inside Denmark's giant LEGO house</td>\n",
       "      <td>https://www.cnn.com/travel/article/lego-house-...</td>\n",
       "      <td>Inside Denmark's giant LEGO house (CNN) — Get ...</td>\n",
       "      <td>[(lego, 0.07634535), (house, 0.06144317), (den...</td>\n",
       "      <td>[lego, house, denmark, skill, four, brick, cre...</td>\n",
       "      <td>#lego #house #denmark #skill #four #brick #cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>['im', 'stinks', 'economic', 'whites', 'white'...</td>\n",
       "      <td>Those are some of the reasons why working clas...</td>\n",
       "      <td>Social Security is running out of money. Ameri...</td>\n",
       "      <td>The economy stinks, but I'm doing OK, say work...</td>\n",
       "      <td>http://money.cnn.com/2016/09/23/news/economy/w...</td>\n",
       "      <td>The economy stinks, but I'm doing OK, say work...</td>\n",
       "      <td>[(working, 0.02298514), (white, 0.0224862), (c...</td>\n",
       "      <td>[working, white, class, said, economy, feel, c...</td>\n",
       "      <td>#working #white #class #said #economy #feel #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>['queen', 'wrong', 'denchs', 'motives', 'goes'...</td>\n",
       "      <td>(CNN) Even taking acknowledged liberties with ...</td>\n",
       "      <td>(CNN) Even taking acknowledged liberties with ...</td>\n",
       "      <td>'Victoria &amp; Abdul' goes skin-deep on great story</td>\n",
       "      <td>https://www.cnn.com/2017/09/22/entertainment/v...</td>\n",
       "      <td>'Victoria &amp; Abdul' goes skin-deep on great sto...</td>\n",
       "      <td>[(abdul, 0.025936889), (queen, 0.02516271), (m...</td>\n",
       "      <td>[abdul, queen, movie, victoria, dench, story, ...</td>\n",
       "      <td>#abdul #queen #movie #victoria #dench #story #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>['page', 'updated', 'specific', 'transcripts',...</td>\n",
       "      <td>Return to Transcripts main pageCNN Transcripts...</td>\n",
       "      <td>\\n\\n\\n\\nReturn to Transcripts main page\\n\\nCNN...</td>\n",
       "      <td>Transcripts</td>\n",
       "      <td>https://www.cnn.com/TRANSCRIPTS/2017.10.04.html</td>\n",
       "      <td>Transcripts \\n\\n\\n\\nReturn to Transcripts main...</td>\n",
       "      <td>[(transcript, 0.18240282), (page, 0.079834886)...</td>\n",
       "      <td>[transcript, page, note, continually, become, ...</td>\n",
       "      <td>#transcript #page #note #continually #become #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>['aunts', 'hefner', 'jennifer', 'men', 'role',...</td>\n",
       "      <td>Story highlights Rebecca Jackson-Artis: My aun...</td>\n",
       "      <td>Story highlights Rebecca Jackson-Artis: My aun...</td>\n",
       "      <td>Playboy's role in creating strong black women</td>\n",
       "      <td>https://www.cnn.com/2017/10/07/opinions/race-s...</td>\n",
       "      <td>Playboy's role in creating strong black women ...</td>\n",
       "      <td>[(aunt, 0.028325772), (black, 0.02813462), (pl...</td>\n",
       "      <td>[aunt, black, playboy, woman, jennifer, revolu...</td>\n",
       "      <td>#aunt #black #playboy #woman #jennifer #revolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>['online', 'farm', 'crowd', 'buying', 'investo...</td>\n",
       "      <td>(CNN) For $1,000 you can be the proud owner of...</td>\n",
       "      <td>Story highlights Livestock Wealth \"crowd farms...</td>\n",
       "      <td>Cash cows: Why investors are buying pregnant c...</td>\n",
       "      <td>https://www.cnn.com/2017/05/01/africa/livestoc...</td>\n",
       "      <td>Cash cows: Why investors are buying pregnant c...</td>\n",
       "      <td>[(farm, 0.03942887), (investor, 0.038357016), ...</td>\n",
       "      <td>[farm, investor, cow, south, stock, africa, li...</td>\n",
       "      <td>#farm #investor #cow #south #stock #africa #li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>['kids', 'crooks', 'steal', 'van', 'school', '...</td>\n",
       "      <td>Recently, crooks went after one the vans' tank...</td>\n",
       "      <td>Omaha,Neb(FOX42KPTM)-Kids Can Community Center...</td>\n",
       "      <td>Crooks steal something valuable from a daycare...</td>\n",
       "      <td>http://fox42kptm.com/news/local/crooks-steal-s...</td>\n",
       "      <td>Crooks steal something valuable from a daycare...</td>\n",
       "      <td>[(van, 0.08062484), (gas, 0.04352283), (kid, 0...</td>\n",
       "      <td>[van, gas, kid, one, said, omaha, get, crook, ...</td>\n",
       "      <td>#van #gas #kid #one #said #omaha #get #crook #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>['island', 'past', 'residents', 'farming', 'sa...</td>\n",
       "      <td>When this opportunity came up, he joined Jerom...</td>\n",
       "      <td>(CNN) Off the coast of Georgia lies a quiet is...</td>\n",
       "      <td>An island's future tied to farming crops from ...</td>\n",
       "      <td>https://www.cnn.com/2016/09/14/health/sapelo-i...</td>\n",
       "      <td>An island's future tied to farming crops from ...</td>\n",
       "      <td>[(sapelo, 0.04227217), (pea, 0.030173205), (is...</td>\n",
       "      <td>[sapelo, pea, island, red, crop, year, residen...</td>\n",
       "      <td>#sapelo #pea #island #red #crop #year #residen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>919</td>\n",
       "      <td>['defects', 'cause', 'birth', 'fever', 'early'...</td>\n",
       "      <td>\"We need to increase public awareness regardin...</td>\n",
       "      <td>(CNN) Running a high fever during early pregna...</td>\n",
       "      <td>How fever in early pregnancy can cause birth d...</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/health/pregnancy...</td>\n",
       "      <td>How fever in early pregnancy can cause birth d...</td>\n",
       "      <td>[(fever, 0.032516886), (defect, 0.031959943), ...</td>\n",
       "      <td>[fever, defect, said, ion, channel, pregnancy,...</td>\n",
       "      <td>#fever #defect #said #ion #channel #pregnancy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>['james', 'commission', 'cancer', 'charities',...</td>\n",
       "      <td>JUST WATCHED Federal Trade Commission: Four ca...</td>\n",
       "      <td>Story highlights Government says donors gave $...</td>\n",
       "      <td>Government says four cancer charities are shams</td>\n",
       "      <td>https://www.cnn.com/2015/05/19/us/scam-charity...</td>\n",
       "      <td>Government says four cancer charities are sham...</td>\n",
       "      <td>[(cancer, 0.091183975), (charity, 0.04948671),...</td>\n",
       "      <td>[cancer, charity, say, four, fund, cnn, patien...</td>\n",
       "      <td>#cancer #charity #say #four #fund #cnn #patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>['mr', 'harvey', 'told', 'accused', 'women', '...</td>\n",
       "      <td>Harvey Weinstein stands accused of rape by mul...</td>\n",
       "      <td>Harvey Weinstein stands accused of rape by mul...</td>\n",
       "      <td>Harvey Weinstein accused of rape in New Yorker...</td>\n",
       "      <td>http://money.cnn.com/2017/10/10/media/harvey-w...</td>\n",
       "      <td>Harvey Weinstein accused of rape in New Yorker...</td>\n",
       "      <td>[(weinstein, 0.055802133), (allegation, 0.0170...</td>\n",
       "      <td>[weinstein, allegation, new, told, said, story...</td>\n",
       "      <td>#weinstein #allegation #new #told #said #story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>922</td>\n",
       "      <td>['los', 'angeles', 'months', 'veterans', 'care...</td>\n",
       "      <td>Los Angeles (CNN) Thousands of veterans who ar...</td>\n",
       "      <td>Los Angeles (CNN) Thousands of veterans who ar...</td>\n",
       "      <td>It's not over: Veterans waiting months for app...</td>\n",
       "      <td>https://www.cnn.com/2015/03/13/us/va-investiga...</td>\n",
       "      <td>It's not over: Veterans waiting months for app...</td>\n",
       "      <td>[(va, 0.042325728), (new, 0.034344263), (los, ...</td>\n",
       "      <td>[va, new, los, veteran, wait, cnn, time, patie...</td>\n",
       "      <td>#va #new #los #veteran #wait #cnn #time #patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>923</td>\n",
       "      <td>['cookies', 'continuing', 'information', 'term...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>2017 world's best travel photos</td>\n",
       "      <td>https://www.cnn.com/travel/gallery/best-travel...</td>\n",
       "      <td>2017 world's best travel photos By continuing ...</td>\n",
       "      <td>[(cooky, 0.11635385), (policy, 0.07552512), (b...</td>\n",
       "      <td>[cooky, policy, browse, continuing, privacy, u...</td>\n",
       "      <td>#cooky #policy #browse #continuing #privacy #u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>['asked', 'told', 'day', 'nursing', 'raped', '...</td>\n",
       "      <td>Bobbi Young holds a photo of her mother, Maril...</td>\n",
       "      <td>Bobbi Young holds a photo of her mother, Maril...</td>\n",
       "      <td>My mother was raped in a nursing home at 88</td>\n",
       "      <td>https://www.cnn.com/2017/02/22/opinions/nursin...</td>\n",
       "      <td>My mother was raped in a nursing home at 88 Bo...</td>\n",
       "      <td>[(mother, 0.025970308), (home, 0.019370604), (...</td>\n",
       "      <td>[mother, home, would, father, day, nursing, to...</td>\n",
       "      <td>#mother #home #would #father #day #nursing #to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>['met', 'survivor', 'trafficking', 'end', 'vic...</td>\n",
       "      <td>Humboldt County, California (CNN) Elle Snow la...</td>\n",
       "      <td>Humboldt County, California (CNN) Elle Snow la...</td>\n",
       "      <td>Sex trafficking survivor who wants to end 'The...</td>\n",
       "      <td>https://www.cnn.com/2017/06/28/world/elle-snow...</td>\n",
       "      <td>Sex trafficking survivor who wants to end 'The...</td>\n",
       "      <td>[(snow, 0.040393244), (say, 0.016762292), (tra...</td>\n",
       "      <td>[snow, say, trafficking, game, trafficker, sex...</td>\n",
       "      <td>#snow #say #trafficking #game #trafficker #sex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>['told', 'secretary', 'added', 'trump', 'iq', ...</td>\n",
       "      <td>Washington (CNN) President Donald Trump, scorn...</td>\n",
       "      <td>Washington (CNN) President Donald Trump, scorn...</td>\n",
       "      <td>Trump boasts of a higher IQ than Tillerson</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/politics/donald-...</td>\n",
       "      <td>Trump boasts of a higher IQ than Tillerson Was...</td>\n",
       "      <td>[(trump, 0.048206978), (tillerson, 0.032561705...</td>\n",
       "      <td>[trump, tillerson, said, iq, comment, presiden...</td>\n",
       "      <td>#trump #tillerson #said #iq #comment #presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>['spanish', 'independence', 'regions', 'meets'...</td>\n",
       "      <td>Carles Puigdemont, the President of Catalonia,...</td>\n",
       "      <td>(CNN) Pro-independence Catalans gathered on th...</td>\n",
       "      <td>Catalans' future on line as parliament meets</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/europe/catalonia...</td>\n",
       "      <td>Catalans' future on line as parliament meets (...</td>\n",
       "      <td>[(independence, 0.021792267), (catalonia, 0.02...</td>\n",
       "      <td>[independence, catalonia, catalan, spain, woul...</td>\n",
       "      <td>#independence #catalonia #catalan #spain #woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>['wrote', 'tiffany', 'disneys', 'thought', 'li...</td>\n",
       "      <td>Tiffany Thornton, who starred on \"Sonny with a...</td>\n",
       "      <td>(CNN) A former Disney Channel star has struck ...</td>\n",
       "      <td>Disney's Tiffany Thornton defends remarrying t...</td>\n",
       "      <td>https://www.cnn.com/2017/10/10/entertainment/t...</td>\n",
       "      <td>Disney's Tiffany Thornton defends remarrying t...</td>\n",
       "      <td>[(love, 0.031988062), (thornton, 0.03165771), ...</td>\n",
       "      <td>[love, thornton, husband, chris, life, new, tw...</td>\n",
       "      <td>#love #thornton #husband #chris #life #new #tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>929</td>\n",
       "      <td>['seattle', 'arrested', 'suspicion', 'rapper',...</td>\n",
       "      <td>Rapper Nelly was arrested on suspicion of rape...</td>\n",
       "      <td>Rapper Nelly was arrested on suspicion of rape...</td>\n",
       "      <td>Nelly arrested on suspicion of rape</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Nelly arrested on suspicion of rape Rapper Nel...</td>\n",
       "      <td>[(arrested, 0.11059645), (suspicion, 0.1041849...</td>\n",
       "      <td>[arrested, suspicion, rape, nelly, attorney, n...</td>\n",
       "      <td>#arrested #suspicion #rape #nelly #attorney #n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>930</td>\n",
       "      <td>['vallabh', 'know', 'months', 'curse', 'diseas...</td>\n",
       "      <td>The family, who prefer not to use their surnam...</td>\n",
       "      <td>(CNN) \"Look, I'm so sorry to do this to you on...</td>\n",
       "      <td>A 'family curse': First insomnia, then death</td>\n",
       "      <td>https://www.cnn.com/2017/09/19/health/fatal-in...</td>\n",
       "      <td>A 'family curse': First insomnia, then death (...</td>\n",
       "      <td>[(said, 0.01969652), (disease, 0.016667614), (...</td>\n",
       "      <td>[said, disease, vallabh, family, prion, one, b...</td>\n",
       "      <td>#said #disease #vallabh #family #prion #one #b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>931</td>\n",
       "      <td>['fairs', 'appeal', 'geary', 'state', 'recipe'...</td>\n",
       "      <td>County fairs, state fairs, street fairs -- you...</td>\n",
       "      <td>(CNN) — If there's one culinary truism about A...</td>\n",
       "      <td>Behind the appeal of America's craziest fair f...</td>\n",
       "      <td>https://www.cnn.com/travel/article/fair-food-a...</td>\n",
       "      <td>Behind the appeal of America's craziest fair f...</td>\n",
       "      <td>[(fair, 0.03479866), (fried, 0.028953891), (fo...</td>\n",
       "      <td>[fair, fried, food, geary, say, dog, recipe, s...</td>\n",
       "      <td>#fair #fried #food #geary #say #dog #recipe #s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>['asking', 'youre', 'harvey', 'women', 'harass...</td>\n",
       "      <td>(CNN) Designer Donna Karan has apologized for ...</td>\n",
       "      <td>(CNN) Designer Donna Karan has apologized for ...</td>\n",
       "      <td>Donna Karan slammed for Harvey Weinstein comments</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/entertainment/do...</td>\n",
       "      <td>Donna Karan slammed for Harvey Weinstein comme...</td>\n",
       "      <td>[(karan, 0.04515107), (woman, 0.026888993), (w...</td>\n",
       "      <td>[karan, woman, weinstein, donna, said, comment...</td>\n",
       "      <td>#karan #woman #weinstein #donna #said #comment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>['20', 'takes', 'america', 'clinton', 'state',...</td>\n",
       "      <td>Of course, Republicans have known for a long t...</td>\n",
       "      <td>(CNN) Amid the twists and turns of a tumultuou...</td>\n",
       "      <td>20 top takes on 2016</td>\n",
       "      <td>https://www.cnn.com/2016/12/21/opinions/best-o...</td>\n",
       "      <td>20 top takes on 2016 (CNN) Amid the twists and...</td>\n",
       "      <td>[(trump, 0.017107368), (read, 0.011944201), (c...</td>\n",
       "      <td>[trump, read, clinton, president, cnn, first, ...</td>\n",
       "      <td>#trump #read #clinton #president #cnn #first #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>['views', 'hotel', 'lodge', 'escapes', 'inn', ...</td>\n",
       "      <td>If you'd like to enjoy a luxurious vacation th...</td>\n",
       "      <td>(CNN) — Upon arrival at the Old Edwards Inn in...</td>\n",
       "      <td>9 luxurious fall escapes</td>\n",
       "      <td>https://www.cnn.com/travel/article/luxury-fall...</td>\n",
       "      <td>9 luxurious fall escapes (CNN) — Upon arrival ...</td>\n",
       "      <td>[(lodge, 0.0128635885), (room, 0.010961346), (...</td>\n",
       "      <td>[lodge, room, hotel, lake, spa, inn, fireplace...</td>\n",
       "      <td>#lodge #room #hotel #lake #spa #inn #fireplace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>['schools', 'deaths', 'trouble', 'hazing', 'st...</td>\n",
       "      <td>The Burch, Hipps and Braham families share a c...</td>\n",
       "      <td>(CNN) Nolan Burch 's parents didn't know what ...</td>\n",
       "      <td>Schools knew of trouble before student deaths</td>\n",
       "      <td>https://www.cnn.com/2015/11/02/us/fraternity-h...</td>\n",
       "      <td>Schools knew of trouble before student deaths ...</td>\n",
       "      <td>[(university, 0.028282506), (fraternity, 0.020...</td>\n",
       "      <td>[university, fraternity, hazing, say, burch, d...</td>\n",
       "      <td>#university #fraternity #hazing #say #burch #d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>936</td>\n",
       "      <td>['incendiary', 'recovered', 'sources', 'rounds...</td>\n",
       "      <td>Story highlights Investigators found \"survival...</td>\n",
       "      <td>Story highlights Investigators found \"survival...</td>\n",
       "      <td>Las Vegas shooter fired 'incendiary' rounds at...</td>\n",
       "      <td>http://www.cnn.com/2017/10/10/us/las-vegas-sho...</td>\n",
       "      <td>Las Vegas shooter fired 'incendiary' rounds at...</td>\n",
       "      <td>[(round, 0.06713945), (tank, 0.05598681), (inc...</td>\n",
       "      <td>[round, tank, incendiary, fuel, source, fired,...</td>\n",
       "      <td>#round #tank #incendiary #fuel #source #fired ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>937</td>\n",
       "      <td>['20', 'consumer', 'contemporary', 'designed',...</td>\n",
       "      <td>Indeed, Karl Marx knew that the epic activitie...</td>\n",
       "      <td>What influences the appearance and character o...</td>\n",
       "      <td>20 designs that defined the modern world</td>\n",
       "      <td>http://edition.cnn.com/interactive/style/20-de...</td>\n",
       "      <td>20 designs that defined the modern world What ...</td>\n",
       "      <td>[(design, 0.06252057), (world, 0.016239975), (...</td>\n",
       "      <td>[design, world, thing, designer, may, consumer...</td>\n",
       "      <td>#design #world #thing #designer #may #consumer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>938</td>\n",
       "      <td>['facebook', 'actor', 'whats', 'movie', 'world...</td>\n",
       "      <td>Chat with us in Facebook Messenger.\\nFind out ...</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>Police take shot at actor on movie set</td>\n",
       "      <td>https://www.cnn.com/videos/us/2017/10/04/polic...</td>\n",
       "      <td>Police take shot at actor on movie set Chat wi...</td>\n",
       "      <td>[(movie, 0.08433947), (police, 0.08109556), (h...</td>\n",
       "      <td>[movie, police, happening, chat, take, messeng...</td>\n",
       "      <td>#movie #police #happening #chat #take #messeng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>939</td>\n",
       "      <td>['races', 'danelle', 'mph', 'blind', 'life', '...</td>\n",
       "      <td>Photos: Blind skier puts her life in her husba...</td>\n",
       "      <td>(CNN) Danelle Umstead can't see when she skis ...</td>\n",
       "      <td>Blind skier races up to 70 mph</td>\n",
       "      <td>https://www.cnn.com/2016/12/16/health/turning-...</td>\n",
       "      <td>Blind skier races up to 70 mph (CNN) Danelle U...</td>\n",
       "      <td>[(life, 0.026308596), (said, 0.02592103), (rob...</td>\n",
       "      <td>[life, said, rob, skier, danelle, photo, husba...</td>\n",
       "      <td>#life #said #rob #skier #danelle #photo #husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>940</td>\n",
       "      <td>['knew', 'harvey', 'harassed', 'hollywood', 'a...</td>\n",
       "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
       "      <td>Journalist Lauren Sivan says Hollywood mogul H...</td>\n",
       "      <td>Reporter accuses Weinstein of sexual advances</td>\n",
       "      <td>https://www.cnn.com/videos/entertainment/2017/...</td>\n",
       "      <td>Reporter accuses Weinstein of sexual advances ...</td>\n",
       "      <td>[(weinstein, 0.09471097), (exactly, 0.06987897...</td>\n",
       "      <td>[weinstein, exactly, reporter, claim, sexually...</td>\n",
       "      <td>#weinstein #exactly #reporter #claim #sexually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>941</td>\n",
       "      <td>['cookies', 'continuing', 'information', 'term...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>By continuing to browse our site you agree to ...</td>\n",
       "      <td>Photos of the Times Square even locals love</td>\n",
       "      <td>http://www.cnn.com/travel/gallery/photos-times...</td>\n",
       "      <td>Photos of the Times Square even locals love By...</td>\n",
       "      <td>[(cooky, 0.08858229), (privacy, 0.063245036), ...</td>\n",
       "      <td>[cooky, privacy, local, revised, browse, term,...</td>\n",
       "      <td>#cooky #privacy #local #revised #browse #term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>942</td>\n",
       "      <td>['merkel', 'cap', 'party', 'limit', 'parties',...</td>\n",
       "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
       "      <td>(CNN) German Chancellor Angela Merkel has agre...</td>\n",
       "      <td>Merkel changes tune on German refugee cap</td>\n",
       "      <td>https://www.cnn.com/2017/10/09/europe/germany-...</td>\n",
       "      <td>Merkel changes tune on German refugee cap (CNN...</td>\n",
       "      <td>[(merkel, 0.024225906), (party, 0.022733122), ...</td>\n",
       "      <td>[merkel, party, limit, position, germany, refu...</td>\n",
       "      <td>#merkel #party #limit #position #germany #refu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           KEYWORDS  \\\n",
       "0             0  ['energy', 'sugars', 'bars', 'grams', 'syrup',...   \n",
       "1             1  ['facebook', 'whats', 'world', 'unfolds', 'tam...   \n",
       "2             2  ['jedi', 'shots', 'rey', 'force', 'wars', 'sta...   \n",
       "3             3  ['clients', 'art', 'science', 'scent', 'collid...   \n",
       "4             4  ['akufoaddo', 'tanker', 'incidents', 'dozens',...   \n",
       "5             5  ['spanish', 'independence', 'regions', 'meets'...   \n",
       "6             6  ['press', 'excuse', 'secretary', 'trump', 'hou...   \n",
       "7             7  ['pollution', 'repeal', 'kellogg', 'asthma', '...   \n",
       "8             8  ['look', 'response', 'force', 'trump', 'tour',...   \n",
       "9             9  ['okunoin', 'tohoku', 'japan', 'risshakuji', '...   \n",
       "10           10  ['land', 'life', 'purchased', 'doug', 'wonder'...   \n",
       "11           11  ['kids', 'parental', 'really', 'husband', 'ste...   \n",
       "12           12  ['kids', 'television', 'impacts', 'drink', 'ad...   \n",
       "13           13  ['kids', 'ferrara', 'way', 'thats', 'ah', 'say...   \n",
       "14           14  ['congress', 'issue', 'trump', 'women', 'calls...   \n",
       "15           15  ['partner', 'men', 'low', 'interest', 'women',...   \n",
       "16           16  ['hes', 'music', 'seattle', 'working', 'world'...   \n",
       "17           17  ['plywoods', 'veneer', 'role', 'wood', 'shapin...   \n",
       "18           18  ['men', 'results', 'users', 'way', 'test', 'ki...   \n",
       "19           19  ['according', 'boundaries', 'generations', 'ac...   \n",
       "20           20  ['hollywood', 'women', 'comments', 'player', '...   \n",
       "21           21  ['reckoned', 'history', 'past', 'nazi', 'confe...   \n",
       "22           22  ['online', 'responsible', 'really', 'technolog...   \n",
       "23           23  ['important', 'cheeses', 'healthy', 'nutrients...   \n",
       "24           24  ['planet', 'book', 'degrees', 'science', 'must...   \n",
       "25           25  ['james', 'release', 'thought', 'think', 'w', ...   \n",
       "26           26  ['planned', 'fetus', 'videos', 'center', 'abor...   \n",
       "27           27  ['rovers', 'hide', 'image', 'opinion', 'camera...   \n",
       "28           28  ['house', 'mary', 'danish', 'prince', 'giant',...   \n",
       "29           29  ['im', 'stinks', 'economic', 'whites', 'white'...   \n",
       "..          ...                                                ...   \n",
       "913         913  ['queen', 'wrong', 'denchs', 'motives', 'goes'...   \n",
       "914         914  ['page', 'updated', 'specific', 'transcripts',...   \n",
       "915         915  ['aunts', 'hefner', 'jennifer', 'men', 'role',...   \n",
       "916         916  ['online', 'farm', 'crowd', 'buying', 'investo...   \n",
       "917         917  ['kids', 'crooks', 'steal', 'van', 'school', '...   \n",
       "918         918  ['island', 'past', 'residents', 'farming', 'sa...   \n",
       "919         919  ['defects', 'cause', 'birth', 'fever', 'early'...   \n",
       "920         920  ['james', 'commission', 'cancer', 'charities',...   \n",
       "921         921  ['mr', 'harvey', 'told', 'accused', 'women', '...   \n",
       "922         922  ['los', 'angeles', 'months', 'veterans', 'care...   \n",
       "923         923  ['cookies', 'continuing', 'information', 'term...   \n",
       "924         924  ['asked', 'told', 'day', 'nursing', 'raped', '...   \n",
       "925         925  ['met', 'survivor', 'trafficking', 'end', 'vic...   \n",
       "926         926  ['told', 'secretary', 'added', 'trump', 'iq', ...   \n",
       "927         927  ['spanish', 'independence', 'regions', 'meets'...   \n",
       "928         928  ['wrote', 'tiffany', 'disneys', 'thought', 'li...   \n",
       "929         929  ['seattle', 'arrested', 'suspicion', 'rapper',...   \n",
       "930         930  ['vallabh', 'know', 'months', 'curse', 'diseas...   \n",
       "931         931  ['fairs', 'appeal', 'geary', 'state', 'recipe'...   \n",
       "932         932  ['asking', 'youre', 'harvey', 'women', 'harass...   \n",
       "933         933  ['20', 'takes', 'america', 'clinton', 'state',...   \n",
       "934         934  ['views', 'hotel', 'lodge', 'escapes', 'inn', ...   \n",
       "935         935  ['schools', 'deaths', 'trouble', 'hazing', 'st...   \n",
       "936         936  ['incendiary', 'recovered', 'sources', 'rounds...   \n",
       "937         937  ['20', 'consumer', 'contemporary', 'designed',...   \n",
       "938         938  ['facebook', 'actor', 'whats', 'movie', 'world...   \n",
       "939         939  ['races', 'danelle', 'mph', 'blind', 'life', '...   \n",
       "940         940  ['knew', 'harvey', 'harassed', 'hollywood', 'a...   \n",
       "941         941  ['cookies', 'continuing', 'information', 'term...   \n",
       "942         942  ['merkel', 'cap', 'party', 'limit', 'parties',...   \n",
       "\n",
       "                                               SUMMARY  \\\n",
       "0    Story highlights Don't be fooled by the word \"...   \n",
       "1    Chat with us in Facebook Messenger.\\nFind out ...   \n",
       "2    ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "3    Lyn Harris' independent space, Perfumer H , in...   \n",
       "4    (CNN) A tanker exploded near a gas station in ...   \n",
       "5    Carles Puigdemont, the President of Catalonia,...   \n",
       "6    \"I think it's fake news, but if he did that, I...   \n",
       "7    President Barak Obama shakes Camryn Kellogg's ...   \n",
       "8    (CNN) Finally lumbering into a devastated Puer...   \n",
       "9    (CNN) — Upon hearing I would have to climb 1,0...   \n",
       "10   Doug Tompkins and Kristine McDivitt should hav...   \n",
       "11   I'm not sure I needed a study to tell me paren...   \n",
       "12   What they found is those underage drinkers who...   \n",
       "13   \"I always say to parents ... you've got to sto...   \n",
       "14   Story highlights Ivanka Trump attends Fortune'...   \n",
       "15   Story highlights Low desire in one partner is ...   \n",
       "16   (CNN) When Jay Park became one of the first an...   \n",
       "17   This exhibition, \"Plywood: Material of the Mod...   \n",
       "18   Story highlights The app Grindr is an effectiv...   \n",
       "19   \"The only generation we do define is Baby Boom...   \n",
       "20   Designer Donna Karan has apologized for the re...   \n",
       "21   (CNN) When it comes to Confederate monuments a...   \n",
       "22   James and Alexa Hirschfeld's successful online...   \n",
       "23   Story highlights Cheese contains important nut...   \n",
       "24   (CNN) \"Climate change is the canvas on which t...   \n",
       "25   If you thought you were getting your hands on ...   \n",
       "26   Abortion photo actually stillborn childThe pho...   \n",
       "27   Photos: Mars rover Curiosity Five years ago an...   \n",
       "28   (CNN) — Get ready to embrace your inner child ...   \n",
       "29   Those are some of the reasons why working clas...   \n",
       "..                                                 ...   \n",
       "913  (CNN) Even taking acknowledged liberties with ...   \n",
       "914  Return to Transcripts main pageCNN Transcripts...   \n",
       "915  Story highlights Rebecca Jackson-Artis: My aun...   \n",
       "916  (CNN) For $1,000 you can be the proud owner of...   \n",
       "917  Recently, crooks went after one the vans' tank...   \n",
       "918  When this opportunity came up, he joined Jerom...   \n",
       "919  \"We need to increase public awareness regardin...   \n",
       "920  JUST WATCHED Federal Trade Commission: Four ca...   \n",
       "921  Harvey Weinstein stands accused of rape by mul...   \n",
       "922  Los Angeles (CNN) Thousands of veterans who ar...   \n",
       "923  By continuing to browse our site you agree to ...   \n",
       "924  Bobbi Young holds a photo of her mother, Maril...   \n",
       "925  Humboldt County, California (CNN) Elle Snow la...   \n",
       "926  Washington (CNN) President Donald Trump, scorn...   \n",
       "927  Carles Puigdemont, the President of Catalonia,...   \n",
       "928  Tiffany Thornton, who starred on \"Sonny with a...   \n",
       "929  Rapper Nelly was arrested on suspicion of rape...   \n",
       "930  The family, who prefer not to use their surnam...   \n",
       "931  County fairs, state fairs, street fairs -- you...   \n",
       "932  (CNN) Designer Donna Karan has apologized for ...   \n",
       "933  Of course, Republicans have known for a long t...   \n",
       "934  If you'd like to enjoy a luxurious vacation th...   \n",
       "935  The Burch, Hipps and Braham families share a c...   \n",
       "936  Story highlights Investigators found \"survival...   \n",
       "937  Indeed, Karl Marx knew that the epic activitie...   \n",
       "938  Chat with us in Facebook Messenger.\\nFind out ...   \n",
       "939  Photos: Blind skier puts her life in her husba...   \n",
       "940  Journalist Lauren Sivan says Hollywood mogul H...   \n",
       "941  By continuing to browse our site you agree to ...   \n",
       "942  (CNN) German Chancellor Angela Merkel has agre...   \n",
       "\n",
       "                                                  TEXT  \\\n",
       "0    Story highlights Don't be fooled by the word \"...   \n",
       "1    Chat with us in Facebook Messenger. Find out w...   \n",
       "2    ESPN's \"Monday Night Football\" had bears, viki...   \n",
       "3    This feature is part of ' Details ,' a new ser...   \n",
       "4    (CNN) A tanker exploded near a gas station in ...   \n",
       "5    (CNN) Pro-independence Catalans gathered on th...   \n",
       "6    (CNN) In a Forbes magazine interview published...   \n",
       "7    (CNN) The days when all three of her children ...   \n",
       "8    Michael D'Antonio is the author of the book \" ...   \n",
       "9    \\n\\n\\n\\nThis article was first published in Ju...   \n",
       "10   Catch \"The Wonder List\" on CNN Saturdays at 9 ...   \n",
       "11   Kelly Wallace is CNN's digital correspondent a...   \n",
       "12   Kelly Wallace is CNN's digital correspondent a...   \n",
       "13   (CNN) Most parents have experienced it: that m...   \n",
       "14   Story highlights Ivanka Trump attends Fortune'...   \n",
       "15   Story highlights Low desire in one partner is ...   \n",
       "16   (CNN) When Jay Park became one of the first an...   \n",
       "17   Written by Tom Morris, CNN London\\n\\nChristoph...   \n",
       "18   Story highlights The app Grindr is an effectiv...   \n",
       "19   We can all agree that Millennials are the wors...   \n",
       "20   Designer Donna Karan has apologized for the re...   \n",
       "21   (CNN) When it comes to Confederate monuments a...   \n",
       "22   James and Alexa Hirschfeld's successful online...   \n",
       "23   Story highlights Cheese contains important nut...   \n",
       "24   CNN columnist John D. Sutter is spending the r...   \n",
       "25   If you thought you were getting your hands on ...   \n",
       "26   Costa Mesa, California (CNN) David Daleiden wa...   \n",
       "27   Photos: Mars rover Curiosity Five years ago an...   \n",
       "28   (CNN) — Get ready to embrace your inner child ...   \n",
       "29   Social Security is running out of money. Ameri...   \n",
       "..                                                 ...   \n",
       "913  (CNN) Even taking acknowledged liberties with ...   \n",
       "914  \\n\\n\\n\\nReturn to Transcripts main page\\n\\nCNN...   \n",
       "915  Story highlights Rebecca Jackson-Artis: My aun...   \n",
       "916  Story highlights Livestock Wealth \"crowd farms...   \n",
       "917  Omaha,Neb(FOX42KPTM)-Kids Can Community Center...   \n",
       "918  (CNN) Off the coast of Georgia lies a quiet is...   \n",
       "919  (CNN) Running a high fever during early pregna...   \n",
       "920  Story highlights Government says donors gave $...   \n",
       "921  Harvey Weinstein stands accused of rape by mul...   \n",
       "922  Los Angeles (CNN) Thousands of veterans who ar...   \n",
       "923  By continuing to browse our site you agree to ...   \n",
       "924  Bobbi Young holds a photo of her mother, Maril...   \n",
       "925  Humboldt County, California (CNN) Elle Snow la...   \n",
       "926  Washington (CNN) President Donald Trump, scorn...   \n",
       "927  (CNN) Pro-independence Catalans gathered on th...   \n",
       "928  (CNN) A former Disney Channel star has struck ...   \n",
       "929  Rapper Nelly was arrested on suspicion of rape...   \n",
       "930  (CNN) \"Look, I'm so sorry to do this to you on...   \n",
       "931  (CNN) — If there's one culinary truism about A...   \n",
       "932  (CNN) Designer Donna Karan has apologized for ...   \n",
       "933  (CNN) Amid the twists and turns of a tumultuou...   \n",
       "934  (CNN) — Upon arrival at the Old Edwards Inn in...   \n",
       "935  (CNN) Nolan Burch 's parents didn't know what ...   \n",
       "936  Story highlights Investigators found \"survival...   \n",
       "937  What influences the appearance and character o...   \n",
       "938  Chat with us in Facebook Messenger. Find out w...   \n",
       "939  (CNN) Danelle Umstead can't see when she skis ...   \n",
       "940  Journalist Lauren Sivan says Hollywood mogul H...   \n",
       "941  By continuing to browse our site you agree to ...   \n",
       "942  (CNN) German Chancellor Angela Merkel has agre...   \n",
       "\n",
       "                                                 TITLE  \\\n",
       "0                             Are energy bars healthy?   \n",
       "1                                   Tamagotchi is back   \n",
       "2    'Star Wars: The Last Jedi' trailer debuts on '...   \n",
       "3    Art and science collide in this one-of-a-kind ...   \n",
       "4    Seven killed, dozens injured in Ghana tanker e...   \n",
       "5         Catalans' future on line as parliament meets   \n",
       "6                The Trump White House's 'joke' excuse   \n",
       "7          Health impact of Trump environmental repeal   \n",
       "8    Trump in Puerto Rico: A narcissist's tour de f...   \n",
       "9    Yamadera Risshakuji in Tohoku: 1,015 steps to ...   \n",
       "10   They purchased paradise ... then gave it all away   \n",
       "11               Parental burnout: It's really a thing   \n",
       "12   How alcohol advertising impacts underage drinking   \n",
       "13   Ah! My kid is having a tantrum, and I want to ...   \n",
       "14   Ivanka Trump calls on Congress to act on immig...   \n",
       "15   When you and your partner have mismatched libidos   \n",
       "16                       Jay Park: from K-pop to Jay-Z   \n",
       "17   Plywood's surprising role in shaping our moder...   \n",
       "18             How Grindr got men to self-test for HIV   \n",
       "19   Here Is When Each Generation Begins and Ends, ...   \n",
       "20       Donna Karan apologizes for Weinstein comments   \n",
       "21   Fareed Zakaria: US could learn from how German...   \n",
       "22   Paperless Post founder's technology helps get ...   \n",
       "23                                  Is cheese healthy?   \n",
       "24   Books: 12 must-reads on climate change (2 degr...   \n",
       "25   Whataburger sells out of James Avery charm hou...   \n",
       "26   The real story behind those Planned Parenthood...   \n",
       "27           Is it ethical to colonize Mars? (Opinion)   \n",
       "28                   Inside Denmark's giant LEGO house   \n",
       "29   The economy stinks, but I'm doing OK, say work...   \n",
       "..                                                 ...   \n",
       "913   'Victoria & Abdul' goes skin-deep on great story   \n",
       "914                                        Transcripts   \n",
       "915      Playboy's role in creating strong black women   \n",
       "916  Cash cows: Why investors are buying pregnant c...   \n",
       "917  Crooks steal something valuable from a daycare...   \n",
       "918  An island's future tied to farming crops from ...   \n",
       "919  How fever in early pregnancy can cause birth d...   \n",
       "920    Government says four cancer charities are shams   \n",
       "921  Harvey Weinstein accused of rape in New Yorker...   \n",
       "922  It's not over: Veterans waiting months for app...   \n",
       "923                    2017 world's best travel photos   \n",
       "924        My mother was raped in a nursing home at 88   \n",
       "925  Sex trafficking survivor who wants to end 'The...   \n",
       "926         Trump boasts of a higher IQ than Tillerson   \n",
       "927       Catalans' future on line as parliament meets   \n",
       "928  Disney's Tiffany Thornton defends remarrying t...   \n",
       "929                Nelly arrested on suspicion of rape   \n",
       "930       A 'family curse': First insomnia, then death   \n",
       "931  Behind the appeal of America's craziest fair f...   \n",
       "932  Donna Karan slammed for Harvey Weinstein comments   \n",
       "933                               20 top takes on 2016   \n",
       "934                           9 luxurious fall escapes   \n",
       "935      Schools knew of trouble before student deaths   \n",
       "936  Las Vegas shooter fired 'incendiary' rounds at...   \n",
       "937           20 designs that defined the modern world   \n",
       "938             Police take shot at actor on movie set   \n",
       "939                     Blind skier races up to 70 mph   \n",
       "940      Reporter accuses Weinstein of sexual advances   \n",
       "941        Photos of the Times Square even locals love   \n",
       "942          Merkel changes tune on German refugee cap   \n",
       "\n",
       "                                                   URL  \\\n",
       "0    https://www.cnn.com/2017/08/25/health/energy-b...   \n",
       "1    http://www.cnn.com/videos/cnnmoney/2017/10/10/...   \n",
       "2    http://money.cnn.com/2017/10/09/media/star-war...   \n",
       "3    https://www.cnn.com/style/article/details-perf...   \n",
       "4    https://www.cnn.com/2017/10/08/africa/ghana-ta...   \n",
       "5    https://www.cnn.com/2017/10/10/europe/cataloni...   \n",
       "6    http://www.cnn.com/2017/10/10/politics/trump-j...   \n",
       "7    https://www.cnn.com/2017/10/10/health/health-e...   \n",
       "8    https://www.cnn.com/2017/10/03/opinions/trump-...   \n",
       "9    https://www.cnn.com/travel/article/yamadera-te...   \n",
       "10   http://www.cnn.com/travel/article/wonder-list-...   \n",
       "11   https://www.cnn.com/2017/05/09/health/parentin...   \n",
       "12   https://www.cnn.com/2016/09/07/health/kids-alc...   \n",
       "13   https://www.cnn.com/2017/10/04/health/tantrums...   \n",
       "14   https://www.cnn.com/2017/10/09/politics/ivanka...   \n",
       "15   https://www.cnn.com/2017/09/21/health/mismatch...   \n",
       "16   https://www.cnn.com/2017/10/08/asia/jay-park-j...   \n",
       "17   https://www.cnn.com/style/article/plywood-mate...   \n",
       "18   https://www.cnn.com/2016/07/25/health/grindr-h...   \n",
       "19   http://www.theatlantic.com/national/archive/20...   \n",
       "20   https://www.cnn.com/videos/entertainment/2017/...   \n",
       "21   https://www.cnn.com/2017/08/20/us/fareed-zakar...   \n",
       "22   http://money.cnn.com/2017/10/04/technology/bus...   \n",
       "23   https://www.cnn.com/2017/09/25/health/cheese-h...   \n",
       "24   https://www.cnn.com/2015/05/19/opinions/sutter...   \n",
       "25   http://cw33.com/2017/10/10/whataburger-and-jam...   \n",
       "26   https://www.cnn.com/2015/10/19/politics/planne...   \n",
       "27   https://www.cnn.com/2015/10/15/opinions/green-...   \n",
       "28   https://www.cnn.com/travel/article/lego-house-...   \n",
       "29   http://money.cnn.com/2016/09/23/news/economy/w...   \n",
       "..                                                 ...   \n",
       "913  https://www.cnn.com/2017/09/22/entertainment/v...   \n",
       "914    https://www.cnn.com/TRANSCRIPTS/2017.10.04.html   \n",
       "915  https://www.cnn.com/2017/10/07/opinions/race-s...   \n",
       "916  https://www.cnn.com/2017/05/01/africa/livestoc...   \n",
       "917  http://fox42kptm.com/news/local/crooks-steal-s...   \n",
       "918  https://www.cnn.com/2016/09/14/health/sapelo-i...   \n",
       "919  http://www.cnn.com/2017/10/10/health/pregnancy...   \n",
       "920  https://www.cnn.com/2015/05/19/us/scam-charity...   \n",
       "921  http://money.cnn.com/2017/10/10/media/harvey-w...   \n",
       "922  https://www.cnn.com/2015/03/13/us/va-investiga...   \n",
       "923  https://www.cnn.com/travel/gallery/best-travel...   \n",
       "924  https://www.cnn.com/2017/02/22/opinions/nursin...   \n",
       "925  https://www.cnn.com/2017/06/28/world/elle-snow...   \n",
       "926  http://www.cnn.com/2017/10/10/politics/donald-...   \n",
       "927  http://www.cnn.com/2017/10/10/europe/catalonia...   \n",
       "928  https://www.cnn.com/2017/10/10/entertainment/t...   \n",
       "929  https://www.cnn.com/videos/entertainment/2017/...   \n",
       "930  https://www.cnn.com/2017/09/19/health/fatal-in...   \n",
       "931  https://www.cnn.com/travel/article/fair-food-a...   \n",
       "932  http://www.cnn.com/2017/10/10/entertainment/do...   \n",
       "933  https://www.cnn.com/2016/12/21/opinions/best-o...   \n",
       "934  https://www.cnn.com/travel/article/luxury-fall...   \n",
       "935  https://www.cnn.com/2015/11/02/us/fraternity-h...   \n",
       "936  http://www.cnn.com/2017/10/10/us/las-vegas-sho...   \n",
       "937  http://edition.cnn.com/interactive/style/20-de...   \n",
       "938  https://www.cnn.com/videos/us/2017/10/04/polic...   \n",
       "939  https://www.cnn.com/2016/12/16/health/turning-...   \n",
       "940  https://www.cnn.com/videos/entertainment/2017/...   \n",
       "941  http://www.cnn.com/travel/gallery/photos-times...   \n",
       "942  https://www.cnn.com/2017/10/09/europe/germany-...   \n",
       "\n",
       "                                              ALL_TEXT  \\\n",
       "0    Are energy bars healthy? Story highlights Don'...   \n",
       "1    Tamagotchi is back Chat with us in Facebook Me...   \n",
       "2    'Star Wars: The Last Jedi' trailer debuts on '...   \n",
       "3    Art and science collide in this one-of-a-kind ...   \n",
       "4    Seven killed, dozens injured in Ghana tanker e...   \n",
       "5    Catalans' future on line as parliament meets (...   \n",
       "6    The Trump White House's 'joke' excuse (CNN) In...   \n",
       "7    Health impact of Trump environmental repeal (C...   \n",
       "8    Trump in Puerto Rico: A narcissist's tour de f...   \n",
       "9    Yamadera Risshakuji in Tohoku: 1,015 steps to ...   \n",
       "10   They purchased paradise ... then gave it all a...   \n",
       "11   Parental burnout: It's really a thing Kelly Wa...   \n",
       "12   How alcohol advertising impacts underage drink...   \n",
       "13   Ah! My kid is having a tantrum, and I want to ...   \n",
       "14   Ivanka Trump calls on Congress to act on immig...   \n",
       "15   When you and your partner have mismatched libi...   \n",
       "16   Jay Park: from K-pop to Jay-Z (CNN) When Jay P...   \n",
       "17   Plywood's surprising role in shaping our moder...   \n",
       "18   How Grindr got men to self-test for HIV Story ...   \n",
       "19   Here Is When Each Generation Begins and Ends, ...   \n",
       "20   Donna Karan apologizes for Weinstein comments ...   \n",
       "21   Fareed Zakaria: US could learn from how German...   \n",
       "22   Paperless Post founder's technology helps get ...   \n",
       "23   Is cheese healthy? Story highlights Cheese con...   \n",
       "24   Books: 12 must-reads on climate change (2 degr...   \n",
       "25   Whataburger sells out of James Avery charm hou...   \n",
       "26   The real story behind those Planned Parenthood...   \n",
       "27   Is it ethical to colonize Mars? (Opinion) Phot...   \n",
       "28   Inside Denmark's giant LEGO house (CNN) — Get ...   \n",
       "29   The economy stinks, but I'm doing OK, say work...   \n",
       "..                                                 ...   \n",
       "913  'Victoria & Abdul' goes skin-deep on great sto...   \n",
       "914  Transcripts \\n\\n\\n\\nReturn to Transcripts main...   \n",
       "915  Playboy's role in creating strong black women ...   \n",
       "916  Cash cows: Why investors are buying pregnant c...   \n",
       "917  Crooks steal something valuable from a daycare...   \n",
       "918  An island's future tied to farming crops from ...   \n",
       "919  How fever in early pregnancy can cause birth d...   \n",
       "920  Government says four cancer charities are sham...   \n",
       "921  Harvey Weinstein accused of rape in New Yorker...   \n",
       "922  It's not over: Veterans waiting months for app...   \n",
       "923  2017 world's best travel photos By continuing ...   \n",
       "924  My mother was raped in a nursing home at 88 Bo...   \n",
       "925  Sex trafficking survivor who wants to end 'The...   \n",
       "926  Trump boasts of a higher IQ than Tillerson Was...   \n",
       "927  Catalans' future on line as parliament meets (...   \n",
       "928  Disney's Tiffany Thornton defends remarrying t...   \n",
       "929  Nelly arrested on suspicion of rape Rapper Nel...   \n",
       "930  A 'family curse': First insomnia, then death (...   \n",
       "931  Behind the appeal of America's craziest fair f...   \n",
       "932  Donna Karan slammed for Harvey Weinstein comme...   \n",
       "933  20 top takes on 2016 (CNN) Amid the twists and...   \n",
       "934  9 luxurious fall escapes (CNN) — Upon arrival ...   \n",
       "935  Schools knew of trouble before student deaths ...   \n",
       "936  Las Vegas shooter fired 'incendiary' rounds at...   \n",
       "937  20 designs that defined the modern world What ...   \n",
       "938  Police take shot at actor on movie set Chat wi...   \n",
       "939  Blind skier races up to 70 mph (CNN) Danelle U...   \n",
       "940  Reporter accuses Weinstein of sexual advances ...   \n",
       "941  Photos of the Times Square even locals love By...   \n",
       "942  Merkel changes tune on German refugee cap (CNN...   \n",
       "\n",
       "                                 PREDICT_KEYWORDS_PROB  \\\n",
       "0    [(bar, 0.08965786), (energy, 0.03715309), (sat...   \n",
       "1    [(unfolds, 0.114573814), (find, 0.10926961), (...   \n",
       "2    [(trailer, 0.039500866), (war, 0.03303859), (s...   \n",
       "3    [(harris, 0.048846304), (scent, 0.047987834), ...   \n",
       "4    [(said, 0.04211693), (incident, 0.037273165), ...   \n",
       "5    [(catalonia, 0.026233945), (independence, 0.02...   \n",
       "6    [(iq, 0.03915731), (tillerson, 0.03371939), (t...   \n",
       "7    [(kellogg, 0.0209633), (power, 0.018572563), (...   \n",
       "8    [(trump, 0.023573738), (said, 0.019111894), (p...   \n",
       "9    [(temple, 0.034045555), (yamadera, 0.028016137...   \n",
       "10   [(tompkins, 0.025351323), (doug, 0.024204291),...   \n",
       "11   [(parent, 0.023723198), (said, 0.01947476), (b...   \n",
       "12   [(alcohol, 0.041508775), (drink, 0.022976939),...   \n",
       "13   [(said, 0.025185507), (kid, 0.020834466), (par...   \n",
       "14   [(trump, 0.037142996), (ivanka, 0.025149425), ...   \n",
       "15   [(sex, 0.03935628), (partner, 0.0274307), (des...   \n",
       "16   [(park, 0.04657846), (jay, 0.019225657), (said...   \n",
       "17   [(plywood, 0.03466115), (material, 0.018155685...   \n",
       "18   [(test, 0.054868255), (hiv, 0.032611907), (stu...   \n",
       "19   [(generation, 0.035122823), (time, 0.019235069...   \n",
       "20   [(donna, 0.09000902), (weinstein, 0.07725886),...   \n",
       "21   [(zakaria, 0.031084336), (germany, 0.030595995...   \n",
       "22   [(said, 0.026316134), (company, 0.023529049), ...   \n",
       "23   [(calorie, 0.078114584), (cheese, 0.05672102),...   \n",
       "24   [(climate, 0.03034277), (degree, 0.024460034),...   \n",
       "25   [(charm, 0.09363935), (james, 0.05903045), (av...   \n",
       "26   [(planned, 0.036541793), (parenthood, 0.029388...   \n",
       "27   [(rover, 0.08781761), (mar, 0.067004286), (cur...   \n",
       "28   [(lego, 0.07634535), (house, 0.06144317), (den...   \n",
       "29   [(working, 0.02298514), (white, 0.0224862), (c...   \n",
       "..                                                 ...   \n",
       "913  [(abdul, 0.025936889), (queen, 0.02516271), (m...   \n",
       "914  [(transcript, 0.18240282), (page, 0.079834886)...   \n",
       "915  [(aunt, 0.028325772), (black, 0.02813462), (pl...   \n",
       "916  [(farm, 0.03942887), (investor, 0.038357016), ...   \n",
       "917  [(van, 0.08062484), (gas, 0.04352283), (kid, 0...   \n",
       "918  [(sapelo, 0.04227217), (pea, 0.030173205), (is...   \n",
       "919  [(fever, 0.032516886), (defect, 0.031959943), ...   \n",
       "920  [(cancer, 0.091183975), (charity, 0.04948671),...   \n",
       "921  [(weinstein, 0.055802133), (allegation, 0.0170...   \n",
       "922  [(va, 0.042325728), (new, 0.034344263), (los, ...   \n",
       "923  [(cooky, 0.11635385), (policy, 0.07552512), (b...   \n",
       "924  [(mother, 0.025970308), (home, 0.019370604), (...   \n",
       "925  [(snow, 0.040393244), (say, 0.016762292), (tra...   \n",
       "926  [(trump, 0.048206978), (tillerson, 0.032561705...   \n",
       "927  [(independence, 0.021792267), (catalonia, 0.02...   \n",
       "928  [(love, 0.031988062), (thornton, 0.03165771), ...   \n",
       "929  [(arrested, 0.11059645), (suspicion, 0.1041849...   \n",
       "930  [(said, 0.01969652), (disease, 0.016667614), (...   \n",
       "931  [(fair, 0.03479866), (fried, 0.028953891), (fo...   \n",
       "932  [(karan, 0.04515107), (woman, 0.026888993), (w...   \n",
       "933  [(trump, 0.017107368), (read, 0.011944201), (c...   \n",
       "934  [(lodge, 0.0128635885), (room, 0.010961346), (...   \n",
       "935  [(university, 0.028282506), (fraternity, 0.020...   \n",
       "936  [(round, 0.06713945), (tank, 0.05598681), (inc...   \n",
       "937  [(design, 0.06252057), (world, 0.016239975), (...   \n",
       "938  [(movie, 0.08433947), (police, 0.08109556), (h...   \n",
       "939  [(life, 0.026308596), (said, 0.02592103), (rob...   \n",
       "940  [(weinstein, 0.09471097), (exactly, 0.06987897...   \n",
       "941  [(cooky, 0.08858229), (privacy, 0.063245036), ...   \n",
       "942  [(merkel, 0.024225906), (party, 0.022733122), ...   \n",
       "\n",
       "                                      PREDICT_KEYWORDS  \\\n",
       "0    [bar, energy, saturated, fat, sugar, others, c...   \n",
       "1    [unfolds, find, tamagotchi, happening, messeng...   \n",
       "2    [trailer, war, star, rey, new, jedi, monday, n...   \n",
       "3    [harris, scent, perfumer, art, perfume, one, c...   \n",
       "4    [said, incident, ghana, gas, addo, ensure, sev...   \n",
       "5    [catalonia, independence, said, spain, catalan...   \n",
       "6    [iq, tillerson, trump, joke, president, know, ...   \n",
       "7    [kellogg, power, air, said, child, asthma, yea...   \n",
       "8    [trump, said, president, rico, puerto, reality...   \n",
       "9    [temple, yamadera, station, hall, japan, rissh...   \n",
       "10   [tompkins, doug, kris, chile, national, south,...   \n",
       "11   [parent, said, burnout, mom, need, time, day, ...   \n",
       "12   [alcohol, drink, said, study, advertising, und...   \n",
       "13   [said, kid, parent, child, tantrum, going, go,...   \n",
       "14   [trump, ivanka, immigration, issue, program, a...   \n",
       "15   [sex, partner, desire, men, one, interest, due...   \n",
       "16   [park, jay, said, asia, seattle, music, pop, b...   \n",
       "17   [plywood, material, wilk, veneer, world, say, ...   \n",
       "18   [test, hiv, study, grindr, kit, men, risk, get...   \n",
       "19   [generation, time, millennials, year, diprete,...   \n",
       "20   [donna, weinstein, karan, remark, scandal, pla...   \n",
       "21   [zakaria, germany, said, country, memorial, am...   \n",
       "22   [said, company, people, paperless, post, techn...   \n",
       "23   [calorie, cheese, ounce, nutrient, one, choles...   \n",
       "24   [climate, degree, book, change, lynas, world, ...   \n",
       "25   [charm, james, avery, whataburger, release, on...   \n",
       "26   [planned, parenthood, video, daleiden, fetus, ...   \n",
       "27   [rover, mar, curiosity, hide, caption, photo, ...   \n",
       "28   [lego, house, denmark, skill, four, brick, cre...   \n",
       "29   [working, white, class, said, economy, feel, c...   \n",
       "..                                                 ...   \n",
       "913  [abdul, queen, movie, victoria, dench, story, ...   \n",
       "914  [transcript, page, note, continually, become, ...   \n",
       "915  [aunt, black, playboy, woman, jennifer, revolu...   \n",
       "916  [farm, investor, cow, south, stock, africa, li...   \n",
       "917  [van, gas, kid, one, said, omaha, get, crook, ...   \n",
       "918  [sapelo, pea, island, red, crop, year, residen...   \n",
       "919  [fever, defect, said, ion, channel, pregnancy,...   \n",
       "920  [cancer, charity, say, four, fund, cnn, patien...   \n",
       "921  [weinstein, allegation, new, told, said, story...   \n",
       "922  [va, new, los, veteran, wait, cnn, time, patie...   \n",
       "923  [cooky, policy, browse, continuing, privacy, u...   \n",
       "924  [mother, home, would, father, day, nursing, to...   \n",
       "925  [snow, say, trafficking, game, trafficker, sex...   \n",
       "926  [trump, tillerson, said, iq, comment, presiden...   \n",
       "927  [independence, catalonia, catalan, spain, woul...   \n",
       "928  [love, thornton, husband, chris, life, new, tw...   \n",
       "929  [arrested, suspicion, rape, nelly, attorney, n...   \n",
       "930  [said, disease, vallabh, family, prion, one, b...   \n",
       "931  [fair, fried, food, geary, say, dog, recipe, s...   \n",
       "932  [karan, woman, weinstein, donna, said, comment...   \n",
       "933  [trump, read, clinton, president, cnn, first, ...   \n",
       "934  [lodge, room, hotel, lake, spa, inn, fireplace...   \n",
       "935  [university, fraternity, hazing, say, burch, d...   \n",
       "936  [round, tank, incendiary, fuel, source, fired,...   \n",
       "937  [design, world, thing, designer, may, consumer...   \n",
       "938  [movie, police, happening, chat, take, messeng...   \n",
       "939  [life, said, rob, skier, danelle, photo, husba...   \n",
       "940  [weinstein, exactly, reporter, claim, sexually...   \n",
       "941  [cooky, privacy, local, revised, browse, term,...   \n",
       "942  [merkel, party, limit, position, germany, refu...   \n",
       "\n",
       "                                               HASHTAG  \n",
       "0    #bar #energy #saturated #fat #sugar #others #c...  \n",
       "1    #unfolds #find #tamagotchi #happening #messeng...  \n",
       "2    #trailer #war #star #rey #new #jedi #monday #n...  \n",
       "3    #harris #scent #perfumer #art #perfume #one #c...  \n",
       "4    #said #incident #ghana #gas #addo #ensure #sev...  \n",
       "5    #catalonia #independence #said #spain #catalan...  \n",
       "6    #iq #tillerson #trump #joke #president #know #...  \n",
       "7    #kellogg #power #air #said #child #asthma #yea...  \n",
       "8    #trump #said #president #rico #puerto #reality...  \n",
       "9    #temple #yamadera #station #hall #japan #rissh...  \n",
       "10   #tompkins #doug #kris #chile #national #south ...  \n",
       "11   #parent #said #burnout #mom #need #time #day #...  \n",
       "12   #alcohol #drink #said #study #advertising #und...  \n",
       "13   #said #kid #parent #child #tantrum #going #go ...  \n",
       "14   #trump #ivanka #immigration #issue #program #a...  \n",
       "15   #sex #partner #desire #men #one #interest #due...  \n",
       "16   #park #jay #said #asia #seattle #music #pop #b...  \n",
       "17   #plywood #material #wilk #veneer #world #say #...  \n",
       "18   #test #hiv #study #grindr #kit #men #risk #get...  \n",
       "19   #generation #time #millennials #year #diprete ...  \n",
       "20   #donna #weinstein #karan #remark #scandal #pla...  \n",
       "21   #zakaria #germany #said #country #memorial #am...  \n",
       "22   #said #company #people #paperless #post #techn...  \n",
       "23   #calorie #cheese #ounce #nutrient #one #choles...  \n",
       "24   #climate #degree #book #change #lynas #world #...  \n",
       "25   #charm #james #avery #whataburger #release #on...  \n",
       "26   #planned #parenthood #video #daleiden #fetus #...  \n",
       "27   #rover #mar #curiosity #hide #caption #photo #...  \n",
       "28   #lego #house #denmark #skill #four #brick #cre...  \n",
       "29   #working #white #class #said #economy #feel #c...  \n",
       "..                                                 ...  \n",
       "913  #abdul #queen #movie #victoria #dench #story #...  \n",
       "914  #transcript #page #note #continually #become #...  \n",
       "915  #aunt #black #playboy #woman #jennifer #revolu...  \n",
       "916  #farm #investor #cow #south #stock #africa #li...  \n",
       "917  #van #gas #kid #one #said #omaha #get #crook #...  \n",
       "918  #sapelo #pea #island #red #crop #year #residen...  \n",
       "919  #fever #defect #said #ion #channel #pregnancy ...  \n",
       "920  #cancer #charity #say #four #fund #cnn #patien...  \n",
       "921  #weinstein #allegation #new #told #said #story...  \n",
       "922  #va #new #los #veteran #wait #cnn #time #patie...  \n",
       "923  #cooky #policy #browse #continuing #privacy #u...  \n",
       "924  #mother #home #would #father #day #nursing #to...  \n",
       "925  #snow #say #trafficking #game #trafficker #sex...  \n",
       "926  #trump #tillerson #said #iq #comment #presiden...  \n",
       "927  #independence #catalonia #catalan #spain #woul...  \n",
       "928  #love #thornton #husband #chris #life #new #tw...  \n",
       "929  #arrested #suspicion #rape #nelly #attorney #n...  \n",
       "930  #said #disease #vallabh #family #prion #one #b...  \n",
       "931  #fair #fried #food #geary #say #dog #recipe #s...  \n",
       "932  #karan #woman #weinstein #donna #said #comment...  \n",
       "933  #trump #read #clinton #president #cnn #first #...  \n",
       "934  #lodge #room #hotel #lake #spa #inn #fireplace...  \n",
       "935  #university #fraternity #hazing #say #burch #d...  \n",
       "936  #round #tank #incendiary #fuel #source #fired ...  \n",
       "937  #design #world #thing #designer #may #consumer...  \n",
       "938  #movie #police #happening #chat #take #messeng...  \n",
       "939  #life #said #rob #skier #danelle #photo #husba...  \n",
       "940  #weinstein #exactly #reporter #claim #sexually...  \n",
       "941  #cooky #privacy #local #revised #browse #term ...  \n",
       "942  #merkel #party #limit #position #germany #refu...  \n",
       "\n",
       "[943 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. LDA 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:09,461 : INFO : -6.437 per-word bound, 86.7 perplexity estimate based on a held-out corpus of 5 documents with 845 words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-6.4372718650208425"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.log_perplexity(corpus) # Perplexity는 낮을 수록 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda, texts=alltext, dictionary=dictionary) # Coherence Model는 높을 수록 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-29 00:47:09,725 : INFO : using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2019-10-29 00:47:10,546 : INFO : 1 batches submitted to accumulate stats from 64 documents (300 virtual)\n",
      "2019-10-29 00:47:13,473 : INFO : 3 accumulators retrieved from output queue\n",
      "2019-10-29 00:47:13,489 : INFO : accumulated word occurrence stats for 300 virtual documents\n"
     ]
    }
   ],
   "source": [
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4777908195146071\n"
     ]
    }
   ],
   "source": [
    "print(coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
